<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Pebblous Data Communication Team">
    <meta name="language" content="Korean">
    <meta name="robots" content="index, follow">
    <meta name="revisit-after" content="7 days">

    <title>차세대 AI를 위한 세 가지 월드 모델 비교: Jeff Hawkins, Yann LeCun, Fei-Fei Li | 페블러스</title>
    <meta name="description" content="Jeff Hawkins의 천 개의 뇌 이론, Yann LeCun의 JEPA, Fei-Fei Li의 공간 지능을 비교 분석합니다. LLM의 한계를 넘어 물리적 세계를 이해하는 차세대 AI 월드 모델의 방향성을 제시합니다.">
    <meta name="keywords" content="월드 모델, World Model, Jeff Hawkins, Yann LeCun, Fei-Fei Li, 천 개의 뇌 이론, Thousand Brains Theory, JEPA, Joint Embedding Predictive Architecture, 공간 지능, Spatial Intelligence, World Labs, Numenta, Meta AI, 피질 기둥, Cortical Column, 참조 프레임, Reference Frame, SDR, 희소 분산 표현, Marble, RTFM, 로보틱스, Robotics, AGI, 인공일반지능, LLM 한계, 생성형 AI, Generative AI, 디지털 트윈, 물리적 AI, Physical AI, 페블러스, Pebblous, 에너지 기반 모델, EBM, 감각운동 통합, 예측 코딩, Predictive Coding">

    <link rel="canonical" href="https://blog.pebblous.ai/project/World%20Model/world-model-comparison.html">
    <link rel="alternate" hreflang="ko" href="https://blog.pebblous.ai/project/World%20Model/world-model-comparison.html">
    <link rel="alternate" hreflang="x-default" href="https://blog.pebblous.ai/project/World%20Model/world-model-comparison.html">

    <!-- Open Graph -->
    <meta property="og:title" content="차세대 AI를 위한 세 가지 월드 모델 비교: Jeff Hawkins, Yann LeCun, Fei-Fei Li">
    <meta property="og:description" content="천 개의 뇌 이론, JEPA, 공간 지능을 비교 분석하여 LLM을 넘어선 차세대 AI 월드 모델의 방향성을 제시합니다.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://blog.pebblous.ai/project/World%20Model/world-model-comparison.html">
    <meta property="og:image" content="https://blog.pebblous.ai/project/World%20Model/image/world-model-comparison.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:site_name" content="Pebblous Blog">
    <meta property="og:locale" content="ko_KR">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="차세대 AI를 위한 세 가지 월드 모델 비교">
    <meta name="twitter:description" content="Jeff Hawkins, Yann LeCun, Fei-Fei Li의 월드 모델 이론 비교 분석">
    <meta name="twitter:image" content="https://blog.pebblous.ai/project/World%20Model/image/world-model-comparison.png">

    <!-- Favicon -->
    <link rel="icon" href="/image/favicon.ico" sizes="any">
    <link rel="icon" href="/image/Pebblous_BM_Orange_RGB.png" type="image/png">

    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-57L9F58B');</script>

    <!-- JSON-LD: Article -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": "차세대 AI를 위한 세 가지 월드 모델 비교: Jeff Hawkins, Yann LeCun, Fei-Fei Li",
        "description": "Jeff Hawkins의 천 개의 뇌 이론, Yann LeCun의 JEPA, Fei-Fei Li의 공간 지능을 비교 분석합니다. LLM의 한계를 넘어 물리적 세계를 이해하는 차세대 AI 월드 모델의 방향성을 제시합니다.",
        "url": "https://blog.pebblous.ai/project/World%20Model/world-model-comparison.html",
        "datePublished": "2026-01-02",
        "dateModified": "2026-01-12",
        "author": {
            "@type": "Organization",
            "name": "Pebblous",
            "url": "https://www.pebblous.ai"
        },
        "publisher": {
            "@type": "Organization",
            "name": "Pebblous",
            "logo": {
                "@type": "ImageObject",
                "url": "https://www.pebblous.ai/image/Pebblous_BM_Orange_RGB.png"
            }
        }
    }
    </script>

    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap" rel="stylesheet">

    <!-- Common Styles -->
    <link rel="stylesheet" href="/styles/common-styles.css?v=20260107">

    <style>
        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f8fafc;
            --bg-card: rgba(255, 255, 255, 0.95);
            --text-primary: #0f172a;
            --text-secondary: #334155;
            --text-muted: #64748b;
            --accent-color: #F86825;
            --teal-color: #0d9488;
            --border-color: #e2e8f0;
        }

        [data-theme="dark"] {
            --bg-primary: #0f172a;
            --bg-secondary: #1e293b;
            --bg-card: rgba(30, 41, 59, 0.95);
            --text-primary: #f1f5f9;
            --text-secondary: #cbd5e1;
            --text-muted: #94a3b8;
            --accent-color: #F86825;
            --teal-color: #14b8a6;
            --border-color: #334155;
        }

        [data-theme="beige"] {
            --bg-primary: #f5f1e8;
            --bg-secondary: #ebe3d5;
            --bg-card: rgba(245, 241, 232, 0.95);
            --text-primary: #2d2a26;
            --text-secondary: #5a534a;
            --text-muted: #78716c;
            --accent-color: #F86825;
            --teal-color: #0d9488;
            --border-color: #d6cec0;
        }

        body {
            font-family: 'Noto Sans KR', sans-serif;
            font-size: 18px;
            letter-spacing: -0.01em;
            background-color: var(--bg-primary);
            color: var(--text-primary);
            transition: background-color 0.3s ease, color 0.3s ease;
            scroll-behavior: smooth;
        }

        /* Share Button Styles */
        .share-container {
            display: flex;
            gap: 1rem;
            align-items: center;
            justify-content: center;
            flex-wrap: wrap;
        }

        .share-label {
            font-size: 0.875rem;
            color: #94a3b8;
            font-weight: 500;
        }

        .share-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.375rem;
            padding: 0;
            background: none;
            border: none;
            color: #64748b;
            cursor: pointer;
            transition: color 0.2s;
            font-size: 0.875rem;
            text-decoration: none;
        }

        .share-btn:hover {
            color: #F86825;
        }

        .share-btn svg {
            width: 1.25rem;
            height: 1.25rem;
        }

        /* Typography enhancements for academic content */
        main p {
            line-height: 1.85;
            margin-bottom: 1.25rem;
        }

        main h3 {
            margin-top: 2.5rem;
        }

        main h4 {
            margin-top: 2rem;
        }

        main ul, main ol {
            margin-bottom: 1.25rem;
        }

        main li {
            margin-bottom: 0.5rem;
            line-height: 1.75;
        }

        /* Table Styles */
        main table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            font-size: 0.95rem;
        }

        main table th {
            background-color: var(--bg-secondary);
            font-weight: 600;
            text-align: left;
            padding: 0.75rem 1rem;
            border: 1px solid var(--border-color);
        }

        main table td {
            padding: 0.75rem 1rem;
            border: 1px solid var(--border-color);
            vertical-align: top;
        }

        main table tbody tr:hover {
            background-color: rgba(248, 104, 37, 0.05);
        }

        /* Blockquote */
        main blockquote {
            border-left: 4px solid var(--accent-color);
            padding-left: 1.5rem;
            margin: 1.5rem 0;
            font-style: italic;
            color: var(--text-secondary);
        }

        /* Reference links */
        .ref-link {
            color: var(--teal-color);
            text-decoration: none;
            font-weight: 500;
        }

        .ref-link:hover {
            text-decoration: underline;
        }

        /* Scholar Cards */
        .scholar-card {
            background: var(--bg-card);
            border: 1px solid var(--border-color);
            border-radius: 0.75rem;
            padding: 1.5rem;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
        }

        .scholar-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 4px;
            height: 100%;
            transition: background 0.3s;
        }

        .scholar-card.hawkins::before { background: linear-gradient(180deg, #f97316, #ea580c); }
        .scholar-card.lecun::before { background: linear-gradient(180deg, #0d9488, #0f766e); }
        .scholar-card.feifei::before { background: linear-gradient(180deg, #8b5cf6, #7c3aed); }

        .scholar-card:hover {
            transform: translateY(-4px);
            box-shadow: 0 12px 24px rgba(0, 0, 0, 0.1);
        }

        /* Key Concept Box */
        .key-concept-box {
            background: var(--bg-secondary);
            border-left: 4px solid var(--teal-color);
            border-radius: 0 0.5rem 0.5rem 0;
            padding: 1.25rem 1.5rem;
            margin: 1.5rem 0;
        }

        .key-concept-box.orange {
            border-left-color: var(--accent-color);
        }

        .key-concept-box.purple {
            border-left-color: #8b5cf6;
        }

        /* Process Flow Cards */
        .process-flow {
            display: flex;
            flex-direction: column;
            gap: 1rem;
            margin: 1.5rem 0;
        }

        @media (min-width: 768px) {
            .process-flow {
                flex-direction: row;
            }
        }

        .process-step {
            flex: 1;
            background: var(--bg-card);
            border: 1px solid var(--border-color);
            border-radius: 0.5rem;
            padding: 1rem;
            position: relative;
            text-align: center;
        }

        .process-step .step-number {
            position: absolute;
            top: -0.75rem;
            left: 50%;
            transform: translateX(-50%);
            width: 1.5rem;
            height: 1.5rem;
            background: var(--teal-color);
            color: white;
            border-radius: 50%;
            font-size: 0.75rem;
            font-weight: 700;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .process-step .step-title {
            font-weight: 600;
            margin-bottom: 0.5rem;
            color: var(--text-primary);
        }

        .process-step .step-desc {
            font-size: 0.875rem;
            color: var(--text-secondary);
        }

        /* Fusion Diagram */
        .fusion-diagram {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 1rem;
            margin: 1.5rem 0;
        }

        @media (max-width: 767px) {
            .fusion-diagram {
                grid-template-columns: 1fr;
            }
        }

        .fusion-item {
            background: var(--bg-card);
            border: 2px solid var(--border-color);
            border-radius: 0.75rem;
            padding: 1.5rem;
            text-align: center;
            transition: all 0.3s;
        }

        .fusion-item:hover {
            border-color: var(--accent-color);
        }

        .fusion-item .fusion-icon {
            font-size: 2rem;
            margin-bottom: 0.75rem;
        }

        .fusion-item .fusion-label {
            font-size: 0.75rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            margin-bottom: 0.25rem;
        }

        .fusion-item .fusion-title {
            font-weight: 700;
            font-size: 1.125rem;
            color: var(--text-primary);
            margin-bottom: 0.5rem;
        }

        .fusion-item .fusion-author {
            font-size: 0.875rem;
            color: var(--teal-color);
        }
    </style>
</head>

<body>
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-57L9F58B"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <!-- Header Placeholder -->
    <div id="header-placeholder"></div>

    <!-- Main Content -->
    <div class="container mx-auto px-4 sm:px-6 lg:px-8 py-8 md:py-12 max-w-[1400px]">
        <div class="lg:flex lg:gap-8 lg:justify-center lg:items-start">

            <!-- TOC Sidebar -->
            <nav class="hidden lg:block lg:w-[240px] lg:shrink-0 sticky top-20 self-start">
                <h3 class="font-bold themeable-heading mb-4 text-lg">목차</h3>
                <ul id="toc-links" class="space-y-3 text-sm border-l-2 themeable-toc-border">
                    <li class="pl-4 hover:text-orange-500 transition-colors">
                        <a href="#intro" class="themeable-text-secondary hover:text-orange-500">1. 서론: 언어를 넘어 세계로</a>
                    </li>
                    <li class="pl-4 hover:text-orange-500 transition-colors">
                        <a href="#hawkins" class="themeable-text-secondary hover:text-orange-500">2. Jeff Hawkins: 천 개의 뇌 이론</a>
                    </li>
                    <li class="pl-4 hover:text-orange-500 transition-colors">
                        <a href="#lecun" class="themeable-text-secondary hover:text-orange-500">3. Yann LeCun: JEPA</a>
                    </li>
                    <li class="pl-4 hover:text-orange-500 transition-colors">
                        <a href="#feifei" class="themeable-text-secondary hover:text-orange-500">4. Fei-Fei Li: 공간 지능</a>
                    </li>
                    <li class="pl-4 hover:text-orange-500 transition-colors">
                        <a href="#comparison" class="themeable-text-secondary hover:text-orange-500">5. 비교 분석</a>
                    </li>
                    <li class="pl-4 hover:text-orange-500 transition-colors">
                        <a href="#conclusion" class="themeable-text-secondary hover:text-orange-500">6. 결론: 월드 모델의 미래</a>
                    </li>
                    <li class="pl-4 hover:text-orange-500 transition-colors">
                        <a href="#faq" class="themeable-text-secondary hover:text-orange-500">FAQ</a>
                    </li>
                    <li class="pl-4 hover:text-orange-500 transition-colors">
                        <a href="#references" class="themeable-text-secondary hover:text-orange-500">참고문헌</a>
                    </li>
                    <li class="pl-4 hover:text-orange-500 transition-colors">
                        <a href="#pdf-download" class="themeable-text-secondary hover:text-orange-500">PDF 다운로드</a>
                    </li>
                </ul>
            </nav>

            <!-- Main Article -->
            <main class="max-w-[700px] px-4 sm:px-6">
                <!-- Hero Section -->
                <header class="text-left mb-16">
                    <h1 id="page-h1-title" class="text-4xl md:text-5xl font-bold themeable-heading mb-6 leading-tight" style="line-height: 1.4;">
                        <!-- PebblousPage.applyConfig()가 자동으로 채움 -->
                    </h1>

                    <div class="flex items-center gap-4 text-sm themeable-muted mb-4">
                        <span id="publish-date"></span>
                        <span>•</span>
                        <span id="publisher"></span>
                        <span>•</span>
                        <span id="reading-time">읽는 시간: 약 20분</span>
                    </div>

                    <div id="share-buttons-placeholder" class="mb-8"></div>
                </header>

                <!-- Section 1: Introduction -->
                <section id="intro" class="mb-12">
                    <h2 class="text-3xl font-bold themeable-heading mb-6 pb-3 border-b-2 themeable-border">
                        1. 서론: 언어를 넘어 세계로의 확장
                    </h2>

                    <p class="themeable-text leading-relaxed">
                        인공지능(AI) 기술은 지난 10년간 심층 신경망(Deep Neural Networks), 특히 대규모 언어 모델(Large Language Models, LLMs)의 비약적인 발전을 통해 인류 지성사에 유례없는 변곡점을 맞이했다. OpenAI의 ChatGPT 시리즈로 대표되는 생성형 AI는 텍스트를 이해하고 생성하는 능력에서 인간에 근접하거나 능가하는 성능을 보여주었다. 그러나 이러한 언어 중심의 AI가 가진 근본적인 한계 또한 명확해지고 있다. <strong>텍스트는 세계를 설명하는 상징(Symbol)일 뿐, 물리적 세계(Physical World) 그 자체는 아니다</strong>. LLM은 방대한 텍스트 데이터의 통계적 상관관계를 학습하여 다음에 올 단어를 예측하는 데 탁월하지만, "왜" 그런 일이 일어나는지에 대한 인과적 추론(Causal Inference)이나, 자신의 행동이 물리적 환경에 어떤 결과를 초래할지에 대한 공간적 이해(Spatial Understanding)는 결여되어 있다. 이른바 "환각(Hallucination)" 현상은 AI가 현실 세계의 법칙에 기반하지 않고 확률적 그럴듯함에 의존하기 때문에 발생하는 필연적인 부작용이다 <a href="#ref-1" class="ref-link">[1]</a>.
                    </p>

                    <p class="themeable-text leading-relaxed">
                        이러한 배경에서 AI 연구의 최전선은 이제 '언어 모델'에서 '<strong>월드 모델(World Model)</strong>'로 급격히 이동하고 있다. 월드 모델이란 에이전트(인간 또는 기계)가 외부 환경의 구조와 작동 원리를 내부적으로 시뮬레이션하여, 행동의 결과를 예측하고 계획을 수립할 수 있게 하는 인지적 프레임워크를 의미한다. 이는 단순히 데이터를 분류하거나 생성하는 것을 넘어, 지능의 본질인 '이해(Understanding)'와 '생존(Survival)'을 가능케 하는 핵심 기제다.
                    </p>

                    <p class="themeable-text leading-relaxed">
                        본 보고서는 월드 모델 연구를 주도하는 세 명의 세계적 석학, <strong>Jeff Hawkins</strong> (Numenta), <strong>Yann LeCun</strong> (Meta), <strong>Fei-Fei Li</strong> (World Labs)의 이론과 기술적 접근 방식을 심층적으로 분석한다. Jeff Hawkins는 뇌과학적 사실에 입각하여 인간의 신피질(Neocortex)이 세계를 모델링하는 메커니즘을 역공학(Reverse Engineering)한다. Yann LeCun은 현재의 생성형 AI가 가진 비효율성을 비판하며, 추상적 표현 공간(Representation Space)에서의 예측과 계획을 강조하는 인지 아키텍처를 제안한다. Fei-Fei Li는 시각적 인식을 넘어 3차원 공간을 구축하고 조작할 수 있는 '공간 지능(Spatial Intelligence)'을 통해 디지털과 물리적 세계의 융합을 시도한다.
                    </p>

                    <p class="themeable-text leading-relaxed">
                        이 세 가지 관점은 상충하는 듯 보이지만, 실상은 일반 인공지능(Artificial General Intelligence, AGI)이라는 거대한 목표를 향해 서로 다른 층위(Layer)에서 해답을 제시하고 있다. 본 보고서는 이들의 이론적 배경, 아키텍처의 기술적 세부 사항, 그리고 각 모델이 제시하는 미래 AI의 청사진을 면밀히 비교 분석함으로써, 차세대 AI가 나아가야 할 방향성을 제시하고자 한다.
                    </p>

                    <!-- Three Scholars Cards -->
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mt-8">
                        <div class="scholar-card hawkins">
                            <h4 class="font-bold themeable-heading text-lg mb-2">Jeff Hawkins</h4>
                            <p class="text-sm text-orange-500 font-medium mb-2">Numenta 창립자</p>
                            <p class="text-sm themeable-text-secondary">뇌과학 기반 <strong>천 개의 뇌 이론</strong>으로 신피질의 작동 원리를 역공학하여 AGI의 구조적 토대를 제시</p>
                        </div>
                        <div class="scholar-card lecun">
                            <h4 class="font-bold themeable-heading text-lg mb-2">Yann LeCun</h4>
                            <p class="text-sm text-teal-500 font-medium mb-2">Meta 수석 AI 과학자</p>
                            <p class="text-sm themeable-text-secondary">추상적 표현 공간에서의 예측을 강조하는 <strong>JEPA</strong>로 효율적인 추론과 계획 능력 구현</p>
                        </div>
                        <div class="scholar-card feifei">
                            <h4 class="font-bold themeable-heading text-lg mb-2">Fei-Fei Li</h4>
                            <p class="text-sm text-purple-500 font-medium mb-2">World Labs 창립자</p>
                            <p class="text-sm themeable-text-secondary">3D 공간 이해와 생성을 통한 <strong>공간 지능</strong>으로 디지털-물리 세계 융합 추진</p>
                        </div>
                    </div>
                </section>

                <!-- Section 2: Jeff Hawkins -->
                <section id="hawkins" class="mb-12">
                    <h2 class="text-3xl font-bold themeable-heading mb-6 pb-3 border-b-2 themeable-border">
                        2. Jeff Hawkins와 Numenta: 생물학적 실재론과 천 개의 뇌 이론
                    </h2>

                    <!-- Key Concept Box -->
                    <div class="key-concept-box orange">
                        <p class="font-semibold themeable-heading mb-1">핵심 개념: 천 개의 뇌 이론</p>
                        <p class="text-sm themeable-text-secondary">뇌는 단일한 계층적 처리 시스템이 아니라, <strong>15만 개의 독립적인 피질 기둥</strong>이 각자 세계 모델을 형성하고 '투표'를 통해 합의에 도달하는 분산 시스템이다. 모든 정보는 <strong>참조 프레임(좌표계)</strong>을 통해 저장되며, 이는 물리적 객체뿐 아니라 추상적 개념에도 적용된다.</p>
                    </div>

                    <p class="themeable-text leading-relaxed">
                        Jeff Hawkins는 팜(Palm) 컴퓨팅의 창업자로 유명하지만, 그의 진정한 열정은 지난 수십 년간 뇌의 작동 원리를 규명하고 이를 기반으로 진정한 지능을 구현하는 데 있었다. 그가 이끄는 <strong>Numenta</strong>는 신경과학적 발견을 수학적 알고리즘으로 변환하는 연구를 지속해왔으며, 이는 '<strong>천 개의 뇌 이론(Thousand Brains Theory)</strong>'으로 집대성되었다.
                    </p>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">2.1 천 개의 뇌 이론 (The Thousand Brains Theory)의 핵심</h3>

                    <p class="themeable-text leading-relaxed">
                        기존의 신경과학과 AI 이론은 뇌가 감각 입력을 계층적으로 처리하여 최상위 계층에서 단일한 객체 모델을 형성한다고 가정했다. 즉, 시각 정보가 V1, V2, V4 등을 거쳐 IT(Inferior Temporal) 피질에 도달해서야 '컵'이라는 객체를 인식한다는 것이다. 그러나 Hawkins는 이러한 계층적 통합설을 부정하고, <strong>분산된 모델링(Distributed Modeling)</strong> 가설을 제시한다 <a href="#ref-3" class="ref-link">[3]</a>.
                    </p>

                    <h4 class="text-xl font-semibold themeable-heading mt-6 mb-3">2.1.1 피질 기둥 (Cortical Column)의 독립성</h4>

                    <p class="themeable-text leading-relaxed">
                        Hawkins의 이론에 따르면, 신피질을 구성하는 약 15만 개의 <strong>피질 기둥(Cortical Columns)</strong> 각각은 완전한 감각운동 모델링 시스템이다. 뇌의 특정 영역만이 모델링을 담당하는 것이 아니라, 모든 피질 기둥이 각자 독립적으로 입력된 감각 정보를 바탕으로 세계에 대한 모델을 학습한다. 예를 들어, 커피잔을 잡고 있는 다섯 손가락은 각각 서로 다른 감각 입력을 받지만, 각 손가락에 연결된 피질 기둥들은 독자적으로 "이것은 커피잔이다"라는 모델을 형성하려고 시도한다 <a href="#ref-5" class="ref-link">[5]</a>.
                    </p>

                    <h4 class="text-xl font-semibold themeable-heading mt-6 mb-3">2.1.2 투표 메커니즘 (Voting Mechanism)과 바인딩 문제의 해결</h4>

                    <p class="themeable-text leading-relaxed">
                        그렇다면 수만 개의 독립된 모델이 어떻게 하나의 통일된 지각(Perception)을 형성하는가? Hawkins는 이를 '<strong>투표(Voting)</strong>'로 설명한다. 피질 기둥들은 신피질의 장거리 신경 연결(Long-range connections)을 통해 서로 정보를 교환한다.
                    </p>

                    <!-- Voting Mechanism Flow -->
                    <div class="process-flow mt-6">
                        <div class="process-step">
                            <span class="step-number">1</span>
                            <p class="step-title mt-2">감각 입력</p>
                            <p class="step-desc">검지: "매끄러운 곡면"<br>엄지: "손잡이"</p>
                        </div>
                        <div class="process-step">
                            <span class="step-number">2</span>
                            <p class="step-title mt-2">개별 판단</p>
                            <p class="step-desc">검지 기둥: 컵? 공? 사과?<br>엄지 기둥: 컵? 주전자?</p>
                        </div>
                        <div class="process-step">
                            <span class="step-number">3</span>
                            <p class="step-title mt-2">투표 & 합의</p>
                            <p class="step-desc">공통 분모 = <strong>"컵"</strong><br>→ 통일된 지각 형성</p>
                        </div>
                    </div>

                    <p class="themeable-text leading-relaxed">
                        위 과정처럼 각 피질 기둥은 독자적으로 판단한 후, 장거리 신경 연결을 통해 정보를 교환하고 합의에 도달한다 <a href="#ref-6" class="ref-link">[6]</a>.
                    </p>

                    <p class="themeable-text leading-relaxed">
                        이러한 방식은 뇌가 손상되거나 노이즈가 많은 환경에서도 강건하게 작동할 수 있는 이유를 설명한다. 일부 기둥이 손상되어도 나머지 기둥들의 투표를 통해 정확한 인식이 가능하기 때문이다.
                    </p>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">2.2 참조 프레임 (Reference Frames): 지능의 좌표계</h3>

                    <p class="themeable-text leading-relaxed">
                        Hawkins 이론의 가장 혁신적인 부분은 뇌가 정보를 저장하고 처리하는 기본 형식이 '<strong>참조 프레임(Reference Frame)</strong>'이라는 발견이다. 그는 뇌의 '격자 세포(Grid Cells)'와 '장소 세포(Place Cells)'가 해마뿐만 아니라 신피질 전체에 존재한다고 주장한다 <a href="#ref-8" class="ref-link">[8]</a>.
                    </p>

                    <h4 class="text-xl font-semibold themeable-heading mt-6 mb-3">2.2.1 객체 중심 좌표계 (Allocentric Representation)</h4>

                    <p class="themeable-text leading-relaxed">
                        우리가 방 안에서 움직여도 방의 구조가 바뀌지 않는 것처럼, 뇌는 관찰자(자아) 중심이 아닌 <strong>객체 중심(Allocentric)</strong>의 좌표계를 사용하여 대상을 모델링한다.
                    </p>

                    <ul class="list-disc pl-6 themeable-text-secondary mb-6">
                        <li><strong>What (특징):</strong> 감각 기관이 느끼는 특징(Feature).</li>
                        <li><strong>Where (위치):</strong> 그 특징이 객체의 참조 프레임 내에서 어디에 위치하는지(Relative Location).</li>
                    </ul>

                    <p class="themeable-text leading-relaxed">
                        피질 기둥의 L4(Layer 4) 층은 감각 입력을 받고, L6(Layer 6) 층은 현재 센서의 위치 정보를 처리한다. 이 두 정보가 결합하여 "이 객체의 이 위치에 이러한 특징이 있다"라는 지식이 형성된다 <a href="#ref-8" class="ref-link">[8]</a>. 이는 기존의 딥러닝이 픽셀 패턴(Texture) 위주로 학습하는 것과 달리, 뇌는 철저히 <strong>구조(Structure)와 기하학(Geometry)</strong>을 학습한다는 것을 시사한다.
                    </p>

                    <h4 class="text-xl font-semibold themeable-heading mt-6 mb-3">2.2.2 추상적 사고로의 확장</h4>

                    <p class="themeable-text leading-relaxed">
                        Hawkins는 이러한 참조 프레임 메커니즘이 물리적 객체뿐만 아니라 수학, 언어, 정치와 같은 <strong>추상적 개념(Abstract Concepts)</strong>을 이해하는 데에도 동일하게 적용된다고 주장한다. 민주주의라는 개념도 뇌 속에서는 관련된 하위 개념들이 특정한 논리적 '위치'와 '관계'를 맺고 있는 구조물로 저장된다는 것이다 <a href="#ref-3" class="ref-link">[3]</a>.
                    </p>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">2.3 감각운동 통합 (Sensorimotor Integration)과 학습</h3>

                    <p class="themeable-text leading-relaxed">
                        Hawkins는 "<em>생각하는 행위 자체가 움직임의 한 형태</em>"라고 말한다. 우리는 가만히 대상을 바라보는 것이 아니라, 눈을 움직이고(Saccade), 손으로 만지며 정보를 수집한다 <a href="#ref-4" class="ref-link">[4]</a>.
                    </p>

                    <ul class="list-disc pl-6 themeable-text-secondary mb-6">
                        <li><strong>예측(Prediction):</strong> 뇌는 끊임없이 다음 감각 입력을 예측한다. "내가 손가락을 오른쪽으로 움직이면, 컵의 손잡이가 느껴질 것이다"라는 예측이 맞으면 모델이 강화되고, 틀리면 수정된다(Predictive Coding) <a href="#ref-6" class="ref-link">[6]</a>.</li>
                        <li><strong>행동(Action):</strong> 따라서 행동은 학습과 분리될 수 없다. Hawkins의 모델에서 지능은 본질적으로 <strong>구체화(Embodied)</strong>되어 있으며, 감각과 운동 시스템은 하나의 루프(Loop)로 통합되어 있다 <a href="#ref-5" class="ref-link">[5]</a>.</li>
                    </ul>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">2.4 희소 분산 표현 (Sparse Distributed Representations, SDR)</h3>

                    <p class="themeable-text leading-relaxed">
                        Numenta 기술의 기저에는 <strong>SDR</strong>이라는 데이터 구조가 있다. 이는 뇌의 뉴런이 매우 희소하게(Sparsely) 활성화되는 것을 모방한 것이다. 2,048개의 비트 중 약 2%(40개)만이 1이 되고 나머지는 0이 되는 식이다 <a href="#ref-11" class="ref-link">[11]</a>.
                    </p>

                    <ul class="list-disc pl-6 themeable-text-secondary mb-6">
                        <li><strong>의미론적 내포:</strong> SDR의 각 비트는 의미를 가진다. 두 SDR이 겹치는 비트가 많을수록 의미적으로 유사하다.</li>
                        <li><strong>강건성:</strong> 40개의 활성 비트 중 절반이 노이즈로 인해 사라져도, 나머지 20개를 통해 전체 패턴을 유추할 수 있다. 이는 생물학적 뇌의 놀라운 노이즈 내성을 설명한다 <a href="#ref-12" class="ref-link">[12]</a>.</li>
                    </ul>
                </section>

                <!-- Section 3: Yann LeCun -->
                <section id="lecun" class="mb-12">
                    <h2 class="text-3xl font-bold themeable-heading mb-6 pb-3 border-b-2 themeable-border">
                        3. Yann LeCun과 Meta: 자율 기계 지능을 위한 인지 아키텍처
                    </h2>

                    <!-- Key Concept Box -->
                    <div class="key-concept-box">
                        <p class="font-semibold themeable-heading mb-1">핵심 개념: JEPA (Joint Embedding Predictive Architecture)</p>
                        <p class="text-sm themeable-text-secondary">픽셀이나 텍스트를 직접 생성하는 것은 비효율적이다. JEPA는 <strong>추상적 표현 공간</strong>에서 예측을 수행하여 불필요한 세부 정보를 제거하고 핵심 인과관계만 학습한다. 에너지 기반 모델(EBM)을 통해 여러 가능한 미래를 명확하게 예측할 수 있다.</p>
                    </div>

                    <p class="themeable-text leading-relaxed">
                        튜링상 수상자이자 Meta의 수석 AI 과학자인 Yann LeCun은 현재 AI 업계를 지배하는 LLM의 자기회귀(Auto-regressive) 방식에 대해 가장 강력한 비판자 중 한 명이다. 그는 진정한 AGI로 나아가기 위해서는 텍스트 생성 모델이 아닌, 추론하고 계획할 수 있는 '<strong>월드 모델</strong>'이 필요하다고 역설하며 <strong>JEPA(Joint Embedding Predictive Architecture)</strong>를 제안했다.
                    </p>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">3.1 생성형 AI에 대한 비판: "LLM은 월드 모델이 아니다"</h3>

                    <p class="themeable-text leading-relaxed">
                        LeCun은 텍스트나 픽셀을 순차적으로 예측하는 방식이 근본적인 한계에 봉착했다고 주장한다 <a href="#ref-1" class="ref-link">[1]</a>.
                    </p>

                    <ul class="list-disc pl-6 themeable-text-secondary mb-6">
                        <li><strong>비효율성:</strong> 비디오 생성 모델(예: Sora)이 3D 세계를 시뮬레이션하는 것처럼 보이지만, 이는 픽셀 공간에서의 통계적 모방일 뿐이다. LeCun은 "월드 모델을 만들기 위해 픽셀을 생성하는 것은 마치 물리학을 배우기 위해 양자 역학 수준의 모든 입자 위치를 계산하는 것과 같이 비효율적"이라고 비판한다 <a href="#ref-15" class="ref-link">[15]</a>.</li>
                        <li><strong>오류 누적:</strong> 자기회귀 모델은 생성된 결과물을 다시 입력으로 사용하기 때문에, 초기 오류가 기하급수적으로 증폭되어 현실과 동떨어진 환각(Drift)을 만들어낸다 <a href="#ref-16" class="ref-link">[16]</a>.</li>
                        <li><strong>데이터 대역폭의 차이:</strong> 인간은 텍스트(초당 몇 바이트)보다 시각 정보(초당 수십 메가바이트)를 통해 훨씬 더 많은 정보를 받아들이며 세계를 배운다. 텍스트만으로 학습한 AI는 물리적 상식(Common Sense)을 가질 수 없다 <a href="#ref-17" class="ref-link">[17]</a>.</li>
                    </ul>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">3.2 JEPA (Joint Embedding Predictive Architecture): 추상적 공간에서의 예측</h3>

                    <p class="themeable-text leading-relaxed">
                        LeCun의 해법은 <strong>입력 공간(Input Space)이 아닌 표현 공간(Representation Space)에서 예측을 수행</strong>하는 것이다 <a href="#ref-18" class="ref-link">[18]</a>.
                    </p>

                    <h4 class="text-xl font-semibold themeable-heading mt-6 mb-3">3.2.1 JEPA의 작동 원리</h4>

                    <p class="themeable-text leading-relaxed">
                        JEPA는 입력 <code>x</code>(현재 상태)와 <code>y</code>(미래 상태)를 직접 연결하지 않는다.
                    </p>

                    <!-- JEPA Process Flow -->
                    <div class="process-flow mt-6 mb-6">
                        <div class="process-step">
                            <span class="step-number">1</span>
                            <p class="step-title mt-2">인코더</p>
                            <p class="step-desc">입력 x, y를 추상 벡터<br><code class="text-xs">s_x</code>, <code class="text-xs">s_y</code>로 변환</p>
                        </div>
                        <div class="process-step">
                            <span class="step-number">2</span>
                            <p class="step-title mt-2">예측기</p>
                            <p class="step-desc"><code class="text-xs">s_x</code> + 잠재변수 <code class="text-xs">z</code><br>→ <code class="text-xs">s_y'</code> 예측</p>
                        </div>
                        <div class="process-step">
                            <span class="step-number">3</span>
                            <p class="step-title mt-2">비생성적</p>
                            <p class="step-desc">픽셀 복원 없이<br>추상 공간에서만 예측</p>
                        </div>
                    </div>

                    <p class="themeable-text leading-relaxed text-sm">
                        인코더는 불필요한 세부 정보(배경 노이즈 등)를 제거하고 중요한 정보(물체 위치, 운동량)만 보존한다 <a href="#ref-19" class="ref-link">[19]</a>. 예측기는 현재 상태와 잠재 변수를 바탕으로 미래 상태를 예측하며, 핵심적으로 JEPA는 픽셀로 복원하지 않고 추상 공간에서만 작동한다.
                    </p>

                    <h4 class="text-xl font-semibold themeable-heading mt-6 mb-3">3.2.2 에너지 기반 모델 (Energy-Based Models, EBM)</h4>

                    <p class="themeable-text leading-relaxed">
                        LeCun의 이론적 토대는 EBM이다. 학습은 두 상태(입력과 예측) 사이의 '에너지(불일치도/비용)'를 최소화하는 방향으로 이루어진다.
                    </p>

                    <ul class="list-disc pl-6 themeable-text-secondary mb-6">
                        <li><strong>호환성(Compatibility):</strong> 관찰된 데이터 <code>x</code>와 <code>y</code>가 물리적으로 호환되면 낮은 에너지를, 불가능한 상황이면 높은 에너지를 부여한다 <a href="#ref-20" class="ref-link">[20]</a>.</li>
                        <li><strong>불확실성 관리:</strong> 미래는 결정되어 있지 않다(Stochastic). JEPA는 잠재 변수 <code>z</code>를 사용하여 여러 가능한 미래를 모델링한다. 생성 모델처럼 모든 픽셀의 평균값을 예측하여 흐릿한(Blurry) 이미지를 만드는 대신, <code>z</code>값에 따라 타당한 여러 미래 상태를 명확한 벡터로 예측할 수 있다 <a href="#ref-18" class="ref-link">[18]</a>.</li>
                    </ul>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">3.3 계층적 계획 (Hierarchical Planning)과 자율 에이전트</h3>

                    <p class="themeable-text leading-relaxed">
                        LeCun이 구상하는 자율 지능 시스템은 6개의 모듈로 구성된다 <a href="#ref-18" class="ref-link">[18]</a>.
                    </p>

                    <ol class="list-decimal pl-6 themeable-text-secondary mb-6">
                        <li><strong>구성기(Configurator):</strong> 작업 목표를 설정한다.</li>
                        <li><strong>인식(Perception):</strong> 센서 입력을 받아 현재 상태를 추정한다.</li>
                        <li><strong>월드 모델(World Model):</strong> 행동에 따른 미래 상태를 예측한다.</li>
                        <li><strong>비용(Cost):</strong> 본능적인 비용(Intrinsic Cost, 예: 충돌 회피)과 학습된 비평가(Critic)를 통해 상태의 가치를 평가한다.</li>
                        <li><strong>단기 기억(Short-term Memory):</strong> 현재 상황과 계획을 저장한다.</li>
                        <li><strong>행동기(Actor):</strong> 비용을 최소화하는 행동 시퀀스를 생성한다.</li>
                    </ol>

                    <p class="themeable-text leading-relaxed">
                        여기서 <strong>계층적 JEPA (H-JEPA)</strong>는 추상화 수준을 달리하여 장기 계획을 가능하게 한다. 상위 레벨에서는 "공항으로 간다"는 거시적 계획을, 하위 레벨에서는 "핸들을 왼쪽으로 10도 꺾는다"는 미시적 제어를 처리한다 <a href="#ref-18" class="ref-link">[18]</a>. 이는 인간의 <strong>시스템 2(System 2)</strong> 사고, 즉 느리고 신중한 계획 능력을 AI에 구현하려는 시도이다 <a href="#ref-23" class="ref-link">[23]</a>.
                    </p>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">3.4 I-JEPA와 V-JEPA</h3>

                    <p class="themeable-text leading-relaxed">
                        Meta는 이 이론을 입증하기 위해 이미지용 <strong>I-JEPA</strong>와 비디오용 <strong>V-JEPA</strong>를 공개했다. I-JEPA는 이미지의 일부를 가리고(Masking) 주변 정보를 통해 그 부분의 '의미적 표현'을 예측하며, V-JEPA는 비디오의 시간적 흐름 속에서 보이지 않는 부분의 시공간적 특징을 예측한다. 이들은 픽셀 생성 없이도 객체 인식과 물리적 상호작용 이해에서 뛰어난 성능(Sample Efficiency)을 보여주었다 <a href="#ref-20" class="ref-link">[20]</a>.
                    </p>
                </section>

                <!-- Section 4: Fei-Fei Li -->
                <section id="feifei" class="mb-12">
                    <h2 class="text-3xl font-bold themeable-heading mb-6 pb-3 border-b-2 themeable-border">
                        4. Fei-Fei Li와 World Labs: 공간 지능과 3D 생성의 융합
                    </h2>

                    <!-- Key Concept Box -->
                    <div class="key-concept-box purple">
                        <p class="font-semibold themeable-heading mb-1">핵심 개념: 공간 지능 (Spatial Intelligence)</p>
                        <p class="text-sm themeable-text-secondary">AI는 2D 이미지와 텍스트에는 능통하지만 <strong>3D 공간 이해와 조작</strong>이 결여되어 있다. World Labs의 <strong>Marble</strong>은 텍스트/이미지로부터 물리적으로 타당한 3D 환경을 생성하며, 로봇이 안전하게 학습할 수 있는 <strong>Sim2Real</strong> 환경을 제공한다.</p>
                    </div>

                    <p class="themeable-text leading-relaxed">
                        Fei-Fei Li는 ImageNet을 통해 컴퓨터 비전의 혁명을 촉발한 인물이다. 그녀는 이제 "보는 것(Seeing)"을 넘어 "행동하는 것(Doing)"으로 AI의 패러다임을 확장하기 위해 World Labs를 설립하고 <strong>'공간 지능(Spatial Intelligence)'</strong>이라는 개념을 주창했다.
                    </p>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">4.1 공간 지능 (Spatial Intelligence): AI의 잃어버린 조각</h3>

                    <p class="themeable-text leading-relaxed">
                        Li는 현재의 AI가 언어와 2D 이미지 생성에는 능통하지만, 3차원 공간을 이해하고 조작하는 능력은 현저히 부족하다고 지적한다. 그녀는 이를 "어둠 속의 언어술사(Wordsmiths in the dark)"라고 표현하며, 현실 감각이 결여된 지능의 한계를 꼬집었다 <a href="#ref-24" class="ref-link">[24]</a>.
                    </p>

                    <ul class="list-disc pl-6 themeable-text-secondary mb-6">
                        <li><strong>정의:</strong> 공간 지능은 "상상(Imagination), 지각(Perception), 행동(Action)"을 연결하는 능력이다. 이는 3D 공간의 깊이, 거리, 물리적 상호작용, 시간적 변화를 이해하는 것을 포함한다 <a href="#ref-26" class="ref-link">[26]</a>.</li>
                        <li><strong>진화적 관점:</strong> 생명체의 지능은 시각적 인식을 통해 환경과 상호작용하며 진화했다. 캄브리아기 대폭발이 '눈'의 탄생으로 시작되었듯, AI의 다음 진화는 3D 공간을 이해하는 능력에서 비롯될 것이다 <a href="#ref-24" class="ref-link">[24]</a>.</li>
                    </ul>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">4.2 Marble: 대형 월드 모델 (Large World Model, LWM)</h3>

                    <p class="themeable-text leading-relaxed">
                        World Labs의 첫 번째 결과물인 <strong>Marble</strong>은 텍스트, 이미지, 비디오 등 다양한 입력을 받아 완전한 3D 상호작용 환경을 생성하는 생성형 월드 모델이다 <a href="#ref-27" class="ref-link">[27]</a>.
                    </p>

                    <h4 class="text-xl font-semibold themeable-heading mt-6 mb-3">4.2.1 명시적 3D 표현 (Explicit 3D Representation)</h4>

                    <p class="themeable-text leading-relaxed">
                        LeCun의 JEPA가 내부적인 추상 표현을 지향하는 것과 달리, Marble은 사용자가 탐색하고 상호작용할 수 있는 <strong>명시적인 3D 자산</strong>을 생성한다.
                    </p>

                    <ul class="list-disc pl-6 themeable-text-secondary mb-6">
                        <li><strong>Gaussian Splats (가우시안 스플랫):</strong> Marble은 3D 장면을 수많은 반투명 입자(Gaussian)의 집합으로 표현하여, 사진과 같은 고해상도(Photorealistic) 시각화를 실시간으로 렌더링한다 <a href="#ref-27" class="ref-link">[27]</a>.</li>
                        <li><strong>Meshes & Colliders:</strong> 시각적 표현뿐만 아니라 물리 엔진이 인식할 수 있는 충돌 메쉬(Collider Mesh)를 함께 생성한다. 이는 생성된 세계가 단순한 배경 그림이 아니라, 로봇이나 게임 캐릭터가 걸어 다니고 물체와 부딪힐 수 있는 물리적 공간임을 의미한다 <a href="#ref-29" class="ref-link">[29]</a>.</li>
                    </ul>

                    <h4 class="text-xl font-semibold themeable-heading mt-6 mb-3">4.2.2 생성 기술의 혁신: 구조와 스타일의 분리</h4>

                    <p class="themeable-text leading-relaxed">
                        Marble은 생성 AI의 고질적인 문제인 '제어 불가능성(Uncontrollability)'을 해결하기 위해 구조와 스타일을 분리하는 접근을 취한다.
                    </p>

                    <ul class="list-disc pl-6 themeable-text-secondary mb-6">
                        <li><strong>Chisel (조각 모드):</strong> 사용자가 기본적인 3D 구조(박스, 평면 등)를 배치하면, AI가 그 위에 텍스트 프롬프트에 맞는 텍스처와 디테일을 입힌다 <a href="#ref-27" class="ref-link">[27]</a>.</li>
                        <li><strong>멀티모달 입력 통합:</strong> 여러 장의 사진이나 비디오를 입력하면 이를 정합(Stitching)하여 일관된 하나의 3D 공간으로 재구성한다. 이는 부동산, 건축, 게임 레벨 디자인 등에서 즉각적인 유용성을 가진다 <a href="#ref-31" class="ref-link">[31]</a>.</li>
                    </ul>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">4.3 RTFM (Real-Time Frame Model): 학습된 렌더러</h3>

                    <p class="themeable-text leading-relaxed">
                        최근 공개된 <strong>RTFM</strong>은 Marble과는 또 다른 접근을 보여준다. 이는 명시적인 3D 지오메트리(Mesh 등)를 생성하지 않고, <strong>신경망 자체가 3D 세계를 암묵적으로 기억하고 렌더링</strong>하는 방식이다 <a href="#ref-32" class="ref-link">[32]</a>.
                    </p>

                    <ul class="list-disc pl-6 themeable-text-secondary mb-6">
                        <li><strong>작동 방식:</strong> RTFM은 비디오 데이터를 학습하여, 입력된 이미지의 새로운 시점(Viewpoint)을 예측한다. 이는 트랜스포머 기반의 자기회귀 모델이지만, 3D 유클리드 공간의 사전 지식(Prior)을 가지고 있어 '공간적 일관성'을 유지한다.</li>
                        <li><strong>컨텍스트 저글링(Context Juggling):</strong> 대규모 세계를 탐색할 때 메모리 폭발을 막기 위해, 현재 시점과 관련된 프레임만을 동적으로 호출하여 지속성(Persistence)을 유지한다. 이는 LeCun의 '추상적 시뮬레이션'과 Li의 '시각적 생성' 사이의 가교 역할을 하는 기술로 평가받는다.</li>
                    </ul>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">4.4 로보틱스와 Sim2Real의 혁명</h3>

                    <p class="themeable-text leading-relaxed">
                        Li의 비전은 궁극적으로 로보틱스로 향한다. 현실 세계에서 로봇을 학습시키는 것은 느리고 위험하다. Marble로 생성된 무한하고 다양한 3D 시뮬레이션 환경(Sim)에서 로봇을 학습시키고, 이를 현실(Real)로 가져오는 <strong>Sim2Real</strong> 전략은 로봇 공학의 데이터 병목 현상을 해결할 열쇠로 꼽힌다 <a href="#ref-29" class="ref-link">[29]</a>.
                    </p>
                </section>

                <!-- Section 5: Comparison -->
                <section id="comparison" class="mb-12">
                    <h2 class="text-3xl font-bold themeable-heading mb-6 pb-3 border-b-2 themeable-border">
                        5. 비교 분석: 세 가지 이론의 통합과 대립
                    </h2>

                    <p class="themeable-text leading-relaxed">
                        세 석학의 이론은 모두 '현재의 AI 한계 극복'과 '물리적 세계의 이해'를 목표로 하지만, 그 접근 방식(Approach)과 존재론적 관점(Ontology)에서 뚜렷한 차이를 보인다.
                    </p>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">5.1 비교 요약표</h3>

                    <p class="themeable-text leading-relaxed mb-4">
                        아래 표는 세 석학의 월드 모델 이론을 7가지 핵심 기준으로 비교한 것이다. 각 접근법의 핵심 아키텍처, 데이터 표현 방식, 생성에 대한 관점, 물리학 구현 방식, 그리고 궁극적인 지향점이 어떻게 다른지 한눈에 파악할 수 있다.
                    </p>

                    <div class="overflow-x-auto mb-8 rounded-lg border themeable-border">
                        <table class="w-full border-collapse text-sm">
                            <thead>
                                <tr class="bg-gradient-to-r from-orange-500/10 via-teal-500/10 to-purple-500/10">
                                    <th class="px-4 py-3 text-left font-bold">비교 항목</th>
                                    <th class="px-4 py-3 text-left font-bold text-orange-600">Jeff Hawkins</th>
                                    <th class="px-4 py-3 text-left font-bold text-teal-600">Yann LeCun</th>
                                    <th class="px-4 py-3 text-left font-bold text-purple-600">Fei-Fei Li</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td class="px-3 py-2 font-semibold">핵심 이론</td>
                                    <td class="px-3 py-2"><strong>천 개의 뇌 이론</strong> (Thousand Brains)</td>
                                    <td class="px-3 py-2"><strong>자율 기계 지능</strong> (JEPA)</td>
                                    <td class="px-3 py-2"><strong>공간 지능</strong> (Spatial Intelligence)</td>
                                </tr>
                                <tr>
                                    <td class="px-3 py-2 font-semibold">주요 아키텍처</td>
                                    <td class="px-3 py-2"><strong>참조 프레임</strong> & 피질 기둥 (SDR)</td>
                                    <td class="px-3 py-2"><strong>Joint Embedding</strong> & 예측기</td>
                                    <td class="px-3 py-2"><strong>생성적 3D 모델</strong> (Marble, RTFM)</td>
                                </tr>
                                <tr>
                                    <td class="px-3 py-2 font-semibold">월드 모델의 정의</td>
                                    <td class="px-3 py-2">피질 기둥에 분산된 수천 개의 <strong>센서-위치 모델</strong></td>
                                    <td class="px-3 py-2">추상적 <strong>표현 공간</strong>에서의 상태 예측 시뮬레이터</td>
                                    <td class="px-3 py-2">물리적 상호작용이 가능한 <strong>명시적 3D 환경</strong></td>
                                </tr>
                                <tr>
                                    <td class="px-3 py-2 font-semibold">데이터 표현</td>
                                    <td class="px-3 py-2">희소 분산 표현 (SDR), Grid Cells</td>
                                    <td class="px-3 py-2">고차원 임베딩 벡터 (Latent Representations)</td>
                                    <td class="px-3 py-2">Gaussian Splats, Meshes, Neural Rendering</td>
                                </tr>
                                <tr>
                                    <td class="px-3 py-2 font-semibold">생성(Generation)</td>
                                    <td class="px-3 py-2"><strong>내부적 예측</strong> (Predictive Coding)을 위한 생성</td>
                                    <td class="px-3 py-2">픽셀 생성 <strong>반대</strong> (비효율적, 환각 위험)</td>
                                    <td class="px-3 py-2"><strong>적극적 생성</strong> (Generative AI)을 통한 공간 구축</td>
                                </tr>
                                <tr>
                                    <td class="px-3 py-2 font-semibold">물리학의 구현</td>
                                    <td class="px-3 py-2">감각운동 학습을 통해 <strong>구조적</strong>으로 체득</td>
                                    <td class="px-3 py-2">에너지 함수 최소화를 통해 <strong>직관적</strong>으로 학습</td>
                                    <td class="px-3 py-2">물리 엔진과의 결합 또는 3D <strong>시뮬레이션</strong> 제공</td>
                                </tr>
                                <tr>
                                    <td class="px-3 py-2 font-semibold">지향점 (Goal)</td>
                                    <td class="px-3 py-2"><strong>생물학적 뇌</strong>의 역공학을 통한 AGI</td>
                                    <td class="px-3 py-2"><strong>인간 수준의 추론/계획</strong> 능력을 가진 AI</td>
                                    <td class="px-3 py-2"><strong>디지털-물리 융합</strong> 및 로보틱스 생태계</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">5.2 논쟁점 1: 표현(Representation) - 구체성 vs. 추상성</h3>

                    <p class="themeable-text leading-relaxed">
                        <strong>Hawkins vs. LeCun:</strong> Hawkins는 뇌가 '지도(Map)'와 같은 기하학적 구조(참조 프레임)를 실제로 가지고 있다고 본다. 정보는 '위치'와 결합되어 저장된다. 반면 LeCun은 정보가 수학적으로 효율적인 '추상 공간'에 압축되어야 한다고 본다. 그러나 LeCun의 JEPA에서 잠재 변수(<code>z</code>)가 공간적 불확실성을 처리하는 방식은 Hawkins의 투표 메커니즘이 불확실성을 해소하는 방식과 기능적으로 유사하다.
                    </p>

                    <p class="themeable-text leading-relaxed">
                        <strong>Li vs. LeCun:</strong> LeCun은 픽셀이나 3D 좌표를 직접 생성하는 것을 "낭비"라고 본다. 지능은 컵의 정확한 3D 메쉬를 그리는 것이 아니라, 컵을 잡을 수 있는 '개념적 이해'만 있으면 된다는 것이다 <a href="#ref-15" class="ref-link">[15]</a>. 반면 Li는 로봇이 실제로 행동하기 위해서는 "구체적인 3D 환경"이 필수적이라고 본다. Li의 Marble은 LeCun이 거부한 '세밀한 픽셀/복셀의 생성'을 통해 역설적으로 로봇에게 '안전한 훈련장'을 제공한다.
                    </p>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">5.3 논쟁점 2: 생성(Generation)의 역할</h3>

                    <p class="themeable-text leading-relaxed">
                        <strong>LeCun의 비판:</strong> Sora와 같은 비디오 생성 모델은 물리 법칙을 이해한 것이 아니라 흉내 내는 것이다. 따라서 엔지니어링 도구로는 훌륭할지 몰라도, 지능 모델로서는 실패할 운명이다.
                    </p>

                    <p class="themeable-text leading-relaxed">
                        <strong>Li의 반박적 수용:</strong> Li의 모델은 생성형이지만, 2D 픽셀의 통계적 나열이 아니라 3D 기하학적 일관성(Geometric Consistency)을 강제한다. 즉, Marble은 '보기에 그럴듯한' 영상이 아니라 '물리적으로 타당한' 3D 구조를 생성함으로써 LeCun의 비판(물리적 이해 부재)을 기술적으로 극복하려 한다 <a href="#ref-31" class="ref-link">[31]</a>.
                    </p>

                    <p class="themeable-text leading-relaxed">
                        <strong>Hawkins의 관점:</strong> 뇌는 끊임없이 입력을 생성(예측)한다. 그러나 이는 외부 출력을 위한 것이 아니라 내부 모델의 검증을 위한 것이다. Hawkins에게 생성은 학습의 수단이지 목적이 아니다.
                    </p>

                    <h3 class="text-2xl font-semibold themeable-heading mt-8 mb-4">5.4 상호보완성: AGI를 향한 융합</h3>

                    <p class="themeable-text leading-relaxed">
                        이 세 이론은 상호 배타적이라기보다 보완적이다.
                    </p>

                    <ol class="list-decimal pl-6 themeable-text-secondary mb-6">
                        <li><strong>구조(Structure):</strong> Hawkins의 <strong>참조 프레임</strong> 이론은 AI가 정보를 저장하는 '데이터 구조'에 대한 청사진을 제공한다. 트랜스포머의 어텐션 메커니즘도 일종의 암묵적 참조 프레임으로 볼 수 있다.</li>
                        <li><strong>추론(Reasoning):</strong> LeCun의 <strong>JEPA</strong>는 이 구조 위에서 작동하는 '추론 엔진'이다. 불필요한 정보를 버리고 핵심 인과관계만을 학습하여 효율적으로 계획을 수립한다.</li>
                        <li><strong>환경(Environment):</strong> Li의 <strong>Marble</strong>은 이 AI가 학습하고 상호작용할 '신체와 환경'을 제공한다. JEPA를 탑재한 로봇(Brain)이 Marble로 생성된 세계(World)에서 Hawkins의 방식(Sensorimotor)으로 학습하는 미래를 그려볼 수 있다.</li>
                    </ol>
                </section>

                <!-- Section 6: Conclusion -->
                <section id="conclusion" class="mb-12">
                    <h2 class="text-3xl font-bold themeable-heading mb-6 pb-3 border-b-2 themeable-border">
                        6. 결론: 월드 모델이 여는 미래
                    </h2>

                    <p class="themeable-text leading-relaxed">
                        Jeff Hawkins, Yann LeCun, Fei-Fei Li는 각기 다른 출발점에서 시작했지만, 결론은 하나의 지점으로 수렴하고 있다. <strong>"지능은 정적인 데이터를 학습하는 것이 아니라, 역동적인 세계의 구조와 인과관계를 내재화하는 것이다."</strong>
                    </p>

                    <ul class="list-disc pl-6 themeable-text-secondary mb-6">
                        <li><strong>Jeff Hawkins</strong>는 우리에게 뇌가 세계를 어떻게 <strong>'좌표화'</strong>하는지 알려주었다. 그의 이론은 AI가 단순한 패턴 매칭을 넘어, 인간처럼 개념을 구조적으로 조작할 수 있는 길을 열어준다.</li>
                        <li><strong>Yann LeCun</strong>은 AI가 어떻게 <strong>'효율적으로'</strong> 생각해야 하는지 제시했다. 그의 비생성적 예측 모델은 AI가 불필요한 계산의 늪에 빠지지 않고, 인간 수준의 상식과 계획 능력을 갖추도록 유도한다.</li>
                        <li><strong>Fei-Fei Li</strong>는 AI에게 <strong>'살아갈 공간'</strong>을 만들어주었다. 그녀의 공간 지능 기술은 디지털 지능을 물리적 현실로 확장시키며, 로보틱스와 메타버스의 경계를 허물고 있다.</li>
                    </ul>

                    <!-- Fusion Diagram: AGI로의 융합 -->
                    <h4 class="text-lg font-semibold themeable-heading mt-8 mb-4 text-center">AGI를 향한 세 이론의 융합</h4>
                    <div class="fusion-diagram">
                        <div class="fusion-item" style="border-color: #f97316;">
                            <div class="fusion-icon">🧠</div>
                            <p class="fusion-label">Layer 1</p>
                            <p class="fusion-title">구조 (Structure)</p>
                            <p class="fusion-author">Jeff Hawkins</p>
                            <p class="text-xs themeable-text-secondary mt-2">참조 프레임으로 정보를 '좌표화'</p>
                        </div>
                        <div class="fusion-item" style="border-color: #0d9488;">
                            <div class="fusion-icon">⚡</div>
                            <p class="fusion-label">Layer 2</p>
                            <p class="fusion-title">추론 (Reasoning)</p>
                            <p class="fusion-author">Yann LeCun</p>
                            <p class="text-xs themeable-text-secondary mt-2">추상 공간에서 효율적 예측</p>
                        </div>
                        <div class="fusion-item" style="border-color: #8b5cf6;">
                            <div class="fusion-icon">🌍</div>
                            <p class="fusion-label">Layer 3</p>
                            <p class="fusion-title">환경 (Environment)</p>
                            <p class="fusion-author">Fei-Fei Li</p>
                            <p class="text-xs themeable-text-secondary mt-2">3D 세계에서 학습하고 행동</p>
                        </div>
                    </div>

                    <p class="themeable-text leading-relaxed">
                        지금 우리는 텍스트 기반의 '챗봇' 시대에서, 물리적 현실을 이해하고 행동하는 '에이전트' 시대로 넘어가는 과도기에 있다. 이 세 석학이 구축하고 있는 월드 모델들은 그 새로운 시대를 지탱할 이론적, 기술적 기둥이 될 것이다. 향후 AI의 발전은 이 세 가지 흐름이 어떻게 융합되어, <strong>신체(Embodiment)를 가진, 추론(Reasoning)하는, 구조적(Structured) 지능</strong>으로 탄생하느냐에 달려 있다.
                    </p>
                </section>

                <!-- FAQ Section -->
                <section id="faq" class="mt-12">
                    <h2 class="text-3xl font-bold themeable-heading mb-6 pb-3 border-b-2 themeable-border">
                        자주 묻는 질문 (FAQ)
                    </h2>

                    <div class="space-y-4">
                        <div itemscope itemtype="https://schema.org/Question" class="border themeable-border rounded-lg p-6">
                            <h3 itemprop="name" class="text-xl font-semibold themeable-heading mb-3">
                                월드 모델(World Model)이란 무엇인가요?
                            </h3>
                            <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                                <div itemprop="text" class="themeable-text-secondary">
                                    <p>월드 모델은 에이전트(인간 또는 기계)가 외부 환경의 구조와 작동 원리를 내부적으로 시뮬레이션하여, 행동의 결과를 예측하고 계획을 수립할 수 있게 하는 인지적 프레임워크입니다. 단순히 데이터를 분류하거나 생성하는 것을 넘어, 지능의 본질인 '이해'와 '생존'을 가능하게 하는 핵심 기제입니다.</p>
                                </div>
                            </div>
                        </div>

                        <div itemscope itemtype="https://schema.org/Question" class="border themeable-border rounded-lg p-6">
                            <h3 itemprop="name" class="text-xl font-semibold themeable-heading mb-3">
                                천 개의 뇌 이론(Thousand Brains Theory)의 핵심은 무엇인가요?
                            </h3>
                            <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                                <div itemprop="text" class="themeable-text-secondary">
                                    <p>Jeff Hawkins의 천 개의 뇌 이론은 신피질의 약 15만 개 피질 기둥이 각각 독립적인 감각운동 모델링 시스템으로 작동한다는 이론입니다. 이 기둥들은 '투표' 메커니즘을 통해 정보를 교환하고 합의에 도달합니다. 핵심은 뇌가 '참조 프레임'이라는 좌표계를 사용해 정보를 저장하며, 이것이 물리적 객체뿐 아니라 추상적 개념에도 적용된다는 것입니다.</p>
                                </div>
                            </div>
                        </div>

                        <div itemscope itemtype="https://schema.org/Question" class="border themeable-border rounded-lg p-6">
                            <h3 itemprop="name" class="text-xl font-semibold themeable-heading mb-3">
                                JEPA와 기존 생성형 AI의 차이점은 무엇인가요?
                            </h3>
                            <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                                <div itemprop="text" class="themeable-text-secondary">
                                    <p>Yann LeCun의 JEPA(Joint Embedding Predictive Architecture)는 입력 공간(픽셀)이 아닌 추상적 표현 공간에서 예측을 수행합니다. 기존 생성형 AI가 픽셀을 순차적으로 예측하여 비효율적이고 오류가 누적되는 반면, JEPA는 불필요한 세부 정보를 제거하고 핵심 인과관계만 학습합니다. 이를 통해 더 효율적인 추론과 계획이 가능해집니다.</p>
                                </div>
                            </div>
                        </div>

                        <div itemscope itemtype="https://schema.org/Question" class="border themeable-border rounded-lg p-6">
                            <h3 itemprop="name" class="text-xl font-semibold themeable-heading mb-3">
                                공간 지능(Spatial Intelligence)이 로보틱스에 왜 중요한가요?
                            </h3>
                            <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                                <div itemprop="text" class="themeable-text-secondary">
                                    <p>Fei-Fei Li의 공간 지능은 AI가 3D 공간을 이해하고 조작하는 능력입니다. 로봇이 현실 세계에서 안전하게 행동하려면 깊이, 거리, 물리적 상호작용을 이해해야 합니다. World Labs의 Marble은 무한한 3D 시뮬레이션 환경을 생성하여 로봇이 안전하게 학습한 후 현실로 전이(Sim2Real)할 수 있게 하며, 이는 로보틱스 데이터 병목 현상을 해결하는 핵심 전략입니다.</p>
                                </div>
                            </div>
                        </div>

                        <div itemscope itemtype="https://schema.org/Question" class="border themeable-border rounded-lg p-6">
                            <h3 itemprop="name" class="text-xl font-semibold themeable-heading mb-3">
                                세 가지 월드 모델 이론은 상호 배타적인가요?
                            </h3>
                            <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                                <div itemprop="text" class="themeable-text-secondary">
                                    <p>아니요, 세 이론은 상호 보완적입니다. Hawkins의 참조 프레임은 데이터 '구조', LeCun의 JEPA는 '추론 엔진', Li의 Marble은 '환경'을 제공합니다. 미래의 AGI는 JEPA를 탑재한 로봇이 Marble로 생성된 세계에서 Hawkins 방식으로 감각운동 학습을 수행하는 형태로 구현될 수 있습니다.</p>
                                </div>
                            </div>
                        </div>

                        <div itemscope itemtype="https://schema.org/Question" class="border themeable-border rounded-lg p-6">
                            <h3 itemprop="name" class="text-xl font-semibold themeable-heading mb-3">
                                LLM의 환각(Hallucination) 문제와 월드 모델의 관계는?
                            </h3>
                            <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                                <div itemprop="text" class="themeable-text-secondary">
                                    <p>LLM의 환각은 AI가 현실 세계의 법칙에 기반하지 않고 확률적 그럴듯함에 의존하기 때문에 발생합니다. 월드 모델은 물리적 세계의 인과관계와 구조를 내재화함으로써 이 문제를 근본적으로 해결하려 합니다. 텍스트는 세계를 설명하는 상징일 뿐이며, 진정한 이해를 위해서는 월드 모델이 필수적입니다.</p>
                                </div>
                            </div>
                        </div>

                        <div itemscope itemtype="https://schema.org/Question" class="border themeable-border rounded-lg p-6">
                            <h3 itemprop="name" class="text-xl font-semibold themeable-heading mb-3">
                                희소 분산 표현(SDR)이란 무엇이며 왜 중요한가요?
                            </h3>
                            <div itemscope itemprop="acceptedAnswer" itemtype="https://schema.org/Answer">
                                <div itemprop="text" class="themeable-text-secondary">
                                    <p>SDR은 Numenta 기술의 기저에 있는 데이터 구조로, 뇌의 뉴런이 매우 희소하게 활성화되는 것을 모방합니다. 2,048개 비트 중 약 2%(40개)만 활성화됩니다. SDR의 각 비트는 의미를 가지며, 겹치는 비트가 많을수록 의미적으로 유사합니다. 활성 비트의 절반이 손실되어도 나머지로 패턴을 유추할 수 있어 노이즈에 강건합니다.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- References Section -->
                <section id="references" class="mt-12">
                    <h2 class="text-3xl font-bold themeable-heading mb-6 pb-3 border-b-2 themeable-border">
                        참고문헌
                    </h2>

                    <ol class="space-y-3 text-sm themeable-text-secondary">
                        <li id="ref-1">
                            <span class="font-semibold text-teal-600">[1]</span>
                            OpenAI's Video-Generating AI Is "Doomed to Failure," Says Meta's Top AI Scientist. Futurism.
                            <a href="https://futurism.com/the-byte/openai-video-ai-doomed-meta-scientist" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-2">
                            <span class="font-semibold text-teal-600">[2]</span>
                            Yan Nuriyev. LLMs Were Just the Warm-Up. AI's Next Revolution is World Models.
                            <a href="https://whoisyan.com/llms-were-just-the-warm-up-ais-next-revolution-is-world-models/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-3">
                            <span class="font-semibold text-teal-600">[3]</span>
                            Jeff Hawkins. A Thousand Brains: A New Theory Of Intelligence. Numenta.
                            <a href="https://www.numenta.com/resources/books/a-thousand-brains-by-jeff-hawkins/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-4">
                            <span class="font-semibold text-teal-600">[4]</span>
                            A Thousand Brains. Internet Archive.
                            <a href="https://dn790007.ca.archive.org/0/items/artificial-intelligence/2021_a_thousand_brains-a_new_theory_of_intelligence-Jeff%20Hawkins%20%282021%29.pdf" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-5">
                            <span class="font-semibold text-teal-600">[5]</span>
                            Christophe Pere. A Thousand Brains Theory: A Review. Medium.
                            <a href="https://medium.com/data-science/a-thousand-brains-theory-a-review-3ea6bbeeced0" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-6">
                            <span class="font-semibold text-teal-600">[6]</span>
                            The Thousand Brains Theory of Intelligence. Numenta.
                            <a href="https://www.numenta.com/blog/2019/01/16/the-thousand-brains-theory-of-intelligence/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-7">
                            <span class="font-semibold text-teal-600">[7]</span>
                            A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex. Numenta.
                            <a href="https://www.numenta.com/assets/pdf/research-publications/papers/Companion-paper-to-Thousand-Brains-Theory-of-Intelligence.pdf" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-8">
                            <span class="font-semibold text-teal-600">[8]</span>
                            The Thousand Brains Theory. Microsoft Research.
                            <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2019/03/42804_The_Thousand_Brains_Theory.pdf" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-9">
                            <span class="font-semibold text-teal-600">[9]</span>
                            The Thousand Brains Project. Numenta.
                            <a href="https://www.numenta.com/wp-content/uploads/2024/06/Short_TBP_Overview.pdf" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-10">
                            <span class="font-semibold text-teal-600">[10]</span>
                            Numenta Publishes a New Theory on Sensorimotor Inference. Numenta.
                            <a href="https://www.numenta.com/press/2017/11/15/numenta-publishes-new-sensorimotor-theory-in-frontiers/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-11">
                            <span class="font-semibold text-teal-600">[11]</span>
                            Sparse Distributed Representations. Numenta.
                            <a href="https://www.numenta.com/assets/pdf/biological-and-machine-intelligence/BaMI-SDR.pdf" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-12">
                            <span class="font-semibold text-teal-600">[12]</span>
                            The HTM Spatial Pooler—A Neocortical Algorithm for Online Sparse Distributed Coding. Frontiers in Computational Neuroscience.
                            <a href="https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2017.00111/full" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-13">
                            <span class="font-semibold text-teal-600">[13]</span>
                            The HTM Spatial Pooler – a neocortical algorithm for online sparse distributed coding. bioRxiv.
                            <a href="https://www.biorxiv.org/content/10.1101/085035v1.full.pdf" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-14">
                            <span class="font-semibold text-teal-600">[14]</span>
                            World Models vs. Word Models: Why Yann LeCun Believes LLMs Will Be Obsolete. Medium.
                            <a href="https://medium.com/state-of-the-art-technology/world-models-vs-word-models-why-lecun-believes-llms-will-be-obsolete-23795e729cfa" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-15">
                            <span class="font-semibold text-teal-600">[15]</span>
                            Yann LeCun doubles down, claims Sora doesn't count. Reddit r/singularity.
                            <a href="https://www.reddit.com/r/singularity/comments/1atk19r/yann_lecun_doubles_down_claims_sora_doesnt_count/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-16">
                            <span class="font-semibold text-teal-600">[16]</span>
                            Yann LeCun: Intense Complaints Before Leaving the Company. 36氪.
                            <a href="https://eu.36kr.com/en/p/3605931513267201" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-17">
                            <span class="font-semibold text-teal-600">[17]</span>
                            Highlights from Lex Fridman's interview of Yann LeCun. LessWrong.
                            <a href="https://www.lesswrong.com/posts/bce63kvsAMcwxPipX/highlights-from-lex-fridman-s-interview-of-yann-lecun" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-18">
                            <span class="font-semibold text-teal-600">[18]</span>
                            A Path Towards Autonomous Machine Intelligence. Temple CIS.
                            <a href="https://cis.temple.edu/tagit/presentations/A%20Path%20Towards%20Autonomous%20Machine%20Intelligence.pdf" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-19">
                            <span class="font-semibold text-teal-600">[19]</span>
                            What is Joint Embedding Predictive Architecture (JEPA)? Turing Post.
                            <a href="https://www.turingpost.com/p/jepa" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-20">
                            <span class="font-semibold text-teal-600">[20]</span>
                            Deep Dive into Yann LeCun's JEPA. Rohit Bandaru.
                            <a href="https://rohitbandaru.github.io/blog/JEPA-Deep-Dive/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-21">
                            <span class="font-semibold text-teal-600">[21]</span>
                            LeCun's 2022 paper on autonomous machine intelligence rehashes but does not cite essential work of 1990-2015. Jürgen Schmidhuber.
                            <a href="https://people.idsia.ch/~juergen/lecun-rehash-1990-2022.html" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-22">
                            <span class="font-semibold text-teal-600">[22]</span>
                            Anil Jain. JEPA: LeCun's Path Towards More Human-Like AI. Medium.
                            <a href="https://medium.com/@anil.jain.baba/jepa-lecuns-path-towards-more-human-like-ai-9535e48b3c65" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-23">
                            <span class="font-semibold text-teal-600">[23]</span>
                            Malcolm Lett. Critical review of LeCun's Introductory JEPA paper. Medium.
                            <a href="https://malcolmlett.medium.com/critical-review-of-lecuns-introductory-jepa-paper-fabe5783134e" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-24">
                            <span class="font-semibold text-teal-600">[24]</span>
                            Viral! Fei-Fei Li's 10,000-Word Article Defines Next Decade of AI. 36氪.
                            <a href="https://eu.36kr.com/en/p/3548078081093508" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-25">
                            <span class="font-semibold text-teal-600">[25]</span>
                            Are World Models the Future of AI? Blockchain Council.
                            <a href="https://www.blockchain-council.org/ai/world-models-future-of-ai/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-26">
                            <span class="font-semibold text-teal-600">[26]</span>
                            Building Spatial Intelligence: How World Labs is Creating the Next Frontier in AI. Radical VC.
                            <a href="https://radical.vc/building-spatial-intelligence-how-world-labs-is-creating-the-next-frontier-in-ai/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-27">
                            <span class="font-semibold text-teal-600">[27]</span>
                            Marble: A Multimodal World Model. World Labs.
                            <a href="https://www.worldlabs.ai/blog/marble-world-model" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-28">
                            <span class="font-semibold text-teal-600">[28]</span>
                            New Marble AI Creates Entire 3D Worlds from Simple Text Prompts. Analytics Vidhya.
                            <a href="https://www.analyticsvidhya.com/blog/2025/11/marble-world-ai-creates-3d-worlds-from-text/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-29">
                            <span class="font-semibold text-teal-600">[29]</span>
                            Scaling Robotic Simulation with Marble. World Labs.
                            <a href="https://www.worldlabs.ai/case-studies/1-robotics" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-30">
                            <span class="font-semibold text-teal-600">[30]</span>
                            Simulate Robotic Environments Faster with NVIDIA Isaac Sim and World Labs Marble. NVIDIA Developer Blog.
                            <a href="https://developer.nvidia.com/blog/simulate-robotic-environments-faster-with-nvidia-isaac-sim-and-world-labs-marble/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-31">
                            <span class="font-semibold text-teal-600">[31]</span>
                            evoailabs. World Models — Not Next, Current Frontier. Medium.
                            <a href="https://evoailabs.medium.com/world-models-not-next-current-frontier-547c5eeb1307" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-32">
                            <span class="font-semibold text-teal-600">[32]</span>
                            RTFM: A Real-Time Frame Model. World Labs.
                            <a href="https://www.worldlabs.ai/blog/rtfm" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                        <li id="ref-33">
                            <span class="font-semibold text-teal-600">[33]</span>
                            Pebblous. (2026). 세계 모델이란 무엇일까? 20억 원 손실을 막는 AI의 조건. Data Clinic Blog.
                            <a href="https://blog.dataclinic.ai/world-model/" class="text-orange-500 hover:underline" target="_blank">링크</a>
                        </li>
                    </ol>
                </section>

                <!-- PDF Download Section -->
                <section id="pdf-download" class="mt-12">
                    <div class="themeable-card rounded-xl p-8 md:p-10 border-2" style="border-color: var(--accent-color);">
                        <div class="flex flex-col md:flex-row items-center gap-8">
                            <div class="flex-shrink-0">
                                <div class="w-24 h-24 rounded-full flex items-center justify-center" style="background: linear-gradient(135deg, #F86825, #FF8C42);">
                                    <svg class="w-12 h-12 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 10v6m0 0l-3-3m3 3l3-3m2 8H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path>
                                    </svg>
                                </div>
                            </div>
                            <div class="flex-1">
                                <h3 class="text-2xl font-bold themeable-heading mb-3">PDF 원본 리포트</h3>
                                <p class="themeable-text-muted mb-6">
                                    본 콘텐츠의 전체 내용을 PDF 형식으로 바로 열람하거나 다운로드하여 오프라인에서도 보실 수 있습니다.
                                </p>
                                <div class="flex flex-col sm:flex-row gap-4">
                                    <button id="open-pdf-modal"
                                       class="inline-flex items-center justify-center gap-2 px-6 py-3 rounded-lg font-bold text-white transition-all hover:scale-105"
                                       style="background: linear-gradient(135deg, #F86825, #FF8C42);">
                                        <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z"></path>
                                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M2.458 12C3.732 7.943 7.523 5 12 5c4.478 0 8.268 2.943 9.542 7-1.274 4.057-5.064 7-9.542 7-4.477 0-8.268-2.943-9.542-7z"></path>
                                        </svg>
                                        바로 보기
                                    </button>
                                    <a href="/project/World%20Model/source/%EC%B0%A8%EC%84%B8%EB%8C%80%20AI%EB%A5%BC%20%EC%9C%84%ED%95%9C%20%EC%84%B8%20%EA%B0%80%EC%A7%80%20%EC%9B%94%EB%93%9C%EB%AA%A8%EB%8D%B8%20%EB%B9%84%EA%B5%90_%20Jeff%20Hawkins%2C%20Yann%20LeCun%2C%20Fei-Fei%20Li.pdf"
                                       download
                                       class="inline-flex items-center justify-center gap-2 px-6 py-3 themeable-card rounded-lg font-bold themeable-heading transition-all hover:scale-105 border-2"
                                       style="border-color: var(--accent-color);">
                                        <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M9 19l3 3m0 0l3-3m-3 3V10"></path>
                                        </svg>
                                        PDF 다운로드
                                    </a>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Related Posts -->
                <section id="related-posts" class="mt-12">
                    <h3 class="text-2xl font-semibold themeable-heading mb-6">관련 포스팅</h3>
                    <div id="related-posts-container"></div>
                </section>
            </main>

        </div><!-- End Flex Layout -->
    </div>

    <!-- Footer Placeholder -->
    <div id="footer-placeholder"></div>

    <!-- PDF Viewer Modal -->
    <div id="pdf-modal" class="fixed inset-0 z-50 hidden">
        <!-- Backdrop -->
        <div class="absolute inset-0 bg-black bg-opacity-75 transition-opacity" id="pdf-modal-backdrop"></div>

        <!-- Modal Content -->
        <div class="relative w-full h-full flex items-center justify-center p-4">
            <div class="relative w-full h-full max-w-7xl max-h-[95vh] themeable-card rounded-xl overflow-hidden shadow-2xl">
                <!-- Header -->
                <div class="flex items-center justify-between p-4 border-b themeable-border">
                    <h3 class="text-xl font-bold themeable-heading">PDF 리포트 미리보기</h3>
                    <button id="close-pdf-modal" class="p-2 hover:bg-opacity-10 rounded-lg transition-colors accent-text">
                        <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
                        </svg>
                    </button>
                </div>

                <!-- PDF Iframe -->
                <iframe
                    id="pdf-iframe"
                    class="w-full h-[calc(100%-60px)]"
                    src=""
                    frameborder="0"
                    allowfullscreen>
                </iframe>
            </div>
        </div>
    </div>

    <!-- Scripts -->
    <script src="/scripts/common-utils.js"></script>

    <!-- Page Initialization Script -->
    <script>
        document.addEventListener('DOMContentLoaded', async function() {
            const config = {
                mainTitle: "차세대 AI를 위한 세 가지 월드 모델 비교",
                subtitle: "Jeff Hawkins, Yann LeCun, Fei-Fei Li",
                pageTitle: "차세대 AI를 위한 세 가지 월드 모델 비교: Jeff Hawkins, Yann LeCun, Fei-Fei Li | 페블러스",

                publishDate: "2026년 1월 2일",
                publisher: "페블러스 데이터 커뮤니케이션 팀",

                defaultTheme: "light",
                category: "tech",
                articlePath: "project/World Model/world-model-comparison.html",
                tags: [
                    "월드 모델", "World Model",
                    "Jeff Hawkins", "Yann LeCun", "Fei-Fei Li",
                    "천 개의 뇌 이론", "Thousand Brains Theory",
                    "JEPA", "Joint Embedding Predictive Architecture",
                    "공간 지능", "Spatial Intelligence",
                    "World Labs", "Numenta", "Meta AI",
                    "피질 기둥", "Cortical Column",
                    "참조 프레임", "Reference Frame",
                    "SDR", "희소 분산 표현",
                    "Marble", "RTFM",
                    "로보틱스", "Robotics",
                    "AGI", "인공일반지능",
                    "LLM 한계", "생성형 AI",
                    "물리적 AI", "Physical AI",
                    "페블러스", "Pebblous"
                ],

                faqs: [
                    {
                        question: "월드 모델(World Model)이란 무엇인가요?",
                        answer: "월드 모델은 에이전트(인간 또는 기계)가 외부 환경의 구조와 작동 원리를 내부적으로 시뮬레이션하여, 행동의 결과를 예측하고 계획을 수립할 수 있게 하는 인지적 프레임워크입니다. 단순히 데이터를 분류하거나 생성하는 것을 넘어, 지능의 본질인 '이해'와 '생존'을 가능하게 하는 핵심 기제입니다."
                    },
                    {
                        question: "천 개의 뇌 이론(Thousand Brains Theory)의 핵심은 무엇인가요?",
                        answer: "Jeff Hawkins의 천 개의 뇌 이론은 신피질의 약 15만 개 피질 기둥이 각각 독립적인 감각운동 모델링 시스템으로 작동한다는 이론입니다. 이 기둥들은 '투표' 메커니즘을 통해 정보를 교환하고 합의에 도달합니다. 핵심은 뇌가 '참조 프레임'이라는 좌표계를 사용해 정보를 저장하며, 이것이 물리적 객체뿐 아니라 추상적 개념에도 적용된다는 것입니다."
                    },
                    {
                        question: "JEPA와 기존 생성형 AI의 차이점은 무엇인가요?",
                        answer: "Yann LeCun의 JEPA(Joint Embedding Predictive Architecture)는 입력 공간(픽셀)이 아닌 추상적 표현 공간에서 예측을 수행합니다. 기존 생성형 AI가 픽셀을 순차적으로 예측하여 비효율적이고 오류가 누적되는 반면, JEPA는 불필요한 세부 정보를 제거하고 핵심 인과관계만 학습합니다."
                    },
                    {
                        question: "공간 지능(Spatial Intelligence)이 로보틱스에 왜 중요한가요?",
                        answer: "Fei-Fei Li의 공간 지능은 AI가 3D 공간을 이해하고 조작하는 능력입니다. 로봇이 현실 세계에서 안전하게 행동하려면 깊이, 거리, 물리적 상호작용을 이해해야 합니다. World Labs의 Marble은 무한한 3D 시뮬레이션 환경을 생성하여 로봇이 안전하게 학습한 후 현실로 전이(Sim2Real)할 수 있게 합니다."
                    },
                    {
                        question: "세 가지 월드 모델 이론은 상호 배타적인가요?",
                        answer: "아니요, 세 이론은 상호 보완적입니다. Hawkins의 참조 프레임은 데이터 '구조', LeCun의 JEPA는 '추론 엔진', Li의 Marble은 '환경'을 제공합니다. 미래의 AGI는 JEPA를 탑재한 로봇이 Marble로 생성된 세계에서 Hawkins 방식으로 감각운동 학습을 수행하는 형태로 구현될 수 있습니다."
                    },
                    {
                        question: "LLM의 환각(Hallucination) 문제와 월드 모델의 관계는?",
                        answer: "LLM의 환각은 AI가 현실 세계의 법칙에 기반하지 않고 확률적 그럴듯함에 의존하기 때문에 발생합니다. 월드 모델은 물리적 세계의 인과관계와 구조를 내재화함으로써 이 문제를 근본적으로 해결하려 합니다."
                    },
                    {
                        question: "희소 분산 표현(SDR)이란 무엇이며 왜 중요한가요?",
                        answer: "SDR은 Numenta 기술의 기저에 있는 데이터 구조로, 뇌의 뉴런이 매우 희소하게 활성화되는 것을 모방합니다. 2,048개 비트 중 약 2%(40개)만 활성화됩니다. SDR의 각 비트는 의미를 가지며, 겹치는 비트가 많을수록 의미적으로 유사합니다. 활성 비트의 절반이 손실되어도 나머지로 패턴을 유추할 수 있어 노이즈에 강건합니다."
                    }
                ]
            };

            await PebblousPage.init(config);

            // PDF Modal functionality
            const pdfModal = document.getElementById('pdf-modal');
            const pdfIframe = document.getElementById('pdf-iframe');
            const openPdfBtn = document.getElementById('open-pdf-modal');
            const closePdfBtn = document.getElementById('close-pdf-modal');
            const pdfBackdrop = document.getElementById('pdf-modal-backdrop');
            const pdfPath = '/project/World%20Model/source/%EC%B0%A8%EC%84%B8%EB%8C%80%20AI%EB%A5%BC%20%EC%9C%84%ED%95%9C%20%EC%84%B8%20%EA%B0%80%EC%A7%80%20%EC%9B%94%EB%93%9C%EB%AA%A8%EB%8D%B8%20%EB%B9%84%EA%B5%90_%20Jeff%20Hawkins%2C%20Yann%20LeCun%2C%20Fei-Fei%20Li.pdf';

            // Open PDF modal
            if (openPdfBtn) {
                openPdfBtn.addEventListener('click', () => {
                    pdfIframe.src = pdfPath;
                    pdfModal.classList.remove('hidden');
                    document.body.style.overflow = 'hidden';
                });
            }

            // Close PDF modal function
            const closePdfModal = () => {
                pdfModal.classList.add('hidden');
                pdfIframe.src = '';
                document.body.style.overflow = '';
            };

            // Close button click
            if (closePdfBtn) {
                closePdfBtn.addEventListener('click', closePdfModal);
            }

            // Backdrop click
            if (pdfBackdrop) {
                pdfBackdrop.addEventListener('click', closePdfModal);
            }

            // ESC key to close
            document.addEventListener('keydown', (e) => {
                if (e.key === 'Escape' && pdfModal && !pdfModal.classList.contains('hidden')) {
                    closePdfModal();
                }
            });
        });
    </script>
</body>
</html>
