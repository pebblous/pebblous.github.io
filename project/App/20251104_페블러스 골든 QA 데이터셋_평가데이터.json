[
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:1:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제2조(정의) 이 법에서 사용하는 용어의 뜻은 다음과 같다. 1. “데이터”란 다양한 부가가치 창출을 위하여 관찰, 실험, 조사, 수집 등으로 취득하거나 정보시스템 및 「소프트웨 어 진흥법」 제2조제1호에 따른 소프트웨어 등을 통하여 생성된 것으로서 광(光) 또는 전자적 방식으로 처리될 수 있는 자료 또는 정보를 말한다. 2. “공공데이터”란 「공공데이터의 제공 및 이용 활성화에 관한 법률」 제2조제2호에 따른 공공데이터를 말한다. 3. “민간데이터”란 국가기관, 지방자치단체 또는 공공기관(「지능정보화 기본법」 제2조제16호에 따른 공공기관을 말 한다. 이하 같다)이 아닌 자가 생성 또는 취득하여 관리하고 있는 데이터를 말한다. 4. “데이터생산자”란 데이터의 생성ᆞ가공ᆞ제작 등과 관련된 경제활동을 하는 자를 말한다. 5. “데이터산업”이란 경제적 부가가치를 창출하기 위하여 데이터의 생산ᆞ유통ᆞ거래ᆞ활용 등 일련의 과정과 관련 된 행위와 이와 관련되는 서비스를 제공하는 산업을 말한다. 6. “데이터사업자”란 데이터산업을 영위하는 자를 말한다. 7. “데이터거래사업자”란 데이터사업자 중 데이터를 직접 판매하거나 데이터를 판매하고자 하는 자와 구매하고자 하는 자 사이의 거래를 알선하는 것을 업으로 하는 자를 말한다. 8. “데이터분석제공사업자”란 데이터사업자 중 데이터를 수집ᆞ결합ᆞ가공하여 통합ᆞ분석한 정보를 제공하는 행 위를 업으로 하는 자를 말한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf",
                    "page": 1
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터산업법은 데이터의 개념, 유형, 산업 및 관련 산업 종사자에 대한 용어를 정의하고 있다. 데이터는 광 또는 전자적 방식으로 처리될 수 있는 자료 또는 정보이며 데이터를 사용해 경제적 부가가치를 창출하는 것을 데이터산업이라 한다. 데이터의 종류로는 민간데이터와 공공데이터가 있고, 종사자의 경우 데이터생산자, 데이터사업자, 데이터거래사업자, 데이터분석제공사업자가 있다.",
        "long_answer": {
            "question": "데이터산업법에 따른 데이터생산자와 데이터사업자의 차이를 비교해 그 차이점에 대해서 설명하시오.",
            "answer": "데이터생산자는 데이터의 생성, 가공, 제작 등과 관련된 경제활동을 하는 자로, 데이터 자체를 만드는 역할에 중점을 둔다. 반면 데이터사업자는 데이터의 생산, 유통, 거래, 활용 등 데이터 관련 산업을 영위하는 주체이다. 따라서 데이터생산자보다 데이터사업자가 데이터산업의 더 넓은 분야에서 경제활동을 수행한다고 판단할 수 있다.",
            "rubric": [
                "데이터 생산; 데이터 관련 모든 산업; 넓은 분야의 경제활동 수행"
            ]
        },
        "short_answer": {
            "question": "데이터산업법에 따르면, 데이터의 생성 가공, 제작 등과 관련된 경제활동을 하는 자를 가리키는 용어는?",
            "answer": "데이터생산자",
            "topic": [
                "데이터산업법에 따른 데이터생산자의 정의"
            ]
        },
        "multiple_choice": {
            "question": "아래 보기 중 데이터산업법의 용어 정의로 옳지 않은 것을 고르시오.",
            "choices": [
                "a) 데이터사업자는 데이터를 생성·가공·제작만 수행하는 자이다.",
                "b) 데이터는 광 또는 전자적 방식으로 처리될 수 있는 자료나 정보이다.",
                "c) 데이터거래사업자는 데이터 거래를 알선하거나 직접 판매하는 자이다.",
                "d) 데이터분석제공사업자는 데이터를 결합·분석하여 정보를 제공한다."
            ],
            "answer": "a",
            "topic": [
                "데이터산업법의 용어 정의"
            ]
        },
        "true_false": {
            "question": "데이터산업법에서는 데이터분석제공사업자를 데이터의 거래를 알선하고 데이터를 생산하는 자로 정의하고 있다.",
            "answer": "FALSE",
            "topic": [
                "데이터산업법의 용어 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:1:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제3조(국가 등의 책무) 1 국가와 지방자치단체는 데이터 생산, 거래 및 활용 촉진을 위한 기반을 조성하기 위하여 노력 하여야 한다. 2 국가와 지방자치단체는 데이터 생산, 거래 및 활용 촉진에 필요한 범위에서 데이터의 국내외 이동이 이루어질 수 있도록 할 수 있다. 3 국가와 지방자치단체는 민간부문의 창의정신을 존중하고 시장중심의 의사형성이 가능하도록 노력하여야 한다. 4 국가와 지방자치단체는 「지식재산 기본법」 제3조제3호에 따른 지식재산권 및 「개인정보 보호법」 제2조제1호에 따른 개인정보의 활용과 보호를 위하여 노력하여야 한다. 5 국가와 지방자치단체는 데이터산업 관련 대기업과 중소기업 및 벤처기업 간의 상생협력과 조화로운 발전을 위 하여 노력하여야 한다. 6 국가와 지방자치단체는 데이터 생산, 거래 및 활용 촉진에 걸림돌이 되는 규제를 최소화하도록 노력하여야 한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf",
                    "page": 1
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "국가와 지방자치단체는 데이터의 생산·거래·활용을 촉진하기 위해 기반을 조성하고, 민간의 창의성과 시장 중심의 발전을 존중하며 규제를 최소화하도록 노력해야 한다. 또한 지식재산권과 개인정보의 보호를 병행하면서 대기업과 중소기업 간의 상생을 도모해야 한다.",
        "long_answer": {
            "question": "국가와 지방자치단체가 데이터산업 발전을 위해 수행해야 하는 주요 책무를 데이터산업법 제3조에서 세 가지 이상 찾아 제시하시오.",
            "answer": "국가와 지방자치단체의 데이터 산업 발전을 위한 책무로는 데이터의 생산, 거래 및 활용을 촉진하기 위한 기반 조성, 데이터의 국내외 이동이 이루어지도록 하는 것, 민간 부분의 창의정신 존중과 시장 중심의 의사형성, 지식재산권, 개인정보 활용 및 보호, 대기업, 중소 및 벤처기업 간의 상생협력할 수 있도록 하는 것, 데이터 산업에 대한 규제를 최소화하도록 노력하는 것 등이 있다.",
            "rubric": [
                "데이터 산업 기반 조성; 데이터 국내외 이동; 창의정신 존중과 시장중심 의사형성; 지식재산권 존중과 개인정보 활용 및 보호; 기업 간 상생협력; 규제 최소화"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 제3조에 따른 국가와 지방자치단체의 의무 중 데이터 산업 관련 기업의 지식재산권을 보호하기 위한 조항은?",
            "answer": "4항",
            "topic": [
                "데이터산업법에 따른 국가와 지방자치단체의 의무"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법 제3조의 내용으로 가장 거리가 먼 것을 고르세요.",
            "choices": [
                "a) 데이터의 생산·거래·활용을 촉진하기 위한 기반을 조성해야 한다.",
                "b) 데이터의 국내외 이동이 이루어질 수 있도록 할 수 있다.",
                "c) 지식재산권과 개인정보 보호를 위해 노력해야 한다.",
                "d) 규제를 강화하여 데이터의 이용을 제한하도록 명시한다."
            ],
            "answer": "d",
            "topic": [
                "데이터산업법에 따른 국가와 지방자치단체의 의무"
            ]
        },
        "true_false": {
            "question": "데이터산업법 제3조는 국가가 민간의 창의적 활동을 때에 따라서 강하게 제한하도록 명시하고 있다.",
            "answer": "FALSE",
            "topic": [
                "데이터산업법에 따른 국가와 지방자치단체의 의무"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:2:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제5조(시행계획) 1 과학기술정보통신부장관은 기본계획에 따라 연차별 데이터산업 진흥 시행계획(이하 “시행계획”이라 한다)을 수립하여야 한다. 이 경우 공공데이터에 관한 사항에 대해서는 행정안전부장관과 협의하여야 한다. 2 시행계획은 제6조에 따른 국가데이터정책위원회의 심의를 거쳐 확정된다. 3 과학기술정보통신부장관은 관계 중앙행정기관의 장 또는 지방자치단체의 장에게 제1항에 따른 시행계획의 수립에 필요한 자료를 요청할 수 있다. 4 제1항부터 제3항까지에서 규정한 사항 외에 시행계획의 수립ᆞ추진 등에 필요한 사항은 대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:2:0001",
                    "page": 2
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 기본계획에 따라 연차별 데이터산업 진흥 시행계획을 수립해야 한다. 시행계획은 국가데이터정책위원회의 심의를 거쳐 확정되며, 필요한 자료 요청 및 세부 절차는 대통령령으로 정한다.",
        "long_answer": {
            "question": "데이터산업법 제 5조의 내용을 바탕으로 데이터산업 진흥을 위한 시행계획의 수립 주체와 그 역할을 설명하시오.",
            "answer": "데이터산업법 제 5조에 따르면 데이터산업 진흥을 위하여 기본계획에 근거한 연차별 시행계획을 수립하는 주체는 과학기술정보통신부장관이다. 과학기술정보통신부장관은 해당 연차별 시행계획을 수립하고, 관계 중앙행정기관이나 지방자치단체에게 연차별 데이터산업 진흥 시행계획의 수립을 위해 필요한 자료를 요청할 수 있다.",
            "rubric": [
                "데이터산업법; 과학기술정보통신부; 연차별 데이터산업 진흥 시행계획 수립; 관계 중앙행정기관; 지방자치단체; 자료 요청"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 제 5조에 따르면 데이터산업 진흥을 위한 시행계획이 확정되기 위해서는 어떤 절차를 거쳐야 하는가?",
            "answer": "국가데이터정책위원회의 심의",
            "topic": [
                "데이터산업 진흥을 위한 연차별 시행계획 확정 절차"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법 제5조의 내용 중 데이터산업 진흥을 위한 연차별 시행계획 데이터산업 진흥을 위한 연차별 시행계획에 대해 가장 적절한 내용을 고르시오.",
            "choices": [
                "a) 시행계획은 과학기술정보통신부장관이 단독으로 확정한다.",
                "b) 시행계획은 기본계획과 무관하게 수립될 수 있다.",
                "c) 시행계획 수립에 필요한 사항은 법률로 직접 규정된다.",
                "d) 시행계획은 국가데이터정책위원회의 심의를 거쳐 확정된다."
            ],
            "answer": "d",
            "topic": [
                "데이터산업 진흥을 위한 연차별 시행계획 수립"
            ]
        },
        "true_false": {
            "question": "데이터산업법 제5조에 따르면, 데이터산업 진흥을 위한 연차별 시행계획 수립 시 공공데이터 관련 사항은 환경부장관과 협의해야 한다.",
            "answer": "FALSE",
            "topic": [
                "데이터산업 진흥을 위한 연차별 시행계획 수립"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:2:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제7조(다른 법률과의 관계) 1 데이터 생산, 거래 및 활용 촉진에 관하여 다른 법률에 특별한 규정이 있는 경우를 제외 하고는 이 법으로 정하는 바에 따른다. 2 개인정보, 저작권 및 공공데이터에 관하여는 각각 「개인정보 보호법」, 「저작권법」, 「공공데이터의 제공 및 이용 활성화에 관한 법률」 등 다른 법률에서 정하는 바에 따른다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:2:0001",
                    "page": 2
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터산업법 제7조에서는 데이터의 생산, 거래, 활용 촉진에 관한 사항은 이 법에 따르되, 개인정보, 저작권, 공공데이터 등은 각 분야의 개별법에 따르는 것으로 규정하고 있다.",
        "long_answer": {
            "question": "데이터산업법에 따르면 데이터 거래와 관련된 내용이나 저작권법과 관련된 부분이 있다면 있다면 데이터산업법과 저작권법 중 어떤 법률이 적용되는지, 그 이유는 무엇인지 설명하시오.",
            "answer": "데이터산업법 제7조에 따르면, 다른 법률의 특별한 규정이 있는 경우가 아니라면 데이터산업법에 따르나, 개인정보, 저작권 및 공공데이터에 관하여는 각각 개인정보보호법, 저작권법, 공공데이터의 제공 및 이용활성화에 관한 법률 등 다른 법률에 따른다고 명시되어 있다. 따라서 저작권법과 관련된 부분이 있다면 데이터산업법이 아니라 저작권법을 적용해야 한다.",
            "rubric": [
                "데이터산업법 7조; 다른 법률의 특별한 규정; 다른 법률에 따름"
            ]
        },
        "short_answer": {
            "question": "데이터 생산 시 개인정보와 관련한 문제가 발생한 경우 어떤 법률을 적용하여 판단하는지 데이터산업법 제 7조의 내용을 바탕으로 대답하시오.",
            "answer": "개인정보보호법",
            "topic": [
                "데이터산업법과 다른 법률과의 관계"
            ]
        },
        "multiple_choice": {
            "question": "보기 중 데이터산업법 제7조의 내용을 옳게 해석한 내용은?",
            "choices": [
                "a) 데이터산업법은 모든 데이터 관련 사안에 우선 적용된다.",
                "b) 개인정보, 저작권, 공공데이터는 각각 해당 분야의 개별법을 따른다.",
                "c) 다른 법률에 특별한 규정이 있어도 데이터산업법이 우선한다.",
                "d) 데이터산업법은 개인정보 보호법을 대체하기 위한 법이다."
            ],
            "answer": "b",
            "topic": [
                "데이터산업법과 다른 법률과의 관계"
            ]
        },
        "true_false": {
            "question": "데이터산업법 제7조에 따르면, 개인정보 보호에 관한 내용은 모두 데이터산업법에 따라 처리한다.",
            "answer": "FALSE",
            "topic": [
                "데이터산업법과 다른 법률과의 관계"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:3:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제9조(데이터의 생산 활성화) 1 정부는 다양한 분야와 형태의 데이터와 데이터상품이 생산될 수 있는 환경을 조성하여  야 하며, 데이터생산자의 전문성을 높이고 경쟁력을 강화하기 위한 시책을 마련하여야 한다.  2 정부는 데이터생산자에게 데이터 생산에 필요한 재정적ᆞ기술적 지원을 할 수 있다.  3 정부는 인력ᆞ시설ᆞ자재ᆞ자금 및 정보 등의 공동활용을 통한 데이터 또는 데이터상품의 개발ᆞ연구를 촉진할  수 있는 제도적 기반을 구축하기 위하여 노력하여야 한다.  4 관계 중앙행정기관의 장은 대통령령으로 정하는 바에 따라 제1항에 따라 마련된 분야별ᆞ형태별 데이터 생산 활  성화 시책을 시행계획에 반영하여야 한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:3:0001",
                    "page": 3
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "정부는 데이터생산자의 전문성과 경쟁력을 강화하기 위한 시책을 마련해야 한다. 또한 다양한 분야와 형태의 데이터와 데이터상품이 생산될 수 있는 환경을 조성하고, 재정적, 기술적, 제도적 지원을 해야 한다. 관계 중앙행정기관의 장은 1항에 따른 데이터 생산 활성화 시책을 시행계획에 반영해야 한다.",
        "long_answer": {
            "question": "데이터산업법 9조 제2항에서 정부가 수행해야 할 역할과 3항에서의 역할에는 어떤 차이가 있는지 설명하시오.",
            "answer": "데이터산업법 9조 제2항은 정부가 데이터생산자에게 데이터 생산에 필요한 재정적, 기술적 지원을 제공하도록 규정하고 있다. 반면 제3항은 정부가 데이터와 데이터상품의 개발 및 연구를 위한 제도적 기반을 구축해야 한다고 규정하고 있다. 따라서 제 2항은 정부가 해야 할 물리적 지원 방법을, 제 3항은 제도적 지원 방법을 규정하고 있다는 차이를 보인다.",
            "rubric": [
                "재정적 지원; 기술적 지원; 제도적 지원"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 9조는 주로 어떤 대상을 지원하기 위해 마련된 조항인가?",
            "answer": "데이터생산자",
            "topic": [
                "데이터산업법 9조의 지원대상"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법 9조에서 나타나는 데이터산업 관련 주체들이 수행해야 할 내용으로 가장 거리가 먼 것은?",
            "choices": [
                "a) 정부는 다양한 분야와 형태의 데이터와 데이터상품을 만들기 위해 데이터 생산 환경을 조성해야 한다.",
                "b) 관계 중앙행정기관은 시행계획에 정부의 데이터 생산 활성화 시책을 반영해야 한다.",
                "c) 데이터 생산자는 모든 데이터 개발 비용을 부담해야 한다.",
                "d) 정부는 자원의 공동활용을 통해 데이터의 연구개발을 촉진하기 위한 제도적 기반을 구축하기 위해 노력해야 한다."
            ],
            "answer": "c",
            "topic": [
                "데이터산업법 9조에 따른 정책 관련자들의 의무"
            ]
        },
        "true_false": {
            "question": "데이터산업법 제9조는 부패 방지와 데이터생산자의 자생력을 위해 정부의 제도적 지원을 금지하고 있다.",
            "answer": "FALSE",
            "topic": [
                "데이터산업법 9조에 따른 정책 관련자들의 의무"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:3:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제10조(데이터 결합 촉진) 1 과학기술정보통신부장관과 행정안전부장관은 데이터 간의 결합을 통해 새로운 데이터의 생산을 촉진하기 위하여 산업 간의 교류 및 다른 분야와의 융합기반 구축 등에 필요한 시책을 마련하여 추진하여야 한다. 2 과학기술정보통신부장관과 행정안전부장관은 공공데이터와 민간데이터의 결합 촉진을 위한 교류 및 협력 방안 등을 마련하여야 한다. 3 과학기술정보통신부장관은 제1항 및 제2항에 따른 데이터 결합을 촉진하기 위하여 다음 각 호의 사항을 지원할 수 있다. 1. 국내외 연구기관ᆞ대학 및 기업 간의 연계 교육 프로그램의 개발과 시행 2. 산업 간 데이터 전문인력의 교류 활성화 3. 결합 데이터의 거래ᆞ활용을 위한 사업 4. 관련 사업을 실시하는 자에 대한 자금 5. 그 밖에 데이터 결합 및 융합 활성화에 필요한 사항 4 제1항에 따른 시책 마련 및 추진의 내용, 제2항에 따른 교류 및 협력 방안, 제3항에 따른 지원 등에 필요한 사항 은 대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:3:0001",
                    "page": 3
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터산업법 제10조는 과학기술정보통신부장관과 행정안전부장관이 데이터 간 결합을 촉진하여 새로운 데이터를 생산하기 위해 제정되었다. 본 조항에서는 다른 분야, 다른 산업, 공공과 민간 데이터 등 서로 다른 분야와의 융합기반 구축 등에 필요한 시책을 마련, 추진, 지원하도록 규정하고 있다.",
        "long_answer": {
            "question": "데이터산업법 제10조에서 새로운 데이터 생산을 위해 수행해야 할 사항과 이 중 과학기술정보통신부장관이 지원할 수 있는 정책을 세 가지 이상 쓰시오.",
            "answer": "데이터산업법 제 10조에 따른 과학기술정보통신부 장관과 행정안전부 장관은 데이터 결합을 통해 데이터 생산 촉진을 위해 분야 간, 산업 간, 공공과 민간 간 데이터 결합, 다른 분야와의 융합기반 구축 등에 필요한 시책을 마련해야 한다. 이 시책 중 과학기술정보통신부장관은 연구기관, 대학, 기업 간 연계 교육, 산업 간 데이터 전문인력 교류, 결합 데이터의 거래 및 활용 지원, 관련 사업자에 대한 자금 지원, 그 밖의 기타 사항 등을 지원할 수 있다. 이에 필요한 지원 등의 사항은 대통령령으로 정한다.",
            "rubric": [
                "데이터 결합; 연구기관, 대학, 기업 간 연계 교육; 산업 간 데이터 전문인력 교류; 결합 데이터의 거래 및 활용 지원; 관련 사업자에 대한 자금 지원; 그 밖의 기타 사항"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 제10조에서 데이터 산업을 위한 지원방법을 수행해야 하는 수행주체를 모두 말하시오.",
            "answer": "과학기술정보통신부장관, 행정안전부장관",
            "topic": [
                "데이터산업법 제10조의 수행 주체"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법 제10조에서 과학기술정보통신부 장관이 지원할 수 있는 사항으로 옳은 것은?",
            "choices": [
                "a) 단순한 데이터 수집",
                "b) 국내외 연구기관·대학·기업 연계 교육 프로그램 개발",
                "c) 산업 간 경쟁 제한 정책",
                "d) 민간 데이터 비공개 유지"
            ],
            "answer": "b",
            "topic": [
                "연구기관, 대학, 기업 간 연계 교육; 산업 간 데이터 전문인력 교류; 결합 데이터의 거래 및 활용 지원; 관련 사업자에 대한 자금 지원; 그 밖의 기타 사항"
            ]
        },
        "true_false": {
            "question": "데이터산업법 10조에 따르면, 과학기술정보통신부 장관은 공공데이터와 민간데이터 결합을 위한 협력 방안을 마련해야 한다.",
            "answer": "TRUE",
            "topic": [
                "데이터산업법 10조에서 과학기술정보통신부 장관의 역할"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:3:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제11조(데이터안심구역 지정) 1 과학기술정보통신부장관과 관계 중앙행정기관의 장은 누구든지 데이터를 안전하게 분석ᆞ활용할 수 있는 구역(이하 “데이터안심구역”이라 한다)을 지정하여 운영할 수 있다. 2 과학기술정보통신부장관과 중앙행정기관의 장은 데이터안심구역 이용을 지원하기 위하여 미개방데이터, 분석 시스템 및 도구 등을 지원할 수 있다. 3 과학기술정보통신부장관과 관계 중앙행정기관의 장은 제2항에 따른 미개방데이터 지원을 위하여 필요한 경우에 는 정부 및 지방자치단체, 공공기관, 민간법인 등에 데이터 제공을 요청할 수 있다. 4 과학기술정보통신부장관과 중앙행정기관의 장은 제3항에 따른 데이터 제공에 필요한 기술적ᆞ재정적 지원을 할 수 있다. 5 과학기술정보통신부장관과 관계 중앙행정기관의 장은 데이터안심구역에 대한 제3자의 불법적인 접근, 데이터의 변경ᆞ훼손ᆞ유출 및 파괴, 그 밖의 위험에 대하여 대통령령으로 정하는 바에 따라 기술적ᆞ물리적ᆞ관리적 보안대 책을 수립ᆞ시행하여야 한다. 6 제1항부터 제5항까지에서 규정한 사항 외에 데이터안심구역의 지정 및 운영 등에 필요한 사항은 대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:3:0001",
                    "page": 3
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터안심구역은 누구든지 데이터를 안전하게 분석하고 활용할 수 있도록 지정된 구역이다. 과학기술정보통신부장관과 관계 중앙행정기관의 장은 데이터안심구역 이용 시 데이터 지원, 데이터에 제공에 필요한 기술 및 재정적 지원 데이터 훼손을 고려한 보안 대책을 수립하고 및 시행해야 한다.",
        "long_answer": {
            "question": "데이터산업법 제 11조에 규정된 데이터안심구역 운영 시 과학기술정보통신부장관과 관계 중앙행정기관의 장, 민간법인의 역할을 각각 서술하시오.",
            "answer": "과학기술정보통신부장관과 관계 중앙행정기관의 장은 데이터안심구역을 지정, 운영하고, 필요한 경우 정부, 민간 등 기관에 데이터 지원을 요청할 수 있다. 민간법인은 데이터 제공자이자 동시에 데이터안심구역의 이용자이다. 과학기술정보통신부장관과 관계 중앙행정기관의 장의 요청을 받으면 데이터 제공자가 되어 데이터 활용을 지원하거나 데이터안심구역을 이용할 수 있다.",
            "rubric": [
                "데이터안심구역 지정; 데이터안심구역 운영; 데이터 지원 요청; 데이터 제공자; 데이터안심구역 이용자;"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 제 11조에 따라, 과학기술정보통신부장관과 관계 중앙행정기관의 장이 데이터안심구역 운영을 위해 데이터 제공을 요구할 수 있는 대상은?",
            "answer": "정부 및 지방자치단체, 공공기관, 민간법인 등",
            "topic": [
                "데이터안심구역 운영에 필요한 데이터 제공 대상"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법 제 11조에 규정된 데이터안심구역에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 데이터안심구역에서는 누구든지 데이터를 무제한 공유할 수 있다.",
                "b) 데이터안심구역은 과학기술정보통신부장관이 단독으로 지정할 수 있다.",
                "c) 데이터안심구역의 보안은 데이터안심구역 이용자가 단독으로 점검하고, 이에 따른 책임을 져야 한다.",
                "d) 데이터안심구역에서는 데이터의 안전한 분석과 활용을 위해 미개방데이터와 도구를 지원받을 수 있다."
            ],
            "answer": "d",
            "topic": [
                "데이터안심구역의 특징"
            ]
        },
        "true_false": {
            "question": "데이터안심구역에서는 제3자의 불법 접근과 데이터 훼손에 대비한 보안대책이 수립·시행되어야 한다.",
            "answer": "TRUE",
            "topic": [
                "데이터안심구역의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:4:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제14조(가치평가 지원 등) 1 과학기술정보통신부장관은 데이터에 대한 객관적인 가치평가를 촉진하기 위하여 데이터 (공공데이터는 제외한다. 이하 이 조에서 같다) 가치의 평가 기법 및 평가 체계를 수립하여 이를 공표할 수 있다. 2 과학기술정보통신부장관은 제1항에 따른 평가 기법 및 평가 체계가 데이터 관련 거래ᆞ금융 등에 활용될 수 있 도록 지원하여야 한다. 3 과학기술정보통신부장관은 유통되는 데이터에 대한 가치평가를 전문적ᆞ효율적으로 하기 위하여 가치평가기관 (이하 “평가기관”이라 한다)을 지정할 수 있다. 4 데이터에 관한 가치평가를 받으려는 자는 제3항에 따라 지정된 평가기관에 신청할 수 있다. 5 제4항에 따라 가치평가 신청을 받은 평가기관은 데이터에 대하여 가치평가를 하고 그 결과를 신청한 자에게 지 체 없이 통보하여야 한다. 6 평가기관은 경영ᆞ영업상 비밀의 유지 등 대통령령으로 정하는 특별한 사유가 있는 경우 외에는 해당 연도의 가 치평가 정보를 다음 연도 1월 말까지 과학기술정보통신부장관에게 통보하여야 한다. 7 평가기관의 장은 다음 각 호의 사항에 관하여 과학기술정보통신부장관과 협의하여야 한다. 1. 평가 대상 2. 평가 범위 3. 평가 수수료 8 평가기관의 지정기준ᆞ지정절차, 가치평가의 신청절차 등에 관하여 필요한 사항은 대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:4:0001",
                    "page": 4
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 데이터의 객관적 가치평가를 촉진을 위해 평가 체계를 수립하고, 이를 거래 및 금융 등에 활용할 수 있도록 지원한다. 또한 유통되고 있는 데이터를 전문적·효율적으로 평가하기 위해 가치평가기관을 지정할 수 있다.",
        "long_answer": {
            "question": "데이터산업법 제14조에 따라 유통되는 데이터의 가치평가를 받는 과정을 서술하시오.",
            "answer": "유통되고 있는 데이터에 대해 가치평가를 받기 위해서는 먼저 가치평가를 받으려는 자가 지정된 평가기관에 신청해야 한다. 평가기관은 가치평가 신청을 받은 데이터에 대해 가치평가를 수행한다. 가치평가 결과가 도출되면 그 결과를 지체없이 신청한 이에게 통보해야 한다.",
            "rubric": [
                "가치평가 신청; 가치평가; 결과 통보;"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 제14조에 따라 유통되는 데이터의 가치평가는 어떤 기관에서 이루어지는가?",
            "answer": "가치평가기관",
            "topic": [
                "데이터 가치평가 주체"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법 14조에서 명시된 데이터 가치평가기관에 대한 설명과 가장 부합하는 것은?",
            "choices": [
                "a) 가치평가기관은 데이터 가치평가를 수행하고 결과를 신청자에게 통보해야 한다.",
                "b) 가치평가기관은 대통령이 직접 지정해야 하며, 이를 장관이 운영한다.",
                "c) 가치평가기관의 경우 공공데이터만을 평가 대상으로 삼는다.",
                "d) 법률에 의해 가치평가기관의 평가 수수료는 일정 액수로 고정되어 있다."
            ],
            "answer": "a",
            "topic": [
                "데이터 가치평가기관의 특징"
            ]
        },
        "true_false": {
            "question": "과학기술정보통신부장관은 데이터 가치평가 체계를 공표하고 이를 거래 및 금융에 활용할 수 있도록 지원해야 한다.",
            "answer": "TRUE",
            "topic": [
                "데이터 가치평가 체계 수립"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:4:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제16조(데이터사업자의 신고) 1 다음 각 호의 사업자는 과학기술정보통신부장관에게 신고하여야 한다. 신고한 사항을  변경하는 경우에도 또한 같다.  1. 데이터거래사업자  2. 데이터분석제공사업자  2 과학기술정보통신부장관 및 관계 중앙행정기관의 장은 제1항에 따라 신고한 사업자에 대하여 필요한 재정적ᆞ  기술적 지원 등을 할 수 있다.  3 제1항에 따른 신고 기준 및 절차 등에 관하여 필요한 사항은 과학기술정보통신부령으로 정한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:4:0001",
                    "page": 4
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터거래사업자와 데이터분석제공사업자는 과학기술정보통신부장관에게 신고해야 한다. 신고한 내용이 변경될 경우에도 다시 신고해야 하며, 신고한 사업자는 필요 시 재정적·기술적 지원을 받을 수 있다.",
        "long_answer": {
            "question": "데이터사업 운영 및 변경 시 사업자가 해야 하는 신고 및 신고한 사업자가 받을 수 있는 지원내용을 설명하세요.",
            "answer": "데이터사업자 중 데이터거래사업자와 데이터분석제공사업자는 사업을 개시할 때와 신고내용이 변경되었을 때 해당 내용을 과학기술정보통신부장관에게 신고해야 한다. 신고 절차와 기준은 과학기술정보통신부령에 따른다. 신고를 완료한 데이터사업자는 과학기술정보통신부장관 및 관계 중양행정기관 장에게 재정, 기술적 지원을 받을 수 있다.",
            "rubric": [
                "과학기술정보통신부장관; 데이터거래사업자; 데이터분석제공사업자; 변경신고; 재정 및 기술적 지원"
            ]
        },
        "short_answer": {
            "question": "데이터사업 중 사업내용이 변경되었을 경우, 해당 내용을 누구에게 신고해야 하는가?",
            "answer": "과학기술정보통신부장관",
            "topic": [
                "데이터사업자의 사업내용 변경신고"
            ]
        },
        "multiple_choice": {
            "question": "데이터사업자 신고와 관련하여 옳은 설명은?",
            "choices": [
                "a) 데이터거래사업자와 데이터분석제공사업자는 신고 대상이다.",
                "b) 데이터사업 신고 내용은 변경되어도 다시 신고할 필요가 없다.",
                "c) 과학기술정보통신부장관은 신고한 데이터사업자에 대해 지원할 수 없다.",
                "d) 데이터사업 신고 기준과 절차는 기업이 자율적으로 정한다."
            ],
            "answer": "a",
            "topic": [
                "데이터사업자 사업 신고"
            ]
        },
        "true_false": {
            "question": "기존 데이터사업자가 이전에 신고했던 내용과 현재 사업 내용이 달라지면 재신고 절차를 밟아야 한다.",
            "answer": "TRUE",
            "topic": [
                "데이터사업자의 사업내용 변경신고"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:5:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제20조(데이터 품질관리 등) 1 과학기술정보통신부장관은 데이터의 품질향상을 위하여 행정안전부장관과 협의하여 품질인증 등 품질관리에 필요한 사업을 추진할 수 있다. 2 과학기술정보통신부장관은 제1항에 따라 품질관리에 필요한 사업을 실시하는 자에게 소요되는 자금의 전부 또 는 일부를 지원할 수 있다. 3 과학기술정보통신부장관은 제1항에 따른 데이터 품질인증을 실시하기 위하여 인증기관을 지정할 수 있다. 4 제3항에 따라 지정받은 인증기관은 데이터 품질인증 신청을 받은 경우 대통령령으로 정하는 품질기준 등에 따라 품질인증을 하여야 한다. 5 제1항부터 제4항까지에서 규정한 사항 외에 품질인증의 대상, 인증기관의 지정 요건, 품질기준 및 품질관리 등에 필요한 사항은 대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:5:0001",
                    "page": 5
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 데이터 품질향상을 위하여 행정안전부장관과 협의하여 데이터 품질관리 관련 사업에 대한 자금지원, 품질인증기관 지정 등을 추진할 수 있다. 품질인증 대상, 인증기관, 품질기준 및 품질관리에 필요한 사항은 대통령령으로 정한다.",
        "long_answer": {
            "question": "데이터산업법 제 20조 내용 중, 데이터 품질관리 인증기관 지정과 품질관리 사업 자금 지원의 차이에 대해 서술하시오.",
            "answer": "데이터 품질인증기관 지정은 데이터 품질관리를 위해 품질인증을 체계적으로 수행할 수 있는 기관을 법적으로 정하는 제도이다. 반면 품질관리 사업 자금 지원은 인증기관이나 품질관리 사업을 실시하는 주체에게 경제적 지원을 제공하는 것이다. 품질인증기관은 데이터 품질기준을 정부에서 직접 관리하기 위한 수단이며, 품질관리 사업자금 지원은 데이터 품질관리를 간접적으로 지원하는 수단이다.",
            "rubric": [
                "품질인증; 법적; 경제적 지원; 정부; 직접; 간접;"
            ]
        },
        "short_answer": {
            "question": "과학기술정보통신부장관이 데이터의 품질향상을 위하여 품질인증 등 품질관리사업을 추진할 때 협의해야 할 관계기관의 장은?",
            "answer": "행정안전부장관",
            "topic": [
                "데이터 품질관리사업 추진 시 협의 대상"
            ]
        },
        "multiple_choice": {
            "question": "보기 중 데이터산업법 20조에 따른 정부 차원의 데이터 품질관리 제도에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 품질관리 사업은 대통령령으로 세부사항이 정해진다.",
                "b) 인증기관은 대통령령으로 정한 품질기준에 따라 인증한다.",
                "c) 품질관리 사업과 관련된 모든 사항은 행정안전부장관이 단독 결정한다.",
                "d) 과학기술정보통신부장관은 품질관리 사업을 수행할 자금을 지원할 수 있다."
            ],
            "answer": "c",
            "topic": [
                "데이터산업법 제20조의 데이터 품질관리 제도"
            ]
        },
        "true_false": {
            "question": "데이터산업법에 따르면, 데이터 품질인증 대상과 인증기관 지정 요건 등 세부 기준은 헌법으로 규정되어 있다.",
            "answer": "FALSE",
            "topic": [
                "데이터산업법 제20조의 데이터 품질관리 세부 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:6:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제24조(창업 등의 지원) 1 정부는 데이터 기반 산업을 활성화하고 기업의 데이터 생산, 거래 및 활용에 관한 역량을 강 화하기 위하여 다음 각 호의 지원을 할 수 있다. 1. 데이터 기반 상품ᆞ서비스의 개발을 위한 추진과제의 발굴ᆞ실행 및 테스트베드의 운영 2. 데이터 기반 기업의 기술역량 강화를 위한 교육 프로그램의 실행 3. 데이터산업 투자생태계 활성화를 위한 지원 4. 데이터 관련 분야 예비창업자, 창업자 또는 기업을 위한 상담과 관련된 사무의 지원 5. 데이터 기반의 우수한 아이디어의 발굴 및 사업화 지원 6. 그 밖에 대통령령으로 정하는 사항 2 정부는 데이터의 생산, 거래 및 활용 등과 관련한 기술을 보유한 데이터 전문기업의 육성을 위하여 노력하여야 한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:6:0001",
                    "page": 6
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "정부는 데이터 기반 산업의 활성화를 위해 기업의 데이터 생산, 거래 및 활용 역량을 강화하기 위해 다양한 지원사업을 추진할 수 있다. 또한 데이터 전문기업 육성을 위해 노력해야 한다.",
        "long_answer": {
            "question": "데이터산업법 제 24조에 따라 정부가 데이터 기반 산업 활성화를 위해 추진할 수 있는 주요 지원 방안을 두 가지 이상 쓰시오.",
            "answer": "정부는 데이터 기반 산업 활성화를 위해 다양한 지원사업을 추진할 수 있다. 이 중에는 데이터 기반 상품·서비스 개발을 위한 과제 발굴 및 테스트베드 운영, 데이터 기반 기업의 기술역량을 강화하기 위한 교육 프로그램 시행, 데이터산업 투자생태계 활성화를 위한 지원, 예비창업자와 창업자를 위한 상담 지원, 데이터 기반 아이디어의 발굴 및 사업화 지원 등이 있다. 또한 언급된 지원 외에 대통령령으로 정하는 사항을 지원할 수 있다.",
            "rubric": [
                "데이터 기반 상품 및 서비스 개발을 위한 과제 발굴 및 테스트베드 운영; 데이터 기반 기업의 기술역량을 강화하기 위한 교육 프로그램 시행; 데이터산업 투자생태계 활성화를 위한 지원; 예비창업자와 창업자를 위한 상담 지원; 데이터 기반 아이디어의 발굴 및 사업화 지원; 대통령령으로 정하는 사항"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 제 24조에서 정부가 육성하기 위해 노력해야 한다고 명시하고 있는 기업은?",
            "answer": "데이터의 생산, 거래 및 활용 등과 관련한 기술을 보유한 데이터 전문기업",
            "topic": [
                "데이터산업법 24조에 따른 정부의 데이터 전문기업 육성 지원"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법 제24조의 내용에 대해 설명한 것으로 맞지 않는 것은?",
            "choices": [
                "a) 정부는 데이터 기반 기업의 기술역량 강화를 위한 교육 프로그램을 실행할 수 있다.",
                "b) 정부는 데이터산업 투자생태계 활성화를 위해 지원할 수 있다.",
                "c) 정부는 데이터 관련 창업자의 상담 지원 서비스를 수행하지 않는다.",
                "d) 정부는 우수한 아이디어의 발굴 및 사업화 지원을 할 수 있다."
            ],
            "answer": "c",
            "topic": [
                "데이터산업법 24조에서 정부의 역할"
            ]
        },
        "true_false": {
            "question": "데이터산업법 24조에 따르면, 정부는 데이터의 생산·거래·활용 관련 기술을 보유한 데이터 전문기업을 육성하기 위해 노력해야 한다.",
            "answer": "TRUE",
            "topic": [
                "데이터산업법 24조에서 정부의 역할"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:6:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제25조(전문인력의 양성) 1 과학기술정보통신부장관과 행정안전부장관은 데이터 전문인력을 양성하기 위하여 다음 각 호의 사항의 시책을 마련하여야 한다. 1. 데이터 전문인력 양성을 위한 정책의 기본방향 및 전문인력의 활용 방안 2. 데이터 전문인력 교육ᆞ훈련 프로그램의 개발 및 활용에 관한 방안 3. 데이터 전문인력의 양성을 위한 학계, 산업계 및 공공기관과의 협력 방안 4. 데이터 전문인력의 고용창출 및 고용연계 지원 방안 5. 데이터 관련 직무표준의 마련 및 자격ᆞ신직종의 정착 지원 방안 2 과학기술정보통신부장관과 행정안전부장관은 제1항의 시책에 따라 실시하는 교육 및 훈련이 「자격기본법」 제 6조의 자격체제에 부합하도록 노력하여야 한다. 3 과학기술정보통신부장관은 대통령령으로 정하는 바에 따라 대학ᆞ연구기관 그 밖의 전문기관을 데이터 전문인 력 양성기관으로 지정하고, 교육 및 훈련에 필요한 사항을 지원할 수 있다. 4 제3항에 따라 지정된 양성기관이 실시하는 데이터 전문인력 양성 교육 및 훈련이 「국민 평생 직업능력 개발법」 에 따른 직업능력개발훈련에 해당하는 경우 국가는 관련법에 따라 훈련비용을 지원한다. 5 제3항에 따른 양성기관의 지정, 운영 및 지정 취소 등에 필요한 사항은 대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:6:0001",
                    "page": 6
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 행정안전부장관이 데이터 전문인력 양성을 위한 정책과 교육훈련, 협력체계, 고용지원, 직무표준 마련 등의 시책을 수립하고 추진해야 한다. 이 시책에 기반한 교육훈련은 자격기본법의 자격체계에 부합하도록 노력해야 한다. 또한 대통령령으로 정하는 바에 따라 데이터 전문인력 양성기관을 지정하고 지원할 수 있다.",
        "long_answer": {
            "question": "데이터산업법 25조의 내용 중, 데이터 전문인력 양성을 위한 시책과 데이터 전문인력 양성기관 지정의 차이점을 비교하라.",
            "answer": "데이터 전문인력 양성 시책은 정부 차원에서 추진해야 하는 정책 방향과 교육, 협력, 고용 등 넓은 범위의 지원방안이다. 반면 데이터인력 양성기관 지정은 대통령령에 따라 데이터 전문인력의 훈련을 위해 양성기관을 기관을 선정하고 지원하는 구체적인 지원 절차이다. 두 가지 모두 데이터 전문인력 양성을 위한 방법이지만 지원방식과 지원범위에서 차이가 있다.",
            "rubric": [
                "넓은 범위의 지원방안; 구체적인 지원 절차"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 25조에 따르면, 데이터 전문인력 양성을 담당하는 주체는 누구인가?",
            "answer": "과학기술정보통신부장관과 행정안전부장관",
            "topic": [
                "데이터 전문인력 양성 담당 주체"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법 제25조의 데이터 전문인력 양성 지원에 대한 내용으로 옳지 않은 것을 선택하시오.",
            "choices": [
                "a) 데이터 전문인력 양성 시책에는 고용창출 및 연계 지원 방안이 포함된다.",
                "b) 데이터 전문인력 양성기관 지정에 관한 사항은 국회의 결정에 따른다.",
                "c) 데이터 전문인력 교육훈련은 자격기본법에 부합하도록 노력해야 한다.",
                "d) 대통령령으로 지정·운영 및 지정취소의 기준을 정할 수 있다."
            ],
            "answer": "b",
            "topic": [
                "데이터산업법 25조의 데이터 전문인력 양성 지원 방안"
            ]
        },
        "true_false": {
            "question": "과학기술정보통신부장관은 대통령령에 따라 데이터 전문인력 양성기관을 지정할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "데이터산업법 25조의 데이터 전문인력 양성기관 지정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:6:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제26조(기술개발의 촉진 및 시범사업 지원) 1 과학기술정보통신부장관은 데이터의 생산ᆞ거래 및 활용에 관한 기술개 발의 추진과 관련하여 민간 부문의 데이터 관련 기술 연구개발을 활성화하고 연구개발투자의 확대를 유도하기 위한 지원시책을 세우고 추진하여야 한다. 2 제1항에 따른 시책에는 다음 각 호에 관한 사항이 포함되어야 한다. 1. 기술의 발전목표 및 산업에의 적용 방안 2. 기술개발 촉진을 위한 투자 재원의 확보 3. 기술개발을 위한 연구개발사업의 추진과 산업계ᆞ학계ᆞ공공기관 간의 협동연구 및 학제 간 연구의 촉진 방안 4. 기술 연구인력ᆞ시설 및 정보 등 연구기반의 확충 5. 국제협력의 촉진 6. 연구성과의 확산 및 기술이전",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:6:0001",
                    "page": 6
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 데이터 생산·거래·활용 관련 기술개발을 촉진, 민간의 데이터 관련 기술 연구개발을 활성화, 연구개발투자 확대를 위한 지원 시책을 세우도록 규정하고 있다. 이 시책에는 기술 발전목표 및 산업적용 방안, 투자재원 확보, 국제협력 촉진 등 여섯 가지 사항이 포함되어야 한다.",
        "long_answer": {
            "question": "데이터산업법 제26조에 따라 과학기술정보통신부장관이 추진해야 하는 기술개발 촉진 시책의 주요 내용을 간략히 설명하시오.",
            "answer": "과학기술정보통신부장관은 데이터의 생산, 거래 및 활용 관련 기술개발을 촉진하기 위해 다양한 지원 시책을 세워야 한다. 이러한 시책에는 여섯 가지의 사항이 포함되어야 한다. 해당 사항에는 기술의 발전목표 및 산업 적용 방안, 연구개발 투자 재원의 확보, 산업계·학계·공공기관 간 협동연구의 촉진, 연구인력과 시설 등 연구기반의 확충, 국제협력의 촉진, 연구성과의 확산 및 기술이전 등의 요소가 있다.",
            "rubric": [
                "기술의 발전목표 및 산업 적용 방안; 연구개발 투자 재원 확보; 분야 및 기관 간 협동연구 및 학제 간 연구 촉진; 연구기반 확충; 국제협력 촉진; 연구성과 확산 및 기술이전"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 제 26조에 따르면 기술개발 촉진 및 시업사업 지원사항에서 규정하는 연구기반이란?",
            "answer": "기술 연구인력과 시설 및 정보 등",
            "topic": [
                "데이터산업법 제 26의 기술개발 촉진 및 시범사업 지원 내용"
            ]
        },
        "multiple_choice": {
            "question": "보기 중 데이터산업법 제26조의 내용으로 옳은 것을 골라라.",
            "choices": [
                "a) 과학기술정보통신부장관은 민간의 기술개발을 제한해야 한다.",
                "b) 기술개발 촉진을 위한 투자 재원의 확보가 포함된다.",
                "c) 연구성과의 확산은 기술개발 시책에서 제외된다.",
                "d) 기술개발은 공공기관에만 국한된다."
            ],
            "answer": "b",
            "topic": [
                "데이터산업법 제 26의 기술개발 촉진 및 시범사업 지원 내용"
            ]
        },
        "true_false": {
            "question": "데이터산업법 제26조의 기술개발을 위한 지원내용에는 국제협력 촉진이 포함되어 있다.",
            "answer": "TRUE",
            "topic": [
                "데이터산업법 제 26의 기술개발 촉진 및 시범사업 지원 내용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:7:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제27조(실태조사) 1 과학기술정보통신부장관은 데이터 거래 및 활용 기반 산업을 촉진하고, 이 법에 따른 시책 및 계획을 효율적으로 수립ᆞ추진하기 위하여 매년 데이터 산업 기반 및 데이터 대상 거래 현황 및 실태에 대한 조사를 실시하고 그 결과를 공표할 수 있다. 2 과학기술정보통신부장관은 제1항의 실태조사를 위하여 필요한 때에는 관계 중앙행정기관의 장, 지방자치단체의 장 또는 공공기관의 장에게 관련 자료(공공데이터에 관한 사항은 제외한다)를 요청할 수 있다. 이 경우 자료를 요청받은 관계 중앙행정기관의 장 등은 특별한 사정이 없으면 요청에 따라야 한다. 3 과학기술정보통신부장관은 데이터사업자나 그 밖의 관련 기관 또는 단체에 대하여 제1항의 실태조사를 위하여 필요한 사항에 대한 협조를 요청할 수 있다. 4 과학기술정보통신부장관은 대통령령으로 정하는 전문기관에 제1항에 따른 실태조사를 의뢰할 수 있다. 5 제1항에 따른 실태조사의 범위와 방법 및 그 밖에 필요한 사항은 대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:7:0001",
                    "page": 7
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 데이터 산업의 기반 조성과 효율적인 정책 추진을 위해 매년 데이터 거래 및 활용 현황을 조사하고 공표할 수 있다. 또한 관계 기관과 단체에 자료 제출과 협조를 요청하거나 전문기관에 실태조사를 의뢰할 수 있다.",
        "long_answer": {
            "question": "데이터산업법 제27조에 따라 과학기술정보통신부장관이 실시하는 실태조사의 목적과 내용에 대해 설명하시오.",
            "answer": "데이터산업법 27조에서는 데이터 산업 기반과 거래 현황을 파악하여 산업 촉진과 정책 수립을 지원하기 위한 실태조사를 실시하도록 하고 있다. 과학기술정보통신부 장관은 매년 조사를 수행하고 그 결과를 공표할 수 있다. 이 과정에서 과학기술정보통신부 장관은 필요 시 관계 중앙행정기관, 지방자치단체 또는 공공기관에 자료를 요청할 수 있고, 데이터사업자 및 관련 단체의 협조를 구하거나 대통령령으로 정하는 전문기관에 조사를 의뢰할 수도 있다.",
            "rubric": [
                "조사 수행; 결과 공표; 자료 요청; 조사 의뢰"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 27조에서 데이터 거래 및 활용 현황 실태조사 수행을 위해 과학기술정보통신부장관이 요청할 수 있는 대상은?",
            "answer": "관계 중앙행정기관의 장, 지방자치단체의 장, 공공기관의 장, 데이터사업자, 관련 기관 또는 단체, 대통령령으로 정하는 전문기관",
            "topic": [
                "데이터산업법 27조 데이터 거래 및 활용 현황 실태조사 내용"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법 제27조의 내용과 일치하지 않는 것은?",
            "choices": [
                "a) 실태조사는 데이터 거래 및 활용 현황을 대상으로 한다.",
                "b) 과학기술정보통신부장관은 데이터 거래 및 활용 현황 실태조사 결과를 공표할 수 있다.",
                "c) 데이터 거래 및 활용 현황 실태조사 시 공공데이터에 관한 사항도 자료 요청 대상에 포함된다.",
                "d) 데이터 거래 및 활용 현황 실태조사 시 관계기관은 특별한 사정이 없으면 요청에 따라야 한다."
            ],
            "answer": "c",
            "topic": [
                "데이터산업법 27조 데이터 거래 및 활용 현황 실태조사 내용"
            ]
        },
        "true_false": {
            "question": "데이터산업법 제27조에 따른 실태조사는 반드시 장관이 현장에서 직접 수행해야 한다.",
            "answer": "FALSE",
            "topic": [
                "데이터산업법 27조 데이터 거래 및 활용 현황 실태조사 주체"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:7:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제28조(표준화의 추진) 1 과학기술정보통신부장관은 행정안전부장관과 협의하여 데이터의 호환성을 확보함으로써 각 종 상품과 서비스에서의 데이터의 결합, 거래 및 활용을 촉진하기 위하여 다음 각 호의 사항에 대한 표준화 기준을 마련하여 고시할 수 있다. 다만, 「산업표준화법」에 따른 한국산업표준이 제정되어 있는 사항에 대하여는 그 표준에 따르며, 한국산업표준의 제정ᆞ개정 등을 추진할 경우에는 같은 법에서 정하는 바에 따른다. 1. 데이터의 저장 형태 및 이전 방식 2. 데이터의 분류 체계 3. 그 밖에 데이터의 결합, 거래 및 활용을 위하여 필요한 사항 2 과학기술정보통신부장관은 데이터의 표준화를 위한 조사ᆞ연구ᆞ개발, 국제표준화기구와의 협력체계 구축 등 데이터 표준화에 필요한 사업을 추진할 수 있다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:7:0001",
                    "page": 7
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 행정안전부장관과 협의하여 데이터의 호환성을 확보하여 데이터 결합, 거래 및 활용을 촉진하기 위한 표준화 기준을 마련하고 고시할 수 있다. 또한 데이터 표준화를 위한 조사·연구·개발 및 국제 협력 사업 등을 추진할 수 있다.",
        "long_answer": {
            "question": "데이터산업법 제28조의 내용을 바탕으로 데이터 표준화를 해야 하는 목적과 그 내용을 설명하라.",
            "answer": "데이터 표준화의 목적은 데이터의 호환성을 확보하여 각종 상품과 서비스에서 데이터의 결합, 거래, 활용을 촉진하기 위한 것이다. 과학기술정보통신부장관은 행정안전부장관과의 협의를 통해 데이터의 저장 형태, 이전 방식, 분류 체계 등의 표준화 기준을 마련하여 고시할 수 있다. 이 과정에서 데이터 표준화를 위한 조사, 연구, 개발 등 각종 사업을 추진할 수 있다.",
            "rubric": [
                "데이터 호환성; 데이터 결합, 거래, 활용 촉진; 표준화 기준 마련; 조사, 연구, 개발 등 사업 추진"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 제 28조의 내용 중, 데이터 표준화 기준을 마련해야 하는 항목에는 어떤 것이 있는가?",
            "answer": "저장 형태, 이전 방식, 분류 체계, 그 밖에 데이터의 결합, 거래 및 활용을 위하여 필요한 사항",
            "topic": [
                "데이터산업법 제 28조 중 데이터 표준화 기준 항목"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법의 데이터의 표준화 추진 조항에 포함된 내용으로 맞지 않는 것은?",
            "choices": [
                "a) 데이터의 호환성 확보는 데이터 결합과 거래 촉진을 위한 것이다.",
                "b) 산업표준이 제정된 경우 그 표준에 따른다.",
                "c) 국제표준화기구와의 협력체계 구축이 가능하다.",
                "d) 과학기술정보통신부장관은 표준화를 위한 연구개발 사업을 추진할 수 없다."
            ],
            "answer": "d",
            "topic": [
                "데이터산업법 제 28조의 내용"
            ]
        },
        "true_false": {
            "question": "데이터산업법 제28조에 따르면, 산업표준에 규정되어 있는 데이터라도 반드시 새로운 표준을 만들어야 한다.",
            "answer": "FALSE",
            "topic": [
                "데이터산업법 내의 표준화 추진 조항과 산업표준화법의 관계"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:7:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제30조(세제지원 등) 1 국가 또는 지방자치단체는 데이터산업의 촉진을 위하여 관련 사업의 수행과 관련한 국세 또는  지방세를 「조세특례제한법」, 「지방세특례제한법」 및 그 밖에 조세 관계 법률 및 조례로 정하는 바에 따라 감면할 수  있다.  2 국가 또는 지방자치단체는 이 법의 목적을 달성하기 위하여 필요하면 대통령령으로 정하는 경우에 한정하여 데  이터사업자에게 보조금을 지급하거나 장기대부를 할 수 있다.  3 과학기술정보통신부장관은 제1항 및 제2항의 조치와 관련하여 행정상 필요한 지원을 할 수 있다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:7:0001",
                    "page": 7
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "국가 또는 지방자치단체는 데이터산업의 촉진을 위해 세제 감면, 보조금 지급, 장기대부 등의 지원을 할 수 있다. 과학기술정보통신부장관은 해당 지원 조치에 관련된 행정적 지원을 제공할 수 있다.",
        "long_answer": {
            "question": "데이터산업 촉진을 위해 데이터사업자의 세금을 감면해줄 때, 감면 주체가 국가일 때와 지방자치단체일 때의 차이를 설명하시오.",
            "answer": "국가와 지방자치단체 모두 데이터산업을 촉진하기 위한 세제 감면 및 재정 지원의 주체로 규정되어 있다. 국가는 조세특례제한법과 그밖에 관계법령에 따라 사업자의 국세를 감면할 수 있고, 지방자치단체는 지방세특례제한법과 관계 법령, 지방 조례에 따라 지방세를 감면할 수 있다. 두 감면 주체의 목적은 같으나 적용되는 법률과 관계법령, 조례 등의 세부적인 차이가 있다.",
            "rubric": [
                "조세특례제한법; 조세 관계 법률; 지방세특례제한법; 조례"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 제 30조에서 데이터사업자에게 세금을 감면해줄 수 있는 지원 주체 두 가지를 모두 쓰시오.",
            "answer": "국가, 지방자치단체",
            "topic": [
                "데이터산업법 제 30조 중 데이터사업자 세금 감면"
            ]
        },
        "multiple_choice": {
            "question": "보기 중 데이터산업법 제30조의 내용과 일치하지 않는 것을 선택하시오.",
            "choices": [
                "a) 과학기술정보통신부장관은 데이터사업자의 세제 지원, 보조금 지원 등을 직접 추진할 수 있다.",
                "b) 데이터사업자는 대통령령으로 정한 경우 보조금을 받을 수 있다.",
                "c) 국가 또는 지방자치단체는 데이터산업 촉진을 위해 세제 및 재정 지원을 할 수 있다.",
                "d) 데이터사업자의 세제 감면은 조세특례제한법 및 지방세특례제한법에 따라 진행한다."
            ],
            "answer": "c",
            "topic": [
                "데이터산업법 제 30조 데이터사업자의 세제지원 내용"
            ]
        },
        "true_false": {
            "question": "입법부는 데이터산업법 제30조에 의거해 데이터사업자에게 데이터산업 보조금을 자체적으로 지급할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "데이터산업법 제 30조 중 데이터사업자 보조금 지원 주체"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:9:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제36조(위원의 제척ᆞ기피 및 회피) 1 위원회의 위원은 다음 각 호의 어느 하나에 해당하는 경우에는 해당 조정사건의 조정에서 제척(除斥)된다. 1. 위원이나 그 배우자 또는 배우자였던 사람이 사건의 당사자가 되거나 사건의 당사자와 공동권리자ᆞ공동의무자 의 관계에 있는 경우 2. 위원이 사건의 당사자와 친족이거나 친족이었던 경우 3. 위원이 해당 사건에 관하여 증언이나 감정(鑑定)을 한 경우 4. 위원이 해당 사건에 관하여 당사자의 대리인으로서 관여하거나 관여하였던 경우 2 당사자는 위원에게 공정한 조정을 기대하기 어려운 사정이 있는 경우에는 위원회에 기피신청을 할 수 있고, 위원 회는 의결로 이를 결정한다. 이 경우 기피신청의 대상인 위원은 그 의결에 참여하지 못한다. 3 위원이 제1항이나 제2항의 사유에 해당하는 경우에는 스스로 해당 사건의 조정을 회피하여야 한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:9:0001",
                    "page": 9
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 분쟁조정위원회의 위원은 당사자와의 관계, 사건 관여 여부 등 공정성을 해칠 우려가 있을 때 조정에서 제척된다. 공정한 조정을 기대하기 어려운 사정이 있는 당사자는 해당 위원의 기피신청을 할 수 있으며, 위원 본인이 조정사건에서 제척 사유가 있는 경우 스스로 해당 사건의 조정을 회피해야 한다.",
        "long_answer": {
            "question": "데이터분쟁조정위원회에서 위원을 제척하는 것과 위원이 회피하는 것은 어떤 점에서 차이가 있는지 설명하시오.",
            "answer": "제척은 법에서 정한 일정한 사유가 존재할 때 위원이 당연히 조정에서 제외되는 것을 의미한다. 반면 회피는 위원 본인이 제척 사유에 해당할 때 스스로 해당 사건의 조정에 참여하지 않는 것이다. 제척과 회피 모두 특정 사유가 있을 경우 데이터분쟁조정 사건에 참여하지 않는 것은 같지만, 조정위원이 스스로 조정 사건에서 빠지는 것과 타의에 의해 사건의 조정에서 제외되는 것에는 결정의 주체와 자율성 면에서 차이를 갖는다.",
            "rubric": [
                "조정에서 제외되는 것; 스스로 조정을 회피하는 것"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 36조의 데이터분쟁조정위원회 관련 법률에서 데이터분쟁조정위원회의 위원에 대한 제척·기피·회피 제도의 공통 목적은 무엇인가?",
            "answer": "공정성 확보",
            "topic": [
                "데이터분쟁조정위원회의 위원에 대한 제척·기피·회피 제도의 목적"
            ]
        },
        "multiple_choice": {
            "question": "데이터 분쟁조정위원회의 위원 제척 사유로 옳은 것은?",
            "choices": [
                "a) 위원이 다른 사건의 당사자와 친족 관계인 경우",
                "b) 위원이 해당 사건에 관해 증언이나 감정을 한 경우",
                "c) 위원이 사건 당사자와 아무런 관계가 없는 경우",
                "d) 위원이 사건 당사자의 대리인과 같은 기관에 근무하는 경우"
            ],
            "answer": "a",
            "topic": [
                "데이터 분쟁조정위원회의 위원 제척 사유"
            ]
        },
        "true_false": {
            "question": "데이터분쟁조정위원회의 위원이 사건 당사자와 친족이거나 친족이었던 경우에는 제척된다.",
            "answer": "TRUE",
            "topic": [
                "데이터 분쟁조정위원회의 위원 제척 사유"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:9:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제38조(조정의 효력) 1 조정은 다음 각 호의 어느 하나의 경우에 성립한다.  1. 제35조제4항에 따른 조정안에 대하여 당사자가 동의한 경우  2. 당사자가 위원회에 조정합의서를 제출한 경우  2 위원회는 제1항에 따라 조정이 성립한 경우에는 위원회의 위원장과 각 당사자가 기명ᆞ날인한 조정조서를 당사  자에게 보내야 한다.  3 제2항에 따른 조정조서는 「민사소송법」에 따른 재판상 화해와 동일한 효력을 갖는다.  4 위원회는 다음 각 호의 어느 하나에 해당하는 경우에는 조정이 성립하지 아니하였음을 당사자에게 통지하여야  한다.  1. 분쟁조정의 신청이 취하되거나 당사자 어느 한 쪽이 분쟁의 조정에 응하지 아니하는 경우  2. 당사자가 위원회의 조정안을 거부한 경우",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:9:0001",
                    "page": 9
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터분쟁조정위원회의 조정은 당사자의 동의나 조정합의서 제출로 성립하며, 조정 성립 시 작성된 조정조서는 재판상 화해와 동일한 효력을 가진다. 조정이 성립하지 않으면 위원회는 그 사실을 당사자에게 통지해야 한다.",
        "long_answer": {
            "question": "데이터분쟁조정위원회의 조정조서에 대해 설명하시오.",
            "answer": "데이터분쟁조정위원회의 조정 조서는 조정이 성립한 경우 위원장과 각 당사자가 기명, 날인하여 당사자에게 보내진다. 조정 성립의 결과로 발생한 조정조서는 민사소송법에 따른 재판상 화해와 동일한 효력을 가진다. 조정이 성립하지 않으면 조정조서는 발생하지 않는다.",
            "rubric": [
                "조정조서; 성립; 위원장; 당사자; 기명; 날인; 민사소송법; 화해"
            ]
        },
        "short_answer": {
            "question": "데이터분쟁조정위원회의 조정이 성립하지 않은 경우 분쟁조정위원회는 어떤 조치를 취해야 하는가?",
            "answer": "분쟁조정 당사자에게 통지",
            "topic": [
                "데이터분쟁조정위원회의 성립"
            ]
        },
        "multiple_choice": {
            "question": "데이터분쟁조정위원회의 조정은 어떤 상황에서 성립하는가?",
            "choices": [
                "a) 당사자가 조정안에 동의하거나 합의서를 제출하면 조정이 성립한다.",
                "b) 조정조서는 단순한 참고문서로 법적 효력이 없다.",
                "c) 조정은 위원회의 일방적 결정으로 자동 성립한다.",
                "d) 조정이 성립하지 않아도 조정조서는 작성된다."
            ],
            "answer": "a",
            "topic": [
                "데이터분쟁조정위원회의 조정 성립 조건"
            ]
        },
        "true_false": {
            "question": "데이터분쟁조정위원회의 조정이 성립하면 조정조서는 민사소송법상 재판상 화해와 동일한 효력을 가진다.",
            "answer": "TRUE",
            "topic": [
                "데이터분쟁조정위원회의 조정조서"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:10:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "제42조(손해배상청구 등) 1 이 법을 위반하는 행위로 인하여 자신의 영업에 관한 이익이 침해되어 손해를 입은 자는 그 위반행위를 한 자에 대하여 위반행위로 인한 손해의 배상을 청구할 수 있다. 이 경우 그 위반행위를 한 자는 고의 또는 과실이 없음을 입증하지 아니하면 책임을 면할 수 없다. 2 법원은 이 법을 위반한 행위에 관한 소송에서 손해의 발생은 인정되나 손해액을 산정하기 곤란한 경우에는 변론 의 취지 및 증거조사 결과를 고려하여 상당한 손해액을 인정할 수 있다. ",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf",
                    "page": 10
                }
            },
            {
                "context_id": "2",
                "text": "제43조(손해배상의 보장) 데이터사업자는 제42조에 따른 손해배상책임의 이행을 위하여 보험 또는 공제에 가입하거나 준비금을 적립하는 등 필요한 조치를 할 수 있다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf",
                    "page": 10
                }
            }
        ],
        "summarization": "데이터산업법 제42조와 제43조는 법 위반으로 인해 영업상 손해를 입은 자가 손해배상을 청구할 수 있도록 규정하며, 데이터사업자가 이러한 배상책임을 보장하기 위해 보험 가입이나 준비금 적립 등의 조치를 취할 수 있도록 한다.",
        "long_answer": {
            "question": "데이터산업법 위반으로 인한 손해배상청구에 대해 설명하시오.",
            "answer": "데이터산업법 위반 행위로 인해 영업상의 이익이 침해된 경우 피해자가 가해자에게 손해배상을 청구할 수 있다. 또한 데이터산업법을 위반한 자는 자신의 고의나 과실이 없음을 입증하지 않으면 책임을 면할 수 없다. 법원은 손해의 발생은 인정되지만 그 액수를 산정하기 어려운 경우, 변론의 취지와 증거조사 결과를 종합해 상당한 손해액을 인정할 수 있다.",
            "rubric": [
                "데이터산업법 위반; 고의나 과실 입증; 손해액 인정;"
            ]
        },
        "short_answer": {
            "question": "데이터사업자가 데이터산업법 위반으로 인한 손해배상책임 이행을 위해 미리 취할 수 있는 조치는?",
            "answer": "보험, 공제, 준비금 적립 등",
            "topic": [
                "데이터사업자의 데이터산업법 위반에 따른 손해배상 이행 준비"
            ]
        },
        "multiple_choice": {
            "question": "데이터산업법 제42조와 제43조의 내용 중 올바른 것은?",
            "choices": [
                "a) a) 위반행위를 한 자는 피해자의 고의나 과실을 입증해야 면책된다.",
                "b) b) 법원은 손해가 발생했더라도 손해액이 불명확하면 배상을 인정할 수 없다.",
                "c) d) 손해배상청구는 법 위반과 관계없이 제기할 수 있다.",
                "d) c) 데이터사업자는 손해배상책임 이행을 위해 보험이나 공제에 가입할 수 있다."
            ],
            "answer": "d",
            "topic": [
                "데이터산업법 위반에 의한 손해배상청구"
            ]
        },
        "true_false": {
            "question": "데이터사업자는 법적으로 손해배상책임을 위한 보험이나 공제 가입이 금지되어 있다.",
            "answer": "FALSE",
            "topic": [
                "데이터산업법상 데이터사업자의 손해배상청구"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:10:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제8장 벌칙  제47조(벌칙) 제41조를 위반하여 직무상 알게 된 비밀을 타인에게 누설하거나 직무상 목적 외의 목적으로 그 비밀을 사  용한 자는 1년 이하의 징역 또는 1천만원 이하의 벌금에 처한다.  제48조(과태료) 1 제20조제4항에 따른 품질인증을 받지 아니하고 품질인증의 표시 또는 이와 유사한 표시를 한 자에  게는 3천만원 이하의 과태료를 부과한다.  2 제1항에 따른 과태료는 대통령령으로 정하는 바에 따라 과학기술정보통신부장관이 부과ᆞ징수한다.",
                "provenance": {
                    "doc_id": "데이터 산업진흥 및 이용촉진에 관한 기본법(법률)(제18475호)(20220420).pdf:10:0001",
                    "page": 10
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터산업법 제8장은 벌칙에 관한 내용으로, 직무상 알게 된 비밀을 누설하거나 목적 외 사용 시 형사처벌을, 품질인증 표시 위반 시 과태료를 부과하는 규정을 담고 있다.",
        "long_answer": {
            "question": "데이터산업법 제8장의 내용과 제정 목적을 설명하시오.",
            "answer": "제47조는 직무상 알게 된 비밀을 타인에게 누설하거나 목적 외로 사용할 경우 1년 이하의 징역 또는 1천만원 이하의 벌금에 처하도록 한다. 또한 제48조는 품질인증을 받지 않고 인증 표시를 사용하는 자에게 3천만원 이하의 과태료를 부과하며, 이를 과학기술정보통신부장관이 부과·징수하도록 규정한다. 종합적으로 데이터산업법 8장은 데이터의 비밀 유지와 품질인증 제도의 신뢰성 확보를 위해 제정된 벌칙 조항이다.",
            "rubric": [
                "비밀 누설; 징역 또는 벌금; 품질인증; 과태료"
            ]
        },
        "short_answer": {
            "question": "데이터산업법 48조의 품질인증 의무를 위반할 시 어떤 제재를 받게 되는가?",
            "answer": "3천만원 이하의 과태료 부과",
            "topic": [
                "데이터산업법 48조 품질인증 의무 위반 시 벌칙"
            ]
        },
        "multiple_choice": {
            "question": "보기 중 데이터산업법 제8장의 벌칙 내용과 일치하지 않는 것은?",
            "choices": [
                "a) 품질인증 표시 위반은 과학기술정보통신부장관이 징역형을 선고한다.",
                "b) 직무상 비밀을 누설하면 1년 이하의 징역형이 가능하다.",
                "c) 품질인증 표시 위반 시 3천만원 이하의 과태료가 부과된다.",
                "d) 제47조와 제48조 모두 위반 시 처벌을 규정하고 있다."
            ],
            "answer": "a",
            "topic": [
                "데이터산업법 제8장의 벌칙 내용"
            ]
        },
        "true_false": {
            "question": "데이터산업법 제47조에 따르면 직무상 알게 된 비밀을 타인에게 누설하면 형사처벌을 받을 수 있다.",
            "answer": "TRUE",
            "topic": [
                "데이터산업법의 직무상 비밀 유지 의무"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:2:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "제4조(적용범위) 1 이 법은 국외에서 이루어진 행위라도 국내 시장 또는 이용자에게 영향을 미 치는 경우에는 적용한다. 2 이 법은 국방 또는 국가안보 목적으로만 개발ᆞ이용되는 인공지능으로서 대통령령으로 정하는 인공지능에 대하여는 적용하지 아니한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:2:mh: 00001",
                    "page": 2
                }
            },
            {
                "context_id": "2",
                "text": "제5조(다른 법률과의 관계) 1 인공지능, 인공지능기술, 인공지능산업 및 인공지능사회(이하 “인 공지능등”이라 한다)에 관하여 다른 법률에 특별한 규정이 있는 경우를 제외하고는 이 법에서 정하는 바에 따른다. 2 인공지능등에 관하여 다른 법률을 제정하거나 개정하는 경우에는 이 법의 목적에 부합하 도록 하여야 한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:2:mh: 00001",
                    "page": 2
                }
            }
        ],
        "summarization": "국외에서 이루어진 행위라도 국내 시장 또는 이용자에게 영향을 미치는 경우 인공지능기본법이 적용되고, 다만 국방·국가안보 목적의 인공지능은 적용 대상에서 제외된다. 또한 인공지능 관련 법률의 제정·개정 시 이 법의 목적에 부합하도록 해야 한다.",
        "long_answer": {
            "question": "인공지능기본법의 4조를 토대로 인공지능기본법 적용이 제외되는 경우와 적용되는 경우를 모두 제시하시오.",
            "answer": "인공지능기본법은 국내 행위, 국내 시장이나 이용자에게 영향을 미치는 국외 행위에 적용된다. 또한 국방 또는 국가안보 목적으로 개발되는 인공지능 중 대통령령으로 정하지 않은 인공지능에 적용된다. 다만 국내에 영향을 끼치지 않는 국외 행위와 국방 또는 국가안보 목적으로만 개발·이용되는 인공지능 중 대통령령으로 정하는 인공지능은 적용되지 않는다.",
            "rubric": [
                "국외 행위; 국내 시장이나 이용자; 국방 또는 국가안보 목적; 대통령령"
            ]
        },
        "short_answer": {
            "question": "목적의 특수성으로 인해 인공지능기본법 적용에서 제외되는 인공지능은?",
            "answer": "국방 또는 국가안보 목적의 인공지능 중 대통령령으로 정하는 것",
            "topic": [
                "인공지능기본법 4조 적용범위"
            ]
        },
        "multiple_choice": {
            "question": "인공지능기본법 4조에 따른 인공지능기본법의 적용 범위에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 국내에서 이루어진 행위에만 적용된다.",
                "b) 국외 행위라도 국내 시장이나 이용자에게 영향을 미치면 적용된다.",
                "c) 모든 인공지능에 예외 없이 적용된다.",
                "d) 국방 목적의 인공지능도 반드시 적용된다."
            ],
            "answer": "b",
            "topic": [
                "인공지능기본법 4조 적용범위"
            ]
        },
        "true_false": {
            "question": "인공지능기본법 5조에 의하면 새로운 인공지능 관련 법률을 제정할 때는 데이터산업법의 규정에 유의하며 제정 절차를 밟아야 한다.",
            "answer": "FALSE",
            "topic": [
                "인공지능기본법에 따른 새로운 인공지능 관련 법률 제정 시 주의사항"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:4:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제8조(위원회의 기능) 1 위원회는 다음 각 호의 사항을 심의ᆞ의결한다.  1. 기본계획의 수립ᆞ변경 및 시행의 점검ᆞ분석에 관한 사항  2. 인공지능등 관련 정책에 관한 사항  3. 인공지능등에 관한 연구개발 전략 수립에 관한 사항  4. 인공지능등에 관한 투자 전략 수립에 관한 사항  5. 인공지능산업 발전과 경쟁력을 저해하는 규제의 발굴 및 개선에 관한 사항  6. 인공지능 데이터센터(「지능정보화 기본법」 제40조제1항에 따른 데이터센터를 말한다. 이  하 같다) 등 인프라 확충 방안에 관한 사항  7. 제조업ᆞ서비스업 등 산업부문 및 공공부문에서의 인공지능 활용 촉진에 관한 사항  8. 인공지능 국제규범 마련 등 인공지능 관련 국제협력에 관한 사항  9. 제2항에 따른 권고 또는 의견의 표명에 관한 사항  10. 고영향 인공지능 규율에 관한 사항  11. 고영향 인공지능과 관련된 사회적 변화 양상과 정책적 대응에 관한 사항  12. 이 법 또는 다른 법률에서 위원회의 심의사항으로 정한 사항  13. 그 밖에 위원회의 위원장이 필요하다고 인정하여 위원회의 회의에 부치는 사항  2 위원회는 국가기관등의 장 및 인공지능사업자 등에 대하여 인공지능의 올바른 사용과 인  공지능윤리의 실천, 인공지능기술의 안전성ᆞ신뢰성에 관한 권고 또는 의견의 표명을 할 수  있다.  3 위원회가 국가기관등의 장에게 법령ᆞ제도의 개선 또는 실천방안의 수립 등에 대하여 제  2항에 따른 권고 또는 의견의 표명을 한 때에는 해당 국가기관등의 장은 법령ᆞ제도 등의 개  선방안과 실천방안 등을 수립하여야 한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:4:0001",
                    "page": 4
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "국가인공지능위원회는 인공지능 관련 정책, 연구개발, 투자, 규제 개선, 국제협력, 고영향 인공지능 규율 등 다양한 사항을 심의·의결하고 권고 또는 의견을 표명할 수 있다. 또한 국가기관 등은 위원회의 권고에 따라 관련 제도와 실천방안을 마련해야 한다.",
        "long_answer": {
            "question": "국가인공지능위원회가 국가기관에게 미칠 수 있는 영향을 간략하게 설명하라.",
            "answer": "국가인공지능위원회는 권고를 통해 국가기관 등에게 법령이나 제도를 개선하도록 할 수 있다. 기본계획 수립부터 고영향 인공지능 관련 사항까지 인공지능과 관련된 거의 모든 분야를 심의하고 의결한다. 인공인공지능기본법 제8조 제3항에 따르면 권고를 받은 기관은 관련 법령이나 제도를 개선하고 실천방안을 마련해야 한다.",
            "rubric": [
                "인공지능위원회; 권고; 국가기관; 제도; 실천방안;"
            ]
        },
        "short_answer": {
            "question": "국가인공지능위원회가 권고할 수 있는 대상은 누구인가?",
            "answer": "국가기관등의 장, 인공지능사업자",
            "topic": [
                "국가인공지능위원회의 권고 대상"
            ]
        },
        "multiple_choice": {
            "question": "국가인공지능위원회의 권한에 대한 설명으로 옳지 않은 것은?",
            "choices": [
                "a) 국가인공지능위원회는 권고를 이행하지 않은 기관에 벌칙을 부과할 수 있다.",
                "b) 국가기관 등에 인공지능 윤리 실천과 관련한 의견을 제시할 수 있다.",
                "c) 국가인공지능위원회의 권고를 받은 기관은 제도 개선과 실천방안을 마련해야 한다.",
                "d) 국가인공지능위원회는 고영향 인공지능 관련 사회적 변화 양상을 논의할 수 있다."
            ],
            "answer": "a",
            "topic": [
                "국가인공지능위원회의 권한"
            ]
        },
        "true_false": {
            "question": "국가인공지능위원회는 인공지능 정책, 연구개발, 투자 전략 등 다양한 사항을 심의·의결한다.",
            "answer": "TRUE",
            "topic": [
                "국가인공지능위원회의 역할"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:5:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제9조(위원의 제척ᆞ기피 및 회피) 1 위원회의 위원은 업무의 공정성 확보를 위하여 다음 각 호의 어느 하나에 해당하는 경우에는 해당 안건의 심의ᆞ의결에서 제척(除斥)된다. 1. 위원 또는 위원이 속한 법인ᆞ단체 등과 직접적인 이해관계가 있는 경우 2. 위원의 가족(「민법」 제779조에 따른 가족을 말한다)이 이해관계인인 경우 2 심의 대상 안건의 당사자(당사자가 법인ᆞ단체 등인 경우에는 그 임원 및 직원을 포함한 다)는 위원에게 공정한 직무집행을 기대하기 어려운 사정이 있으면 위원회에 기피 신청을 할 수 있으며, 위원회는 기피 신청이 타당하다고 인정하면 의결로 기피를 결정하여야 한다. 3 위원은 제1항 또는 제2항의 사유에 해당하면 스스로 해당 안건의 심의를 회피하여야 한 다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:5:0001",
                    "page": 5
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능위원회의 위원은 공정성을 보장하기 위해 이해관계가 있거나 공정한 직무수행이 어려운 경우 심의·의결에서 제척된다. 이해관계 등이 있는 당사자는 위원에 대한 기피 신청을 할 수 있으며, 위원은 제척 사유가 있을 경우 스스로 회피해야 한다.",
        "long_answer": {
            "question": "국가인공지능위원회의 위원 제척 제도는 어떤 목적을 가지고 있으며, 구체적으로 어떤 경우에 적용되는가?",
            "answer": "국가인공지능위원회의 위원 제척 제도는 위원회의 심의와 의결의 공정성을 확보하기 위해 제정되었다. 위원 또는 그가 속한 법인·단체가 안건과 직접적인 이해관계가 있거나, 위원의 가족이 이해관계인일 경우 제척된다. 또한, 위원 스스로 공정한 판단이 어렵다고 판단될 때는 회피해야 하며, 이해관계 당사자가 위원의 공정성을 의심할 만한 사정이 있을 때 기피 신청을 할 수 있다.",
            "rubric": [
                "이해관계; 가족; 이해관계인; 회피; 기피"
            ]
        },
        "short_answer": {
            "question": "국가인공지능위원회 심의 시 위원 기피 신청 주체는 누구인가?",
            "answer": "심의 대상 안건의 당사자",
            "topic": [
                "국가인공지능위원회 심의 기피"
            ]
        },
        "multiple_choice": {
            "question": "국가인공지능위원회의 위원 제척 관련 규정에 대한 설명으로 옳지 않은 것은?",
            "choices": [
                "a) 회피는 위원 본인이 사유를 인식하지 못하더라도 자동으로 이루어진다.",
                "b) 제척은 위원의 가족이 이해관계인인 경우에도 적용된다.",
                "c) 기피는 위원회가 타당하다고 인정하면 의결로 결정된다.",
                "d) 제척은 위원 또는 그가 속한 단체와 안건의 이해관계가 있을 때 발생한다."
            ],
            "answer": "a",
            "topic": [
                "국가인공지능위원회의 위원 제척 관련 규정"
            ]
        },
        "true_false": {
            "question": "국가인공지능위원회 위원의 가족이 심의가 필요한 안건의 이해관계인인 경우 위원은 해당 안건의 심의에서 제척된다.",
            "answer": "TRUE",
            "topic": [
                "국가인공지능위원회의 위원 제척 관련 규정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:5:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제10조(분과위원회 등) 1 위원회는 위원회의 업무를 전문 분야별로 수행하기 위하여 필요한 경 우 분과위원회를 둘 수 있다. 2 위원회는 인공지능등 관련 특정 현안을 논의하기 위하여 필요한 경우 특별위원회를 둘 수 있다. 3 위원회는 인공지능등 관련 사항을 전문적으로 검토하기 위하여 관계 전문가 등으로 구성 된 자문단을 둘 수 있다. 4 그 밖에 분과위원회, 특별위원회 및 자문단의 구성ᆞ운영 등에 필요한 사항은 대통령령으 로 정한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:5:0001",
                    "page": 5
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "국가인공지능위원회는 업무를 전문적으로 수행하기 위해 분과위원회, 특별위원회, 자문단을 둘 수 있다. 그 구성과 운영 등에 필요한 사항은 대통령령으로 정한다.",
        "long_answer": {
            "question": "국가인공지능위원회의 자문단이 분과위원회 및 특별위원회와 다른 점을 찾아 서술하시오.",
            "answer": "자문단은 분과위원회나 특별위원회와 달리 전문가 등으로 구성되어 전문적 검토를 수행하는 조직이다. 분과위원회는 위원회의 업무를 전문 분야별로 나누어 수행하기 위한 조직이며, 특별위원회는 특정 현안을 논의하기 위해 일시적으로 구성되는 조직이다.",
            "rubric": [
                "내부 조직; 관계 전문가; 전문적 검토;"
            ]
        },
        "short_answer": {
            "question": "국가인공지능위원회의 분과위원회는 무엇을 위해 설치되는가?",
            "answer": "전문 분야별 업무 수행",
            "topic": [
                "국가인공지능위원회의 분과위원회"
            ]
        },
        "multiple_choice": {
            "question": "국가인공지능위원회에 대한 내용으로 옳은 것은?",
            "choices": [
                "a) 위원회는 모든 현안을 자체적으로만 논의해야 한다.",
                "b) 분과위원회는 특정 현안을 논의하기 위해 설치된다.",
                "c) 자문단은 관계 전문가 등으로 구성될 수 있다.",
                "d) 분과위원회와 자문단의 구성은 위원회의 내부 규정으로 정한다"
            ],
            "answer": "c",
            "topic": [
                "국가인공지능위원회의 조직"
            ]
        },
        "true_false": {
            "question": "국가인공지능위원회의 분과위원회와 자문단의 구성·운영에 관한 사항은 위원회가 임의로 정할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "국가인공지능위원회 분과위원회와 자문단 조직"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:5:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제11조(인공지능정책센터) 1 과학기술정보통신부장관은 인공지능 관련 정책의 개발과 국제규  범 정립ᆞ확산에 필요한 업무를 종합적으로 수행하기 위하여 인공지능정책센터(이하 “센터  ”라 한다)를 지정할 수 있다.  2 센터는 다음 각 호의 사업을 수행한다.  1. 기본계획의 수립ᆞ시행에 필요한 전문기술의 지원  2. 인공지능과 관련한 시책의 개발 및 관련 사업의 기획ᆞ시행에 관한 전문기술의 지원  3. 인공지능의 활용 확산에 따른 사회, 경제, 문화 및 국민의 일상생활 등에 미치는 영향의 조  사ᆞ분석  4. 인공지능 및 인공지능기술 관련 정책 개발을 지원하기 위한 동향 분석,사회ᆞ문화 변화  와 미래예측 및 법ᆞ제도의 조사ᆞ연구  5. 다른 법령에서 센터의 업무로 정하거나 센터에 위탁한 사업  6. 그 밖에 국가기관등의 장이 위탁하는 사업  3 그 밖에 센터의 지정 등에 필요한 사항은 대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:5:0001",
                    "page": 5
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능정책센터는 인공지능과 관련된 정책 개발 등 업무를 종합적으로 수행하기 한 기관이다. 인공지능 정책의 개발, 국제규범 정립, 사회적 영향 분석 등 종합적 지원, 연구, 사업을 수행한다.",
        "long_answer": {
            "question": "인공지능정책센터의 주요 사업을 크게 세 가지로 나누어 설명하라.",
            "answer": "인공지능정책센터는 주요 기능은 크게 정책 지원사업, 조사와 분석 등 연구사업, 그 외의 위탁사업으로 나눌 수 있다. 센터는 인공지능 시책의 개발 및 사업의 기획·시행에 필요한 전문기술을 지원한다. 또한 인공지능에 대한 사회, 경제, 문화, 일상생활에 미치는 영향 등을 분석한다. 이외 국가기관등의 장이나 타 법령에서 위탁한 사업을 수행한다.",
            "rubric": [
                "정책 지원; 연구; 위탁"
            ]
        },
        "short_answer": {
            "question": "인공지능정책센터는 어느 기관의 기관장이 지정하는가?",
            "answer": "과학기술정보통신부장관",
            "topic": [
                "인공지능정책센터 지정"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 인공지능정책센터의 업무로 옳은 것은?",
            "choices": [
                "a) 인공지능 기술의 민간 상용화만 담당한다.",
                "b) 인공지능 정책 개발과 사회적 영향 분석을 수행한다.",
                "c) 인공지능 관련 기술의 국제 수출을 직접 추진한다.",
                "d) 과학기술정보통신부의 일반 행정 사무만 대행한다."
            ],
            "answer": "b",
            "topic": [
                "인공지능정책센터의 업무 범위"
            ]
        },
        "true_false": {
            "question": "인공지능정책센터는 인공지능 관련 기본계획의 수립과 시행에 필요한 전문기술을 지원한다.",
            "answer": "TRUE",
            "topic": [
                "인공지능정책센터의 업무 범위"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:7:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제15조(인공지능 학습용데이터 관련 시책의 수립 등) 1 과학기술정보통신부장관은 관계 중앙 행정기관의 장과 협의하여 인공지능의 개발ᆞ활용 등에 사용되는 데이터(이하 “학습용데이터 ”라 한다)의 생산ᆞ수집ᆞ관리ᆞ유통 및 활용 등을 촉진하기 위하여 필요한 시책을 추진하여 야 한다. 2 정부는 학습용데이터의 생산ᆞ수집ᆞ관리ᆞ유통 및 활용 등에 관한 시책을 효율적으로 추진하기 위하여 지원대상사업을 선정하고 예산의 범위에서 지원할 수 있다. 3 정부는 학습용데이터의 생산ᆞ수집ᆞ관리ᆞ유통 및 활용의 활성화 등을 위하여 다양한 학습용데이터를 제작ᆞ생산하여 제공하는 사업(이하 “학습용데이터 구축사업”이라 한다)을 시행할 수 있다. 4 과학기술정보통신부장관은 학습용데이터 구축사업의 효율적 수행을 위하여 학습용데이 터를 통합적으로 제공ᆞ관리할 수 있는 시스템(이하 “통합제공시스템”이라 한다)을 구축ᆞ관 리하고 민간이 자유롭게 이용할 수 있도록 제공하여야 한다. 5 과학기술정보통신부장관은 통합제공시스템을 이용하는 자에 대하여 비용을 징수할 수 있 다. 6 그 밖에 제2항에 따른 지원대상사업의 선정 및 지원, 학습용데이터 구축사업의 시행, 통합 제공시스템의 구축ᆞ관리 및 제5항에 따른 비용의 징수 등에 필요한 사항은 대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:7:0001",
                    "page": 7
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 관계 중앙행정기관의 기관과 협의하여 인공지능 학습용데이터의 활용 등을 위한 시책을 수립하고 추진해야 하며, 학습용데이터 구축사업을 위한 학습용데이터 통합제공시스템을 구축 및 관리해야 한다. 정부는 해당 시책을 위해 예산 지원, 학습용데이터 구축사업 등을 지원할 수 있다.",
        "long_answer": {
            "question": "인공지능기본법 제 15조에 기반하여 과학기술정보통신부 장관, 정부, 관계 중앙행정기관의 장의 역할을 각각 서술하시오.",
            "answer": "과학기술정보통신부장관은 인공지능 학습데이터의 활용 등을 위한 시책을 수립하고 추진하며, 통합제공시스템 구축과 관리를 맡는다. 정부는 인공지능 학습데이터 시책을 지원하기 위한 사업을 시행한다. 관계 중앙행정기관의 장은 시책 수립 과학기술정보통신부장관과 협의해서 인공지능 학습데이터 관련 시책 수립과 추진을 지원한다.",
            "rubric": [
                "시책 수립 및 추진; 통합제공시스템 구축관리; 지원사업 시행; 협의"
            ]
        },
        "short_answer": {
            "question": "정부가 인공지능기본법 제 15조에 기반해서 직접 시행할 수 있는 학습용데이터 관련 사업의 명칭은?",
            "answer": "학습용데이터 구축사업",
            "topic": [
                "인공지능기본법 15조에 따른 인공지능 학습용데이터 활성화를 위한 정부의 역할"
            ]
        },
        "multiple_choice": {
            "question": "아래의 보기 중 인공지능기본법에 명시된 인공지능 학습용 데이터 관련 내용으로 옳은 것은?",
            "choices": [
                "a) 정부는 예산의 범위에서 학습용데이터 관련 사업을 지원할 수 있다.",
                "b) 학습용데이터 구축사업은 민간이 독자적으로 수행해야 한다.",
                "c) 과학기술정보통신부장관은 데이터 유통을 제한해야 한다.",
                "d) 통합제공시스템은 정부 기관만 이용할 수 있도록 제한된다."
            ],
            "answer": "a",
            "topic": [
                "인공지능기본법 내 인공지능 학습용데이터 내용"
            ]
        },
        "true_false": {
            "question": "인공지능 학습용데이터 통합제공시스템은 민간의 이용을 제한하기 위해 운영된다.",
            "answer": "FALSE",
            "topic": [
                "인공지능 학습용데이터 통합제공시스템의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:8:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제17조(중소기업등을 위한 특별지원) 1 이 법에 따라 인공지능기술 및 인공지능산업과 관련한  각종 지원시책을 시행할 때에는 중소기업등을 우선 고려하여야 한다.  2 정부는 인공지능산업에 대한 중소기업등의 참여 활성화를 위하여 노력하여야 하며, 이와  관련한 사항을 기본계획에 반영하여야 한다.  3 과학기술정보통신부장관은 인공지능의 안전성 및 신뢰성 확보를 위하여 중소기업등의 제  34조에 따른 조치 이행 및 제35조에 따른 영향평가를 지원할 수 있다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:8:0001",
                    "page": 8
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:8:0001",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능산업 지원 시 중소기업을 우선 고려하고, 정부가 중소기업의 인공지능산업 참여를 활성화하도록 해야 한다. 또한 과학기술정보통신부장관은 중소기업의 인공지능 안전 및 신뢰성 확보를 위한 조치 이행 또는 영향평가를 지원할 수 있다.",
        "long_answer": {
            "question": "인공지능기본법에에서 중소기업을 주제로 한 조항을 찾고, 중소기업이 받을 수 있는 지원에 대해 설명하시오.",
            "answer": "중소기업의 경우 인공지능산업 관련 지원시책이 있을 경우 우선 지원 고려대상이 될 수 있다. 인공지능기본법 17조에는 인공지능산업과 관련한 지원시책을 시행할 때 중소기업을 우선 고려하도록 명시하고 있다. 정부는 인공지능산업 기본계획에 중소기업의 참여 활성화와 관련한 사항을 반영하여야 한다.",
            "rubric": [
                "인공지능기본법 17조; 중소기업 우선 고려"
            ]
        },
        "short_answer": {
            "question": "인공지능기본법 제17조의 주제가 되는 대상은 누구인가?",
            "answer": "중소기업등",
            "topic": [
                "인공지능기본법 제17조의 대상"
            ]
        },
        "multiple_choice": {
            "question": "인공지능기본법 제17조의 내용으로 옳지 않은 것은?",
            "choices": [
                "a) 인공지능산업 분야에서 중소기업을 위한 특별지원이 규정되어 있다.",
                "b) 정부는 중소기업의 인공지능산업 참여를 촉진해야 한다.",
                "c) 과기정통부장관은 인공지능의 안전성과 신뢰성 확보를 위해 중소기업 등에 인공지능 관련 영향평가를 지원할 수 있다.",
                "d) 정부는 인공지능산업 지원 시 대기업을 우선 고려해야 한다."
            ],
            "answer": "d",
            "topic": [
                "인공지능기본법의 중소기업 지원 방법"
            ]
        },
        "true_false": {
            "question": "인공지능기본법에 따르면 과기정통부장관은 중소기업의 인공지능 관련 조치 이행이나 영향평가를 지원할 수 없다.",
            "answer": "FALSE",
            "topic": [
                "인공지능기본법의 중소기업 지원 방법"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:8:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제18조(창업의 활성화) 1 정부는 인공지능산업 분야의 창업을 활성화하기 위하여 다음 각 호의 사업을 추진할 수 있다. 1. 인공지능산업 분야의 창업자 발굴 및 육성ᆞ지원 등에 관한 사업 2. 인공지능산업 분야의 창업 활성화를 위한 교육ᆞ훈련에 관한 사업 3. 제21조에 따른 전문인력의 우수 인공지능기술에 대한 사업화 지원 4. 인공지능기술의 가치평가 및 창업자금의 금융지원 5. 인공지능 관련 연구 및 기술개발 성과의 제공 6. 인공지능산업 분야의 창업을 지원하는 기관ᆞ단체의 육성 7. 그 밖에 인공지능산업 분야의 창업 활성화를 위하여 필요한 사업 2 지방자치단체는 인공지능산업 분야의 창업을 지원하는 공공기관 등 공공단체에 출연하거 나 출자할 수 있다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:8:0001",
                    "page": 8
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "정부와 지방자치단체는 인공지능산업 분야의 창업을 활성화하기 위해 창업자 발굴, 교육·훈련, 금융지원, 기술 성과 제공 등 다양한 사업을 추진할 수 있다. 또한 지방자치단체는 인공지능산업 분야 창업을 활성화하기 위해 공공기관 또는 단체에 출연하거나 출자할 수 있다.",
        "long_answer": {
            "question": "인공기능기본법 18조에 명시된 중앙정부의 인공지능산업 분야 창업지원과 지방자치단체의 인공지능산업 분야 창업지원 방식에는 어떤 차이가 있는가?",
            "answer": "중앙정부의 경우, 국가 차원의 인공지능산업 분야 사업에 대해 금융지원, 사업화 지원, 직접 사업 추진 등을 통해 창업 전반을 포괄적으로 지원한다. 반면 지방자치단체는 공공기관이나 단체에 출연·출자하여 인공지능산업 분야의 창업을 지원한다.",
            "rubric": [
                "창업 전반에 대한 지원; 공공단체; 출연; 출자;"
            ]
        },
        "short_answer": {
            "question": "인공지능산업 분야의 창업 지원을 위해 지자체가 출연 또는 출자의 방법으로 지원할 수 있는 대상은?",
            "answer": "공공단체",
            "topic": [
                "지방자치단체의 인공지능산업 분야 창업 지원"
            ]
        },
        "multiple_choice": {
            "question": "인공지능산업 창업 활성화와 관련하여 인공지능기본법 제18조의 내용과 일치하지 않는 것은?",
            "choices": [
                "a) 정부는 인공지능산업 창업 활성화를 위해 인공지능기술의 가치평가 및 금융지원을 할 수 있다.",
                "b) 정부는 인공지능 창업자의 교육 및 훈련을 지원할 수 있다.",
                "c) 정부는 인공지능산업 분야 창업 지원 기관을 육성할 수 있다.",
                "d) 지방자치단체는 인공지능산업 분야 창업 관련 기관에 출연할 수 없다."
            ],
            "answer": "d",
            "topic": [
                "인공지능기본법의 인공지능산업 분야 창업 지원"
            ]
        },
        "true_false": {
            "question": "정부는 인공지능산업 분야의 창업 활성화를 위해 인공지능 관련 연구성과를 제공할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "인공지능기본법의 인공지능산업 분야 창업 지원"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:9:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제22조(국제협력 및 해외시장 진출의 지원) 1 정부는 인공지능과 관련한 국제적 동향을 파악하 고 국제협력을 추진하여야 한다. 2 정부는 인공지능산업의 경쟁력 강화와 해외시장 진출을 촉진하기 위하여 인공지능산업에 종사하는 개인ᆞ기업 또는 단체 등에 대하여 다음 각 호의 지원을 할 수 있다. 1. 인공지능산업 관련 정보ᆞ기술ᆞ인력의 국제교류 2. 인공지능산업 관련 해외진출에 관한 정보의 수집ᆞ분석 및 제공 3. 국가 간 인공지능기술, 인공지능제품 또는 인공지능서비스의 공동 연구ᆞ개발 및 국제표 준화 4. 인공지능산업 관련 외국자본의 투자유치 5. 인공지능등 관련 해외 전문 학회 및 전시회 참가 등 홍보 및 해외 마케팅 6. 인공지능제품 또는 인공지능서비스의 수출에 필요한 판매체계ᆞ유통체계 및 협력체계 등 의 구축 7. 인공지능윤리에 관한 국제적 동향 파악 및 국제협력 8. 그 밖에 인공지능산업의 경쟁력 강화와 해외시장 진출 촉진을 위하여 필요한 사항 3 정부는 제2항 각 호에 따른 지원을 효율적으로 수행하기 위하여 대통령령으로 정하는 바 에 따라 공공기관 또는 그 밖의 단체에 이를 위탁하거나 대행하게 할 수 있으며, 이에 필요한 비용을 보조할 수 있다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:9:0001",
                    "page": 9
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "정부는 인공지능의 국제 동향을 파악하고 국제협력을 추진해야 하며, 인공지능산업의 경쟁력 강화와 해외시장 진출을 촉진하기 위해 다양한 지원을 할 수 있다. 또한 이러한 지원은 공공기관이나 단체에 위탁하거나 대행시킬 수 있다.",
        "long_answer": {
            "question": "정부가 인공지능산업의 경쟁력 강화와 해외시장 진출을 위해 추진해야 하는 주요 지원 방안은 무엇인가?",
            "answer": "정부는 인공지능산업의 경쟁력 강화를 위해 다양한 국제협력과 해외진출 지원을 수행해야 한다. 주요 지원 방안으로는 인공지능산업 관련 정보·기술·인력의 국제교류, 해외진출에 관한 정보의 수집 및 제공, 기술, 제품, 서비스 공동 연구·개발과 국제표준화 추진이 포함된다. 또한 외국자본 투자유치, 홍보 및 해외 마케팅, 수출체계 구축, 인공지능윤리 관련 국제협력 등이 있다.",
            "rubric": [
                "국제교류; 국제표준화 추진; 투자유치; 홍보 및 마케팅; 수출체계; 인공지능윤리"
            ]
        },
        "short_answer": {
            "question": "인공지능기본법 제22조에서 정부로부터 인공지능산업에 대한 경쟁력 강화와 해외시장 진출을 위한 국제협력 지원을 받을 수 있는 대상은?",
            "answer": "인공지능산업에 종사하는 개인 및 기업 또는 단체",
            "topic": [
                "인공지능기본법 제 22조의 지원 대상"
            ]
        },
        "multiple_choice": {
            "question": "인공지능기본법 제22조에 따른 인공지능산업 관련 정부지원 내용과 일치하지 않는 것은?",
            "choices": [
                "a) a) 정부는 인공지능산업 관련 외국자본 투자유치를 지원할 수 있다.",
                "b) b) 정부는 인공지능윤리에 관한 국제협력을 추진해야 한다.",
                "c) d) 정부는 인공지능 기술의 국제표준화를 지원할 수 있다.",
                "d) c) 정부는 인공지능산업의 지원 업무를 민간 기업에 위탁할 수 없다."
            ],
            "answer": "d",
            "topic": [
                "인공지능산업 경쟁력 강화와 해외시장 진출을 위한 정부지원 방안"
            ]
        },
        "true_false": {
            "question": "정부는 인공지능산업의 해외시장 진출을 촉진하기 위해 해외 전문 학회 및 전시회 참가를 지원할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "인공지능산업 경쟁력 강화와 해외시장 진출을 위한 정부지원 방안"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:10:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제26조(한국인공지능진흥협회의 설립) 1 인공지능등과 관련한 연구 및 업무에 종사하는 자는 인공지능의 개발ᆞ이용 촉진, 인공지능산업 및 인공지능기술의 진흥, 인공지능등에 대한 교 육ᆞ홍보 등을 위하여 대통령령으로 정하는 바에 따라 과학기술정보통신부장관의 인가를 받 아 한국인공지능진흥협회(이하 “협회”라 한다)를 설립하거나 협회로 지정받을 수 있다. 2 협회는 법인으로 한다. 3 협회는 다음 각 호의 업무를 수행한다. 1. 인공지능기술, 인공지능제품 또는 인공지능서비스의 이용 촉진 및 확산 2. 인공지능등에 대한 현황 및 관련 통계 조사 3. 인공지능사업자를 위한 공동이용시설의 설치ᆞ운영 및 전문인력 양성을 위한 교육 등 4. 인공지능사업자 및 인공지능 관련 전문인력의 해외진출 지원 5. 안전하고 신뢰할 수 있는 인공지능의 개발ᆞ활용을 위한 교육 및 홍보 6. 이 법 또는 다른 법률에 따라 협회가 위탁받은 사업 7. 그 밖에 협회의 설립목적을 달성하는 데 필요한 사업으로서 정관으로 정하는 사업 4 국가 및 지방자치단체는 인공지능산업의 발전과 신뢰 기반 조성을 위하여 필요한 경우 예 산의 범위에서 협회의 사업수행에 필요한 자금을 지원하거나 운영에 필요한 경비를 보조할 수 있다. 5 협회 회원의 자격과 임원에 관한 사항, 협회의 업무 등은 정관으로 정하며, 그 밖에 정관 에 포함하여야 할 사항은 대통령령으로 정한다. 6 과학기술정보통신부장관은 제1항에 따른 인가를 한 때에는 그 사실을 공고하여야 한다. 7 협회에 관하여 이 법에 규정된 것을 제외하고는 「민법」 중 사단법인에 관한 규정을 준용 한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:10:0001",
                    "page": 10
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "한국인공지능진흥협회는 인공지능의 개발·이용 촉진, 산업 진흥, 교육·홍보 등을 위해 설립되는 법인이다. 한국인공지능진흥협회는 인공지능 관련 조사, 교육, 해외진출 지원, 안전한 활용 등을 수행하며 국가와 지방자치단체로부터 지원을 받을 수 있다.",
        "long_answer": {
            "question": "한국인공지능진흥협회가 수행하는 업무를 세 가지 이상 써라.",
            "answer": "한국인공지능진흥협회의 공식 업무는 인공지능기술, 제품, 서비스의 이용 촉진, 통계조사, 공동이용시설 운영, 전문인력의 해외진출 지원, 인공지능 신뢰성, 안전성 강화를 위한 교육이 있다. 또한 다른 법률에 의해 위탁받은 사업과 협회 정관으로 정해진 사업 등을 추진한다.",
            "rubric": [
                "인공지능기술; 제품, 서비스의 이용 촉진; 통계조사; 공동이용시설 운영; 전문인력의 해외진출 지원; 인공지능 신뢰성과 안전성 강화를 위한 교육; 위탁사업 등"
            ]
        },
        "short_answer": {
            "question": "한국인공지능진흥협회를 설립할 수 있는 자격은?",
            "answer": "인공지능등과 관련한 연구 및 업무에 종사하는 자",
            "topic": [
                "한국인공지능진흥협회를 설립 자격"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 한국인공지능진흥협회에 대한 설명으로 옳지 않은 것은?",
            "choices": [
                "a) 협회는 법인으로 한다.",
                "b) 협회는 과학기술정보통신부장관의 인가를 받아야 한다.",
                "c) 협회는 국가의 지원을 받을 수 없다.",
                "d) 협회는 인공지능의 이용 촉진을 위한 업무를 수행할 수 있다."
            ],
            "answer": "c",
            "topic": [
                "한국인공지능진흥협회의 특징"
            ]
        },
        "true_false": {
            "question": "한국인공지능진흥협회는 국가기관으로서 행정권을 직접 행사한다.",
            "answer": "FALSE",
            "topic": [
                "한국인공지능진흥협회의 권한"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:10:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제25조(인공지능 데이터센터 관련 시책의 추진 등) 1 정부는 인공지능의 개발ᆞ활용 등에 이용  되는 데이터센터(이하 “인공지능 데이터센터”라 한다)의 구축 및 운영을 활성화하기 위하여  필요한 시책을 추진하여야 한다.  2 정부는 제1항에 따른 시책을 추진하기 위하여 다음 각 호의 업무를 수행할 수 있다.  1. 인공지능 데이터센터의 구축 및 운영에 필요한 행정적ᆞ재정적 지원  2. 중소기업, 연구기관 등의 인공지능 데이터센터 이용 지원  3. 인공지능 데이터센터 등 인공지능 관련 인프라 시설의 지역별 균형 발전을 위한 지원",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:10:0001",
                    "page": 10
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "정부는 인공지능의 개발과 활용을 위한 인공지능 데이터센터의 구축과 운영을 활성화하기 위한 시책을 추진해야 한다. 또한 이를 위해 행정·재정적 지원, 이용 지원, 지역 균형 발전을 위한 인프라 지원 등의 업무를 수행할 수 있다.",
        "long_answer": {
            "question": "인공지능 데이터센터 관련 시책을 추진하기 위해 정부가 수행할 수 있는 세 가지 업무에 대해 설명하라.",
            "answer": "정부는 인공지능 데이터센터의 구축과 운영을 활성화하기 위해 필요한 시책 추진을 위해 세 가지 업무를 수행할 수 있다. 먼저 데이터센터 구축 및 운영에 필요한 행정적 및 재정적 지원을 제공한다. 또한 중소기업과 연구기관 등의 데이터센터 이용을 지원하며, 인공지능 데이터센터 등 인공지능 관련 인프라 시설의 지역 간 불균형을 해소하기 위한 지원도 함께 수행한다.",
            "rubric": [
                "행정; 재정적 지원; 데이터센터 이용 지원; 지역 간 불균형 해소 지원"
            ]
        },
        "short_answer": {
            "question": "정부가 인공지능 데이터센터 이용을 지원해 주고자 하는 대상은?",
            "answer": "중소기업, 연구기관",
            "topic": [
                "정부의 인공지능 데이터센터 이용 지원 대상"
            ]
        },
        "multiple_choice": {
            "question": "정부가 진행하는 인공지능 데이터센터 관련 시책의 내용으로 옳은 것은?",
            "choices": [
                "a) 정부는 민간의 자율적 운영을 방해하기 위해 인공지능 데이터센터 규제를 강화한다.",
                "b) 정부는 인공지능 데이터센터 구축 및 운영에 필요한 재정적 지원을 할 수 있다.",
                "c) 정부는 대기업만을 대상으로 인공지능 데이터센터 이용 지원을 추진한다.",
                "d) 정부는 인공지능 데이터센터의 수도권 집중을 촉진한다."
            ],
            "answer": "b",
            "topic": [
                "정부의 인공지능 데이터센터 시책 추진을 위한 업무 내용"
            ]
        },
        "true_false": {
            "question": "정부는 인공지능 데이터센터 시책 추진 시 중소기업의 인공지능 데이터센터 이용 지원은 포함하지 않는다.",
            "answer": "FALSE",
            "topic": [
                "인공지능 데이터센터 시책 추진을 위한 정부의 지원 범위"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:11:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제27조(인공지능 윤리원칙 등) 1 정부는 인공지능윤리의 확산을 위하여 다음 각 호의 사항을 포함하는 인공지능 윤리원칙(이하 “윤리원칙”이라 한다)을 대통령령으로 정하는 바에 따라 제 정ᆞ공표할 수 있다. 1. 인공지능의 개발ᆞ활용 등의 과정에서 사람의 생명과 신체, 정신적 건강 등에 해가 되지 아니하도록 하는 안전성과 신뢰성에 관한 사항 2. 인공지능기술이 적용된 제품ᆞ서비스 등을 모든 사람이 자유롭고 편리하게 이용할 수 있 는 접근성에 관한 사항 3. 사람의 삶과 번영에의 공헌을 위한 인공지능의 개발ᆞ활용 등에 관한 사항 2 과학기술정보통신부장관은 사회 각계의 의견을 수렴하여 윤리원칙이 인공지능의 개발ᆞ 활용 등에 관여하는 모든 사람에 의하여 실현될 수 있도록 실천방안을 수립하고 이를 공개 및 홍보ᆞ교육하여야 한다. 3 중앙행정기관 또는 지방자치단체의 장이 인공지능윤리기준(그 명칭 및 형태를 불문하고 인공지능윤리에 관한 법령, 기준, 지침, 가이드라인 등을 말한다)을 제정하거나 개정하는 경 우 과학기술정보통신부장관은 윤리원칙 및 제2항에 따른 실천방안과의 연계성ᆞ정합성 등 에 관한 권고 또는 의견의 표명을 할 수 있다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:11:0001",
                    "page": 11
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "정부은 안전성, 접근성, 공헌성 등을 포함한 인공지능윤리원칙을 제정·공표할 수 있다. 또한 과학기술정보통신부장관은 실천방안을 수립·홍보하며, 다른 행정기관이나 지자체장이 윤리기준을 제정·개정할 때 그에 대한 권고나 의견을 제시할 수 있다.",
        "long_answer": {
            "question": "인공지능기본법 제27조에 따라 정부가 제정할 수 있는 인공지능 윤리원칙에는 어떤 주요 내용이 포함되어야 하는가?",
            "answer": "정부가 제정하는 인공지능 윤리원칙에는 인공지능의 안전성과 신뢰성, 접근성, 그리고 사람의 삶과 번영에 공헌할 수 있는 인공지능의 개발과 활용에 관한 내용이 포함된다. 안전성과 신뢰성은 인공지능의 개발과 활용 과정에서 사람의 생명, 신체, 정신적 건강에 해가 되지 않도록 하는 것을 의미한다. 접근성은 인공지능 기술이 적용된 제품과 서비스를 모든 사람이 자유롭고 편리하게 이용할 수 있도록 보장하는 것이다.",
            "rubric": [
                "안전성; 신뢰성; 접근성; 공헌"
            ]
        },
        "short_answer": {
            "question": "인공지능 윤리원칙이란 무엇을 위해 제정된 원칙인가?",
            "answer": "인공지능윤리의 확산",
            "topic": [
                "인공지능 윤리원칙의 제정 목적"
            ]
        },
        "multiple_choice": {
            "question": "인공지능 윤리원칙 및 기준에 대해 설명한 인공지능기본법 제27조의 내용과 일치하지 않는 것은?",
            "choices": [
                "a) 인공지능 윤리원칙은 대통령령에 따라 제정되고 공표될 수 있다.",
                "b) 과기정통부장관은 지자체 또는 타 중앙행정기관에 인공지능윤리기준에 대한 권고 또는 의견 표명을 할 수 있다.",
                "c) 인공지능 윤리원칙에는 인공지능의 신뢰성이 포함되지 않는다.",
                "d) 다른 행정기관이 인공지능 윤리기준을 제정할 때 과기정통부장관은 의견을 제시할 수 있다."
            ],
            "answer": "c",
            "topic": [
                "인공지능기본법 제27조 상 인공지능 윤리원칙 및 기준에 대한 내용"
            ]
        },
        "true_false": {
            "question": "과학기술정보통신부장관은 인공지능 윤리원칙이 실현될 수 있도록 실천방안을 수립하고 이를 홍보해야 한다.",
            "answer": "TRUE",
            "topic": [
                "인공지능 윤리원칙에 대한 과학기술정보통신부 장관의 역할"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:11:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제28조(민간자율인공지능윤리위원회의 설치 등) 1 다음 각 호의 기관 또는 단체는 윤리원칙을 준수하기 위하여 민간자율인공지능윤리위원회(이하 “민간자율위원회”라 한다)를 둘 수 있다. 1. 인공지능기술 연구 및 개발을 수행하는 사람이 소속된 교육기관ᆞ연구기관 2. 인공지능사업자 3. 그 밖에 대통령령으로 정하는 인공지능기술 관련 기관 2 민간자율위원회는 다음 각 호의 업무를 자율적으로 수행한다. 1. 인공지능기술 연구ᆞ개발ᆞ활용에 있어서 윤리원칙의 준수 여부 확인 2. 인공지능기술 연구ᆞ개발ᆞ활용의 안전 및 인권침해 등에 관한 조사ᆞ연구 3. 인공지능기술 연구ᆞ개발ᆞ활용의 절차 및 결과에 관한 조사ᆞ감독 4. 해당 기관 또는 단체의 연구자 및 종사자에 대한 윤리원칙 교육 5. 인공지능기술 연구ᆞ개발ᆞ활용에 적합한 분야별 인공지능윤리 지침 마련 6. 그 밖에 윤리원칙 구현에 필요한 업무 3 민간자율위원회의 구성ᆞ운영 등에 필요한 사항은 해당 기관 또는 단체 등에서 자율적으 로 정한다. 다만, 그 구성을 특정한 성(性)으로만 할 수 없으며, 사회적ᆞ윤리적 타당성을 평 가할 수 있는 경험과 지식을 갖춘 사람 및 그 기관 또는 단체에 종사하지 아니하는 사람을 각각 포함하여야 한다. 4 과학기술정보통신부장관은 민간자율위원회의 공정하고 중립적인 구성ᆞ운영을 위하여 표준 지침 등을 마련하여 보급할 수 있다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:11:0001",
                    "page": 11
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "민간자율인공지능윤리위원회는 인공지능 연구·개발·활용 과정에서 윤리원칙 준수를 확인하고 안전성 및 인권침해를 조사하는 자율기구이다. 해당 위원회는 교육기관·연구기관·사업자 등이 설치할 수 있으며, 공정하고 중립적인 구성을 위해 과학기술정보통신부가 표준 지침을 마련할 수 있다.",
        "long_answer": {
            "question": "민간자율인공지능윤리위원회의 설치 등에 관한 조항인 인공지능기본법 제 28조에서, 민간자율인공지능윤리위원회의 위원 구성을 제한에 대한 내용을 찾고 그 이유를 추론하시오.",
            "answer": "민간자율인공지능윤리위원회의 구성은 특정 성으로만 이루어질 수 없고, 사회 윤리적 타당성을 평가할 수 있는 사람, 위원회를 설립하는 해당 기관 또는 단체에 종사하지 않는 사람이 포함되어야 한다. 성별적 편향성, 사회 윤리적 타당성, 위원회 업무의 중립성과 공정성을 유지하지 위한 조항으로 추론할 수 있다.",
            "rubric": [
                "특성 성; 사회 윤리적 타당성; 해당 기관 또는 단체에 종사하지 않는 사람; 성별적 편향성; 중립성; 공정성"
            ]
        },
        "short_answer": {
            "question": "민간자율인공지능윤리위원회의 설립 등에 관한 법에서 과학기술정보통신부장관은 어떤 역할을 할 수 있는가?",
            "answer": "표준 지침 보급",
            "topic": [
                "민간자율인공지능윤리위원회의 설립"
            ]
        },
        "multiple_choice": {
            "question": "민간자율인공지능윤리위원회에 대한 설명으로 옳은 것을 고르시오.",
            "choices": [
                "a) 인공지능사업자는 민간자율인공지능윤리위원회를 설치할 수 없다.",
                "b) 민간자율인공지능윤리위원회는 윤리원칙 교육과 지침 마련 등의 업무를 수행할 수 있다.",
                "c) 민간자율인공지능윤리위원회의 모든 위원은 해당 기관 소속 인원으로만 구성되어야 한다.",
                "d) 정부는 민간자율위원회의 운영을 직접 지휘한다."
            ],
            "answer": "b",
            "topic": [
                "민간자율인공지능윤리위원회의 설립과 운영"
            ]
        },
        "true_false": {
            "question": "민간자율인공지능윤리위원회는 해당 기관이 자율적으로 구성하고 운영할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "민간자율인공지능윤리위원회의 설립과 운영"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:12:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제30조(인공지능 안전성ᆞ신뢰성 검ᆞ인증등 지원) 1 과학기술정보통신부장관은 단체등이 인 공지능의 안전성ᆞ신뢰성 확보를 위하여 자율적으로 추진하는 검증ᆞ인증 활동(이하 “검ᆞ인 증등”이라 한다)을 지원하기 위하여 다음 각 호의 사업을 추진할 수 있다. 1. 인공지능의 개발에 관한 가이드라인 보급 2. 검ᆞ인증등에 관한 연구의 지원 3. 검ᆞ인증등에 이용되는 장비 및 시스템의 구축ᆞ운영 지원 4. 검ᆞ인증등에 필요한 전문인력의 양성 지원 5. 그 밖에 검ᆞ인증등을 지원하기 위하여 대통령령으로 정하는 사항 2 과학기술정보통신부장관은 검ᆞ인증등을 받고자 하는 중소기업등에 대하여 대통령령으 로 정하는 바에 따라 관련 정보를 제공하거나 행정적ᆞ재정적 지원을 할 수 있다. 3 인공지능사업자가 고영향 인공지능을 제공하는 경우 사전에 검ᆞ인증등을 받도록 노력하 여야 한다. 4 국가기관등이 고영향 인공지능을 이용하려는 경우에는 검ᆞ인증등을 받은 인공지능에 기 반한 제품 또는 서비스를 우선적으로 고려하여야 한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:12:0001",
                    "page": 12
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 인공지능의 안전성과 신뢰성 확보를 위해 검·인증 활동을 지원하고, 중소기업 및 국가기관의 검·인증 활용을 촉진하도록 규정하고 있다. 또한 고영향 인공지능의 경우 사전 검·인증을 권장하며, 공공기관은 인증된 인공지능을 우선 고려해야 한다.",
        "long_answer": {
            "question": "인공지능기본법 제30조에서 과학기술정보통신부장관이 추진할 수 있는 인공지능 검·인증 지원 사업에는 어떤 내용이 포함되는가?",
            "answer": "과학기술정보통신부장관이 추진할 수 있는 인공지능의 검·인증 지원 사업에는 총 5가지 항목이 있다. 인공지능 개발에 관한 가이드라인 보급, 검·인증 관련 연구 지원, 관련 장비 및 시스템 구축·운영, 전문인력 양성 지원 등이 있고, 이에 더해 대통령령으로 정하는 검인증 지원 사항을 추진할 수 있다.",
            "rubric": [
                "검인증; 가이드라인; 연구; 장비 및 시스템; 전문인력 양성; 대통령령"
            ]
        },
        "short_answer": {
            "question": "고영향 인공지능을 제공하는 인공지능사업자가 사전에 고려해야 하는 것은?",
            "answer": "사전 검·인증",
            "topic": [
                "고영향 인공지능을 제공하는 인공지능사업자의 의무"
            ]
        },
        "multiple_choice": {
            "question": "인공지능기본법 제30조의 인공지능 검인증에 대한 내용으로 옳은 것은?",
            "choices": [
                "a) 국가기관은 검·인증을 받은 인공지능을 우선적으로 고려해야 한다.",
                "b) 과학기술정보통신부장관은 인공지능 검·인증을 직접 수행해야 한다.",
                "c) 고영향 인공지능을 제공하는 사업자는 사전 검·인증을 반드시 받아야 한다.",
                "d) 검·인증 지원은 민간기업이 아닌 공공기관에 한정된다."
            ],
            "answer": "a",
            "topic": [
                "인공지능기본법 제30조 인공지능 검인증 내용"
            ]
        },
        "true_false": {
            "question": "과학기술정보통신부장관은 인공지능의 안전성과 신뢰성 확보를 위해 검·인증 관련 장비 구축을 지원할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "인공지능기본법상 인공지능 검인증 지원 내용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:12:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제31조(인공지능 투명성 확보 의무) 1 인공지능사업자는 고영향 인공지능이나 생성형 인공지 능을 이용한 제품 또는 서비스를 제공하려는 경우 제품 또는 서비스가 해당 인공지능에 기반 하여 운용된다는 사실을 이용자에게 사전에 고지하여야 한다. 2 인공지능사업자는 생성형 인공지능 또는 이를 이용한 제품 또는 서비스를 제공하는 경우 그 결과물이 생성형 인공지능에 의하여 생성되었다는 사실을 표시하여야 한다. 3 인공지능사업자는 인공지능시스템을 이용하여 실제와 구분하기 어려운 가상의 음향, 이 미지 또는 영상 등의 결과물을 제공하는 경우 해당 결과물이 인공지능시스템에 의하여 생성 되었다는 사실을 이용자가 명확하게 인식할 수 있는 방식으로 고지 또는 표시하여야 한다. 이 경우 해당 결과물이 예술적ᆞ창의적 표현물에 해당하거나 그 일부를 구성하는 경우에는 전시 또는 향유 등을 저해하지 아니하는 방식으로 고지 또는 표시할 수 있다. 4 그 밖에 제1항에 따른 사전고지, 제2항에 따른 표시, 제3항에 따른 고지 또는 표시의 방법 및 그 예외 등에 관하여 필요한 사항은 대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:12:0001",
                    "page": 12
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능사업자는 고영향 또는 생성형 인공지능을 이용한 제품·서비스를 제공할 때, 해당 인공지능의 사용 사실과 생성 결과물임을 이용자에게 명확히 고지하거나 표시해야 한다. 이는 인공지능이 실제와 유사한 결과물을 만들어낼 때 이용자가 이를 인식할 수 있도록 투명성을 확보하기 위한 의무이다.",
        "long_answer": {
            "question": "고영향 인공지능을 이용한 제품 또는 서비스를 제공하는 인공지능사업자의 고지의무에 대해 설명하시오.",
            "answer": "고영향 인공지능으로 생성된 제품이나 서비스를 제공하는 인공지능사업자는 이용자가 제품이나 서비스가 고영향 인공지능에 의해 운용된다는 사실을 인식할 수 있도록 하기 위해 사전 고지를 해야 한다. 해당 고지의무는 인공지능의 투명성을 확보하기 위해 지정된 조항이다. 특히 실제와 구분하기 어려운 가상의 음향, 이미지, 영상 등의 결과물의 경우 이용자가 명확하게 인식할 수 있도록 고지 또는 표시하여야 한다.",
            "rubric": [
                "투명성; 고영향 인공지능; 실제과 구분하기 어려운 가상의 결과물;"
            ]
        },
        "short_answer": {
            "question": "고영향 인공지능을 제공하는 인공지능사업자는 이용자에게 무엇을 알려야 하는가?",
            "answer": "제품이나 서비스가 해당 인공지능에 기반하여 운용된다는 사실",
            "topic": [
                "고영향 인공지능을 제공하는 인공지능사업자의 고지 의무"
            ]
        },
        "multiple_choice": {
            "question": "인공지능사업자의 투명성 확보 의무에 대해 옳게 설명한 것을 고르시오.",
            "choices": [
                "a) 인공지능사업자는 고영향 인공지능을 이용할 경우 사전에 이용자에게 고지해야 한다.",
                "b) 인공지능사업자는 생성형 인공지능의 결과물이라도 표시하지 않아도 된다.",
                "c) 예술적 표현물은 표시 의무가 전혀 없다.",
                "d) 인공지능사업자는 대통령령과 무관하게 자율적으로 표시 방식을 정할 수 있다."
            ],
            "answer": "a",
            "topic": [
                "인공지능사업자의 투명성 확보 의무"
            ]
        },
        "true_false": {
            "question": "인공지능사업자가 예술적·창의적 표현물을 고영향 인공지능을 통해 생성한 경우 그 생성한 사실을 반드시 동일한 방식으로 표시해야 한다.",
            "answer": "FALSE",
            "topic": [
                "인공지능사업자의 투명성 확보 의무"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:13:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제34조(고영향 인공지능과 관련한 사업자의 책무) 1 인공지능사업자는 고영향 인공지능 또는 이를 이용한 제품ᆞ서비스를 제공하는 경우 고영향 인공지능의 안전성ᆞ신뢰성을 확보하기 위하여 다음 각 호의 내용을 포함하는 조치를 대통령령으로 정하는 바에 따라 이행하여야 한 다. 1. 위험관리방안의 수립ᆞ운영 2. 기술적으로 가능한 범위에서의 인공지능이 도출한 최종결과, 인공지능의 최종결과 도출에 활용된 주요 기준, 인공지능의 개발ᆞ활용에 사용된 학습용데이터의 개요 등에 대한 설명 방안의 수립ᆞ시행 3. 이용자 보호 방안의 수립ᆞ운영 4. 고영향 인공지능에 대한 사람의 관리ᆞ감독 5. 안전성ᆞ신뢰성 확보를 위한 조치의 내용을 확인할 수 있는 문서의 작성과 보관 6. 그 밖에 고영향 인공지능의 안전성ᆞ신뢰성 확보를 위하여 위원회에서 심의ᆞ의결된 사 항 2 과학기술정보통신부장관은 제1항 각 호에 따른 조치의 구체적인 사항을 정하여 고시하고 , 인공지능사업자에게 이를 준수하도록 권고할 수 있다. 3 인공지능사업자가 다른 법령에 따라 제1항 각 호에 준하는 조치를 대통령령으로 정하는 바에 따라 이행한 경우에는 제1항에 따른 조치를 이행한 것으로 본다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:13:0001",
                    "page": 13
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능사업자는 고영향 인공지능의 안전성과 신뢰성을 확보하기 위해 위험관리, 이용자 보호, 사람의 감독 등 대통령령으로 정한 조치를 이행해야 한다. 또한 과학기술정보통신부장관은 이러한 조치의 구체적 사항을 정하여 고시하고 준수를 권고할 수 있다.",
        "long_answer": {
            "question": "인공지능기본법 제34조에 명시된 인공지능사업자의 책무와 과학기술정보통신부장관의 역할을 각각 설명하시오.",
            "answer": "인공지능사업자는 실제로 고영향 인공지능을 운영하며 인공지능에 대한 위험관리방안 수립, 설명방안 수립, 이용자 보호방안 수립, 인공지능 관리 감독 등 직접적인 조치를 수행한다. 과학기술정보통신부장관은 이러한 조치의 구체적인 세부사항을 정하여 고시하고, 사업자들에게 그 이행을 권고하는 역할을 맡는다.",
            "rubric": [
                "위험관리방안; 설명방안; 이용자 보호 방안; 관리감독"
            ]
        },
        "short_answer": {
            "question": "고영향 인공지능을 제공하는 인공지능사업자의 안전성과 신뢰성 확보 책임을 명시한 법률은?",
            "answer": "인공지능기본법 제34조",
            "topic": [
                "인공지능기본법 제34조 고영향 인공지능과 관련한 사업자의 책무"
            ]
        },
        "multiple_choice": {
            "question": "인공지능기본법 제34조의 내용으로 틀린 것을 고르시오.",
            "choices": [
                "a) 인공지능사업자는 고영향 인공지능의 이용자 보호 방안을 수립해야 한다.",
                "b) 고영향 인공지능의 안전성과 신뢰성을 확보하기 위한 위험관리방안을 수립해야 한다.",
                "c) 고영향 인공지능을 이용하는 인공지능사업자가 다른 법령을 통해 동일한 수준의 조치를 이행한 경우에는 본 조항을 이행한 것으로 본다.",
                "d) 사람의 관리·감독은 고영향 인공지능의 신뢰성 확보 방안에 포함되지 않는다."
            ],
            "answer": "d",
            "topic": [
                "인공지능기본법 제34조 고영향 인공지능과 관련한 사업자의 책무"
            ]
        },
        "true_false": {
            "question": "인공지능기본법 제34조에 따르면 과학기술정보통신부장관은 고영향 인공지능 긴뢰성과 안전성 확보 관련 조치의 세부사항을 정하여 고시할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "인공지능기본법 제34조 고영향 인공지능과 관련한 과학기술정보통신부장관의 역할"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:13:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제35조(고영향 인공지능 영향평가) 1 인공지능사업자가 고영향 인공지능을 이용한 제품 또는 서비스를 제공하는 경우 사전에 사람의 기본권에 미치는 영향을 평가(이하 “영향평가”라 한다 )하기 위하여 노력하여야 한다. 2 국가기관등이 고영향 인공지능을 이용한 제품 또는 서비스를 이용하려는 경우에는 영향 평가를 실시한 제품 또는 서비스를 우선적으로 고려하여야 한다. 3 그 밖에 영향평가의 구체적인 내용ᆞ방법 등에 관하여 필요한 사항은 대통령령으로 정한 다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:13:0001",
                    "page": 13
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능사업자가 고영향 인공지능을 활용할 때 사람의 기본권에 미치는 영향을 사전에 평가하도록 규정하고 있다. 또한 국가기관 등은 고영향 인공지능을 사용할 때 이러한 영향평가가 실시된 제품 또는 서비스를 우선적으로 고려해야 함을 명시한다.",
        "long_answer": {
            "question": "고영향 인공지능 영향평가의 목적과 내용을 설명하라.",
            "answer": "고영향 인공지능 영향평가는 인공지능이 사람의 기본권에 미치는 영향을 사전에 점검하기 위한 제도이다. 인공지능사업자는 고영향 인공지능을 이용한 제품 또는 서비스를 제공하기 전에 인공지능이 인간의 기본권에 미치는 영향을 평가해야 한다.",
            "rubric": [
                "고영향 인공지능; 기본권; 영향평가"
            ]
        },
        "short_answer": {
            "question": "인공지능사업자가 고영향 인공지능 영향평가를 해야 하는 시점은 언제인가?",
            "answer": "고영향 인공지능을 이용한 제품 또는 서비스를 제공하기 전",
            "topic": [
                "고영향 인공지능 영향평가의 시점"
            ]
        },
        "multiple_choice": {
            "question": "고영향 인공지능 영향평가에 대한 설명으로 옳지 않은 것은?",
            "choices": [
                "a) 고영향 인공지능은 사람의 기본권에 영향을 줄 수 있다.",
                "b) 고영향 인공지능 영향평가 방법 등 세부사항은 대통령령에서 정한다.",
                "c) 국가기관은 영향평가가 실시된 제품을 우선 고려한다.",
                "d) 인공지능사업자는 영향평가를 반드시 실시해야 하며, 노력 의무가 없다."
            ],
            "answer": "d",
            "topic": [
                "인공지능기본법 35조 고영향 인공지능 영향평가 규정"
            ]
        },
        "true_false": {
            "question": "인공지능사업자는 고영향 인공지능 제품을 제공할 때 영향평가를 생략할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "인공지능기본법 35조 고영향 인공지능 영향평가 규정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제36조(국내대리인 지정) 1 국내에 주소 또는 영업소가 없는 인공지능사업자로서 이용자 수,  매출액 등이 대통령령으로 정하는 기준에 해당하는 자는 다음 각 호의 사항을 대리하는 자(이  하 “국내대리인”이라 한다)를 서면으로 지정하고, 이를 과학기술정보통신부장관에게 신고하  여야 한다.  1. 제32조제2항에 따른 이행 결과의 제출  2. 제33조제1항에 따른 고영향 인공지능 해당 여부 확인의 요청  3. 제34조제1항 각 호에 따른 안전성ᆞ신뢰성 확보 조치의 이행에 필요한 지원(같은 항 제  5호에 따른 문서의 최신성ᆞ정확성에 대한 점검을 포함한다)  2 국내대리인은 국내에 주소 또는 영업소가 있는 자로 한다.  3 국내대리인이 제1항 각 호와 관련하여 이 법을 위반한 경우에는 해당 국내대리인을 지정  한 인공지능사업자가 그 행위를 한 것으로 본다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "국내에 주소나 영업소가 없는 인공지능사업자가 일정 기준에 해당할 경우, 국내대리인을 지정하고 이를 과학기술정보통신부장관에게 신고하도록 규정한다. 또한 국내대리인은 법 위반 시 인공지능사업자와 동일한 책임을 지며, 국내에 주소 또는 영업소를 두어야 한다.",
        "long_answer": {
            "question": "인공지능기본법 제36조에서 국내대리인의 지정이 필요한 이유와 그 역할을 설명하라.",
            "answer": "국내대리인 지정 제도는 국내에 주소나 영업소가 없는 인공지능사업자가 국내 법령을 이행하도록 하기 위한 장치이다. 국내대리인은 인공지능사업자를 대신하여 법령에서 규정한 이행결과 제출, 고영향 인공지능 여부 확인 요청, 안전성 및 신뢰성 확보 조치 지원 등의 역할을 수행한다. 국내대리인이 법령에 규정된 업무를 위반한 경우에는 해당 국내대리인을 지정한 인공지능사업자가 그 행위를 한 것으로 본다.",
            "rubric": [
                "인공지능사업자 대신; 이행결과 제출; 고영향 인공지능 여부 확인; 안전성 및 신뢰성 확보 조치 이행"
            ]
        },
        "short_answer": {
            "question": "인공지능사업자의 국내대리인은 누구를 대신해 법적 의무를 수행하는가?",
            "answer": "국내에 주소나 영업소가 없는 인공지능사업자",
            "topic": [
                "인공지능사업자의 국내대리인 지정"
            ]
        },
        "multiple_choice": {
            "question": "인공지능기본법 제36조에 따른 인공지능사업자 국내대리인의 역할로 옳은 것은?",
            "choices": [
                "a) 인공지능사업자를 대신해 이행결과를 제출한다.",
                "b) 인공지능사업자의 매출을 관리한다.",
                "c) 인공지능 서비스를 직접 운영한다.",
                "d) 인공지능 기술의 개발 방향을 결정한다."
            ],
            "answer": "a",
            "topic": [
                "인공지능사업자의 국내대리인 지정"
            ]
        },
        "true_false": {
            "question": "인공지능사업자의 국내대리인이 법을 위반하더라도 인공지능사업자는 그 책임에서 완전히 면제된다.",
            "answer": "FALSE",
            "topic": [
                "인공지능사업자의 국내대리인의 책임"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제37조(인공지능산업의 진흥을 위한 재원의 확충 등) 1 국가는 기본계획 및 이 법에 따른 시책 등을 효과적으로 추진하기 위하여 필요한 재원을 지속적이고 안정적으로 확충할 수 있는 방 안을 마련하여야 한다. 2 과학기술정보통신부장관은 인공지능산업의 진흥을 위하여 필요한 경우에는 공공기관으 로 하여금 인공지능산업의 진흥에 관한 사업 등에 필요한 지원을 하도록 권고할 수 있다. 3 국가 및 지방자치단체는 기업 등 민간이 적극적으로 인공지능산업의 진흥과 관련된 사업 에 투자할 수 있도록 필요한 조치를 마련하여야 한다. 4 국가 및 지방자치단체는 인공지능산업의 발전단계 등을 종합적으로 고려하여 투자재원을 효율적으로 집행하도록 노력하여야 한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "국가는 인공지능산업의 진흥을 위해 필요한 재원을 안정적으로 마련해야 하며, 공공기관의 지원 권고와 민간의 투자 촉진을 통해 효율적인 자원 집행을 도모해야 한다. 또한 국가와 지방자치단체는 인공지능산업의 발전단계에 맞춰 재원을 종합적이고 효율적으로 운영해야 한다.",
        "long_answer": {
            "question": "인공지능기본법 제 37조에서 국가 및 과학기술정보통신부장관의 역할과 그 차이를 서술하시오.",
            "answer": "국가는 기본계획 및 시책에 필요한 재원을 안정적으로 확충할 수 있는 방안을 마련하여야 한다. 과학기술정보통신부장관은 공공기관에 대해 인공지능산업 진흥 사업을 지원하도록 권고할 수 있다. 인공지능기본법 37조에서 국가의 역할은 해야 한다는 강제성 또는 당위성이 있으나, 과학기술정보통신부장관 권고의 경우 강제성을 띠지 않는다는 차이가 있다.",
            "rubric": [
                "재원; 확충; 인공지능산업 진흥 사업 지원; 권고;"
            ]
        },
        "short_answer": {
            "question": "국가와 지방자치단체가 인공지능산업 진흥을 위해 투자재원을 집행할 때, 고려해야 하는 요소는?",
            "answer": "인공지능산업의 발전단계 등",
            "topic": [
                "인공지능산업 진흥을 위한 재원 확충"
            ]
        },
        "multiple_choice": {
            "question": "인공지능기본법 제37조의 내용으로 옳은 것은?",
            "choices": [
                "a) 국가와 지방자치단체는 민간의 투자를 촉진하기 위한 조치를 마련해야 한다.",
                "b) 국가는 일시적인 재원을 통해 인공지능산업을 지원한다.",
                "c) 과학기술정보통신부장관은 민간 기업에 직접 재정 지원을 명령할 수 있다.",
                "d) 지방자치단체는 공공기관의 사업을 제한할 수 있다."
            ],
            "answer": "a",
            "topic": [
                "인공지능산업 진흥을 위한 재원 확충"
            ]
        },
        "true_false": {
            "question": "과학기술정보통신부장관은 공공기관에 인공지능산업 관련 사업을 의무적으로 수행하도록 명령할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "인공지능기본법 제37조 내용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제38조(실태조사, 통계 및 지표의 작성) 1 과학기술정보통신부장관은 통계청장과 협의하여 기  본계획 및 인공지능등 관련 시책과 사업의 기획ᆞ수립ᆞ추진을 위하여 국내외 인공지능등에  관한 실태조사, 통계 및 지표를 「과학기술기본법」 제26조의2에 따른 통계와 연계하여 작성ᆞ  관리하고 공표하여야 한다.  2 과학기술정보통신부장관은 제1항에 따른 통계 및 지표의 작성을 위하여 관계 중앙행정기  관의 장, 지방자치단체의 장 및 공공기관의 장에게 자료의 제출 등 협조를 요청할 수 있다.  이 경우 협조를 요청받은 기관의 장은 특별한 사정이 없으면 이에 따라야 한다.  3 그 밖에 제1항에 따른 실태조사, 통계 및 지표의 작성ᆞ관리 및 공표 등에 필요한 사항은  대통령령으로 정한다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 인공지능 관련 정책의 수립과 추진을 위해 통계청장과 협의하여 국내외 인공지능 실태조사, 통계 및 지표를 작성, 관리, 공표해야 한다. 자료 수집 과정에서는 관계 기관의 협조를 받아 자료를 수집할 수 있으며, 실태조사에 대한 세부 사항은 대통령령으로 정한다.",
        "long_answer": {
            "question": "과학기술정보통신부장관과 관계 기관의 협조 관계를 설명하라.",
            "answer": "과학기술정보통신부장관과 통계청장과는 국내외 인공지능 등에 관한 실태조사, 통계 및 지표 작성 시에 협의하는 관계이다. 관계 중앙행정기관, 지방자치단체, 공공기관과는 자료 수집 등 협조를 요청하는 관계이다. 해당 관계 기관과의 협업을 통해 국내외 인공지능등에 관한 실태조사, 통계 및 지표를 작성, 관리, 공표해야 한다.",
            "rubric": [
                "통계청장; 협의; 관계 중앙행정기관; 지방자치단체; 공공기관; 협조"
            ]
        },
        "short_answer": {
            "question": "국내외 인공지능 실태조사 및 통계 작성을 위해 협조를 요청받는 기관은 어떤 기관들인가?",
            "answer": "중앙행정기관, 지방자치단체, 공공기관",
            "topic": [
                "인공지능 실태조사 및 통계 작성 규정"
            ]
        },
        "multiple_choice": {
            "question": "인공지능 실태조사 및 통계 작성에 대한 설명으로 적절한 내용은?",
            "choices": [
                "a) 과학기술정보통신부장관은 독자적으로 통계를 작성하며 통계청장과 협의할 필요가 없다.",
                "b) 관계 기관은 장관의 인공지능 실태조사 및 통계 작성에 대한 협조 요청을 받더라도 응할 의무가 없다.",
                "c) 대통령령으로 인공지능 실태조사 및 통계 작성에 관한 구체적 절차를 정할 수 있다.",
                "d) 통계는 정보통신망법에 따라 작성되어야 한다."
            ],
            "answer": "c",
            "topic": [
                "인공지능 실태조사 및 통계 작성 규정"
            ]
        },
        "true_false": {
            "question": "과학기술정보통신부장관은 인공지능 관련 실태조사와 통계를 작성, 관리, 공표해야 한다.",
            "answer": "FALSE",
            "topic": [
                "인공지능 실태조사 및 통계 작성 규정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:15:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "제40조(사실조사 등) 1 과학기술정보통신부장관은 다음 각 호의 어느 하나에 해당하는 경우에 는 인공지능사업자에 대하여 관련 자료를 제출하게 하거나, 소속 공무원으로 하여금 필요한 조사를 하게 할 수 있다. 1. 제31조제2항ᆞ제3항, 제32조제1항ᆞ제2항 또는 제34조제1항에 위반되는 사항을 발견하 거나 혐의가 있음을 알게 된 경우 2. 제31조제2항ᆞ제3항, 제32조제1항ᆞ제2항 또는 제34조제1항의 위반에 대한 신고를 받거 나 민원이 접수된 경우 2 과학기술정보통신부장관은 제1항에 따른 조사를 위하여 필요한 경우 소속 공무원으로 하 여금 인공지능사업자의 사무소ᆞ사업장에 출입하여 장부ᆞ서류, 그 밖의 자료나 물건을 조 사하게 할 수 있다. 이 경우 조사의 내용ᆞ방법 및 절차 등에 관하여 이 법에서 정하는 사항 을 제외하고는 「행정조사기본법」에서 정하는 바에 따른다. 3 과학기술정보통신부장관은 제1항 및 제2항에 따른 조사 결과 인공지능사업자가 이 법을 위반한 사실이 있다고 인정되면 인공지능사업자에게 해당 위반행위의 중지나 시정을 위하여 필요한 조치를 명할 수 있다.",
                "provenance": {
                    "doc_id": "인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(법률)(제20676호)(20260122).pdf:15:0001",
                    "page": 15
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "과학기술정보통신부장관은 인공지능사업자가 인공지능기본법 31조, 32조, 34조 등을 위반했거나 위반 혐의가 있는 경우, 또는 신고나 민원을 접수한 경우 관련 자료를 제출하게 할 수 있다. 조사 결과 위반 사실이 확인되면 사업자에게 시정 또는 중지에 필요한 조치를 내릴 수 있다.",
        "long_answer": {
            "question": "과학기술정보통신부장관이 소속 공무원을 통해 인공지능사업자의 사무소 또는 사업장에 출입하여 조사하게 할 수 있도록 법률로 정해져 있는 상황은 어떤 상황인가?",
            "answer": "조사 대상인 인공지능사업자가 인공지능기본법 제31조, 제32조, 제34조의 규정을 위반했거나 위반 혐의가 있는 경우 소속 공무원에게 사무소나 사업장에 출입하여 장부나 자료를 조사하게 할 수 있다. 이 경우 조사의 내용과 방법 및 절차 등에 관하여 이 법에서 정하는 사항을 제외하고는 행정조사기본법을 따른다.",
            "rubric": [
                "인공지능기본법; 위반; 혐의;"
            ]
        },
        "short_answer": {
            "question": "인공지능기본법 40조에 따른 사실조사를 할 때, 본 법률에서 규정되지 않은 조사의 내용과 방법 및 절차 등은 어떤 법률에 의거해 수행해야 하는가?",
            "answer": "행정조사기본법",
            "topic": [
                "인공지능기본법 40조의 사실조사 방법"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 인공지능기본법 제40조의 사실조사 규정에 부합하지 않는 것은?",
            "choices": [
                "a) 장관은 민원이 접수된 경우 조사할 수 있다.",
                "b) 사실조사 결과 위반 사실이 없으면 시정조치를 명할 수 있다.",
                "c) 사실조사의 방법과 절차는 인공지능기본법에서 정하는 사항을 제외하면 행정조사기본법을 따른다.",
                "d) 사실조사 결과 위반이 인정되면 시정 명령을 내릴 수 있다."
            ],
            "answer": "b",
            "topic": [
                "인공지능기본법 40조의 사실조사 규정"
            ]
        },
        "true_false": {
            "question": "과학기술정보통신부장관은 인공지능사업자가 인공지능기본법 31조, 32조, 34조 등을 위반했다고 인정되면 시정조치를 명할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "인공지능기본법 40조의 사실조사 규정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:18:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "GDPR은 자연인(natural person)에 관한 기본권과 자유(특히 개인정보보호에 대한 권리)를 보호하고(제1조제2항), EU 역내에서 개인정보의 자유로운 이동(제1조제3항) 을 보장하는 것을 목적으로 한다. GDPR은 개인정보 삭제권, 처리 제한권, 개인정보 이동권, 반대권(거부권) 등의 신규 권리 추가 및 기존 권리 명확화를 통하여 기존 Directive 95/46/EC보다 정보주체의 권리를 확대·강화하였으며, 개인정보 처리 활동의 기록, DPO의 지정, 개인정보 영향평 가, Data protection by design and by default 등을 규정함으로써 기업의 책임성을 강화하였다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:18:0001",
                    "page": 18
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR은 자연인의 기본권과 자유(개인정보 보호를 중점으로)를 보호하고 EU 역내 개인정보의 자유로운 이동을 보장하기 위해 제정되었다. 기존 Directive 95/46/EC 정보주체의 권리를 확대하고 기업의 책임성을 강화하였다.",
        "long_answer": {
            "question": "GDPR이 기존 Directive 95/46/EC와 비교하여 강화된 점을 설명하시오.",
            "answer": "GDPR은 기존 Directive 95/46/EC에 비해 정보주체와 기업 책임성이 더욱 확대되고 강화되었다. 정보주체의 권리는 개인정보 삭제권, 이동권, 처리 제한권 등 신규 권리 추가 및 기존 권리 명확화를 통해 강화했다. 기업의 책임성은 개인정보 영향평가, DPO 지정, 데이터 처리 기록 등을 통해 강화했다.",
            "rubric": [
                "정보주체; 권리; 확대; 기업; 책임성; 강화"
            ]
        },
        "short_answer": {
            "question": "기존 Directive 95/46/EC과 비교해 GDPR에서 추가된 정보주체의 신규 권리는 무엇인가?",
            "answer": "개인정보 삭제권, 처리 제한권, 개인정보 이동권, 반대권(거부권) 등",
            "topic": [
                "GDPR에서 추가된 정보주체의 신규 권리"
            ]
        },
        "multiple_choice": {
            "question": "기존 Directive 95/46/EC과 비교해서 GDPR에 추가된 내용으로 옳지 않은 것은?",
            "choices": [
                "a) 개인정보 삭제권과 이동권을 명확히 규정하였다.",
                "b) 개인정보 처리 활동의 기록을 요구한다.",
                "c) 정보주체의 권리를 제한하였다.",
                "d) DPO 지정과 개인정보 영향평가 등을 규정하였다."
            ],
            "answer": "c",
            "topic": [
                "기존 Directive 95/46/EC과 비교해서 GDPR에 추가된 내용"
            ]
        },
        "true_false": {
            "question": "GDPR은 EU 역내에서 개인정보의 자유로운 이동을 보장하는 것을 목적으로 한다.",
            "answer": "TRUE",
            "topic": [
                "GDPR의 목적"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:19:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "1.3 GDPR의 법적 효력 GDPR은 지침(Directive)과 달리 “Regulation”이라는 법 형식으로 제정되어 법적 구 속력을 가지며, 모든 EU 회원국 내에 직접적으로 적용된다(제99조). 기존 Directive에서는 회원국 간 개인정보보호 법제가 서로 달라 규제에 어려움이 있 었으나, GDPR 제정을 통하여 통일된 개인정보보호 규제가 가능하게 되었다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:19:mh: 00001",
                    "page": 19
                }
            },
            {
                "context_id": "2",
                "text": "GDPR 일부 조항에 대해서는 회원국의 별도 입법이 요구되므로, 기업들은 GDPR 이  외에 각 회원국의 개인정보보호 관련 입법 동향에 대하여 지속적으로 모니터링할 필  요가 있다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:19:mh: 00001",
                    "page": 20
                }
            }
        ],
        "summarization": "GDPR은 EU 전역에 직접 적용되는 법적 구속력을 가진 규정(Regulation)으로, 모든 EU 회원국에 적용되는 통일된 개인정보보호 법제니다. 다만 일부 조항은 회원국의 별도 입법이 필요하여 기업은 각국의 입법 동향을 지속적으로 모니터링해야 한다.",
        "long_answer": {
            "question": "기존 Directive와 GDPR의 차이를 비교하여 설명하라.",
            "answer": "기존 Directive 체제에서는 각 회원국의 개인정보보호 법제가 상이하여 규제에 어려움이 있었다. 반면, GDPR은 Regulation으로 제정되어 모든 EU 회원국에 동일하게 적용된다. EU는 GDPR을 통해 통일된 개인정보보호 규제를 할 수 있게 되었다.",
            "rubric": [
                "Regulation; 통일; 개인정보보호 규제"
            ]
        },
        "short_answer": {
            "question": "GDPR은 어떤 형태의 법 형식인가?",
            "answer": "Regulation",
            "topic": [
                "GDPR의 법 형태"
            ]
        },
        "multiple_choice": {
            "question": "보기 중 GDPR의 특징으로 옳은 것은?",
            "choices": [
                "a) GDPR은 각 회원국이 선택적으로 적용할 수 있는 지침이다.",
                "b) GDPR은 모든 회원국 내에 직접적으로 적용되는 규정이다.",
                "c) GDPR은 법적 구속력이 없는 비권고성 문서이다.",
                "d) GDPR은 회원국별로 서로 다른 법체계를 유지하도록 규정한다."
            ],
            "answer": "b",
            "topic": [
                "GDPR의 법적 효력"
            ]
        },
        "true_false": {
            "question": "GDPR은 모든 조항이 완전히 동일하게 적용되므로, EU회원국이 별도 입법을 할 필요가 없다.",
            "answer": "FALSE",
            "topic": [
                "GDPR의 적용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:21:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.1 EU 역내 및 역외 적용 EU 내 설립된 기관의 개인정보 처리 활동 외에 다음 경우를 적용 범위에 포함하였다. 1 EU 밖에서 EU 내에 있는 정보주체에게 재화나 용역을 제공하는 경우 2 또는 EU 내에 있는 정보주체가 수행하는 활동을 모니터링하는 경우",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:21:0001",
                    "page": 21
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "EU의 GDPR은 총 세 가지의 경우에 적용된다. GDPR은 EU 내에서 설립된 기관의 개인정보 처리 활동과, EU 외부에서 EU 내 정보주체에게 재화나 용역을 제공하거나 EU 내 정보주체의 활동을 모니터링하는 경우에도 적용된다.",
        "long_answer": {
            "question": "EU 역내 기관과 EU 역외 기관의 GDPR 적용 기준은 어떤 차이가 있는지 설명하시오.",
            "answer": "EU 역내 기관은 설립 장소를 기준으로 GDPR의 적용을 받는다. 반면 EU 역외 기관의 경우 EU내에서의 활동을 기준으로 GDPR이 적용된다. 만약 EU 외부 기관이 EU 내 정보주체에게 재화나 용역을 제공하거나 EU 내 정보주체의 활동을 모니터링한다면 GDPR이 동일하게 적용된다.",
            "rubric": [
                "역외; 재화; 용역; 정보주체; 모니터링"
            ]
        },
        "short_answer": {
            "question": "EU 외부 기관이 GDPR의 적용을 받을 수 있는 두 가지 경우는?",
            "answer": "EU 내 정보주체에게 재화나 용역을 제공, EU 내 정보주체의 활동 모니터링",
            "topic": [
                "EU 외부 기관이 GDPR의 적용을 받는 경우"
            ]
        },
        "multiple_choice": {
            "question": "GDPR의 적용 범위에 대한 설명으로 거리가 먼 것은?",
            "choices": [
                "a) EU 내 설립 기관의 개인정보 처리 활동 시 적용된다.",
                "b) EU 외부 기관이 EU 내 정보주체에게 용역을 제공하는 경우에도 적용된다.",
                "c) EU 역외 기관도 일정 조건하에서 적용될 수 있다.",
                "d) EU 외부 기관이 EU 내 정보주체를 모니터링하는 경우에는 적용되지 않는다."
            ],
            "answer": "d",
            "topic": [
                "GDPR의 적용 범위"
            ]
        },
        "true_false": {
            "question": "EU 외부 기관이 EU 내 정보주체의 활동을 모니터링하면 GDPR이 적용된다.",
            "answer": "TRUE",
            "topic": [
                "EU 외부 기관의 GDPR의 적용 범위"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:21:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "개인정보를 “식별되었거나 또는 식별 가능한 자연인(정보주체)과 관련된 모든 정보”로  정의하면서(제4조제1항), 기존 Directive에 명시되지 않았으나 판례, 유권해석, 개별법  차원에서 인정된 개념을 포함하였다.  1 자연인이 사용하는 장치, 애플리케이션, 도구와 프로토콜을 통해 제공되는 개인  식별이 가능한 경우의 IP 주소, 쿠키(cookie) ID, RFID(무선 인식) 태그 등을 개  인정보(온라인 식별자)에 포함한다(전문 제30항).  2 위치정보를 개인정보의 정의에 명시적으로 규정하였다(제4조제1항).  3 민감한 성격의 개인정보를 ‘특수한 범주의 개인정보’(이하 ‘민감정보’)라고 정의하  면서, 유전정보와 생체 인식정보를 명시적으로 규정하였다(제9조제1항).",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:21:mh: 00001",
                    "page": 21
                }
            },
            {
                "context_id": "2",
                "text": "4 개인정보의 가명처리(pseudonymisation) 개념을 명문화함으로써(제4조제5항),  분리 보관 및 특별조치 등을 통하여 개인정보를 활용할 수 있도록 하였다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:21:mh: 00001",
                    "page": 22
                }
            }
        ],
        "summarization": "GDPR은 개인정보를 식별되었거나 식별 가능한 자연인과 관련된 모든 정보로 정의하고, IP 주소, 쿠키 ID, RFID 태그, 위치정보, 유전정보, 생체 인식정보 등을 포함한다. 또한 가명처리 개념을 도입하여 개인정보를 분리 보관 및 활용할 수 있도록 하였다.",
        "long_answer": {
            "question": "기존 Directive와 비교하여 GDPR에서 개인정보의 정의와 범위가 어떻게 달라졌는지 설명하시오.",
            "answer": "기존 Directive에 비해 GDPR에서는 개인정보의 범위가 확장되었다고 볼 수 있다. GDPR은 개인정보를 '식별되었거나 식별 가능한 자연인과 관련된 모든 정보'로 정의한다. 이 정의에는 기존 Directive에 없던 판례와 유권해석, 개별법 차원에서 인정된 개념이 포함되었다.",
            "rubric": [
                "판례; 유권해석; 개별법"
            ]
        },
        "short_answer": {
            "question": "GDPR에서 개인식별이 가능한 경우 개인정보가 될 수 있는 온라인 식별자에는 어떤 정보가 포함되는가?",
            "answer": "IP 주소, 쿠키 ID, RFID 태그 등",
            "topic": [
                "GDPR의 개인정보 온라인 식별자"
            ]
        },
        "multiple_choice": {
            "question": "GDPR에서 규정한 개인정보의 정의에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 개인정보는 익명화된 정보만 포함한다.",
                "b) 온라인 식별자는 개인정보에 포함되지 않는다.",
                "c) 위치정보와 생체정보는 개인정보의 정의에 포함된다.",
                "d) 개인정보는 법인과 관련된 모든 정보이다."
            ],
            "answer": "c",
            "topic": [
                "GDPR의 개인정보 정의"
            ]
        },
        "true_false": {
            "question": "GDPR은 개인 식별이 가능한 IP 주소나 쿠키 ID도 개인정보에 포함된다고 규정한다.",
            "answer": "TRUE",
            "topic": [
                "GDPR의 개인정보 온라인 식별자"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:22:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "동의 요건의 강화 및 아동 개인정보 처리에 대한 동의 원칙  GDPR에 따른 유효한 동의는 수집되는 개인정보가 이용되는 목적에 대한 명시적 동의 여야 한다(GDPR 제7조 및 제4조). 컨트롤러는 동의를 받았다는 사실을 증명할 수 있어 야 하고, 해당 동의는 철회될 수 있다. 만 16세 미만의 아동에게 직접 정보사회서비스를 제공할 때에는 부모나 보호자의 동의 를 받아야 한다(제8조제1항). 다만, 각 회원국은 개별 법률을 통하여 부모나 보호자의 동의를 요하는 아동의 연령 기준을 만 13세까지 낮추어 규정할 수 있다(제8조제2항).",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:22:0001",
                    "page": 22
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR은 개인정보 수집 시 명시적 동의를 요구하며, 동의는 언제든 철회할 수 있다. 또한 만 16세 미만 아동에게 정보사회서비스를 제공할 때는 부모나 보호자의 동의가 필요하다.",
        "long_answer": {
            "question": "개인정보 수집 동의를 받을 때, 해당 동의가 GDPR에 따른 유효한 동의가 되기 위한 조건은 무엇인가?",
            "answer": "GDPR에서는 개인정보를 수집할 때, 개인정보가 이용되는 목적에 대한 명시적 동의만이 유효한 동의로 인정받는다. 개인정보 컨트롤러는 동의를 받았다는 사실을 증명할 수 있어야 한다. 또한, 해당 개인정보 수집 동의는 언제든 철회될 수 있다.",
            "rubric": [
                "명시적 동의; 컨트롤러; 증명"
            ]
        },
        "short_answer": {
            "question": "GDPR의 기준으로 부모자 보호자 동의 없이 아동에게 직접 정보사회서비스를 제공할 수 있는 최저 연령은?",
            "answer": "만 16세",
            "topic": [
                "GDPR의 아동 개인정보 처리 원칙"
            ]
        },
        "multiple_choice": {
            "question": "GDPR의 개인정보 수집 동의 및 아동 개인정보 처리 요건에 대한 설명으로 옳은 것을 고르시오.",
            "choices": [
                "a) GDPR에서는 개인정보 이용 목적에 대한 포괄적 동의만으로 유효한 개인정보 종의가 된다.",
                "b) 개인정보 컨트롤러는 개인정보 수집 동의를 받았다는 사실을 증명할 필요가 없다.",
                "c) 개인정보 수집 동의는 언제든 철회될 수 있다.",
                "d) GDPR에 따르면, 모든 아동에게 부모의 동의 없이 정보사회서비스를 제공할 수 있다."
            ],
            "answer": "c",
            "topic": [
                "GDPR의 개인정보 수집 동의 및 아동 개인정보 처리 요건"
            ]
        },
        "true_false": {
            "question": "GDPR은 아동에게 정보사회서비스 제공 시 부모 동의 기준을 반드시 모든 국가에서 만 16세가 되도록 규제하고 있다.",
            "answer": "FALSE",
            "topic": [
                "GDPR의 아동 개인정보 처리 원칙"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:24:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.9 책임성과 거버넌스 공공 기관이나 정기적·체계적·대규모 등 일정 기준에 해당하는 컨트롤러나 프로세서 는 DPO(Data Protection Officer)를 지정해야 하고(제37조~제39조), 컨트롤러에게 도 GDPR 각 규정의 준수를 위하여 일정한 의무가 부과된다. 예를 들면, 문서보관의무 나 개인정보 영향평가(제35조)를 받을 의무가 있으며, 기획 단계에서부터 기본적으로 정보보호가 높은 수준으로 설정될 수 있도록 관련활동을 수행하여야 한다(privacy by design and by default, 제25조). 구체적으로 개인정보보호를 위하여 아래와 같은 책임성 및 거버넌스가 요구된다. 1 처리 활동의 기록(제30조) 2 높은 위험(high risk)을 내재한 개인정보 처리에 대하여 개인정보 영향평가 수행 (제35조) 3 DPO 지정(제37조) 4 개인정보 침해 통지 및 종합적 기록 유지(제33조~제34조) 5 Data protection by design and by default 이행(제25조) 등",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:24:0001",
                    "page": 24
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR에서는 공공기관이나 일정 기준을 충족하는 컨트롤러 및 프로세서는 DPO를 지정해야 한다. 컨트롤러도 GDPR 규정 준수를 위해 문서보관 의무나 개인정보 영향평가 등을 받을 의무가 있으며, 정보보호가 높은 수준으로 설정되도록 기획 단계에서부터 관련활동을 수행해야 한다.",
        "long_answer": {
            "question": "GDPR에서 컨트롤러와 프로세서에게 요구되는 주요 책임성과 거버넌스 요소를 설명하라.",
            "answer": "GDPR은 공공기관이나 정기적, 체계적, 대규모 개인정보 처리를 수행하는 컨트롤러나 프로세서에게 DPO를 지정하도록 하고 있다. 또한 개인정보 처리 활동의 기록 유지, 높은 위험이 있는 개인정보 처리에 대한 개인정보 영향평가 수행, 개인정보 침해 발생 시 통지 및 기록 관리, Data protection by design and by default 이행 등의 의무를 부과한다.",
            "rubric": [
                "DPO; 처리 활동 기록; 영향평가; 개인정보 침해 통지; Data protection by design and by default"
            ]
        },
        "short_answer": {
            "question": "GDPR에 따라 일정 기준에 해당하는 컨트롤러나 프로세서가 반드시 지정해야 하는 직책은?",
            "answer": "DPO(Data Protection Officer)",
            "topic": [
                "GDPR의 책임성과 거버넌스 조치"
            ]
        },
        "multiple_choice": {
            "question": "GDPR에서 일정 기준의 컨트롤러나 프로세서에서 부과되는 책임성과 거버넌스 조치로 옳은 것은?",
            "choices": [
                "a) 개인정보 처리 활동의 기록 유지가 요구된다.",
                "b) 개인정보 보호는 사후 점검으로 충분하다.",
                "c) DPO 지정은 선택 사항이다.",
                "d) 개인정보 침해는 통지하지 않아도 된다."
            ],
            "answer": "a",
            "topic": [
                "GDPR의 책임성과 거버넌스 조치"
            ]
        },
        "true_false": {
            "question": "GDPR은 높은 위험을 내재한 개인정보 처리에 대해 개인정보 영향평가를 수행하도록 정하고 있다.",
            "answer": "TRUE",
            "topic": [
                "GDPR의 책임성과 거버넌스 조치"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:25:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "GDPR이 인정하는 개인정보의 역외 이전 메커니즘에 따르는 경우에만 EU 역외로의 개  인정보 이전이 허용된다.  1 적정성 결정(adequacy decision)을 통하여 개인정보보호 관련 법제가 적절한 수준  의 보호를 보장하고 있다고 인정된 국가로 이전하는 경우(제45조)  2 ‘적절한 보호조치(appropriate safeguards)의 제공’, ‘정보주체의 권리 행사 보장’,  ‘효과적인 법적 구제 수단의 존재’에 모두 해당하는 경우(제46조)  – 적절한 보호조치에는 구속력 있는 기업 규칙(Binding Corporate Rules), 표준  개인정보보호 조항(Standard data protection clauses), 승인된 행동규약(code of  conduct), 승인된 인증 메커니즘(certification) 등이 포함  3 적정성 결정이나 적절한 보호조치가 없는 경우에도 명시적 동의(explicit consent),  계약의 이행 또는 정보주체의 요청으로 필요한 경우, 공익의 중요한 이유 등과 같은  특정 상황에서 예외 요건에 해당하는 경우에 역외 이전이 가능하다(제49조).",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:25:0001",
                    "page": 25
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR은 EU 역외로 개인정보를 이전할 때, 적정성 결정, 적절한 보호조치 등의 조건 구비, 예외적 상황 중 하나의 메커니즘을 충족해야만 한다. 해당 매커니즘에 따르는 경우에만 EU 역외로의 개인정보 이전을 허용한다.",
        "long_answer": {
            "question": "GDPR에서 EU 역외로의 개인정보 이전을 허용하는 세 가지의 상황에 대해 쓰시오.",
            "answer": "GDPR에서 EU 역외로의 개인정보 이전을 허용하는 상황 중 첫 번째는 적정성 결정에 따라 해당 국가가 적절한 수준의 개인정보보호를 보장하는 경우이다. 두 번째 경우는 적절한 보호조치, 정보주체 권리행사 보장, 효과적인 법적 구제 수단이 모두 준비되어 있는 경우이다. 세 번째는 적정성 결정이나 보호조치가 없어도 명시적 동의, 계약 이행, 정보주체의 요청으로 필요한 경우, 중요한 공익적인 이유 등의 예외 상황에 해당할 때이다.",
            "rubric": [
                "적정성 결정; 적절한 보호조치; 정보주체 권리행사 보장; 효과적인 법적 구제 수단; 명시적 동의; 계약 이행; 정보주체; 요청; 공익적;"
            ]
        },
        "short_answer": {
            "question": "적정성 결정이나 적절한 보호조치가 없는 경우에도 GDPR에서 인정하는 개인정보의 역외 이전 사유는?",
            "answer": "명시적 동의, 계약 이행 또는 정보주체의 요청, 공익",
            "topic": [
                "GDPR의 개인정보의 역외 이전 예외 조건"
            ]
        },
        "multiple_choice": {
            "question": "아래 보기에서 GDPR에서 인정하는 개인정보 역외 이전 조건에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) GDPR의 역외 이전 조건 중 적절한 보호조치의 종류에는 승인된 인증 메커니즘이 포함될 수 있다.",
                "b) 정보주체의 명시적 동의가 있으면 예외적으로 이전이 가능하다.",
                "c) 표준 개인정보보호 조항은 GDPR의 역외 이전 조건 중 적절한 보호조치의 한 종류이다.",
                "d) 적정성 결정이 없는 경우에는 어떠한 경우에도 이전이 불가능하다."
            ],
            "answer": "d",
            "topic": [
                "GDPR의 개인정보의 역외 이전 조건"
            ]
        },
        "true_false": {
            "question": "GDPR은 어떠한 경우에도 적정성 결정 없이 개인정보의 역외 이전을 허용하지 않는다.",
            "answer": "FALSE",
            "topic": [
                "GDPR의 개인정보의 역외 이전 예외 조건"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:25:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.12 개인정보 침해 시 통지의무  컨트롤러는 개인의 권리와 자유에 위험을 일으킬 가능성이 있는 침해가 발생한 경우,  개인정보 침해 사실을 인지한 시점으로부터 72시간 내에 감독기구에 신고하여야 하며,  개인의 자유와 권리에 높은 위험이 예상될 때에는 부당한 지체 없이(without undue  delay) 침해 사실을 정보주체에게 통지하여야 한다.  다만 개인정보 침해가 개인의 자유와 권리에 위험을 일으킬 가능성이 낮은 경우 통지  하지 않을 수 있다.  만약, 감독기구에 대한 신고가 72 시간 이내에 이루어지지 않는 경우에는 지체된 이유  를 함께 신고해야 한다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:25:0001",
                    "page": 25
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "개인의 권리와 자유에 위험을 일으킬 수 있는 개인정보 침해 발생 시 개인정보의 컨트롤러는 72시간 내 감독기구에 신고해야 한다. 또한 개인의 권리와 자유에 높은 위험이 예상된다면 정보주체에게 그 침해 사실을 지체없이 통보해야 한다.",
        "long_answer": {
            "question": "개인정보 침해 발생 시, GDPR에 따라 개인정보 컨트롤러가 해야 하는 의무 중에 감독기구 신고와 정보주체 통지는 어떤 차이가 있는지 비교하시오.",
            "answer": "개인정보 침해 발생 시 컨트롤러는 침해 사실을 인지한 시점으로부터 무조건 72시간 이내에 감독기구에 신고해야 한다. 이에 비해 정보주체 통지는 개인의 자유와 권리에 높은 위험이 예상될 때 부당한 지체 없이 수행되어야 하고, 위험을 일으킬 가능성이 낮다면 통지하지 않아도 된다. 감독기구 신고는 반드시 해야 하지만, 비해 정보주체 통지는 위험 수준에 따라 통지 여부를 결정할 수 있다.",
            "rubric": [
                "72시; 감독기구; 정보주체 통지; 위험;"
            ]
        },
        "short_answer": {
            "question": "GDPR에 따르면, 개인정보 침해 발생 시 컨트롤러가 감독기구에 신고해야 하는 데드라인은 언제까지인가?",
            "answer": "72시간",
            "topic": [
                "개인정보 침해 시 GDPR에 따른 컨트롤러의 의무"
            ]
        },
        "multiple_choice": {
            "question": "개인정보 침해 시 GDPR에 따른 컨트롤러의 의무에 대해 옳게 이야기한 것을 고르시오.",
            "choices": [
                "a) 72시간 이내 감독기구에 신고해야 하며, 높은 위험 시 정보주체에도 통지해야 한다.",
                "b) 위험이 낮은 경우에도 반드시 통지를 해야 한다.",
                "c) 모든 침해는 즉시 정보주체에게 통지해야 한다.",
                "d) 신고 지연 시 별도의 조치가 필요하지 않다."
            ],
            "answer": "a",
            "topic": [
                "개인정보 침해 시 GDPR에 따른 컨트롤러의 의무"
            ]
        },
        "true_false": {
            "question": "GDPR에 따르면, 개인정보 컨트롤러는 개인정보 침해 사실을 인지한 후 72시간 내에 감독기구에 신고해야 한다.",
            "answer": "TRUE",
            "topic": [
                "개인정보 침해 시 GDPR에 따른 컨트롤러의 의무"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:26:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.13 제재  각각의 개인정보 처리에 따라 제재 규정을 적용하며, ‘사업체 집단’ 매출을 바탕으로  과징금(fines imposed by reference to the revenues of an undertaking)을 부과  한다.  1 GDPR 규정의 일반적 위반의 경우 직전 회계연도의 전 세계 매출액 2% 또는 1천만  유로 중 더 큰 금액을 상한으로 하여 부과  2 GDPR 규정의 심각한 위반의 경우 직전 회계연도의 전 세계 매출액 4% 또는 2천  만 유로 중 더 큰 금액을 상한으로 하여 부과",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:26:0001",
                    "page": 26
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR는 개인정보 처리 규정 위반 시 사업체 매출을 기준으로 과징금을 부과한다. GDPR의 위반 정도에 따라 과징금의 상한 금액이 달라진다.",
        "long_answer": {
            "question": "GDPR의 개인정보 처리 규정 위반 시 일반적 위반과 심각한 위반의 과징금 상한선은 얼마인가?",
            "answer": "일반적 GDPR 위반은 직전 회계연도의 전 세계 매출액 2% 또는 1천만 유로 중 큰 금액을 상한으로, 심각한 위반은 4% 또는 2천만 유로 중 큰 금액을 상한으로 하여 과징금을 부과한다. 따라서 심각한 위반은 일반적 위반보다 비율로 하면 2%, 금액으로 하면 1천만 유로 더 높은 금액의 과징금이 부과된다.",
            "rubric": [
                "일반적 위반; 2%; 1천만 유로; 심각한 위반; 4%; 2천만 유로;"
            ]
        },
        "short_answer": {
            "question": "GDPR의 개인정보 처리 규정 위반 시 과징금 부과 기준은 무엇인가?",
            "answer": "사업체 매출",
            "topic": [
                "GDPR의 개인정보 처리 규정 위반 시 과징금 부과 기준"
            ]
        },
        "multiple_choice": {
            "question": "GDPR의 개인정보 처리 규정 위반 시 과징금 액수 산정 방법으로 잘못된 것은?",
            "choices": [
                "a) 일반적 위반 상한은 직전 회계연도 매출액 2% 또는 1천만 유로 중 큰 금액이다.",
                "b) 심각한 위반 상한은 직전 회계연도 매출액 4% 또는 2천만 유로 중 큰 금액이다.",
                "c) 과징금은 사업체 집단 매출을 기준으로 산정된다.",
                "d) 모든 과징금은 직전 회계연도 매출액 1%를 상한으로 한다."
            ],
            "answer": "d",
            "topic": [
                "GDPR의 개인정보 처리 규정 위반 시 과징금 액수 산정 기준"
            ]
        },
        "true_false": {
            "question": "일반적 GDPR 개인정보 처리 규정 위반 과징금은 직전 회계연도 매출액 5%를 상한으로 부과된다.",
            "answer": "FALSE",
            "topic": [
                "GDPR의 개인정보 처리 규정 위반 시 과징금 액수 산정 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:26:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.14 인증제도 및 인증기관에 대한 인정  GDPR은 기업의 GDPR 준수 입증을 위해 인증 메커니즘(certification mechanism)  의 이용을 권장하고 있다.  인증 제도를 활용할 경우 기업은 기술적·관리적 조치 및 개인정보 이전과 관련한 적절  한 보호조치를 실시하고 있음을 입증할 수도 있다.  인증서는 감독기구나 지정된 인증기관이 발행하며 인증의 유효기간은 최대 3년이다.  GDPR은 인증을 발급하는 인증기관(certification bodies)이 소관 감독기구(competent  supervisory authority)나 국가의 인정 기관(national accreditation body), 또는 두 기  관 모두의 인정을 받도록 요구하고 있다.  이는 인증 메커니즘 수립과 개인정보보호를 보장하기 위한 것으로, 효과적인 인증 메커  니즘을 도입할 경우 GDPR 준수와 정보주체에 대한 투명성 향상 효과를 제공할 것으로  기대된다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:26:0001",
                    "page": 26
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR은 기업이 개인정보 보호를 위해 인증 메커니즘을 활용하도록 권장하며, 감독기구나 지정된 인증기관이 발행한 인증서는 최대 3년 동안 유효하다. 인증기관은 소관 감독기구나 국가 인정 기관, 또는 두 기관 모두의 인정을 받아야 한다.",
        "long_answer": {
            "question": "GDPR 인증 제도를 활용할 경우 기업이 얻을 수 있는 효과를 쓰시오.",
            "answer": "GDPR 인증 제도를 활용하면 기업은 기술적, 관리적 조치 및 개인정보 이전과 관련한 적절한 보호조치를 실시하고 있음을 입증할 수 있다. GDPR은 인증기관 소관 감독기구나, 국가 인정기관 또는 두 기관 모두의 인정을 받도록 요구하고 있다.",
            "rubric": [
                "적절한 보호조치; 입증;"
            ]
        },
        "short_answer": {
            "question": "감독기구나 지정된 인증기관이 발행한 GDPR 준수 인증서의 유효기간은 최대 얼마인가?",
            "answer": "3년",
            "topic": [
                "GDPR 준수 입증을 위한 인증서의 유효기간"
            ]
        },
        "multiple_choice": {
            "question": "GDPR 준수 인증 관련 잘못된 설명은 무엇인가?",
            "choices": [
                "a) 인증서는 감독기구나 지정된 인증기관이 발급한다.",
                "b) 인증기관은 국가 인정 기관으로부터만 인정을 받으면 충분하다.",
                "c) 인증 메커니즘은 기업의 개인정보 보호 조치 입증에 사용될 수 있다.",
                "d) 인증의 유효기간은 최대 3년이다."
            ],
            "answer": "b",
            "topic": [
                "GDPR 준수 입증을 위한 인증 매커니즘의 내용"
            ]
        },
        "true_false": {
            "question": "GDPR 준수 입증을 위한 인증서는 기업이 스스로 발급하며 유효기간 제한이 없다.",
            "answer": "FALSE",
            "topic": [
                "GDPR 준수 입증을 위한 인증 매커니즘의 내용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:29:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "컨트롤러는 개인정보 처리의 목적과 수단을 결정하는 주체를 의미하며, 이와 같은 결  정은 컨트롤러 단독으로 하거나 또는 제3자와 공동으로 할 수 있다.  자연인을 비롯하여 법인, 정부부처 및 관련기관, 기타 단체 등이 컨트롤러가 될 수 있다.  이 때 개인정보 처리의 목적과 수단이 EU 또는 회원국(member state)의 법률에 의  해 결정되는 경우, 컨트롤러 또는 컨트롤러 지정을 위한 기준은 EU 또는 회원국의 법  률에 의해 정의될 수 있다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:29:0001",
                    "page": 29
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "컨트롤러는 개인정보 처리의 목적과 수단을 결정하는 주체로, 단독 또는 제3자와 공동으로 결정할 수 있다. 컨트롤러는 자연인, 법인, 정부부처 및 기타 단체가 될 수 있으며, 관련 법률에 따라 정의될 수도 있다.",
        "long_answer": {
            "question": "GDPR에서 컨트롤러는 무엇을 결정하며, 누가 컨트롤러가 될 수 있는가?",
            "answer": "GDPR에서 컨트롤러는 개인정보 처리의 목적과 수단을 결정한다. 자연인을 비롯하여 법인, 정부부처, 관련기관 및 기타 단체가 컨트롤러가 될 수 있고, 개인정보 처리의 목적과 수단이 EU 또는 회원국 법률에 의해 결정된다면, 컨트롤러 또한 관련 법률을 통해 정의될 수 있다.",
            "rubric": [
                "컨트롤러; 개인정보 처리; 목적; 수단; 법률;"
            ]
        },
        "short_answer": {
            "question": "GDPR에서 컨트롤러란 무엇인가?",
            "answer": "개인정보 처리 주체",
            "topic": [
                "컨트롤러의 정의"
            ]
        },
        "multiple_choice": {
            "question": "GDPR에서 정의하는 컨트롤러에 대한 설명으로 옳은 내용은?",
            "choices": [
                "a) 컨트롤러는 개인정보 처리 과정에서 단독으로만 목적을 결정할 수 있다.",
                "b) 컨트롤러는 자연인, 법인, 정부부처 등 다양한 주체가 될 수 있다.",
                "c) 컨트롤러는 항상 EU 법률에 의해 지정된다.",
                "d) 컨트롤러는 목적과 수단을 결정할 필요가 없다."
            ],
            "answer": "b",
            "topic": [
                "GDPR에서 컨트롤러의 특징"
            ]
        },
        "true_false": {
            "question": "컨트롤러는 개인정보 처리의 목적과 수단을 단독으로 또는 제3자와 공동으로 결정할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "GDPR에서 컨트롤러의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:32:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "감독기구  GDPR은 EU 회원국마다 하나 이상의 감독기구(supervisory authority 또는 data  protection authority)의 설립을 의무화함으로써 컨트롤러와 프로세서의 개인정보 처  리 활동에 대한 공조와 통제가 가능하도록 하고 있다. 감독기구는 다음 사유에 해당하  는 경우 컨트롤러 또는 프로세서의 개인정보 처리에 관여할 수 있다.  1 컨트롤러나 프로세서가 자국 영토에 설립한 사업장에서 행하는 정보 처리  2 공익을 위하여 정부부처 및 관련기관이나 민간기구가 행하는 정보 처리  3 자국 영토의 정보주체에 영향을 미치는 정보 처리  4 EU 역내에 설립되지 않은 컨트롤러나 프로세서가 해당 감독기구가 설립된 국가에  거주하는 정보주체를 대상으로 행하는 정보 처리 등(전문 제122항)",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:32:0001",
                    "page": 32
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR은 EU 회원국마다 하나 이상의 감독기구 설립을 의무화하여 개인정보 처리 활동을 공조하거나 통제하도록 하고 있다. 있다. 감독기구는 자국 영토 내 정보 처리, 공익 목적 정보 처리, 정보주체에 영향을 미치는 처리, 또는 EU 외부 컨트롤러가 자국 거주 정보주체를 대상으로 하는 처리 등에 관여할 수 있다.",
        "long_answer": {
            "question": "GDPR에서 감독기구가 자국 영토 내 개인정보 처리와 EU 외부 컨트롤러의 정보 처리에 관여할 때의 차이점을 찾아 설명하시오.",
            "answer": "GDPR에 규정되어 있는 감독기구는 개인정보 처리 컨트롤러와 프로세서가 EU 역내에 있는지 또는 역외에 있는지에 따라 관여할 수 있는 범위가 달라진다. 자국 영토 내에서 이루어지는 컨트롤러 또는 프로세서의 정보 처리 활동에는 직접 관여할 수 있지만 EU 외부에 설립된 컨트롤러나 프로세서가 해당 감독기구가 설립되어 있는 국가에 거주하는 정보주체를 대상으로 처리할 때만 관여할 수 있다.",
            "rubric": [
                "역내; 외부; 정보 처리; 정보주체;"
            ]
        },
        "short_answer": {
            "question": "GDPR의 개인정보 처리 감독기구는 EU회원국 하나당 몇 개 이상 설치되어야 하는가?",
            "answer": "1개",
            "topic": [
                "GDPR의 개인정보 처리 감독기구 설립"
            ]
        },
        "multiple_choice": {
            "question": "아래 중 GDPR에서 감독기구가 관여할 수 없는 상황은 어떤 것인지 고르시오.",
            "choices": [
                "a) 자국 영토 내 정보 처리",
                "b) 공익 목적 정보 처리",
                "c) EU 외부 컨트롤러가 해당 국가 거주 정보주체를 대상으로 처리",
                "d) EU 외부 컨트롤러가 다른 국가 거주 정보주체를 대상으로 처리"
            ],
            "answer": "d",
            "topic": [
                "GDPR의 개인정보 처리 감독기구의 관여 범위"
            ]
        },
        "true_false": {
            "question": "GDPR 감독기구는 컨트롤러나 프로세서가 자국 영토에 설립한 사업장에서 행하는 정보 처리에 관여할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "GDPR의 개인정보 처리 감독기구의 관여 범위"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:32:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "GDPR은 본문 전반에 걸쳐 다음과 같이 감독기구의 업무와 권한을 명시하고 있다(제 57조). 1 컨트롤러와 프로세서와의 협력 2 영향평가의 수행 등에 대한 자문 3 개인정보 침해 통지에 대한 신고 접수 및 민원 처리 4 개인정보 침해 대책에 대한 지침 마련 5 제28조제8항 및 제46조제2항(d)의 표준 개인정보보호 조항의 채택 6 개인정보 역외 이전에 대한 고지 접수 7 GDPR 시행과 관련한 조사 실시 8 개인정보처리 관련 위험, 규칙, 안전 조치 및 권리에 대한 공공 의식의 향상 9 감독기구 간 상호 협력 등 감독기구는 업무 수행과 권한 행사에서 완전한 독립성을 가져야 하며, 별도의 연간 공 공 예산을 받아야 한다. 또한 다른 감독기구와의 상호 협력 및 지원과 관련된 업무 등 효과적인 업무 수행에 필요한 재정·인적 자원, 부지, 기반 시설을 제공받을 수 있다(전 문 제120항).",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:32:0001",
                    "page": 32
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR은 감독기구가 컨트롤러와 프로세서 협력, 영향평가 자문, 개인정보 침해 신고 및 민원 처리 등 다양한 업무를 수행하도록 하고 있다. 감독기구는 업무 수행과 권한 행사에서 독립성을 유지해야 하며, 효과적인 업무 수행을 위해 재정, 인적자원, 시설 등을 제공받을 수 있다.",
        "long_answer": {
            "question": "DPR에서 감독기구에게 보장되어야 할 권한 또는 지원 세 가지에 대해 설명하시오.",
            "answer": "감독기구는 업무 수행과 권한 행사에서 독립성을 보장받아야 한다. 또한 별도의 연간 공공 예산을 확보해야 한다. 마지막으로 업무 수행을 효과적으로 하기 위해 필요한 재정, 인적자원, 부지, 기반 시설을 제공받을 수 있다.",
            "rubric": [
                "독립성; 별도 예산; 재정; 인적 자원; 기반 시설; 부지;"
            ]
        },
        "short_answer": {
            "question": "감독기구의 업무와 권한은 GDPR의 몇 조에 명시되어 있는가?",
            "answer": "제57조",
            "topic": [
                "GDPR에서 감독기구의 업무와 권한"
            ]
        },
        "multiple_choice": {
            "question": "GDPR에 명시된 감독기구의 권한과 업무 수행 내용에 가장 가까운 것을 고르시오.",
            "choices": [
                "a) 감독기구는 외부의 지시에 따라 업무를 수행해야 한다.",
                "b) 감독기구는 업무 수행과 권한 행사에서 독립성을 가져야 하며, 재정과 인적 자원을 제공받는다.",
                "c) 감독기구는 표준 개인정보보호 조항을 채택할 수 없고, 영향평가 자문도 하지 않는다.",
                "d) 감독기구는 다른 감독기구와 상호 협력할 필요가 없다."
            ],
            "answer": "b",
            "topic": [
                "GDPR에서 감독기구의 업무와 권한"
            ]
        },
        "true_false": {
            "question": "GDPR에서 감독기구는 GDPR 시행과 관련한 조사를 진행하지 않는다.",
            "answer": "FALSE",
            "topic": [
                "GDPR에서 감독기구의 업무와 권한"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:37:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "#3 가명처리된 정보의 활용 GDPR은 제6조제4항을 통하여 개인정보 처리의 당초 목적과 양립가능성 여부를 판단하는 보호조치 중 하나로 가명처리를 지목하고 있다. 특히 전문 제50항 및 제156항은 공익을 위한 기록 보존의 목적, 과학이나 역사적 연구의 목적, 또는 통계 목적인 경우의 정보 처리는 당초 목적과 양립가능성이 있 는 것으로 보고 가명처리를 통하여 추가적인 개인정보 처리가 가능하다고 밝히 고 있다. 다만 이러한 경우 추가적 정보는 제4조제5항에 따라 기술적·관리적 조 치 하에 별도 분리 보관되어야 한다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:37:0001",
                    "page": 37
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "가명처리는 개인정보 처리의 당초 목적과 다른 목적의 양립가능성을 판단하는 중요한 보호조치이다. 공익적 기록 보존, 과학이나 역사 연구, 통계 목적이 있는 경우 가명처리를 통해 추가적으로 개인정보 처리를 할 수 있다.",
        "long_answer": {
            "question": "GDPR에서 가명처리를 통해서 추가적으로 개인정보를 처리할 수 있는 경우 세 가지를 모두 쓰시오.",
            "answer": "GDPR에서 가명처리를 통해서 추가적으로 개인정보를 처리할 수 있는 경우는 공익을 위한 기론 보존, 과학 또는 역사적 연구, 통계목적인 경우 세 가지이다. 이 경우 당초의 개인정보 처리 목적과 이 세 가지 목적이 양립할 수 있다고 판단한다. 다만 이 경우 추가적인 정보들은 별도 분리 보관되어야 한다.",
            "rubric": [
                "공익; 기록 보존; 연구; 통계"
            ]
        },
        "short_answer": {
            "question": "GDPR에 따르면 당초와 다른 목적으로 개인정보를 처리하기 위한 가명처리 시 추가 정보는 어떻게 보관되어야 하는가?",
            "answer": "별도 분리 보관",
            "topic": [
                "GDPR에 따른 개인정보 활용을 위한 가명처리"
            ]
        },
        "multiple_choice": {
            "question": "GDPR에서 가명처리를 통한 개인정보 활용과 관련된 내용으로 옳지 않은 것은?",
            "choices": [
                "a) 공익적 기록 보존 목적의 정보 처리는 가명처리를 통해 추가 처리가 가능하다.",
                "b) 과학적 연구 목적의 정보 처리는 당초 목적과 양립가능성이 있다고 본다.",
                "c) 추가 정보는 별도의 기술적·관리적 조치 없이 함께 보관할 수 있다.",
                "d) 통계 목적의 정보 처리도 가명처리를 통해 허용될 수 있다."
            ],
            "answer": "c",
            "topic": [
                "GDPR에 따른 개인정보 활용을 위한 가명처리"
            ]
        },
        "true_false": {
            "question": "GDPR에 따르면, 공익적 기록 보존 목적의 정보 처리라면 가명처리 없이도 자유롭게 개인정보 처리를 할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "GDPR에 따른 개인정보 활용을 위한 가명처리"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:41:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "GDPR은 전체 또는 부분적으로 자동화된 수단에 의한 개인정보의 처리에 적용된다  (전자적 데이터베이스나 컴퓨터로 운영되는 파일링시스템 등).  다만, 수기 처리(manual processing)와 같이 비자동화 수단에 의한 개인정보 처리라  고 하더라도(관련성 있는)파일링시스템의 일부를 구성하는 경우 등에는 적용 대상이  된다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:41:0001",
                    "page": 41
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR은 전자적 데이터베이스나 컴퓨터로 운영되는 파일링시스템 등과 같이 자동화 수단에 의한 개인정보의 처리에 적용된다. 다만 비자동화 수단에 의한 처리라도 관련성이 있는 파일링시스템의 일부를 구성하는 경우 적용대상이 된다.",
        "long_answer": {
            "question": "자동화 수단을 통한 개인정보 처리와 비자동화 수단을 통한 개인정보 처리의 GDPR 적용 여부를 쓰시오.",
            "answer": "자동화된 개인정보 처리는 GDPR의 직접적인 적용 대상이다. 이에 비해 수기 처리와 같은 비자동화 방식은 원칙적으로 GDPR이 적용되지 않는다. 다만 수기에 의한 개인정보 처리라도 관련된 파일링시스템의 일부를 구성하고 있다면 GDPR의 적용을 받는다.",
            "rubric": [
                "자동화; 비자동화; 수기; 파일링시스템"
            ]
        },
        "short_answer": {
            "question": "GDPR이 적용될 수 있는 자동화 수단에 대한 개인정보 처리의 예시를 두 가지 쓰시오.",
            "answer": "전자적 데이터베이스, 컴퓨터로 운영되는 파일링시스템",
            "topic": [
                "GDPR의 물적 적용 범위"
            ]
        },
        "multiple_choice": {
            "question": "GDPR의 적용 대상에 대해 틀리게 설명한 것은?",
            "choices": [
                "a) 전자적 데이터베이스로 개인정보를 처리한 것은 GDPR의 적용 대상이다.",
                "b) 비자동화 수단으로 개인정보를 처리한 것은 파일링시스템의 일부일 경우 적용될 수 있다.",
                "c) 모든 형태의 수기 개인정보 처리가 GDPR의 적용 대상이다.",
                "d) 컴퓨터로 운영되는 파일링시스템을 통해 개인정보를 처리한 것은 GDPR이 적용된다."
            ],
            "answer": "c",
            "topic": [
                "GDPR의 물적 적용 범위"
            ]
        },
        "true_false": {
            "question": "GDPR은 전자적 데이터베이스나 컴퓨터 기반 파일링시스템을 통한 개인정보 처리에 적용된다.",
            "answer": "TRUE",
            "topic": [
                "GDPR의 물적 적용 범위"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:43:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "4.3 적용 예외(National derogations)(제2조제2항) GDPR은 다음 경우에 해당하는 개인정보 처리에는 적용되지 않는다. 1 EU 법률의 범위를 벗어나는 활동 2 개별 회원국에서 수행하는 EU의 공동 외교 안보 정책과 관련된 활동 3 자연인이 순수하게 수행하는 개인 또는 가사 활동 (purely personal or household activities) 4 공공 안전의 위협에 대한 보호 및 예방을 포함하여, 관할 감독기구 (competent authorities)의 범죄 예방, 수사, 탐지, 기소 및 형사처벌 집행 관련 활동",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:43:0001",
                    "page": 43
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR은 몇 가지의 적용 예외 상황에서는 적용되지 않는다. EU 법률의 범위를 벗어나는 활동, 외교 안보 정책 활동, 개인적 활동, 범죄 예방 및 수사 등 공공 안전 관련 활동에 해당하는 개인정보 처리에는 적용되지 않는다.",
        "long_answer": {
            "question": "GDPR의 적용 예외 상황 중, 개인정보 처리의 목적에 따라 인해 적용 예외가 되는 경우와 그렇지 않은 경우를 나누어 설명하라.",
            "answer": "개인정보 처리 목적에 의해 GDPR의 적용 예외가 되는 상황은 개별 회원국에서 수행하는 EU 공공의 외교 안보 정책 활동, 자연인이 하는 개인적 활동, 또한 공공 안전의 위협에 대한 보호 및 예방, 수사, 탐지, 기소 및 형사처벌 집행 관련 활동 등이 있다. 목적에 따른 적용 예외가 아닌 경우로는 EU법률의 범위를 벗어나는 활동이 있다.",
            "rubric": [
                "외교 안보 정책; 자연인; 공공 안전; 형사처벌; EU법률의 범위"
            ]
        },
        "short_answer": {
            "question": "GDPR이 적용되지 않는 개인정보 처리 활동 중 목적에 따라 예외가 된 개인정보 처리 활동이 아닌 것은?",
            "answer": "EU 법률을 벗어나는 활동",
            "topic": [
                "GDPR의 적용 예외 상황"
            ]
        },
        "multiple_choice": {
            "question": "개인정보 처리 활동 중 GDPR이 적용되지 않는 경우로 옳은 것은?",
            "choices": [
                "a) 개인이 순수하게 수행하는 가사 활동",
                "b) 공공 행정 절차에서의 개인정보 처리",
                "c) 상업적 목적의 데이터 분석",
                "d) 민간 기업의 고객 정보 수집"
            ],
            "answer": "a",
            "topic": [
                "GDPR의 적용 예외 상황"
            ]
        },
        "true_false": {
            "question": "모든 형태의 공공 안전 관련 개인정보 처리활동은 GDPR의 보호를 반드시 따라야 한다.",
            "answer": "FALSE",
            "topic": [
                "GDPR의 적용 예외 상황"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:50:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "목적 제한(purpose limitation)의 원칙은 개인정보를 수집할 때 처음부터 개인정보의 처리 목적을 구체적이고 명시적으로 제시해야 하고, 적법한 목적을 위해서 수집해야 하 며, 최초 수집 목적과 부합하지 않는 방식의 추가 처리를 하지 않는다는 원칙이다. 목적 제한의 원칙을 준수하기 위해서는 다음의 사항을 고려해야 한다. 첫째, 개인정보를 수집하는 이유와 수집한 개인정보로 무엇을 할 것인지 처음부터 명확 히 해야 한다. 둘째, 목적을 명확화하기 위하여 문서화해야 한다. 셋째, 정보주체에게 목적을 투명하게 알려야 한다. 넷째, 원래의 목적과 다른 목적으로 개인정보를 이용하거나 제공하려는 경우 그 목적은 공정하고 합법적이며 투명해야 한다. 다만 공익을 위한 기록 보존 목적, 과학적·역사적 연 구 목적 또는 통계 목적을 위한 개인정보의 추가 처리는 가명처리 등 안전한 조치를 취하는 한 원래 목적과 양립 가능한 것으로 본다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:50:0001",
                    "page": 50
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "목적 제한 원칙은 개인정보를 처음 수집할 때 처리 목적의 명확성과 구체성, 목적의 적법성을 지키면서 수집 목적에 부합하지 않는 방식으로 추가 처리하지 않는다는 원칙이다. 다만, 공익 등 예외의 상황에서는 가명처리 등을 통해 원래의 목적과 다른 목적으로 개인정보를 추가 처리할 수 있다.",
        "long_answer": {
            "question": "GDPR에 따라 개인정보 처리를 하려는 경우, 개인정보 수집 단계에서 목적 제한의 원칙을 지키기 위해 해야 하는 것을 쓰시오.",
            "answer": "먼저 개인정보 수집 목적과 활용 방안을 명확히 해야 한다. 그 후 수집 목적을 명확히 하기 위해 문서화하고, 개인정보를 수집하는 정보주체에게 그 목적을 투명하게 알려야 한다. 또한 원래 목적과 다른 목적으로 개인정보를 이용 또는 제공하려는 경우 그 목적 또한 공정하고 합법적이며 투명해야 한다.",
            "rubric": [
                "목적; 활용; 문서화; 정보주체; 공정; 합법; 투명"
            ]
        },
        "short_answer": {
            "question": "GDPR에 따라 목적 제한의 원칙을 지켜 개인정보를 처리할 때, 개인정보의 목적을 투명하게 알려야 하는 대상은?",
            "answer": "정보주체",
            "topic": [
                "GDPR의 목적 제한 원칙 준수사항"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 GDPR의 목적 제한의 원칙에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 개인정보는 수집 후 필요에 따라 새로운 목적에 자유롭게 사용할 수 있다.",
                "b) 개인정보는 최초의 수집 목적에 부합하지 않는 방식으로 추가 처리할 수 없다.",
                "c) 개인정보의 수집 목적은 반드시 내부 관리용으로만 문서화해야 한다.",
                "d) 개인정보의 추가 처리는 항상 금지된다."
            ],
            "answer": "b",
            "topic": [
                "GDPR의 목적 제한 원칙 준수사항"
            ]
        },
        "true_false": {
            "question": "목적 제한의 원칙에서는 개인정보의 처리 목적을 처음부터 구체적이고 명시적으로 제시해야 한다.",
            "answer": "TRUE",
            "topic": [
                "GDPR의 목적 제한 원칙 준수사항"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:50:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "목적 제한의 원칙은 개인정보의 수집 이유를 명확히 공개하고, 개인정보의 처리를 공개 된 목적으로 제한함으로써 개인정보의 처리 활동이 정보주체의 합리적인 기대와 일치 하게 하는 것을 목적으로 한다. 처음부터 처리 목적을 명확히 해두면 개인정보의 처리에 대한 컨트롤러의 책임감을 높 이고 컨트롤러가 은연중에 처리 목적을 확대하는 것을 막을 수 있다. 또한 정보주체는 컨트롤러가 개인정보를 어떻게 이용할지 이해할 수 있고, 개인정보 처리에 대한 동의 여 부를 결정하는 등 정보주체의 권리 행사에도 도움을 준다. 목적제한은 합법성, 공정성, 투명성 원칙과도 관련이 있다. 개인정보의 처리 이유를 명 확히 하면 처리가 공정하고 합법적이며 투명하다고 할 수 있기 때문이다. 따라서 개인정보를 불공정하거나 불법적, 혹은 은닉을 목적으로 이용하면 목적 제한 원 칙과 합법성, 공정성, 투명성 원칙을 둘 다 위반한 것이 될 수 있다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:50:0001",
                    "page": 50
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "목적 제한의 원칙이 필요한 이유는 개인정보 처리 활동이 정보주체의 합리적 기대와 일치해야 하기 때문이다. 개인정보 처리 목적을 명확히 하면 개인정보 처리에 대한 컨트롤러의 책임감을 높일 수 있고, 정보주체의 개인정보 처리 목적에 대한 이해도를 높이고 개인정보에 대한 권리 행사에 도움을 받을 수 있으며, 합법성, 공정성, 투명성을 보장할 수 있다.",
        "long_answer": {
            "question": "GDPR에서 목적 제한의 원칙과 합법성 공정성 투명성 원칙과의 관계를 설명하라.",
            "answer": "GDPR에서 목적 제한의 원칙과 합법성, 공정성, 투명성 법칙은 서로 연결되어 있다. 목적 제한의 원칙에 기반해 개인정보의 처리 이유를 명확히 하면 그 처리가 공정하고 합법적이며 투명하다고 볼 수 있다. 반면에 개인정보를 불법적이거나 불공정한 목적으로, 또는 은닉을 목적으로 이용하는 경우, 합법성, 공정성,투명성 원칙 모두를 위반하게 된다.",
            "rubric": [
                "개인정보; 처리; 이유; 공정; 합법; 투명"
            ]
        },
        "short_answer": {
            "question": "GDPR에서 목적 제한의 원칙과 연관되어 있는 다른 원칙 세 가지를 쓰시오.",
            "answer": "합법성, 공정성, 투명성 원칙",
            "topic": [
                "GDPR에서 목적 제한의 원칙와 다른 원칙들과의 관계"
            ]
        },
        "multiple_choice": {
            "question": "GDPR에 규정되어 있는 목적 제한의 원칙을 위반한 사례는?",
            "choices": [
                "a) 개인정보를 수집할 때 이용 목적을 명확히 알린 경우",
                "b) 정보주체가 동의 여부를 결정할 수 있도록 설명한 경우",
                "c) 개인정보 처리 과정의 투명성을 보장한 경우",
                "d) 공개된 목적 외의 불법적 이용을 한 경우"
            ],
            "answer": "d",
            "topic": [
                "목적 제한의 원칙 위반 사례"
            ]
        },
        "true_false": {
            "question": "개인정보를 불공정하거나 불법적인 목적으로 이용하면 GDPR에 규정되어 목적 제한 원칙과 합법성·공정성·투명성 원칙 모두를 위반한 것이다.",
            "answer": "TRUE",
            "topic": [
                "GDPR에 규정된 목적 제한의 원칙 내용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:53:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "‘최소처리(data minimisation)’ 원칙이란 처리 목적을 달성하기 위하여 적절한 범위 내에서, 처리 목적과 합리적으로 관련이 있고, 목적을 달성하기 위하여 필요한 것 이상 으로 처리하지 않는다는 원칙이다. 최소처리 원칙은 정확성 원칙, 보유기간 제한 원칙과 함께 “개인정보 처리 표준”에 관 한 세 가지 원칙 중 첫 번째 원칙에 해당한다. 컨트롤러는 목적 달성에 필요한 최소한의 개인정보를 파악하고, 그 범위 내의 개인정 보만 가지고 있어야 하며, 그 이상의 개인정보를 가지고 있어서는 안 된다. 또한, 컨트롤러는 목적 달성에 필요한 개인정보만 수집해서 보유할 것임을 보장하기 위 한 적절한 프로세스를 갖추고 있다는 것도 증명해야 한다. 정보주체는 목적 달성에 적합하지 않은 불완전한 개인정보의 정정·보완을 요구할 수 있고, 목적 달성에 필요하지 않은 개인정보의 삭제를 요구할 수도 있다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:53:0001",
                    "page": 53
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "최소처리 원칙은 목적 달성을 위해 필요한 최소한의 범위 내에서만 개인정보를 수집하고 이용해야 한다는 원칙이다. 컨트롤러는 적절한 프로세스를 갖추어 필요한 개인정보만 보유해야 하고, 정보주체는 불필요하거나 부적절한 개인정보를 정정 보완하거나 삭제를 요구할 수 있다.",
        "long_answer": {
            "question": "GDPR의 개인정보 최소처리 원칙에서 컨트롤러의 의무에 대해 쓰시오.",
            "answer": "GDPR의 개인정보 최소처리 원칙에 의하면 컨트롤러는 목적 달성에 필요한 최소한의 개인정보만 보유해야 한다. 그 목적 범위 이상의 개인정보를 가지고 있어서는 안 된다. 또한 목적 달성에 필요한 개인정보만 수집해서 보유할 수 있는 적절한 프로세스를 갖추고 있다는 사실도 증명해야 한다.",
            "rubric": [
                "목적 달성; 최소; 범위; 프로세스; 증명"
            ]
        },
        "short_answer": {
            "question": "GDPR의 개인정보 최소처리 원칙에서, 목적 달성에 필요한 최소한의 개인정보만을 가지고 있어야 하는 개인정보 처리 주체는?",
            "answer": "컨트롤러",
            "topic": [
                "GDPR의 개인정보 최소처리 원칙에서 컨트롤러의 의무"
            ]
        },
        "multiple_choice": {
            "question": "아래의 보기 중 GDPR의 개인정보 최소처리 원칙과 부합하지 않는 것은?",
            "choices": [
                "a) 최소처리 원칙은 개인정보 처리 표준의 첫 번째 원칙이다.",
                "b) 컨트롤러는 목적 달성에 필요한 개인정보만 수집해야 한다.",
                "c) 정보주체는 필요하지 않은 개인정보의 삭제를 요구할 수 있다.",
                "d) 최소처리 원칙은 개인정보를 가능한 한 많이 수집하여 처리하는 것을 권장한다."
            ],
            "answer": "d",
            "topic": [
                "GDPR의 개인정보 최소처리 원칙"
            ]
        },
        "true_false": {
            "question": "GDPR의 개인정보 최소처리 원칙에 의하면 정보주체는 부적절한 개인정보의 삭제를 요구할 수 없다.",
            "answer": "FALSE",
            "topic": [
                "GDPR의 개인정보 최소처리 원칙에서 정보주체의 권리"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:56:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "‘의견’에 관한 정보가 기록되어 있는 경우에 정보주체가 기록에 동의하지 않았거나 정 보주체가 중요하다고 생각하는 정보를 고려하지 않았다고 해서 반드시 그 기록이 부 적절하거나 관련성이 없는 것은 아니다. 그러나 의견의 기록이 적절한 것이 되기 위해서는 그 기록이 사실이 아니라 의견이라 는 것을 분명히 해야 한다. 또한 의견의 기록에는 독자가 그것을 정확하게 이해할 수 있도록 충분한 관련 정보가 포함되어 있어야 한다. 예를 들어 작성 일자, 작성자의 이름과 직위를 명시해야 한다. 어떤 의견이 논란이 되거나 매우 민감할 가능성이 있는 경우, 또는 이용·공개될 때 중 대한 영향을 미칠 경우에는 그 의견의 근거나 정황을 진술해 두는 것이 더욱 중요하다. 또한, 기록이 다른 곳에 보관된 상세한 기록을 요약한 것이라면 기록에 이 점을 분명히 밝혀야 한다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:56:0001",
                    "page": 56
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "정보주체의 의견 정보가 기록되어 있을 때, 정보주체가 동의하지 않거나 중요 정보를 고려하지 않았다고 해도 기록이 부적절한 것은 아니다. 다만 의견을 기록할 때 의견임을 명확히 하고 독자가 그것을 정확하게 이해하도록 충분한 관련 정보를 포함해야 한다.",
        "long_answer": {
            "question": "GDPR의 개인정보 처리 원칙 중 정보주체의 의견 정보를 기록할 때, 그 의견이 공개되었을 때 중대한 영향을 미칠 가능성이 있는 의견이라면 기록 시 어떤 추가 조치를 해야 하는가?",
            "answer": "기본적으로 모든 의견 정보는 그 기록이 의견이라는 것을 분명히 해야 하고, 독자가 정확히 이해할 수 있도록 충분한 관련 정보를 포함해야 한다. 이에 더해 논란이 되거나 민감한 주제의 의견이라면 그 의견의 근거나 정황을 진술해 두는 것이 중요하다. 또한 의견 기록이 다른 곳에 보관된 상세한 기록을 가져와 요약한 것이라면 기록에 그 점을 밝혀야 한다.",
            "rubric": [
                "충분한; 관련 정보; 근거; 정황; 기록; 다른 곳; 요약"
            ]
        },
        "short_answer": {
            "question": "GDPR의 개인정보 처리 원칙 중 정보주체의 의견 정보를 기록할 때, 해당 의견이 사회적 논란의 소지가 될 수 있는 의견이라면 추가로 함께 기록해야 하는 것은?",
            "answer": "의견의 근거, 정황",
            "topic": [
                "GDPR의 개인정보 처리 시 정보주체에 관한 의견 정보 기록 원칙"
            ]
        },
        "multiple_choice": {
            "question": "아래의 보기에서 GDPR의 개인정보 처리 시 정보주체 의견 기록 원칙에 대한 적절한 설명을 고르시오.",
            "choices": [
                "a) 정보주체가 동의하지 않으면 기록은 반드시 부적절하다.",
                "b) 의견임을 명확히 하고 관련 정보를 포함하면 기록은 적절할 수 있다.",
                "c) 의견 기록에는 작성자 이름과 일자를 포함할 필요가 없다.",
                "d) 논란 가능성이 있는 의견은 근거를 밝히지 않아도 된다."
            ],
            "answer": "b",
            "topic": [
                "GDPR의 개인정보 처리 시 정보주체에 관한 의견 정보 기록 원칙"
            ]
        },
        "true_false": {
            "question": "정보주체가 정보주체의 의견 기록에 동의하지 않으면, 해당 의견은 사용할 수 없는 것이므로 폐기한다.",
            "answer": "FALSE",
            "topic": [
                "GDPR의 개인정보 처리 시 정보주체에 관한 의견 정보 기록 원칙"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:75:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "합법처리의 근거(lawful basis for processing)란 개인정보의 처리를 정당화 해주는 법적 근거를 말한다. GDPR 제6조제1항은 개인정보를 합법적으로 처리할 수 있는 6가 지 요건을 규정하고 있다. 다만, 공공기관이 공무 수행을 위하여 처리한 경우 ‘적법한 이익’을 합법처리의 근거로 제시할 수 없다. 1 (동의) 정보주체가 특정 목적을 위해 개인정보 처리에 명확히 동의한 경우 2 (계약) 정보주체가 당사자인 계약의 이행 또는 계약 체결 전 정보주체의 요청에 응 하기 위하여 필요한 경우 3 (법적 의무) 컨트롤러에게 적용되는 법령상 의무(계약상 의무 제외) 준수를 위하여 필요한 경우 4 (중대한 이익) 정보주체 또는 제3자의 중대한 이익(생명)을 보호하기 위하여 처리가 필요한 경우 5 (공적 업무 수행) 공무 수행 또는 공적 권한 행사를 위하여 필요하고 그 업무와 권 한이 법령상 명확한 근거를 가지고 있는 경우 6 (적법한 이익) 컨트롤러 또는 제3자의 적법한 이익 추구 목적을 위하여 필요한 경우 - 다만, 정보주체(특히 아동)의 이익, 기본적 권리 및 자유가 그 이익보다 중요한 경우 는 제외",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:75:mh: 00001",
                    "page": 75
                }
            },
            {
                "context_id": "2",
                "text": "합법처리의 근거는 정당한 이유 없이 나중에 다른 근거로 바꿀 수 없으므로 처음부터 신중하게 검토되어야 한다. 특히 동의를 합법처리의 근거로 한 경우 다른 근거로 변경 할 수 없다. 다만, 목적이 변경되었더라도 새로운 목적이 최초 목적과 양립 가능한 경우(제6조4항)  (원래 합법처리의 근거가 동의 혹은 제23조1항인 경우 제외)에는 최초의 합법처리 근  거에 따라 처리를 계속할 수 있다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:75:mh: 00001",
                    "page": 76
                }
            }
        ],
        "summarization": "합법처리의 근거는 개인정보 처리의 정당성을 제공하는 법적 근거를 의미한다. GDPR 제6조제1항은 개인정보의 합법적으로 처리하기 위한 6가지 요건을 규정하고 있으며, 다만 공공기관이 공무수행을 위해 처리한 경우 '적법한 이익'을 합법처리의 근거로 제시할 수 없다. 다만 최초 목적이 새로운 목적과 양립 가능한 경우에는 최초 합법처리 근거에 따라 처리를 계속할 수 있다.",
        "long_answer": {
            "question": "GDPR 제6조제1항에서 규정하는 개인정보 처리의 합법적 근거에는 어떤 항목들이 있는지 설명하고 합법처리 근거의 요건이 추가되었을 때의 해결 방법을 서술하시오.",
            "answer": "GDPR 제6조제1항의 개인정보의 합법처리를 위한 6가지 요건은 동의, 계약, 법적 의무, 중대한 이익, 공적 업무 수행, 적법한 이익 등의 요건이 있다. 기본적으로 합법처리 근거는 정당한 이유 없이 다른 근거로 바꿀 수 없으나, 새로운 목적이 최초 목적과 양립할 수 있는 경우 최초의 합법처리 근거에 따라 처리를 계속할 수 있다.",
            "rubric": [
                "동의; 계약; 법적 의무; 중대한 이익; 공적 업무 수행; 적법한 이익; 양립; 최초 목적;"
            ]
        },
        "short_answer": {
            "question": "GDPR 제6조제1항의 개인정보 합법처리의 근거로 '적법한 이익'을 제시할 수 없는 상황은?",
            "answer": "공공기관의 공무 수행",
            "topic": [
                "GDPR의 개인정보 합법처리 근거"
            ]
        },
        "multiple_choice": {
            "question": "GDPR 제 6조제1항 개인정보 합법처리의 근거에 가장 알맞은 내용은?",
            "choices": [
                "a) 공공기관이 공무 수행 시 '적법한 이익'을 개인정보 합법처리의 근거로 사용한다.",
                "b) 정보주체가 명확히 동의한 경우 개인정보를 합법적으로 처리할 수 있다.",
                "c) 컨트롤러의 불법적 이익을 위한 것이라고 해도 수집 과정이 정당했다면 개인정보 합법처리 근거가 될 수 있다.",
                "d) 정보주체의 동의가 없으면 ‘중대한 이익’을 개인정보 합법처리의 근거로 쓸 수 없다."
            ],
            "answer": "b",
            "topic": [
                "GDPR의 개인정보 합법처리 근거"
            ]
        },
        "true_false": {
            "question": "GDPR 제6조제1항에 따르면, 정보주체가 동의하면 개인정보를 합법적으로 처리할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "GDPR의 개인정보 합법처리 근거"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:118:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "GDPR상 ‘민감정보’란 인종·민족의 기원, 정치적 견해, 종교·철학적 신념, 노동조합의  가입 여부를 나타내는 개인정보의 처리와 유전자 정보, 개인을 고유하게 식별할 수 있  는 생체정보, 건강정보, 성생활·성적 취향에 관한 정보를 의미한다(제9조제1항).  생체정보도 민감정보에 포함되나 모든 생체정보가 민감정보에 포함되는 것은 아니고  정보주체를 식별할 목적으로 이용되는 생체정보(지문, 홍채, 성문, 안면윤곽 등)만 민  감정보로 보호를 받는다.  범죄정보는 GDPR 제10조에 의해서 별도로 보호를 받고 있기 때문에 제9조의 민감정  보 처리에 관한 규정은 적용되지 않는다.  민감정보는 정보주체에 대한 불법적인 차별을 목적으로 이용되는 등 정보주체의 기본  적 권리와 자유에 보다 중요한 위험을 초래할 수 있기 때문에 별도의 보호가 필요하다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:118:0001",
                    "page": 118
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR상 민감정보는 인종, 정치적 견해, 종교적 신념, 유전자 정보, 정보주체 식별을 위한 일부 생체정보, 건강정보 등 정보주체의 기본적 권리와 자유에 중요한 위험을 초래할 수 있는 개인정보를 의미한다. 범죄정보와 별도로 보호된다.",
        "long_answer": {
            "question": "모든 생체정보가 GDPR상의 민감정보로 보호되지 않는 이유를 설명하시오.",
            "answer": "GDPR에서는 모든 생체정보가 민감정보로 간주되지 않는다. 민감정보는 정보주체의 기본적 권리와 자유에 위험을 초래할 수 있는 정보여야 하므로, 정보주체를 식별하는 목적으로 이용되는 고유한 생체정보만 민감정보로 보호를 받는다. 민감정보로 보호받는 생체정보로는 지문, 홍채, 성문, 안면윤곽 등으로 제한된다.",
            "rubric": [
                "기본적 권리; 자유; 식별; 고유; 생체정보;"
            ]
        },
        "short_answer": {
            "question": "GDPR상 민감정보의 종류를 규정하고 있는 조항은?",
            "answer": "제9조제1항",
            "topic": [
                "GDPR상의 민감정보에 대한 규정"
            ]
        },
        "multiple_choice": {
            "question": "GDPR상 민감정보에 대한 정보로 잘못된 것은?",
            "choices": [
                "a) 정보주체 식별 목적의 생체정보만 민감정보로 보호된다.",
                "b) 범죄정보는 별도로 보호되므로 GDPR 제9조 규정을 적용하지 않는다.",
                "c) 민감정보는 정보주체의 권리와 자유에 위험을 초래하지 않는 정보들이다.",
                "d) 민감정보에는 인종, 정치적 견해, 건강정보 등이 포함된다."
            ],
            "answer": "c",
            "topic": [
                "GDPR상의 민감정보에 대한 규정"
            ]
        },
        "true_false": {
            "question": "모든 생체정보는 정보주체 식별 여부와 상관없이 민감정보로 보호된다.",
            "answer": "FALSE",
            "topic": [
                "GDPR상의 민감정보 중 생체정보"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:119:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "‘범죄정보’란 형사상 유죄판결 및 범죄행위와 관련된 정보를 의미한다. 이와 같은 범죄  정보에는 범죄혐의, 범죄행위, 유죄판결 등에 관한 정보가 포함된다.  행정법상 과징금·과태료 처분이나 민사법상 손해배상판결은 범죄정보에 포함되지 않  는다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:119:mh: 00001",
                    "page": 119
                }
            },
            {
                "context_id": "2",
                "text": " ‘범죄정보’를 처리하기 위해서는 제6조에 따른 합법처리의 요건과 함께 제10조에 따른  범죄정보의 처리요건을 갖추어야 한다. 그러나 범죄정보는 민감정보와 달리 정보주체의  동의가 있어도 처리할 수 없다. 법률상 범죄정보를 처리할 수 있는 공적 권한이 반드시  있어야 처리가 가능하다.  구체적으로 범죄정보는 아래와 같이 공적 권한이 존재하는 경우에만 처리가 가능하다.  1 컨트롤러가 공적 권한의 통제 하에 있을 경우  2 범죄정보의 보호를 위해 적절한 안전장치를 규정하는 EU법 또는 회원국법이 허가  하는 경우  특히 범죄경력을 종합적으로 기록한 범죄경력 종합기록부는 공적 권한의 통제 하에서  만 처리가 가능하다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:119:mh: 00001",
                    "page": 120
                }
            }
        ],
        "summarization": "GDPR상 범죄정보란 형사상 유죄판결과 범죄행위와 관련된 정보를 의미하며, 범죄혐의, 범죄행위, 유죄판결 등이 포함된다. 범죄정보는 민감정보와 달리 정보주체의 동의가 있어도 처리할 수 없으며, 법률상 공적 권한이 있어야만 처리할 수 있다.",
        "long_answer": {
            "question": "사기범죄로 인해 형사처벌과 민사상 손해배상을 판결이 둘 다 나온 경우, 두 판결 중 GDPR상 범죄정보가 될 수 있는 정보와 그 이유를 설명하시오.",
            "answer": "두 사건 중 GDPR상 범죄정보가 될 수 있는 판결은 형사처벌 판결이다. 범죄정보는 형사상 유죄판결이나 범죄행위와 관련된 정보만을 의미한다. 그러므로 동일한 사기 사건이라도 형사처벌 관련 정보만 범죄정보로 기록되며, 민사상 손해배상 판결 정보는 범죄정보 범주에 들어가지 않는다.",
            "rubric": [
                "형사; 유죄판결; 범죄행위; 손해배상;"
            ]
        },
        "short_answer": {
            "question": "GDPR상 범죄정보에 포함되는 정보를 세 가지 쓰시오.",
            "answer": "범죄혐의, 범죄행위, 유죄판결",
            "topic": [
                "GDPR상 범죄정보의 종류"
            ]
        },
        "multiple_choice": {
            "question": "보기에서 GDPR상 범죄정보에 대한 잘못 이야기한 것을 고르시오.",
            "choices": [
                "a) a) 범죄정보는 유죄판결과 관련된 정보를 포함한다.",
                "b) b) 범죄정보는 공적 권한 통제 하에서만 처리할 수 있다.",
                "c) c) 민감정보와 달리 정보주체 동의만으로 처리 가능하다.",
                "d) d) 과징금·과태료 처분은 범죄정보에 포함되지 않는다."
            ],
            "answer": "c",
            "topic": [
                "GDPR상 범죄정보의 특징"
            ]
        },
        "true_false": {
            "question": "범죄정보는 정보주체의 동의가 있어도 처리할 수 없으며, 법률상 공적 권한이 있어야 처리할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "GDPR상 범죄정보의 처리요건"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:129:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "컨트롤러는 제15조 내지 제22조에 따른 정보주체의 요청에 따라 취해진 조치에 대한 정보를 제공하여야 한다. 컨트롤러는 정보주체의 권리 행사를 용이하게 할 수 있도록 하여야 하고, 컨트롤러는 제11조제2항에 따라 자신이 정보주체를 식별할 위치에 있지 아니하다는 점을 입증하지 않는 한, 제15조 내지 제22조에 따른 정보주체 본인의 권리 를 행사하기 위한 요청을 거절해서는 안 된다.  컨트롤러는 제15조 내지 22조에 해당하는 정보주체의 요청에 대하여 다음 기준을 준 수하여야 한다. 1 요청을 접수한 후 1개월 이내 부당한 지체 없이(without undue delay) 제공한다. 2 요청의 복잡성과 요청 횟수를 고려하여 필요한 경우 2개월 추가 연장하여 제공할 수 있다. 다만 요청을 접수한 지 한 달 이내에 지체 사유와 이러한 연장에 대하여 고지하여야 한다. 3 요청에 대하여 조치를 취하지 않으면, 컨트롤러는 늦어도 접수 후 1개월 이내에 미 조치 사유, 감독기구에 민원을 제기할 권리, 사법적 구제를 청구할 권리를 정보주 체에게 고지하여야 한다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:129:0001",
                    "page": 129
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "컨트롤러는 정보주체가 제15조 내지 제22조에 따른 권리를 행사하기 위해 요청할 경우 이에 대한 조치 정보를 제공해야 한다. 요청 시기는 접수 후 1개월 이내가 원칙이며, 복잡한 경우 2개월 연장이 가능하고, 미조치 시 사유와 권리 고지를 해야 한다.",
        "long_answer": {
            "question": "GDPR에서 컨트롤러가 정보주체의 권리 요청을 거절할 수 있는 경우와 없는 경우를 비교하여 설명하라.",
            "answer": "컨트롤러는 일반적으로 정보주체의 요청을 거절할 수 없다. 단, 제11조제2항에 따라 자신이 정보주체를 식별할 위치에 있지 않다는 점을 입증하는 경우에만 거절할 수 있다.",
            "rubric": [
                "식별; 입증; 권리; 행사"
            ]
        },
        "short_answer": {
            "question": "일반적인 경우, GDPR에서 컨트롤러가 정보주체의 개인정보 관련 요청을 접수한 후 요청에 대한 정보를 언제까지 제공해야 하는가?",
            "answer": "1개월 이내",
            "topic": [
                "GDPR에서 정보주체의 요청 시 컨트롤러의 정보 제공 시기"
            ]
        },
        "multiple_choice": {
            "question": "GDPR상 컨트롤러의 정보주체의 요청 처리 과정에 대해 올바르게 설명한 것은?",
            "choices": [
                "a) 요청의 내용이 복잡하면 3개월까지 연장할 수 있다.",
                "b) 컨트롤러는 개인정보에 대한 정보주체의 조치 요청을 무조건 거절할 수 있다.",
                "c) 컨트롤러는 요청 접수 후 1개월 이내 지체 없이 정보주체에게 조치 요청에 대한 정보를 제공해야 한다.",
                "d) 미조치 시 정보주체에게 별도의 통지를 하지 않아도 된다."
            ],
            "answer": "c",
            "topic": [
                "GDPR에서 정보주체의 요청 시 컨트롤러의 정보 제공 과정"
            ]
        },
        "true_false": {
            "question": "컨트롤러는 정보주체 요청에 대해 자신이 식별 위치에 있지 않음을 입증하지 않아도 요청을 거절할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "GDPR에서 정보주체의 요청 시 컨트롤러 요청 거절 요건"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:132:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "제13조 및 제14조에 따라 제공되는 정보와 제15조부터 제22조까지와 제34조에 따라  취해진 모든 통지와 조치는 무료로 제공되어야 한다. 컨트롤러는 제13조 및 제14조에  따른 정보제공 또는 제15조 내지 제22조, 제34조에 따라 취해진 통지 및 조치에 대하  여 정보주체에게 요금을 청구할 수 없다. 이는 투명성 요구사항에 따라 제공되는 정보  가 재정적 거래, 예컨대 상품 또는 서비스에 대한 구입 또는 지불을 조건으로 할 수 없  음을 의미한다. 예컨대, 구매와 관련하여 정보주체의 개인정보가 수집되는 경우 제13조  에 따라 제공해야 하는 정보는 거래가 마무리된 후가 아니라 결제가 이루어지기 전, 그  리고 정보가 수집되는 시점에 제공되어야 한다. 또한 정보주체에게 무료 서비스가 제공  되는 경우 제13조제1항이 “개인정보를 획득하는 시점”에 정보를 제공할 것을 요구하는  점을 고려하여 제13조의 정보는 등록 후가 아닌 그 전에 제공되어야 한다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:132:mh: 00001",
                    "page": 132
                }
            },
            {
                "context_id": "2",
                "text": "정보주체의 요구가 명백하게 근거가 없거나 과도한 경우, 특히 요청이 반복적인 경우 컨 트롤러는 (i) 정보 내지 통지를 제공하거나 요청된 조치를 취하는 행정적 비용을 고려하 여 합리적인 수수료를 부과하거나, (ii) 요청에 따른 조치의 거부를 할 수 있다. 다만, 요 청이 명백하게 근거가 없거나 과도하다는 점을 입증할 책임은 컨트롤러에게 있다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:132:mh: 00001",
                    "page": 133
                }
            }
        ],
        "summarization": "GDPR에서 정보주체는 제13조, 제14조, 제15조에서 제22조, 제34조에 따른 정보 제공 및 통지를 무료로 받을 권리가 있으며, 컨트롤러는 이에 대해 요금을 청구할 수 없다. 단, 요청이 명백히 근거 없거나 과도할 경우 합리적 수수료 부과 또는 조치 거부가 가능하며, 그 입증 책임은 컨트롤러에게 있다.",
        "long_answer": {
            "question": "GDPR의 13,14,15~22조, 34조에 해당하는 정보를 정보주체에게 제공할 때, 정보와 통지가 무료로 이루어져야 하는 이유를 설명하라.",
            "answer": "정보주체의 권리를 보장하기 위해 제13조 및 제14조에 따른 정보 제공, 제15조부터 제22조, 제34조에 따른 통지와 조치는 모두 무료로 제공되어야 한다. 이는 정보의 투명성 요구사항에 의해 재정적 거래나 서비스 이용을 조건으로 정보를 제공하는 것을 막기 위해서이다. 다만 정보주체의 요구가 명백하게 근거가 없거나 과도한 경우, 특히 요청이 반복적인 경우 컨트롤러는 정보 내지 통지를 하거나, 요청을 거부하거나 수수료를 부과하는 등 조치를 취할 수 있다.",
            "rubric": [
                "투명성 요구사항; 재정적 거래; 과도; 반복; 거부; 수수료; 내지 통지;"
            ]
        },
        "short_answer": {
            "question": "정보주체가 GDPR의 13,14,15~22조, 34조에 해당하는 요구할 때, 정보 제공을 거부하기 위해서 정보주체의 요구가 과도하거나 요구 근거가 정당하지 않다는 부분을 입증해야 하는 주체는?",
            "answer": "컨트롤러",
            "topic": [
                "GDPR상 정보주체의 요청 시 컨트롤러의 정보제공 의무"
            ]
        },
        "multiple_choice": {
            "question": "GDPR상 정보주체의 정보 제공 요청 시 컨트롤러가 해야 할 일로 적절하지 않은 것은?",
            "choices": [
                "a) 정보 제공 요청이 과도할 경우 합리적 수수료를 부과할 수 있다.",
                "b) 정보 제공 요청이 근거 없는 요구로 판단되면 조치를 거부할 수 있다.",
                "c) 정보 제공 요청의 과도함 또는 근거 없음은 정보주체가 입증해야 한다.",
                "d) 정보 제공 요청이 반복적일 경우에도 동일한 기준이 적용된다."
            ],
            "answer": "c",
            "topic": [
                "GDPR상 정보주체의 요청 시 컨트롤러의 정보제공 의무"
            ]
        },
        "true_false": {
            "question": "컨트롤러는 정보주체의 요구가 정당할 경우 무료로 정보를 제공해야 한다.",
            "answer": "TRUE",
            "topic": [
                "GDPR상 정보주체의 요청 시 컨트롤러의 정보제공 의무"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:177:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "4.2.3 개인정보 영향평가를 의무적으로 수행하여야 하는 경우(제35조제3항) 특히 다음 중 하나에 해당하는 경우 개인정보 영향평가를 의무적으로 수행해야 한다. 1 자동화된 처리(프로파일링 포함)에 근거한 개인에 대한 체계적이고 광범위한 평가 로, 해당 평가를 바탕으로 한 결정이 해당 정보주체에게 법적 효력을 미치거나 이와 유사하게 중대한 영향을 미치는 경우 2 민감정보 또는 범죄정보에 대한 대규모 처리를 하는 경우 3 공개적으로 접근 가능한 장소에 대한 대규모의 체계적인 모니터링을 하는 경우(예: CCTV)  4.2.4 개인정보 영향평가 수행이 예외인 경우 아래와 같은 경우에는 개인정보 영향평가를 실시하지 않아도 된다. 1 감독기구가 유럽개인정보보호이사회(EDPB)에 통보한 개인정보 영향평가가 요구되 지 않는 처리 작업 종류 목록에 해당되는 경우(제35조제5항) 2 컨트롤러에게 적용되는 법적 의무 이행을 위하여 필요한 처리나 공익을 위하여 수 행되는 직무의 이행 또는 컨트롤러에게 부여된 공적 권한의 행사에 필요한 처리인 경우로 해당 법률에서 특정 처리 작업이나 일련의 관련 작업을 규정하고 있으며 해 당 법적 근거 채택 과정에서 개인정보 영향평가가 이미 실시된 경우(제35조제10항)",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:177:mh: 00001",
                    "page": 177
                }
            },
            {
                "context_id": "2",
                "text": "새로운 기술을 사용하고 그 처리 유형이 ‘개인의 권리와 자유에 높은 위험’을 초래할 가능성이 있는 경우, 개인정보 처리 이전에 예상되는 개인정보 처리에 대한 영향평가 를 수행하여야 한다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:177:mh: 00001",
                    "page": 176
                }
            }
        ],
        "summarization": "개인정보 처리가 새로운 기술을 사용하고 그 처리 유형이 개인의 권리와 자유에 높은 위험을 초래할 가능성이 있는 경우 개인정보 영향평가를 수행하여야 한다. 특정한 경우에는 개인정보 영향평가를 의무적으로 수행해야 하며, 영향평가가 요구되지 않는 개인정보 처리 작업 증 예외적인 경우 개인정보 영향평가를 실시하지 않아도 된다.",
        "long_answer": {
            "question": "GDPR상 개인정보 영향평가를 의무적으로 수행해야 하는 경우를 모두 설명하라.",
            "answer": "개인정보 영향평가를 의무적으로 수행해야 하는 경우는 세 가지이다. 자동화된 처리나 프로파일링을 통해 개인을 체계적으로 평가하고, 그 결과가 법적 효력을 미치거나 유사한 영향을 주는 경우와 민감정보나 범죄정보를 대규모로 처리하는 경우, 또는 공개적으로 접근할 수 있는 장소에서 대규모로 체계적인 모니터링을 수행하는 경우에도 반드시 평가가 필요하다.",
            "rubric": [
                "개인; 체계적; 광범위; 법적 효력; 민감정보; 범죄정보; 공개적; 대규모; 모니터링"
            ]
        },
        "short_answer": {
            "question": "개인정보 영향평가의 예외 적용을 받을 수 있는 경우는 모두 몇 가지인가?",
            "answer": "2(두 가지 경우)",
            "topic": [
                "GDPR상 개인정보 영향평가 예외 상황"
            ]
        },
        "multiple_choice": {
            "question": "GDPR상 개인정보 영향평가를 수행하지 않아도 되는 경우가 아닌 것은?",
            "choices": [
                "a) 민감정보를 대규모로 처리하는 경우",
                "b) 법적 의무 이행을 위한 처리로 이미 평가가 완료된 경우",
                "c) 감독기구가 지정한 평가 불필요 목록에 포함된 경우",
                "d) 공적 권한 수행에 필요한 처리로 법에서 이미 평가된 경우"
            ],
            "answer": "a",
            "topic": [
                "GDPR상 개인정보 영향평가 예외 상황"
            ]
        },
        "true_false": {
            "question": "민감정보의 대규모 처리는 GDPR에 따라 개인정보 영향평가를 의무적으로 수행해야 하는 경우에 해당한다.",
            "answer": "TRUE",
            "topic": [
                "GDPR상 개인정보 영향평가 의무 적용 상황"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:140:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "컨트롤러는 정보주체의 정정 요구가 있으면 부당한 지체 없이(without undue delay) 다음과 같이 필요한 조치를 하여야 한다. 1 정정을 위한 조치는 정정 요구를 받은 시점으로부터 1개월 이내에 이행하여야 한 다. 다만 정정 요구가 복잡한 경우 2개월 추가 연장이 가능하다(제12조제3항). 2 정정 요구에 따른 조치를 취하지 않은 경우 정보주체에게 그 이유 및 감독기구에 민원을 제기할 수 있고 사법적 구제를 청구할 수 있음을 알려 주어야 한다(제12조 제4항). 3 개인정보를 수령인에게 공개·제공하였다면 가능한 한 그 수령인에게 정정에 대하 여 통지하여야 한다(제19조). 또한 컨트롤러는 정보주체가 요구하는 경우 그 정보 의 수령인에 대하여도 정보주체에게 통지하여야 한다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:140:mh: 00001",
                    "page": 140
                }
            },
            {
                "context_id": "2",
                "text": " 정보주체는 본인에 관한 개인정보에 대하여 정확하지 않은 부분을   수정하도록 컨트롤러에게 요구할 수 있다(제16조). ",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:140:mh: 00001",
                    "page": 139
                }
            }
        ],
        "summarization": "정보주체는 자신의 개인정보가 정확하지 않을 경우 정정을 요구할 권리를 가진다. 컨트롤러는 정정 요구를 받은 후 지체 없이 조치를 취해야 하며, 처리 지연이나 미조치 시 그 사유와 구제 방법을 정보주체에게 알려야 한다.",
        "long_answer": {
            "question": "GDPR에서 컨트롤러가 정보주체의 정정 요청을 받아 정정조치를 할 때와 정정조치를 하지 않을 때 해야 할 일을 각각 설명하시오.",
            "answer": "컨트롤러가 정보주체에게 개인정보의 정정에 대한 요구를 받았다면 부당한 지체 없이 조치를 취해야 하며, 통상 1개월 이내에 정정해야 한다. 정정 요구가 복잡한 경우에는 2개월까지 추가 연장할 수 있다. 정정요구에 따른 조치를 취하지 않으려면 정보주체에게 그 이유, 감독기구 민원 제기가 가능하다는 것, 사업적 구제를 청구할 수 있다는 것을 알려야 한다.",
            "rubric": [
                "부당한 지체; 1개월; 2개월; 이유; 감독기구; 사업적 구제;"
            ]
        },
        "short_answer": {
            "question": "GDPR에서 컨트롤러가 정보주체에게 정정 요구 내용이 복잡한 정정 요청을 받았다면 최대 언제까지 조치 기간을 추가 연장할 수 있는가?",
            "answer": "2개월",
            "topic": [
                "GDPR에서 정보주체의 정보 정정 요구 시 컨트롤러의 역할"
            ]
        },
        "multiple_choice": {
            "question": "GDPR에서 규정한 개인정보 정정권에 관한 설명으로 옳은 것은?",
            "choices": [
                "a) 정보주체는 부정확한 개인정보에 대해 정정을 요구할 수 있다.",
                "b) 컨트롤러는 정정 요구를 받은 즉시 처리하지 않아도 된다.",
                "c) 정정 요구는 반드시 3개월 이내에 처리해야 한다.",
                "d) 복잡한 정정 요구라도 추가 연장은 허용되지 않는다."
            ],
            "answer": "a",
            "topic": [
                "GDPR에서 정보주체의 개인정보 정정권"
            ]
        },
        "true_false": {
            "question": "GDPR에서 개인정보 정정 요구를 받았을 때, 정정 요구가 복잡하더라도 컨트롤러는 조치 기간을 연장할 수 없다.",
            "answer": "FALSE",
            "topic": [
                "GDPR에서 정보주체의 개인정보 정정권"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:142:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "정보주체는 컨트롤러에게 본인에 관한 개인정보의 삭제를 요구할 권리를 가진다(제17 조제1항). 이 권리는 정보주체가 원하는 경우 자신에 관한 개인정보를 삭제하도록 함으 로써 개인정보의 처리가 더 이상 이루어지지 않도록 하기 위한 권리이다. 특히 GDPR 에서는 해당 개인정보가 제3자에게 공개된 경우 해당 제3자들에 대하여도 일정한 사 항을 알리고 합리적 조치를 취하도록 할 의무를 부과하고 있다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:142:mh: 00001",
                    "page": 142
                }
            },
            {
                "context_id": "2",
                "text": "컨트롤러는 다음 중 하나에 해당할 경우 부당한 지체 없이(without undue delay) 개 인정보를 삭제할 의무를 부담한다. 1 개인정보가 수집 목적 또는 다른 방식으로 처리되는 목적에 더 이상 필요하지 않은 경우 2 정보주체가 동의를 철회하고 해당 처리에 대한 다른 법적 근거가 없는 경우 3 정보주체가 제21조제1항(국가 안보·국방·공공안보·범죄예방)에 따라서 처리에 반대 하고 관련 처리에 대하여 우선하는 정당한 사유가 없는 경우, 또는 제21조제2항에 따라서 직접 마케팅을 위한 처리에 반대하는 경우 4 개인정보가 불법적으로 처리된 경우(GDPR 위반 등) 5 정보처리자에 적용되는 유럽연합 내지 회원국 법률에 따른 법적 의무 준수를 위하 여 삭제되어야 하는 경우 6 아동에게 직접 제공되는 정보 사회 서비스와 관련하여 개인정보가 수집된 경우 개인정보의 처리가 합법적이라는 점에 대한 입증 책임은 컨트롤러에게 있다. 책임 의 원칙에 따라 컨트롤러는 언제라도 개인정보 처리에 정당한 근거가 있음을 보여 줄 수 있어야 한다. 개인정보를 수령인에게 공개·제공하였다면 가능한 수령인에게 그 삭제에 대하여 통지 하여야 한다(제19조). 또한 컨트롤러는 정보주체가 요구하는 경우 그 정보의 수령인에 대하여도 정보주체에게 통지하여야 한다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:142:mh: 00001",
                    "page": 143
                }
            }
        ],
        "summarization": "정보주체는 자신에 관한 개인정보의 삭제를 요구할 권리가 있고, 삭제 요구를 받은 컨트롤러는 정당한 사유가 없는 한 이를 부당한 지체 없이 삭제해야 한다. 또한, 개인정보가 수령인에게 공개된 경우 컨트롤러는 수령인에게 삭제를 통지하고 정보주체가 요청하면 수령인 정보를 알려야 한다.",
        "long_answer": {
            "question": "GDPR에서 개인정보 삭제권을 규정한 목적과 컨트롤러의 개인정보 삭제 의무에 대해 설명하시오.",
            "answer": "개인정보 삭제권은 정보주체가 원할 경우 본인의 개인정보를 삭제함으로써 더 이상 개인정보 처리가 이루어지지 않도록 하기 위해 규정된 권리이다. 정보주체가 개인정보 삭제를 요청하면 개인정보 컨트롤러가 부당한 지체 없이 이를 삭제해야 한다. 또한 개인정보가 불법적으로 처리된 경우 등 특정 상황에서도 컨트롤러에게 개인정보 삭제 의무가 주어진다.",
            "rubric": [
                "개인정보 처리; 삭제권; 부당한 지체; 의무;"
            ]
        },
        "short_answer": {
            "question": "GDPR에 개인정보 삭제권을 행사할 수 있는 권리 주체는?",
            "answer": "정보주체",
            "topic": [
                "GDPR상 개인정보 삭제권의 권리주체"
            ]
        },
        "multiple_choice": {
            "question": "GDPR상 개인정보 삭제권에 대한 내용으로 옳은 것은?",
            "choices": [
                "a) 개인정보가 더 이상 목적에 필요하지 않은 경우 컨트롤러는 삭제해야 한다.",
                "b) 개인정보가 불법적으로 처리된 경우에도 삭제할 의무가 없다.",
                "c) 정보주체가 동의를 철회해도 다른 법적 근거가 있으면 삭제하지 않아도 된다.",
                "d) 제3자에게 제공된 개인정보는 삭제 통지 대상이 아니다."
            ],
            "answer": "a",
            "topic": [
                "GDPR상 개인정보 삭제권 규정"
            ]
        },
        "true_false": {
            "question": "GDPR은 제3자에게 공개된 개인정보의 삭제에 관해 아무런 규정을 두고 있지 않다.",
            "answer": "FALSE",
            "topic": [
                "GDPR상 개인정보 삭제권 규정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:170:0001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.1.1 기업의 종업원이 250명 이상인 경우 GDPR은 영세 및 중소기업(micro, small and medium-sized enterprise)의 상황을 고려하여, 종업원 수 250명 이상의 기업을 대상으로 개인정보 처리 활동을 의무적으 로 문서화하고 보유하도록 규정하고 있다. 2.1.2 예외(종업원 수 250명과 무관) 해당 기업이 수행하는 개인정보의 처리가 다음 중 하나에 해당하는 경우에는 종업원 수와 무관하게 개인정보 처리 활동의 기록이 필요하다. 1 정보주체의 권리와 자유에 위험을 초래할 가능성이 있거나 간헐적이지 않은 개인정 보 처리 2 민감정보 처리 3 범죄경력 및 범죄행위에 관련된 개인정보 처리",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:170:0001",
                    "page": 170
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GDPR은 250명 이상의 종업원을 둔 기업에게 개인정보 처리 활동을 문서화하고 보유할 것을 의무화한다. 또한 종업원 수와 상관없이 정보주체의 권리와 자유에 위험할 수 있는 정보, 간헐적이지 않은 개인정보 처리, 민감정보, 범죄 관련 정보 등을 처리하는 경우에도 개인정보 처리 활동을 기록해야 한다.",
        "long_answer": {
            "question": "GDPR에서 종업원 수 250명 이상인 기업과 미만인 기업의 개인정보 처리 기록 의무를 비교하라.",
            "answer": "GDPR에서 종업원 수 250명 이상의 기업은 개인정보 처리 활동을 반드시 문서화해야 한다. 반면 250명 미만의 기업은 원칙적으로 의무가 없지만, 특정한 예외 조건이 있으면 개인정보 처리 활동을 기록해야 한다. 예외 조건으로는 정보주체의 권리 또는 자유 침해 가능성이 있는 개인정보, 간헐적이지 않은 개인정보, 민감정보, 범죄 관련 개인정보 처리등의 경우가 있다.",
            "rubric": [
                "문서화; 250명; 예외;"
            ]
        },
        "short_answer": {
            "question": "GDPR에서 기업이 개인정보 처리 활동을 반드시 문서화해야 하는 종업원 수 기준은 몇 명인가?",
            "answer": "250명",
            "topic": [
                "GDPR상 기업의 개인정보 처리 활동 문서화 의무"
            ]
        },
        "multiple_choice": {
            "question": "GDPR에 따른 기업의 개인정보 처리 활동 기록에 대한 내용으로 옳은 것은?",
            "choices": [
                "a) 250명 이상의 기업은 개인정보 처리 활동을 문서화하고 보유해야 한다.",
                "b) 종업원 수가 250명 미만인 기업은 어떤 경우에도 기록할 필요가 없다.",
                "c) 기록 의무는 오직 민감정보 처리 기업에만 적용된다.",
                "d) GDPR은 기업 규모와 관계없이 모든 기업에 동일하게 의무를 부여한다."
            ],
            "answer": "a",
            "topic": [
                "GDPR상 기업의 개인정보 처리 활동 문서화 의무"
            ]
        },
        "true_false": {
            "question": "GDPR은 종업원 수 250명 이상의 기업에게 개인정보 처리 활동을 기록하고 문서화하도록 의무화하고 있다.",
            "answer": "TRUE",
            "topic": [
                "GDPR상 기업의 개인정보 처리 활동 문서화 의무"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:146:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "정보주체는 자신에 관한 개인정보의 처리를 차단하거나 제한할 권리를 갖는다(제18조 제1항). 개인정보 처리가 제한되면 컨트롤러는 그 정보를 보유만 할 수 있고 이용, 제공 등의 처리는 제한된다. 정보주체의 처리 제한권은 개인정보의 정확성, 처리의 합법성 등에 대하여 다툼이 있거나 소송 수행 등을 위하여 보존의 필요성이 있는 경우에 이용 을 제한하되 삭제를 보류할 수 있도록 요구할 수 있는 권리이다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:146:mh: 00001",
                    "page": 146
                }
            },
            {
                "context_id": "2",
                "text": "정보주체는 컨트롤러에게 본인에 관한 개인정보의 삭제를 요구할 권리를 가진다(제17 조제1항). 이 권리는 정보주체가 원하는 경우 자신에 관한 개인정보를 삭제하도록 함으 로써 개인정보의 처리가 더 이상 이루어지지 않도록 하기 위한 권리이다. 특히 GDPR 에서는 해당 개인정보가 제3자에게 공개된 경우 해당 제3자들에 대하여도 일정한 사 항을 알리고 합리적 조치를 취하도록 할 의무를 부과하고 있다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:146:mh: 00001",
                    "page": 142
                }
            }
        ],
        "summarization": "정보주체는 자신의 개인정보 처리를 차단하거나 제한할 수 있는 권리를 가진다. 이 권리는 개인정보의 정확성이나 합법성에 다툼이 있거나 보존의 필요성이 있는 경우에 개인정보의 이용을 제한하되 삭제하지는 않을 수 있는 권리이다.",
        "long_answer": {
            "question": "GDPR상 개인정보 처리 제한권은 개인정보 삭제권과 어떤 차이가 있는가?",
            "answer": "개인정보 처리 제한권은 정보를 완전히 삭제하는 대신 일정 기간 보존을 허용하면서 이용을 제한하는 권리이다. 삭제권은 개인정보를 삭제해서 개인정보 처리가 아예 이루어지지 않게 할 수 있는 권리이다. 처리 제한권은 개인정보의 이용만을 제한한 채 삭제하지 않고 보존할 수 있도록 요구할 수 있다는 점에서 삭제권과 구별된다.",
            "rubric": [
                "개인정보 처리 제한; 보존; 이용; 삭제;"
            ]
        },
        "short_answer": {
            "question": "GDPR상 개인정보 처리 제한시 컨트롤러는 어떤 행위를 제한받게 되는가?",
            "answer": "이용, 제공 등 처리",
            "topic": [
                "GDPR상 개인정보 처리 제한권의 내용"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 GDPR상 개인정보 처리 제한권에 대한 설명으로 옳지 않은 것은?",
            "choices": [
                "a) 개인정보 처리 제한권은 소송 수행과 관련된 개인정보 보존 필요성과 무관하다.",
                "b) 정보주체는 처리 제한권을 행사하여 삭제를 보류할 수 있다.",
                "c) 개인정보 처리 제한 시 정보 이용과 제공이 제한된다.",
                "d) 컨트롤러는 개인정보 처리 제한권에 의해 제한된 정보를 보유만 할 수 있다."
            ],
            "answer": "a",
            "topic": [
                "GDPR상 개인정보 처리 제한권의 내용"
            ]
        },
        "true_false": {
            "question": "개인정보 처리 제한권이 행사되면 컨트롤러는 개인정보를 자유롭게 제공할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "GDPR상 개인정보 처리 제한권의 내용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:149:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "개인정보 이동권(제20조)은 정보주체의 개인정보를 다른 컨트롤러에게 전송할 수 있  게 해줌으로써 정보주체에게 자신과 관련한 개인정보에 대하여 더 많은 통제력을 부  여하고 또한 EU 내에서 개인정보의 자유로운 흐름을 지원하며 컨트롤러들 간의 경쟁  을 촉진하며 디지털 단일시장(digital single market) 전략 맥락에서 새로운 서비스  개발을 유도하기 위하여 마련된 것이다.37  개인정보 이동권은 처리한 개인정보를 받을 수 있는 권리와 한 컨트롤러로부터 다른  컨트롤러에게 개인정보를 전송할 수 있는 두 가지의 내용으로 구성된다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:149:mh: 00001",
                    "page": 149
                }
            },
            {
                "context_id": "2",
                "text": "개인정보 이동권은 다음 두 조건에 모두 해당하는 경우 적용된다.  1 처리가 정보주체의 동의에 근거하거나 계약의 이행을 위한 경우  2 처리가 자동화된 수단에 의해 이루어지는 경우",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:149:mh: 00001",
                    "page": 150
                }
            }
        ],
        "summarization": "개인정보 이동권은 정보주체가 자신의 개인정보를 다른 컨트롤러에게 전송할 수 있도록 하는 권리이다. 이 권리는 정보주체가 개인정보를 받을 수 있는 권리와 한 컨트롤러에서 다른 컨트롤러로 전송할 수 있는 권리로 구성되며, 특정 조건이 갖추어져야 적용할 수 있다.",
        "long_answer": {
            "question": "개인정보 이동권은 단순히 정보를 받는 권리와 컨트롤러 간 전송 권리로 구성된다. 이 두 권리를 비교하여 설명하라.",
            "answer": "첫 번째 권리는 정보주체가 자신의 개인정보를 받을 수 있는 권리이며, 두 번째 권리는 한 컨트롤러에서 다른 컨트롤러로 개인정보를 전송할 수 있는 권리이다. 두 가지 권리 모두 정보주체가 자신의 개인정보를 통제할 수 있도록 하는 권리이나, 첫 번째 권리에서 정보주체가 직접 개인정보를 이용하는 것과 달리 두 번째 권리에서는 개인정보 컨트롤러를 통해 권리를 행사한다.",
            "rubric": [
                "전송; 직접; 컨트롤러;"
            ]
        },
        "short_answer": {
            "question": "GDPR에서 자신의 개인정보를 컨트롤러가 다른 컨트롤러에게 전송할 수 있도록 하는 권리는?",
            "answer": "개인정보 이동권",
            "topic": [
                "GDPR에서 규정한 개인정보 이동권의 개념"
            ]
        },
        "multiple_choice": {
            "question": "개인정보 이동권에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 개인정보 이동권은 모든 개인정보 처리에 무조건 적용된다.",
                "b) 개인정보 이동권은 정보주체가 자신의 데이터를 다른 컨트롤러로 전송할 수 있게 한다.",
                "c) 개인정보 이동권은 EU 외부에서만 적용된다.",
                "d) 개인정보 이동권은 단순히 컨트롤러가 정보를 보유하는 권리이다."
            ],
            "answer": "b",
            "topic": [
                "GDPR에서 규정한 개인정보 이동권의 특징"
            ]
        },
        "true_false": {
            "question": "개인정보 이동권은 정보주체가 자신의 개인정보를 다른 컨트롤러로 전송할 수 있는 권리를 포함한다.",
            "answer": "TRUE",
            "topic": [
                "GDPR에서 규정한 개인정보 이동권의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:153:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "정보주체의 반대권(제21조)은 컨트롤러에 대하여 자신의 개인정보 처리에 반대할 권리를 지칭한다. GDPR은 다음 세 가지 경우에 대하여 정보주체의 반대권을 보장하고 있다. 1 직접 마케팅(프로파일링 포함) 2 컨트롤러의 적법한 이익(제6조제1항(f)) 또는 공적 업무 수행에 근거한 개인정보의 처리(제6조제1항(e)) 3 과학적·역사적 연구 및 통계 목적의 처리",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:153:mh: 00001",
                    "page": 153
                }
            },
            {
                "context_id": "2",
                "text": "정보주체가 반대권을 행사하는 경우 컨트롤러는 문제된 정보를 더 이상 처리하여서는 안 된다. 다만, 반대권 행사 이전에 해당 정보주체의 개인정보에 대한 처리는 여전히 적 법한 것으로 유지된다.",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:153:mh: 00001",
                    "page": 154
                }
            }
        ],
        "summarization": "정보주체의 반대권은 자신의 개인정보 처리에 반대할 수 있는 권리이며, GDPR은 직접 마케팅, 컨트롤러의 적법한 이익 또는 공적 업무 수행, 연구 및 통계 목적의 개인정보 처리에 대한 반대권을 보장하고 있다. 반대권이 행사되면 컨트롤러는 해당 정보를 더 이상 처리할 수 없지만, 반대 이전의 처리는 여전히 적법하다.",
        "long_answer": {
            "question": "정보주체가 GDPR에 명시된 정보주체의 반대권을 행사하기 전과 후의 개인정보 처리의 적법성은 어떻게 달라지는가?",
            "answer": "정보주체가 반대권을 행사하면 컨트롤러는 해당 정보를 더 이상 처리할 수 없다. 그러나 반대권 행사 이전에 수행한 개인정보 처리는 여전히 적법한 것으로 판단된다. 즉, 반대권을 이용해서 반대권 행사 이전에 수행한 개인정보 처리에 대한 부분에 영향을 끼칠 수 없다.",
            "rubric": [
                "컨트롤러; 반대권 행사 이전; 적법"
            ]
        },
        "short_answer": {
            "question": "정보주체가 GDPR에 명시된 정보주체의 반대권을 행사할 수 있는 경우를 한 가지 이상 쓰시오.",
            "answer": "직접 마케팅, 컨트롤러의 적법한 이익 또는 공적 업무 수행에 근거한 개인정보의 처리, 과학적 역사적 연구 및 통계 목적의 처리",
            "topic": [
                "GDPR상 정보주체의 반대권이 보장되는 경우"
            ]
        },
        "multiple_choice": {
            "question": "GDPR에서 정보주체의 반대권이 보장되는 경우로 옳은 선택지를 고르시오.",
            "choices": [
                "a) 컨트롤러의 적법한 이익에 근거한 처리",
                "b) 단순 서비스 개선을 위한 내부 기록 관리",
                "c) 일반적인 직원 근무 기록 처리",
                "d) 법적 의무와 관계없는 개인정보 저장"
            ],
            "answer": "a",
            "topic": [
                "GDPR상 정보주체의 반대권이 보장되는 경우"
            ]
        },
        "true_false": {
            "question": "정보주체가 반대권을 행사하면 컨트롤러는 해당 개인정보를 1개월 이내에 삭제해야 한다.",
            "answer": "FALSE",
            "topic": [
                "정보주체의 반대권 행사"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:185:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": " DPO를 반드시 지정하여야 하는 경우(제37조제1항) 컨트롤러와 프로세서는 자유로이 DPO를 지정할 수 있으나, 다음 중 하나의 경우에는  반드시 DPO를 지정하여야 한다.  - 정부부처 또는 관련기관의 경우(사법적 권한을 행사하는 법원은 예외)  - 컨트롤러 또는 프로세서의 ‘핵심 활동’이 다음 중 하나에 해당되는 경우  ① 정보주체에 대한 ‘대규모’의 ‘정기적이고 체계적인 모니터링’  ② 민감정보나 범죄정보에 대한 ‘대규모’의 처리",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:185:mh: 00001",
                    "page": 185
                }
            },
            {
                "context_id": "2",
                "text": "다만, GDPR은 DPO 지정 의무와 관련하여 회원국의 개별조항을 통하여 그 범주를 제 한할 수 있게 하고 있다.  DPO를 지정하거나 또는 지정 요건에 해당하지 않아 지정하지 않는 경우, 그와 같은  결정을 내린 사유를 문서화해야 한다. DPO 지정 요건에 해당하지 않더라도 DPO를  자발적으로 지정할 수 있다. 다만 자발적으로 DPO를 지정한 경우라도 DPO의 지정· 지위·책무 등과 관련한 GDPR 제37조~제39조가 적용되므로 유의하여야 한다.  ",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:185:mh: 00001",
                    "page": 186
                }
            }
        ],
        "summarization": "DPO(Data Protection Officer)는 컨트롤러와 프로세서가 자유롭게 지정할 수 있으나, 특정 경우에는 반드시 지정해야 한다. 또한, 지정 여부와 관계없이 그 결정 사유를 문서화해야 하며, 자발적 지정 시에도 GDPR 제37조~제39조가 적용된다.",
        "long_answer": {
            "question": "GDPR에서 DPO를 자발적으로 지정하는 것과 반드시 지정해야 하는 것의 차이를 비교하여 설명하라.",
            "answer": "GDPR에 따라 DPO를 반드시 지정해야 하는 경우에는 GDPR 제37조에 따라 법적 의무가 발생하며, 특정 요건을 충족해야 한다. 반면, 자발적으로 지정하는 경우에는 법적 의무는 없지만, 지정, 지위, 책무 등과 관련하여 GDPR 제37조~제39조가 적용된다. 따라서 자발적 지정도 GDPR의 규정을 일부 준수해야 한다.",
            "rubric": [
                "법적 의무; 지정; 지위; 책무;"
            ]
        },
        "short_answer": {
            "question": "DPO를 자발적으로 지정할 시 적용해야 할 CDPR 조항은?",
            "answer": "GDPR 제37조~제39조",
            "topic": [
                "GDPR상 DPO의 자발적 지정"
            ]
        },
        "multiple_choice": {
            "question": "CDPR에 명시된 DPO 지정에 대한 내용 중 잘못된 것은?",
            "choices": [
                "a) 정부부처는 반드시 DPO를 지정해야 한다.",
                "b) DPO 지정 요건에 해당하지 않으면 지정하지 않아도 된다.",
                "c) DPO 지정 여부와 사유는 반드시 문서화해야 한다.",
                "d) 자발적으로 DPO를 지정하면 GDPR이 적용되지 않는다."
            ],
            "answer": "d",
            "topic": [
                "GDPR상 DPO의 지정"
            ]
        },
        "true_false": {
            "question": "DPO 지정 요건에 해당하지 않더라도 컨트롤러와 프로세서가 자발적으로 DPO를 지정할 수 있으며, 이 경우 GDPR 제37조~제39조가 적용된다.",
            "answer": "TRUE",
            "topic": [
                "GDPR상 DPO의 지정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:188:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "규제와 거버넌스"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "DPO는 제39조에 명시된 업무를 수행할 수 있는 능력을 바탕으로 지정되어야 한다(제 37조제5항). 필요한 전문 지식의 수준은 DPO가 수행하는 처리 작업과 보호 수준에  따라 결정되어야 하며, 이는 다음과 같이 제시할 수 있다.  ① GDPR에 대한 심도 있는 이해 및 자국과 EU 개인정보보호 법률, 관행에 대한 전문 지식  ② 개인정보 처리 작업에 대한 이해  ③ 정보 기술 및 보안에 대한 이해  ④ 기업 및 조직에 대한 지식  ⑤ 조직 내에서 개인정보보호 문화를 활성화할 수 있는 능력",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:188:mh: 00001",
                    "page": 188
                }
            },
            {
                "context_id": "2",
                "text": "DPO는 다음과 같은 업무를 수행하여야 한다(제39조). ①         컨트롤러와 프로세서 및 임직원에게 GDPR과 다른 개인정보 보호법규 준수 의무 에 대하여 알리고 자문  ② 내부 정보보호 활동 관리 등 GDPR 및 다른 개인정보 보호법규 이행 상황 모니터링  ③ 컨트롤러 또는 프로세서에게 정보 제공, 조언 및 권고 사항 제시  ④         개인정보 영향평가에 대한 자문 및 평가 이행 감시 ",
                "provenance": {
                    "doc_id": "우리_기업을_위한_EU_일반_개인정보보호법GDPR_가이드북2022.12._개정.pdf:188:mh: 00001",
                    "page": 189
                }
            }
        ],
        "summarization": "DPO는 GDPR 제39조에 명시된 업무를 수행할 수 있는 능력을 갖춘 자로 지정되어야 하며, GDPR 및 개인정보보호 관련 법률, IT·보안, 조직 이해 등 다양한 전문 지식을 필요로 한다. 또한 DPO는 GDPR 준수 자문, 내부 이행 모니터링, 영향평가 자문 등의 역할을 수행한다.",
        "long_answer": {
            "question": "조직이 DPO를 지정할 때 필요한 GDPR에 대한 심도 있는 이해 및 자국과 EU 개인정보보호 법률, 관행에 대한 전문 지식에 대한 능력은 DPO가 어떤 업무를 진행할 때 필요한 능력인지 쓰시오.",
            "answer": "DPO의 GDPR 이해능력, EU 개인정보보호 법률과 관행에 대한 전문 지식은 컨트롤러와 프로세서 및 임직원에게 GDPR과 다른 개인정보보호 법규의 준수 의무를 알리고 자문하는 업무를 수행할 때 필요한 능력이다. 또한 내부 정보보호 활동을 관리하고 GDPR 이행 상황을 모니터링할 때에도 필요하다. 마지막으로 개인정보보호 법률에 관련한 지식은 개인정보 영향평가에 대한 자문과 감시를 수행할 때에도 도움을 줄 수 있다.",
            "rubric": [
                "컨트롤러; 프로세서; 임직원; GDPR; 자문; 모니터링; 개인정보 영향평가; 감시;"
            ]
        },
        "short_answer": {
            "question": "DPO가 GDPR과 다른 개인정보 보호법규 준수 의무에 대하여 알리고 자문하는 업무를 수행해야 할 대상은?",
            "answer": "컨트롤러, 프로세서, 임직원",
            "topic": [
                "GDPR상 DPO의 업무"
            ]
        },
        "multiple_choice": {
            "question": "GDPR상 DPO의 업무로 옳은 것은?",
            "choices": [
                "a) 조직의 모든 인사 업무를 총괄한다.",
                "b) 내부 정보보호 활동을 관리하고 GDPR 이행을 모니터링한다.",
                "c) 기술 개발을 담당하며 보안 시스템을 설계한다.",
                "d) 법적 책임을 대신 지는 대리인 역할을 한다."
            ],
            "answer": "b",
            "topic": [
                "GDPR상 DPO의 업무"
            ]
        },
        "true_false": {
            "question": "DPO는 GDPR 준수 여부를 모니터링하고 조직 내 개인정보보호 문화를 활성화해야 한다.",
            "answer": "TRUE",
            "topic": [
                "GDPR상 DPO의 업무"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:9:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1. 데이터 과학의 기본개념 1.1 데이터 과학의 정의 □ 데이터 과학1)의 사전적 의미 및 학계, 통계학자, 데이터 과학자가 말하는 데이터 과학의 정의는 다음과 같다. ○ 데이터 과학(data science)이란, 데이터마이닝과 유사하게 정형, 비정형 형태를 포함한 다양한 데이터로부터 지식과 인사이트를 추출하는데 과학적 프로세스, 알고리즘, 시스템을 동원하는 융합분야이다(위키피디아). ○ 데이터 과학은 대용량 데이터로부터 통찰력과 지식을 얻고 추론하기 위한 과학적 방법론과 인간과 사회에 유용한 디지털 솔루션을 만들고 적용하고 개선하는 공학적 측면을 포괄하는 새로운 학문이다(서울대 데이터사이언스대학원, 2019). ○ 데이터 과학은 데이터의 수집과 저장에 필요한 데이터 프로세싱 기술과 데이터 분석에 관한 지식을 기반으로 다량의 데이터로부터 패턴을 찾아내고, 통계적 추정, 예측모델링 등을 통하여 필요한 정보를 창출하고, 이를 실제로 활용하는 것을 연구하는 융합과학이다(박성현2), 2020). ○ 데이터 과학이란 적절한 컴퓨터 툴과 통계방법을 효율적으로 사용하여 실제적인 문제에 대한 해답을 찾아내는 활동이다(권재명3), 2016).",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:9:0001",
                    "page": 9
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 과학은 정형적 혹은 비정형적 데이터를 과학적 방법과 알고리즘으로 분석하여 지식과 통찰을 얻는 융합분야이다. 또한 통계적 추정과 예측모델링을 통해 실제 문제 해결과 디지털 솔루션 개발에 활용되는 응용 중심의 분야라고 할 수 있다.",
        "long_answer": {
            "question": "데이터 과학의 기본적인 개념에 대해서 설명해 보라.",
            "answer": "데이터 과학은 정형, 비정형적인 형태를 포함하여 지식과 인사이트를 추출하기 위한 기술적인 프로세스, 알고리즘, 시스템을 사용하는 응용 분야 중 하나이다. 특히 인간 사회에 유용할 수 있는 디지털 솔루션을 개발하고 개선하는 측면에서 공학적 영역을 포괄한다고 볼 수 있다. 즉, 데이터 과학은 다량의 데이터에서 패턴을 찾거나 통계적으로 추정하거나, 예측모델링을 활용하여 필요한 정보를 만들어내는 융합과학이라고 할 수 있다.",
            "rubric": [
                "데이터 과학; 정형, 비정형; 디지털 솔루션; 응용과학"
            ]
        },
        "short_answer": {
            "question": "과학적 방법론과 통계적 모델을 활용하여 데이터를 처리하고 분석하여 실제 인간 사회의 문제를 해결할 수 있는 응용 분야를 무엇이라 하는가?",
            "answer": "데이터 과학",
            "topic": [
                "데이터 과학의 정의"
            ]
        },
        "multiple_choice": {
            "question": "아래의 보기 중 데이터 과학의 개념에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 데이터 과학은 데이터를 수집 및 저장뿐만 아니라, 데이터 분석 및 패턴 발견, 통계적 추정 등을 하는 독립적 학문이다.",
                "b) 데이터 과학은 비정형적 데이터만을 가지고 과학적 방법과 알고리즘으로 분석하여 지식과 통찰을 얻는 응용 분야이다.",
                "c) 데이터 과학은 통계학과 컴퓨터공학의 이론을 포함하며, 경험과 직관에 의존하는 분석 활동이다.",
                "d) 데이터 과학은 예측모델링과 데이터 시각화와 같은 복잡한 프로세스와 단순 정리 작업도 모두 포함된 학문이다."
            ],
            "answer": "b",
            "topic": [
                "데이터 과학의 정의"
            ]
        },
        "true_false": {
            "question": "데이터 과학은 데이터를 저장하는 기술에 초점을 두어 패턴을 발견하거나 통계적 수치를 제시하는 것과는 별개의 영역이다.",
            "answer": "FALSE",
            "topic": [
                "데이터 과학의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:11:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2 데이터기술(DT)은 주로 통계학을 이용하여 데이터를 다루는 기술이다. ○ 데이터의 측정, 수집, 축적 기술에서부터 시작하여 데이터의 전송, 분석 및 해석 능력, 데이터로부터 정보와 지식을 창출하는 기술, 통계적 모형화 기술, 미래를 예측하는 기술 등을 다루는 통계 기반의 과학적 기술이다. ○ 현대통계학의 영역확장에 속하며 데이터의 취급, 소프트웨어의 구축, 모형화 및 미래예측 기술을 주로 다루고 있다. 3 데이터 시각화는 자료와 수치와 특성을 도형의 크기, 모양 및 색상으로 변환하여 보는 이들이 패턴을 찾도록 하는 것으로써, 도식적인 형태 안에 추상적 혹은 정량적으로 표현된 속성이나 변수를 포함하는 정보이다. ○ 시각화 분류에는 데이터시각5), 정보시각화, 정보디자인, 인포그래픽이 있다. □ 데이터 시각화의 목적은 데이터 분석과 의사소통이다. ○ 데이터에 내재된 경향이나 분석결과를 쉽게 이해할 수 있도록 시각적으로 표현하고 전달하는 과정을 통해 데이터를 일일이 살펴보지 않고도 결과를 알 수 있게끔 정보를 명확하고 효과적으로 전달하는 것이다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:11:0001",
                    "page": 11
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 기술(DT)은 통계학을 기반으로 데이터를 측정, 수집, 분석, 예측하는 과학적 기술로, 데이터의 전송과 해석에서 미래 예측까지 포괄한다. 또한 데이터 시각화는 수치와 특성을 시각적 요소로 표현해 정보를 명확히 전달하고 분석결과를 효과적으로 이해하도록 돕는 과정이다.",
        "long_answer": {
            "question": "데이터기술(DT)와 데이터 시각화의 차이점을 설명하라.",
            "answer": "데이터기술(DT)은 통계학을 기반으로 하여 데이터를 수집 및 분석, 해석을 하여 예측 모델을 구축하는 과학적 기술이다. 반면에 데이터 시각화는 분석된 데이터를 시각적으로 구현하여 정보를 좀더 명확하고 효과적으로 전달하는 것을 목표로 한다. 즉, 데이터기술은 데이터 처리와 분석에 초점을 두었다면, 데이터 시각화는 그 결과를 이해하고 효과적으로 전달하기 위한 방법으로 활용된다.",
            "rubric": [
                "데이터기술(DT); 데이터 시각화; 데이터 분석 및 해석; 시각화; 전달 방식"
            ]
        },
        "short_answer": {
            "question": "데이터를 수집하고 분석한 후, 데이터에 대한 통계 자료나 예측 모델을 구축하는 데에 활용되는 기술은 무엇인가?",
            "answer": "데이터기술(DT)",
            "topic": [
                "데이터기술(DT)의 특징"
            ]
        },
        "multiple_choice": {
            "question": "아래의 서술 중 데이터기술(DT)과 데이터 시각화에 대한 설명으로 옳지 않은 것을 골라라.",
            "choices": [
                "a) 데이터기술(DT)은 데이터를 수집하고 분석하고 축적하는 데에서 출발한다.",
                "b) 데이터 시각화는 분석된 데이터를 효과적으로 전달하기위한 수단으로 활용할 수 있다.",
                "c) 데이터 시각화는 정보시각화, 정보디자인, 인포그래픽 등으로 구성된다.",
                "d) 데이터기술(DT)은 현대통계학의 영역과는 무관한 기술 방식이다."
            ],
            "answer": "d",
            "topic": [
                "데이터기술(DT)와 데이터 시각화의 특징"
            ]
        },
        "true_false": {
            "question": "데이터 시각화는 이미 분석된 자료를 활용하여 시각화한 자료로 데이터의 이해를 효과적으로 돕기 위한 방법이다.",
            "answer": "TRUE",
            "topic": [
                "데이터 시각화의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:10:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "1 통계학은 조사나 실험을 통해 얻은 데이터를 바탕으로 알지 못하는 것에 대한 추론하는 학문으로서, 불확실한 상황에서 의사결정을 내릴 때 과학적 길잡이 역할을 한다. ○ 통계학이 학문으로서 독자적인 지위를 갖게 된 이유는 데이터로부터 정보와 지식을 얻는 이론과 방법을 제공하기 때문이다. ○ 통계학은 이론개발에 계속 치중하여 연구하고 데이터 과학은 통계적 방법에 대한 이론 개발보다는 적용에 국한하여 발전해 나갈 것이며, 통계학과 데이터 과학은 상생의 공존관계를 유지하면서 서로 발전해나갈 것임을 예측4)했다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf",
                    "page": 10
                }
            },
            {
                "context_id": "2",
                "text": "□ 통계학은 데이터 과학에서 생각하는 것만큼 중요하지 않았다. ○ 중요한건 통계학을 공부하면서 자연스레 습득하는 비판적 사고방식이며, 데이터 과학에서 통계적 방법론을 사용하지만 통계학을 집중적으로 다루지 않은 건, 데이터의 크기가 커서 간단한 히스토그램만으로도 충분히 데이터를 분석할 수 있기 때문이다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf",
                    "page": 11
                }
            }
        ],
        "summarization": "통계학은 데이터를 통해 불확실한 상황에서 의사결정을 지원하는 학문으로, 정보와 지식을 얻는 이론과 방법을 제공한다. 데이터 과학에서 통계학은 통계적 방법론을 활용하나, 적용 중심으로 발전하였다. 즉, 데이터 과학과 통계학은 서로 상호보완적인 관계라고 할 수 있다.",
        "long_answer": {
            "question": "데이터 과학에서 통계학의 위치에 대해서 서술하라.",
            "answer": "데이터 과학에서 통계학은 통계학이 가지고 있는 이론적인 발전보다는 적용에 초점을 두고 발전하고 있다. 즉, 통계학은 조사나 실험을 통해서 얻는 데이터로 기존에 알지 못하는 영역을 추론하는 학문이며 불확실한 상황에 대해 의사결정을 지원한다. 데이터 과학은 통계학이 가진 방법론을 활용할 수 있는 길잡이 역할을 한다.",
            "rubric": [
                "데이터 과학; 통계학; 통계적 방법론; 길잡이 역할"
            ]
        },
        "short_answer": {
            "question": "조사나 실험을 통해서 얻은 데이터로 미래의 불확실한 상황을 추론하는 분야를 무엇이라고 하는가?",
            "answer": "통계학",
            "topic": [
                "통계학의 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 데이터 과학과 통계학의 관계에 대한 설명으로 올바른 것은 무엇인가?",
            "choices": [
                "a) 데이터 과학과 통계학은 상생의 공존관계를 유지하면서 서로 발전하는 관계이다.",
                "b) 통계학은 데이터 과학의 하위 분야로 이론적인 발전에 도움을 준다.",
                "c) 데이터 과학과 통계학은 상반되는 분야로 각각 다른 특징을 지니고 있다.",
                "d) 통계학은 데이터 과학의 상위 학문 분야로서, 통계학을 발전시키기 위한 하나의 방법론이다."
            ],
            "answer": "a",
            "topic": [
                "데이터 과학과 통계학의 관계"
            ]
        },
        "true_false": {
            "question": "데이터 과학에서 통계학에서의 방법론을 차용하였을 뿐, 각 분야는 서로 아무런 관련이 없다.",
            "answer": "FALSE",
            "topic": [
                "데이터 과학과 통계학의 관계"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:12:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터마이닝 분야별 정리 컴퓨터 과학 패턴인식 기술뿐만 아니라 통계적·수학적 분석방법을 이용하여 저장된 거대한 자료로부터 우리에게 유익하고 흥미 있는 새로운 관계, 성향, 패턴 등 다양하고 가치 있는 정보를 찾아내는 일련의 과정 경영정보시스템(MIS) 거대한 데이터베이스 혹은 자료에서 유용한 정보를 추출하는 일련의 과정뿐만 아니라 값진 정보를 사용자가 전문적 지식 없이 사용할 수 있는 의사결정 지원 시스템 개발과정을 통칭 통계학 올바른 의사결정을 지원하기 위한 데이터 분석 및 모형 선택 방법론의 개발",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:12:0001",
                    "page": 12
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "컴퓨터 과학에서 데이터마이닝은 패턴인식, 통계 및 수학적 분석방법을 이용하여 다량의 데이터로부터 인간에게 유익하고 흥미로운 정보를 찾아내느 과정을 의미한다. 반면 경영정보시스템(MIS)은 다량의 데이터베이스에서 유용한 정보를 추출하며 이러한 정보에 대해 사용자가 사전지식이 없더라도 의사결정을 할 수 있도록 지원하는 시스템 개발과정에 적용된다. 통계학의 경우 데이터마이닝은 올바른 의사결정을 지원하기 위해 데이터를 분석하거나 모형을 선택할 수 있는 방법론으로 활용된다.",
        "long_answer": {
            "question": "컴퓨터 과학에서 데이터마이닝의 활용법에 대해 기술하라.",
            "answer": "데이터마이닝은 컴퓨터 과학 분야에서 패턴인식 기술뿐만 아니라 통계적, 수학적 분석방법으로 활용된다. 즉, 기존에 가지고 있는 거대한 데이터베이스에서부터 사용자들에게 반드시 필요하고 목적에 맞는 데이터를 추출하는 것이다. 이를 통해 관계성, 성향, 패턴 등의 가치 있는 정보를 파악할 수 있도록 하는 데 도움을 준다.",
            "rubric": [
                "컴퓨터 과학; 데이터마이닝; 패턴인식; 통계적, 수학적 분석방법; 관계성, 성향, 패턴 파악"
            ]
        },
        "short_answer": {
            "question": "사용자가 올바른 의사결정을 할 수 있도록 대랑의 데이터베이스에서 유의미한 정보를 추출할 수 있는 지원 시스템을 무엇이라고 하는가?",
            "answer": "경영정보시스템(MIS)",
            "topic": [
                "경영정보시스템(MIS)의 개념"
            ]
        },
        "multiple_choice": {
            "question": "아래는 데이터마이닝에 대한 분야별 정리 자료이다. 틀린 설명을 골라라.",
            "choices": [
                "a) 통계학에서 데이터마이닝은 올바른 의사결정을 위한 데이터 분석 방법론으로 개발된다.",
                "b) 컴퓨터 과학과 경영정보시스템(MIS), 통계학에서의 데이터마이닝은 가치 있는 정보를 추출하는 것을 핵심으로 한다.",
                "c) 경영정보시스템(MIS)은 오로지 경영과 관련된 분야에서만 활용할 수 있다.",
                "d) 컴퓨터 과학에서 데이터마이닝은 성향, 패턴 등을 파악하는 데에 용이하다."
            ],
            "answer": "c",
            "topic": [
                "데이터마이닝 분야별 특징"
            ]
        },
        "true_false": {
            "question": "데이터마이닝은 컴퓨터과학, 경영정보시스템(MIS), 통계학 등에서 고루 사용되는 과학적 기술이다.",
            "answer": "TRUE",
            "topic": [
                "데이터마이닝 분야별 활용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:11:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "2 데이터기술(DT)은 주로 통계학을 이용하여 데이터를 다루는 기술이다. ○ 데이터의 측정, 수집, 축적 기술에서부터 시작하여 데이터의 전송, 분석 및 해석 능력, 데이터로부터 정보와 지식을 창출하는 기술, 통계적 모형화 기술, 미래를 예측하는 기술 등을 다루는 통계 기반의 과학적 기술이다. ○ 현대통계학의 영역확장에 속하며 데이터의 취급, 소프트웨어의 구축, 모형화 및 미래예측 기술을 주로 다루고 있다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:11:mh: 00001",
                    "page": 11
                }
            },
            {
                "context_id": "2",
                "text": "4 데이터마이닝(data mining)은 대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 패턴을 파악하거나 예측하여 의사결정에 활용하는 방법으로 데이터 과학에서 분석과정의 핵심역할을 한다. ○ 데이터마이닝 기법 및 도구에는 연관분석, 분류분석, 예측분석, 군집분석, 텍스트마이닝, 사회연결망분석 등이 있다. □ 데이터 마이닝 전체 프로세스에서 시간이 가장 많이 소요되는 부분은 모델 구축이 아니라 데이터 준비이며, 다음으로 데이터와 업무에 대한 이해이다. ○ 분석작업의 80%가 데이터 정제 및 준비, 20%만이 모델링에 쓰인다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:11:mh: 00001",
                    "page": 12
                }
            }
        ],
        "summarization": "데이터기술(DT)는 통계학을 기반으로 데이터를 수집, 분석, 예측하는 과학적 기술이며, 현대 통계학의 확장된 영역이다. 반면에 데이터마이닝은 대규모 데이터에서 통계적 규칙과 패턴을 자동으로 찾아 의사결정에 활용하는 과정으로, 전체 분석의 대부분은 데이터 정제와 준비에 소요된다.",
        "long_answer": {
            "question": "데이터기술(DT)와 데이터마이닝(data mining)의 차이를 설명하라.",
            "answer": "통계학을 기반으로 하여 데이터를 측정하고 수집하며, 이를 통해 결과값을 분석하여 앞으로의 상황을 예측하는 과학적 기술을 데이터기술(DT)이라고 한다. 그러나 데이터마이닝의 경우 대규모의 데이터베이스에서 통계적 규칙이나 패턴을 찾아 의사결정을 위해 활용할 수 있는 분석 방법의 일종이다. 즉, 데이터기술(DT)는 데이터마이닝(data mining)과 달리 분석에 그치지 않고 상황을 추론할 수 있으므로 데이터마이닝에 비해 더 큰 영역이라 할 수 있다.",
            "rubric": [
                "데이터기술(DT); 데이터마이닝(data mining); 예측; 분석 방법의 일종"
            ]
        },
        "short_answer": {
            "question": "대규모로 저장된 데이터에서 자동으로 통계 규칙이나 패턴을 파악하는 분석 방법의 일종으로 데이터 과학의 핵심역할을 하는 것은 무엇이라 하는가?",
            "answer": "데이터마이닝(data mining)",
            "topic": [
                "데이터마이닝의 정의"
            ]
        },
        "multiple_choice": {
            "question": "데이터기술과 데이터마이닝에 대한 설명으로 알맞은 것은?",
            "choices": [
                "a) 데이터마이닝에서 가장 많은 시간이 필요한 것은 데이터를 모델링하는 과정이다.",
                "b) 데이터기술은 주로 통계학을 이용하여 데이터를 다루는 기술이라고 할 수 있다.",
                "c) 데이터마이닝과 데이터기술은 데이터 과학과는 관련이 없는 방법론이다.",
                "d) 데이터마이닝에서는 통계적 규칙이나 패턴 파악을 하지 않는다."
            ],
            "answer": "b",
            "topic": [
                "데이터기술과 데이터마이닝의 특징"
            ]
        },
        "true_false": {
            "question": "데이터마이닝의 기법에는 연관분석, 분류분석, 군집분석 등이 있다.",
            "answer": "TRUE",
            "topic": [
                "데이터마이닝의 기법"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:12:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5 빅데이터 기술은 대규모 데이터와 그 데이터를 처리할 수 있는 기술이며, 빅데이터의 속성은 대용량(volume), 속도(velocity), 다양성(variety)6)이다. ○ 빅데이터 때문에 인과관계를 중심으로 한 과학이론과 그러한 연구에서 핵심적인 역할을 해 왔던 표본데이터, 즉 스몰데이터 분석법들의 종말을 예고7)하기도 했다. ○ 빅데이터 덕분에 이전까지 밝혀내기 어려웠던 많은 새로운 지식을 얻게 될 것이지만, 지금까지 통계분석이 사용된 모든 분야의 모든 문제에 빅데이터 분석이 성공적으로 사용되기는 어려울 것이다. □ 통계학의 스몰(표본)데이터는 인과관계를 분석하지만, 데이터 과학의 빅데이터는 상관관게만으로 분석이 가능(빅데이터 분석의 해결과제는 질적 분석)하다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:12:0001",
                    "page": 12
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "빅데이터의 기술은 대량의 데이터를 가지고 처리할 수 있는 기술로 대용량, 속도, 다양성을 특징으로 하고 있다. 빅데이터 기술은 스몰데이터가 가지고 있는 단점을 극복하여 이전까지 밝혀내기 어려웠던 새로운 많은 지식을 얻을 수 있게 되었다.",
        "long_answer": {
            "question": "빅데이터 기술의 특징은 무엇인가?",
            "answer": "빅데이터 기술은 스몰데이터와 달리 대량의 데이터를 활용하여 인과관계를 분석하는 기술이다. 빅데이터는 대용량, 속도, 다양성이라는 특징을 가지고 있으며 스몰데이터가 하지 못한 다양한 영역에서의 데이터를 분석할 수 있게 되었다. 또한 스몰데이터와 달리 빅데이터 기술은 상관관계만으로도 질적 해석이 가능하다는 특징을 지니고 있다.",
            "rubric": [
                "빅데이터 기술; 스몰데이터; 대용량, 속도, 다양성; 상관관계를 통한 질적 해석"
            ]
        },
        "short_answer": {
            "question": "대규모의 데이터를 활용하여 분석하는 기술로, 대용량, 속도 다양성이라는 특징을 가지고 있는 기술을 무엇이라고 하는가?",
            "answer": "빅데이터 기술",
            "topic": [
                "빅데이터 기술의 개념과 특징"
            ]
        },
        "multiple_choice": {
            "question": "빅테이터의 기술에 대한 특징으로 틀린 것은?",
            "choices": [
                "a) 빅데이터 기술을 활용하면 모든 분야에서의 문제점을 쉽게 해결할 수 있다.",
                "b) 빅데이터 기술은 표본 데이터가 가지고 있는 분석법의 한계를 뛰어 넘었다.",
                "c) 빅데이터 기술의 가장 큰 특징은 다양성, 속도, 대용량이라는 점이다.",
                "d) 빅데이터 기술은 정량적 해석뿐만 아니라 정성적 해석도 가능하다."
            ],
            "answer": "a",
            "topic": [
                "빅데이터 기술의 특징"
            ]
        },
        "true_false": {
            "question": "빅데이터 기술로 판단할 수 있는 속성은 다양성이다.",
            "answer": "FALSE",
            "topic": [
                "빅데이터 기술의 속성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:13:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "6 인공지능(artificial intelligence)은 인간의 학습능력과 추론능력, 지각능력, 자연언어의 이해능력 등을 컴퓨터 프로그램으로 실현한 기술이다. ○ 기계학습(machine learning)은 데이터 학습을 통해 패턴이나 규칙을 찾아내는 역할을 하는 인공지능의 한 부분으로 컴퓨터에게 어떤 일을 시키는 알고리즘과 기술을 개발하는 분야이다. ○ 딥러닝(deep learning)은 머신러닝의 한 분야이다. 머신러닝은 인공지능을 가능하게 해주는 기술 중의 하나이며, 딥러닝은 머신러닝에 들어가는 알고리즘의 하나이다. □ 인공지능은 사람을 대체하는 존재가 아니라 사람의 기능을 강화해주는 존재라고 할 수 있다. ○ 인공지능은 현재 사람이 할 수 있는 단순작업을 매우 효율적으로 매우 빠르게 수행하도록 실현할 수 있기 때문8)이다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:13:0001",
                    "page": 13
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능은 인간의 학습능력, 추론능력, 지각능력, 자연언어의 이해능력을 컴퓨터 프로그램을 실현한 기술 중 하나이다. 인공지능에는 기계학습과 딥러닝으로 나눌 수 있다. 인공지능은 지금까지 사람이 할 수 있는 단순작업을 대체하여 매우 효율적이면서도 빠르게 수행할 수 있게 실현된 기술이라 할 수 있다.",
        "long_answer": {
            "question": "인공지능의 영역과 특징에 대해서 설명하라.",
            "answer": "인공지능은 기계학습과 딥러닝으로 구분할 수 있다. 기계학습이란 데이터를 학습하여 패턴이나 규칙을 찾아나는 역할을 수행하며 컴퓨터에게 명령하기 위한 알고리즘을 개발하는 것이라 할 수 있다. 반면에 딥러닝의 경우, 머신러닝의 한 분야이자 알고리즘으로 딥러닝을 통해 머신러닝을 가능하게 해주는 기술 중 일부라고 할 수 있다.",
            "rubric": [
                "인공지능; 기계학습, 머신러닝; 딥러닝; 알고리즘; 데이터 학습; 패턴이나 규칙"
            ]
        },
        "short_answer": {
            "question": "인간의 학습능력과 추론능력, 지각능력, 이해능력 등을 컴퓨터 프로그램으로 실현시키는 기술은?",
            "answer": "인공지능",
            "topic": [
                "인공지능의 정의"
            ]
        },
        "multiple_choice": {
            "question": "제시된 보기 내용 중 인공지능에 대한 설명으로 부합하지 않는 것을 선택하라.",
            "choices": [
                "a) 인공지능은 기계학습으로 이루어진 것으로 인간의 사고 능력을 수행하기 위한 프로그램의 일종이라 할 수 있다.",
                "b) 인공지능의 탄생으로 인해 단순작업에 효율성을 높였다.",
                "c) 딥러능은 머신 러닝의 일부라고 할 수 있으며 인공지능의 하위 영역에 속한다.",
                "d) 인공지능은 인간을 대체하기 위해 나온 기술로 인간이 할 수 있는 모든 영역에 대체하여 사용할 수 있다."
            ],
            "answer": "d",
            "topic": [
                "인공지능의 특징"
            ]
        },
        "true_false": {
            "question": "인공지능은 기계학습, 딥러닝, 데이터마이닝으로 구성될 수 있다.",
            "answer": "FALSE",
            "topic": [
                "인공지능의 영역"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:13:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "① 지도학습(=감독학습, 관리학습): 입력 데이터들을 통해 입력변수들의 정보를 받아서 정해진 반응변수(출력변수)에 대한 예측 값을 얻는 것 ② 비지도학습(=자율학습): 입력데이터만 있고 미리 정해진 출력번수가 없음. 데이터 안에 숨어있는 패턴이나 규칙을 찾아내고 싶을 때 사용 ③ 강화학습(Reinforcement learning): 전혀 데이터가 존재하지 않은 상황에서 판단을 내리거나 행동을 했을 때 결과치를 통해 학습해야 할 경우, 스스로 행동하며 시행착오(trial-error)를 통해 학습하는 방식",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:13:0001",
                    "page": 13
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "지도학습은 입력 데이터로부터 입력변수의 정보를 가지고 정해진 반응변수에 대해 예측값을 얻는 학습 방식인 반면에 비지도학습인 경우, 입력데이터만 있으며 출력변수가 없어 데이터 안의 숨은 패턴이나 규칙을 찾을 때 사용하는 학습방식이다. 강화학습의 경우, 데이터가 전혀 존재하는 상황에서 결과치를 통해 학습해야하는 경우, 스스로 행동하여 시행착오를 통해 학습하는 방식이다.",
        "long_answer": {
            "question": "지도학습과 비지도학습이 각각 무엇인지 설명하시오.",
            "answer": "지도학습은 입력 데이터와 그에 따른 반응변수의 상관관계를 통해서 예측값을 얻는 학습 방식이다. 그러나 비지도학습인 경우, 입력데이터는 존재하지만 그에 대한 반응변수 없이 학습하는 방식을 말한다. 비지도학습은 데이터 내에서 숨겨진 패턴이나 규칙을 찾을 때 많이 활용하는 학습 방식이라 할 수 있다.",
            "rubric": [
                "지도학습; 비지도학습; 입력데이터; 반응변수"
            ]
        },
        "short_answer": {
            "question": "데이터가 없는 상태에서 결과치를 얻고자 할 때, 스스로 행동하여 학습하는 방식을 무엇이라 하는가?",
            "answer": "강화학습",
            "topic": [
                "강화학습의 개념"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 학습 방식에 대한 설명으로 가장 알맞은 것을 찾아라.",
            "choices": [
                "a) 지도학습은 자율학습이라고 부른다.",
                "b) 비지도학습은 데이터가 전혀 없는 상황에서 시행착오를 통해 스스로 학습하는 방식을 의미한다.",
                "c) 강화학습은 데이터가 존재하지 않지만 시행착오를 거친 후, 스스로 행동하는 학습 방식을 말한다.",
                "d) 지도학습은 감독학습 또는 관리학습이라 부르며 입력데이터만 가지고 패턴이나 규칙을 찾는 학습방식을 나타낸다."
            ],
            "answer": "c",
            "topic": [
                "지도학습, 비지도학습, 강화학습의 의미"
            ]
        },
        "true_false": {
            "question": "비지도학습은 데이터 내부에 있는 패턴이나 규칙을 찾는 데 용이한 학습 방식이다.",
            "answer": "TRUE",
            "topic": [
                "비지도학습의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터마이닝과 머신러닝 비교 데이터마이닝 사용되는 기법 연관분석, 회귀분석, 분류 분석방법론 통계학적 관점 방법론 목적 패턴이나 인사이트 추론 활용분야 리서치 분야 머신러닝 사용되는 기법 지도학습, 비지도학습, 강화학습 분석방법론 컴퓨터사이언스관점 방법론 목적 정확한 예측 활용분야 비지니스분야",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터마이닝과 머신러닝을 비교하였을 때, 사용되는 기법에서 데이터마이닝은 연관분석, 회귀분석, 분류 기법을 사용하나 머신러닝은 지도학습, 비지도학습, 강화학습을 활용한다. 분석방법론에서는 데이터마이닝의 경우 통계학적 관점 방법론이지만 머신러닝은 컴퓨터사이언스관점 방법론이라 할 수 있으며 이외에도 목적과 활용분야에서도 각각의 차이를 보이고 있다.",
        "long_answer": {
            "question": "데이터마이닝과 머신러닝에서 사용 목적과 기법은 각각 무엇인가?",
            "answer": "데이터마이닝을 사용하는 목적은 패턴이나 인사이트를 추론하기 위해서 사용되는 기술로 그 기법에는 연관분석, 회귀분석, 분류와 같은 방법을 활용하고 있다. 그러나 머신러닝의 경우 데이터마이닝과는 달리, 사용 목적면에서 데이터를 가지고 정확한 예측을 하기 위해 사용하는 경우가 많다. 또한 그 기법에는 지도학습, 비지도학습, 강화학습을 주로 사용한다.",
            "rubric": [
                "데이터마이닝; 머신러닝; 패턴이나 인사이트 추론; 연관분석, 회귀분석, 분류; 예측; 지도학습, 비지도학습, 강화학습"
            ]
        },
        "short_answer": {
            "question": "머신러닝과 데이터마이닝의 분석 방법론은 각각 어떤 것인가?",
            "answer": "컴퓨터사이언스관점 방법론, 통계학적 관점 방법론",
            "topic": [
                "머신러닝과 데이터마이닝의 분석방법론"
            ]
        },
        "multiple_choice": {
            "question": "다음은 머신러닝과 데이터마이닝에 대한 설명이다. 설명 중 틀린 것을 골라라.",
            "choices": [
                "a) 머신러닝에 주로 사용되는 기법에는 지도학습, 비지도 학습, 강화학습이 있다.",
                "b) 데이터마이닝은 리서치 분야에서 많이 활용되고 있다.",
                "c) 머신러닝은 데이터마이닝과 달리 정확한 예측을 하기 위한 목적으로 사용된다.",
                "d) 데이터마이닝은 컴퓨터사이언스관점 방법론에 입각하여 분석한다."
            ],
            "answer": "d",
            "topic": [
                "머신러닝과 데이터마이닝의 주된 특징"
            ]
        },
        "true_false": {
            "question": "데이터마이닝은 주로 지도학습, 비지도학습, 강화학습을 사용하는 기술이다.",
            "answer": "FALSE",
            "topic": [
                "데이터마이닝의 사용 기법"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:14:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "2. 데이터 과학 연구영역 2.1 데이터 과학의 포괄범위 □ 데이터 과학은 데이터 처리와 관련된 IT(해킹스킬), 분석적 영역(수학과 통계학, 지식), 비즈니스 컨설팅 영역(내용적 전문성)을 포괄한다. ○ 이러한 영역별 요소에 기반하여 많은 데이터에서 정보를 찾고, 복잡한 대용량 데이터를 구조화하거나 불완전한 데이터를 서로 연결해 조직화된 결과를 얻는다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:14:mh: 00001",
                    "page": 14
                }
            },
            {
                "context_id": "2",
                "text": "□ 데이터 과학은 데이터를 다루고 그 안에서 유의미한 결과를 추출해 내는 모든 것을 통칭하는 것이라 할 수 있다. '데이터 분석' 기술은 '데이터마이닝 → 빅데이터 → 인공지능 → 데이터 과학'으로 변천하였다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:14:mh: 00001",
                    "page": 15
                }
            }
        ],
        "summarization": "데이터 과학의 범위는 다양하다. 주로 데이터 처리와 관련된 IT나 분석적 영역, 비즈니스 컨설팅 영역을 포괄하고 있다. 이러한 영역에서 데이터 과학은 정보를 찾아주고 대량의 데이터를 구조화하며 조직화하여 유의미한 결과값을 얻을 수 있게 하는 것이라 할 수 있다.",
        "long_answer": {
            "question": "데이터 과학이 활용되는 영역에 대해서 서술해 보라.",
            "answer": "데이터 과학은 IT, 비즈니스 컨설팅 등 영역에서 활용되는 분야라고 할 수 있다. IT에서는 해킹 스킬과 같은 곳에서 활용될 수 있으며, 비즈니스 컨설팅에서는 내용적 전문성을 갖추기 위해 기술적으로 사용되는 경우가 있다. 이 뿐만 아니라, 수학과 통계학, 지식 정보 추출과 같은 곳에서도 두루 사용하는 응용 분야라 하겠다.",
            "rubric": [
                "데이터 과학; IT, 해킹스킬; 비즈니스 컨설팅; 분석적 영역"
            ]
        },
        "short_answer": {
            "question": "데이터 과학의 변천 과정을 순서대로 써라.",
            "answer": "데이터마이닝, 빅데이터, 인공지능, 데이터 과학",
            "topic": [
                "데이터 과학의 변천 과정"
            ]
        },
        "multiple_choice": {
            "question": "데이터 과학의 영역과 그 변천 과정에 대한 설명으로 가장 적합한 것은?",
            "choices": [
                "a) 데이터 과학은 복잡한 소규모의 데이터를 활용하여 이를 구조화하고 조직화하는 것이 핵심이다.",
                "b) 데이터 과학은 수학이나 통계학, 지식 정보 추출에서도 활용된다.",
                "c) 데이터 과학은 비즈니스 컨설팅과 같은 영역에서는 활용하기가 어렵다.",
                "d) 데이터 과학의 가장 첫 시작은 머신러닝이다."
            ],
            "answer": "b",
            "topic": [
                "데이터 과학의 영역과 그 변천 과정"
            ]
        },
        "true_false": {
            "question": "데이터 과학은 복잡하고 대규모의 데이터를 활용하여 이를 구조화하고 조직하여 결과를 얻는 것이 목적이다.",
            "answer": "TRUE",
            "topic": [
                "데이터 과학의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:21:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "□ 최근, 유럽 국가들을 중심으로 국가통계의 품질 및 조사환경 개선에 대한 공감대가 형성됨에 따라, 이에 대한 해결방안으로서 빅데이터 및 인공지능 기술 도 입이 추진 및 검토되고 있다.  ○ AI·빅데이터 통계 도입 관련 주요 논의사항16)에서 국가통계 개선이 이슈로 부각된 주요 원인들로 아래와 같은 현상들이 거론되고 있다. ❶ 새로운 유형의 산업이 빠르게 등장함에 따른 산업구조 반영의 어려움 ❷ 기업 활동의 다양화(지역에 기반 하지 않은 산업, 사무실 연락처 부재 등) ❸ 조사별 응답자 중복에 의한 회수율 약화 ❹ 즉시 활용 가능한 민간 중심의 데이터의 급증 등 ○ 또한, 공통적인 문제 인식과는 별개로 AI 또는 빅데이터 기술 도입에 대한 가치 판단 및 취지는 국가별로 상이하며, 사안에 접근하는 방식 또한 다양하다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:21:0001",
                    "page": 21
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "AI와 빅데이터 통계의 도입과 관련하여 국가별 주요 논의사항으로는 새로운 유형의 산업에 대한 빠른 반영이 어려움, 기업 활동의 다양화, 조사별 응답자 중복에 의한 회수율 약화, 즉시 활용 가능한 민간 중심의 데이터의 급증 등이다. 이러한 쟁점에 대한 해결 방안과 도입 자체에 대한 가치 판단 및 취지는 국가별로 상이하다고 할 수 있다.",
        "long_answer": {
            "question": "빅데이터와 AI의 도입하고자 할 때, 국가통계 개선이 이슈로 부각되는 주요 원인에 대해서 설명하라.",
            "answer": "인공지능과 빅데이터 도입과 관련하여 국가 차원에서 개선해야할 이슈로는 다음과 같다. 첫째, 새로운 유형의 산업이 빠르게 등장해서 산업구조 반영이 바로 어렵고 기업활동이 다양하다는 것이다. 또한 조사별 응답자 중복에 의한 회수율이 낮으며 즉시 활용 가능한 민간 중심의 데이터 급증 등을 문제점으로 나타낼 수 있다.",
            "rubric": [
                "산업구조 반영의 빠른 반영 어려움; 기업활동의 다양화; 중복에 의한 회수율; 민간 중심의 데이터 급증"
            ]
        },
        "short_answer": {
            "question": "인공지능과 빅데이터 통계 도입에 있어 지역에 기반하지 않은 산업이 있거나 사무실 연락처 부재 등의 원인은 무엇에 의한 것인가?",
            "answer": "기업 활동의 다양화",
            "topic": [
                "인공지능과 빅데이터 통계 도입의 이슈"
            ]
        },
        "multiple_choice": {
            "question": "AI와 빅데이터 통계 도입과 관련한 주요 이슈 상황 중 틀린 것은?",
            "choices": [
                "a) 조사에 따른 응답자의 중복이 적어 회수율이 높다는 점이다.",
                "b) 새로운 유형의 산업이 빠르게 등장함에 따라 실제 산업구조에 적용이 바로 어렵다는 점이다.",
                "c) 기업활동이 다양하여 일일히 대응하게 힘들다는 점이다.",
                "d) 이미 즉시 활용가능한 민간 중심의 데이터가 급증하고 있기 때문이다."
            ],
            "answer": "a",
            "topic": [
                "AI와 빅데이터 통계 도입 관련 이슈"
            ]
        },
        "true_false": {
            "question": "빅데이터와 인공지능 통계 도입에 있어 주요 논의사항으로는 기업활동의 단순화가 핵심이다.",
            "answer": "FALSE",
            "topic": [
                "빅데이터와 인공지능 통계 도입 관련 이슈"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:21:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "□ '제6차 유엔 빅데이터 컨퍼런스(2020.8)' 주요 논의 사항은 다음과 같다. ○ 빅데이터를 활용하는 주된 목표 중 하나는 공식통계 생산이며, 코로나19를 계기로 빠른 의사결정을 위한 데이터 공유 및 스튜어드십을 강조했다. ○ 광범한 데이터 공유를 위해 통계법 등 법·제도 완비와 양방향 데이터 공유를 위한 오픈 플랫폼이 필요하며, 데이터와 통계를 공유할 수 있도록 협업과 위임을 통하여 다른 기관의 참여를 확대하고, 통계청은 감독 및 품질관리 역할 수행해야 한다. ○ 빅데이터 프로젝트의 출발점은 '사용자의 수요'이며, 빅데이터 활용의 문제점을 살펴보고 먼저 소규모 실험을 실시한 후 대규모 프로젝트로 확장 실행하는 과정이 필요하다. ○ 또한 코로나19로 통계의 적절성, 즉 '가장 중요한 고객이 무엇을 원하는가'에 대한 파악과 시의성이 가장 중요하다. ○ 새로운 기술을 활용하여 생산된 통계 지표에 대한 대중들의 신뢰를 얻기 위해서는 커뮤니케이션이 중요하고, 빅데이터 활용 및 공유를 위한 투자가 필요하며, 이러한 데이터를 분석하고 활용할 수 있는 인적 자원 양성을 위한 교육이 필요하다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:21:0001",
                    "page": 21
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "제6차 유엔 빅데이터 컨퍼런스(2020.8)에서는 코로나19 이후 신속한 의사결정을 위한 데이터 공유와 스튜어드십의 중요성을 강조하였다. 또한 법과 제도의 정비, 오픈 플랫폼의 구축, 기관 간의 협업 확대, 인적 자원 양성뿐만 아니라 사용자 중심의 빅데이터 활용을 통한 통계의 신뢰성 제고 방안을 논의하였다.",
        "long_answer": {
            "question": "2020년 제6차 유엔 빅데이터 컨퍼런스에서 빅데이터 활용의 주된 목표와 통계청의 역할 수행은 무엇인지 설명하라.",
            "answer": "제6차 유엔 빅데이터 컨퍼런스에서는 빅데이터를 활용하는 주된 목표 중 하나를 공식통계를 생산하는 것이며, 코로나19 이후로 빠른 의사결정을 위한 데이터의 공유와 스튜어드십을 강조하였다. 이를 위해 국가와 각 기관에서는 광범한 데이터를 서로 공유하며 통계법 등 법과 제도를 완비하여 협업과 위임이 필요하다고 했다. 이를 위해서는 양방향 데이터 공유를 위한 오픈 플랫폼을 만들어 통계청은 감독 및 품질 관리 역할을 수행해야한다고 언급했다.",
            "rubric": [
                "공식통계 생산; 양방향 데이터 공유; 감독 및 품질 관리 역할"
            ]
        },
        "short_answer": {
            "question": "제6차 유엔 빅데이터 컨퍼런스 중 코로나19 이후 통계에서 가장 중요하게 언급한 요소는 무엇인가?",
            "answer": "적절성, 시의성",
            "topic": [
                "코로나19 이후 통계의 중요 요소"
            ]
        },
        "multiple_choice": {
            "question": "2020년 제6차 유엔 빅데이터 컨퍼런스에서 논의한 주요 사항이다. 이에 대한 설명으로 가장 부합하는 것은?",
            "choices": [
                "a) 빅데이터 프로젝트의 출발점은 '사용자의 공급'이며, 먼저 대규모 실험을 실시해야한다는 점을 강조하였다.",
                "b) 새로운 기술을 활용하기 때문에 통계 지표에 대해 대중들의 신뢰를 얻을 필요가 없다.",
                "c) 코로나19 이후 통계에서 중요한 점은 사용자의 요구와 시의성이다.",
                "d) 광범위한 데이터만 확보되면 되는 것이기 때문에 양방향 데이터 공유는 의미가 없다."
            ],
            "answer": "c",
            "topic": [
                "제6차 유엔 빅데이터 컨퍼런스의 주된 논의 사항"
            ]
        },
        "true_false": {
            "question": "제 6차 유엔 빅데이터 컨퍼런스에서 통계 지표가 신뢰를 얻기 위해서는 인적 자원 양성을 위한 교육이 필요하다고 했다.",
            "answer": "TRUE",
            "topic": [
                "제6차 유엔 빅데이터 컨퍼런스의 주된 논의 사항"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "데이터 과학(Data Science) 기초 연구.pdf:22:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "□ 유엔유럽경제위원회(UNECE)에서 발간한 '공식통계에 있어서 빅데이터는 무엇을 의미하는가?17)'의 주요 내용은 다음과 같다. ○ 국가 통계기관이 공식통계 작성에 빅데이터를 활용하는 시도들을 살펴보면, 빅데이터의 공식통계 활용에는 세 가지의 영역이 있음을 알 수 있다. (❶ 빅데이터와 공식통계의 결합 ❷ 빅데이터로 공식통계를 대체 ❸ 새로운 데이터의 간극 채우기) ○ 또한, 빅데이터와 공식통계의 결합은 지난 수십 년간 수행한 행정자료를 공식통계에 결합·활용한 측면과 유사하며, 이 둘을 결합하여 통계 모델링에 적용한다면 공식통계 수준의 품질을 유지하면서 빅데이터로부터 취득한 실시간 정보로 추정치를 향상시킬 수 있다. □ 한편, 행정(통계)분야에 인공지능 도입의 쟁점요소들은 데이터의 중요성, 기술 및 인프라, 법제도 및 규제, 정책 및 전략, 윤리 및 가치 등이다. ○ 데이터의 양과 질이 충분치 않을 때, 알고리즘을 비롯한 기술적 문제, 개인정보보호나 규제 등과의 충돌, 인공지능에 대한 지나친 과신 등이 문제가 된다. ○ 이를 위한 해결방안으로 충분한 양질의 데이터 확보, 인공지능 기술의 사회적 영향력 검토, 인공지능의 자율성 관리 등 인공지능 도입에 대한 막연한 기대가 아닌 객관적이고 철저한 분석과 검토가 필요하다.",
                "provenance": {
                    "doc_id": "데이터 과학(Data Science) 기초 연구.pdf:22:0001",
                    "page": 22
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "유엔유럽경제위원회는 빅데이터의 공식통계 활용을 '결합, 대체, 보완'이라는 세 영역으로 제시하며, 행정자료와의 결합을 통해 통계의 품질과 시의성을 높일 수 있다고 보았다. 또한 인공지능 도입 시 데이터 품질, 법과제도, 윤리 등 다양한 쟁점을 고려하여 객관적이고 체계적인 검토가 필요하다고 강조했다.",
        "long_answer": {
            "question": "유엔유럽경제위원회에서 공표한 공식 통계와 빅데이터의 결합이 가지는 의미는 무엇인가?",
            "answer": "빅데이터와 공식통계의 결합은 지난 수십년 간 모아온 행정자료를 공식통계에 결합하며 이를 활용하는 측면과 유사하다고 하였다. 또한 이 둘을 결합하여 통계 모델링에 적용한다면 공식 통계의 수준을 높일 수 있다고 하였다. 더 나아가 실시간으로 정보를 취득할 수 있어 추정치를 향상시킬 수 있다고 보았다.",
            "rubric": [
                "빅데이터와 공식통계; 통합; 추정치 향상; 수준 향상"
            ]
        },
        "short_answer": {
            "question": "행정과 통계 분야에서 인공지능 도입의 쟁점요소는 무엇인지 모두 써라.",
            "answer": "데이터의 중요성, 기술 및 인프라, 법제도 및 규제, 정책 및 전략, 윤리 및 가치",
            "topic": [
                "행정과 통계분야에서의 인공지능 도입 대한 쟁점요소"
            ]
        },
        "multiple_choice": {
            "question": "공식통계에 있어 빅데이터가 가지는 의미로 가장 알맞게 설명한 것은?",
            "choices": [
                "a) 공식통계에서 빅데이터의 활용은 대량의 행정자료를 수합하고 활용하는 데에 있어 용이하다.",
                "b) 데이터의 양과 질이 충분하지 않아도 인공지능에 대한 믿음은 확실하다.",
                "c) 인공지능의 도입으로 윤리 및 가치 영역에 나타나는 문제점은 모두 해결이 된다.",
                "d) 빅데이터를 도입한다고 하더라도, 추정치 능력이 바로 향상되지 않는다."
            ],
            "answer": "a",
            "topic": [
                "공식통계에서 빅데이터가 가지는 의미"
            ]
        },
        "true_false": {
            "question": "공식통계에서 데이터의 양질이 보장되지 않은 빅데이터도 충분히 활용할 가치가 있다.",
            "answer": "FALSE",
            "topic": [
                "공식통계에서 빅데이터가 가지는 의미"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:11:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "Ÿ 오픈AI에서 “Language models are few-shot learner”라는 논문을 발표하며, GPT-3모델을 전 세계에 공개(‘20.6) - GPT-3는 기존에 공개된 마이크로소프트의 Turing-LNG보다 모델의 사이즈가 10배 이상 큰 1,750억개의 매개변수를 가진 초대규모 모델 - 학습에 활용된 데이터(단어)는 크롤링(4,100억개), 웹텍스트(190억개), 책1(120 억개), 책2(550억개), 위키피디아(30억개)로 초대규모 데이터셋 Ÿ 논문 제목에서 추측할 수 있듯이, 초대규모 모델인 GPT-3는 퓨샷러닝에서 우수한 성능을 나타내고 있음을 강조 - (원샷러닝) GPT-3와 같은 범용성 높은 언어모델에 하나의 예시만 주어지고 번역 등 원하는 Task를 해결하도록 하는 방식 - (퓨샷러닝) 원샷러닝은 하나의 예시만 주어졌으나, 퓨샷러닝은 두 개 이상의 예시를 주며, 모델이 몇 가지의 사례를 이해하고 번역 등 Task 수행 Ÿ 타 모델의 미세조정(Fine-tuning)*으로 재학습된 최고 신기록을 GPT-3 모델  은 퓨샷러닝을 통해 경신하는 등 우수한 성능 보여주고 있음  * 퓨샷러닝은 소량의 데이터로 모델의 재학습시키는 것이지만, 미세조정은 퓨샷러  닝보다는 많은 Task 데이터로 모델을 재학습하는 것을 의미",
                "provenance": {
                    "doc_id": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:11:0001",
                    "page": 11
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "2020년 오픈AI는 1,750억 개의 매개변수를 가진 초대규모 언어모델 GPT-3을 공개하였다. 이 언어모델은 텍스트 데이터로 학습되었으며 소수의 예시만으로도 다양한 작업을 수행하는 퓨샷러닝에서 뛰어난 성능을 보인다고 밝혔다.",
        "long_answer": {
            "question": "원샷 러닝과 퓨샷러닝의 차이점을 비교하여 기술하라.",
            "answer": "원샷 러닝은 GPT-3과 같은 범용성이 높은 언어모델에 하나의 예시만 주어지고 번역하는 등 원하는 Task를 해결하는 방식이다. 반면에 퓨샷러닝의 경우, 원샷 러닝이 하나의 예시만 주어졌다고 하였을 때, 퓨샷 러닝은 두 개 이상의 예시를 주는 것이다. 그러므로 퓨샷 러닝은 모델이 여러 가지의 사례를 이해하여 번역 등의 Task를 수행하는 것이다.",
            "rubric": [
                "원샷 러닝; 퓨샷 러닝; 예시 수량 차이"
            ]
        },
        "short_answer": {
            "question": "1,750억 개의 매개변수를 가진 언어모델로, 오픈AI에서 2020년에 처음 발표한 언어모델은 무엇인가?",
            "answer": "GPT-3",
            "topic": [
                "GPT-3의 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 GPT-3에 대한 설명이다. 설명 중 틀린 것을 골라라.",
            "choices": [
                "a) GPT-3은 원샷 러닝뿐만 아니라 퓨샷 러닝에서도 우수한 성능을 보였다.",
                "b) 퓨샷 러닝은 소량의 데이터로 모델을 재학습시키는 것이지만 미세조정은 퓨샷러닝보다 많은 Task 데이터를 학습하였다.",
                "c) GPT-3은 기존에 공개된 마이크로소프트의 언어모델보다 매개변수가 적다.",
                "d) 원샷 러닝은 예시를 하나만 제시하여 Task를 수행하는 방식이다."
            ],
            "answer": "c",
            "topic": [
                "GPT-3의 특징"
            ]
        },
        "true_false": {
            "question": "GPT-3의 학습에 사용한 데이터는 크롤링, 웹텍스트, 책, 위키피디아 등의 방대한 자료라 할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "GPT-3의 학습 데이터"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:13:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "연합학습(Federated Learning) 개념 Ÿ 구글은 2017년 구글IO 세미나를 통해 분산된 디바이스에서 각각 학습을 하여, 모델의 가중치만 중앙 서버로 전달하는 연합학습의 개념 소개 - 데이터의 이동 없이 분산 학습이 가능하므로, 개인정보보호 이슈 및 컴퓨팅 파워의 효율적 운영에 대한 해결책으로 부상 < 연합학습의 학습 순서 설명 > 1 서버에서 보유한 데이터로 학습하여 기본적인 모델 생성 2 생성된 기본 모델을 여러 클라이언트에게 배포 3 클라이언트는 보유한 데이터를 활용하여 모델 업데이트 4 업데이트된 모델의 파라미터 값을 서버로 전송하고, 클라이언트로부터 전달받은 파라미터를 통해 서버는 새롭게 모델 업데이트 5 업데이트된 모델을 클라이언트에게 다시 전송 6 반복 Ÿ NVIDIA는 데이터 이동관련 개인정보보호 이슈를 해결하면서, 방대한 양의 의료 데 이터를 활용하기 위해 연합학습 플랫폼을 개발하여 의료 이미지 분석 서비스 지원",
                "provenance": {
                    "doc_id": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:13:0001",
                    "page": 13
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "2017년 구글이 제시한 연합학습은 데이터 이동 없이 각 디바이스에서 모델을 학습하고 파라미터만 공유하는 방식으로 개인정보보호와 연산 효율성을 높이는 분산 학습 기법이다. 이후 NVDIA 등은 이를 의료 분야에 적용해 대규모 의료 데이터를 활용하는 플랫폼을 개발했다.",
        "long_answer": {
            "question": "연합학습의  학습 순서에 대해서 서술하라.",
            "answer": "연학학습은 먼저 서버에 보유한 데이터로 학습하여 기본적인 모델을 생성한다. 생성된 기본 모델로 여러 클라이언트에 배포를 하고 그 모델로 클라이언트는 자신이 보유한 데이터로 모델을 업데이트를 한다. 그리고 업데이트된 모델의 파라미터 값을 서버로 전송하여 이 서버에서 받은 파라미터로 모델을 업데이트 하며, 이를 다시 클라이언트에 전달하는 방식으로 학습을 진행한다.",
            "rubric": [
                "연합학습; 서버 보유; 파라미터; 모델의 업데이트"
            ]
        },
        "short_answer": {
            "question": "데이터 이동 없이 분산 학습이 가능하여 개인정보보호 이슈 및 컴퓨팅 파워의 효율적인 운영에 대한 해결책으로 활용할 수 있는 학습 방식을 무엇이라 하는가?",
            "answer": "연합학습",
            "topic": [
                "연합학습의 개념과 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음은 연합학습에 대한 특징을 기술한 것이다. 보기의 내용 중 올바르지 않는 것을 선택하라.",
            "choices": [
                "a) 연합학습은 구글이 2017년 구글IO 세미나에서 소개한 학습 방식이다.",
                "b) 연합학습에서의 핵심은 공유받은 모델을 더이상 수정하지 않아도 된다는 점이다.",
                "c) NVDIA는 이를 활용하여 의료 의미지 분석 서비스를 지원하는 플랫폼을 개발하였다.",
                "d) 연합학습으로 인해 개인정보보호 이슈를 해결할 수 있었다."
            ],
            "answer": "b",
            "topic": [
                "연합학습의 특징"
            ]
        },
        "true_false": {
            "question": "연합학습은 분산된 디바이스에서 모델의 가중치만 중앙 서버로 전달하는 방식을 말한다.",
            "answer": "TRUE",
            "topic": [
                "연합학습의 학습 방식"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "엣지 AI(Edge AI) “온디바이스 AI를 위한 모델 경량화”  엣지  AI  장점 보안(Security) - 데이터를 주고받지 않고 로컬 장치에서 처리가 가능하므로 데이터 프라이버시 이슈에서 자유로워, 기업은 차별화된 개인 서비스 기 능 제공 가능  높은 응답성 (Highly Responsive) - 여러 개의 네트워크 노드에서 실행 가능해, 데이터와 프로세싱 간 물리적 거리를 좁혀 병목현상을 줄이고 애플리케이션 속도 가속화  비용 절감 (Reduced Costs) - 데이터를 전송하기 위한 통신망과 높은 대역폭이 불필요하므로 해당 비용이 절감되는 효과",
                "provenance": {
                    "doc_id": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "엣지 AI는 데이터를 로컬장치에서 처리하는 것이 가능하여 데이터 프라이버시 이슈에서 자유롭다. 또한 네트워크 병목 현상을 줄여 빠른 응답성을 확보하며, 통신 비용과 대역폭 사용을 최소화해 비용 절감 효과를 얻을 수 있다.",
        "long_answer": {
            "question": "엣지 AI의 장점에 대해서 설명해 보라.",
            "answer": "엣지 AI는 데이터를 주고받지 않고 로컬 장치에서 처리가 가능하다는 점에서 보안의 문제점을 해결할 수 있는 장점이 있다. 또한 여러 개의 네트워크 노드에 실행이 가능하므로 높은 응답성을 가지고 있다는 것이 특징이다. 그 외에도 데이터를 전송하기 위한 통신망과 높은 대역폭이 불필요해 비용을 절감할 수 있다.",
            "rubric": [
                "엣지 AI; 보안; 높은 응답성; 비용 절감"
            ]
        },
        "short_answer": {
            "question": "온디바이스 AI를 위한 모델로 기존의 모델보다 경량화된 것을 무엇이라고 하는가?",
            "answer": "엣지 AI",
            "topic": [
                "엣지 AI의 정의"
            ]
        },
        "multiple_choice": {
            "question": "엣지 AI가 가지고 있는 장점에 대해 설명한 내용 중 거리가 먼 것은?",
            "choices": [
                "a) 엣지 AI는 데이터를 주고받지 않은 상태로 로컬 장치에서 처리가 가능하므로 기업은 차별화된 개인 서비스 기능을 제공 받을 수 있다.",
                "b) 여러 개의 네트워크 노드에서 실행이 가능하여 애플리케이션 속도를 가속화할 수 있다.",
                "c) 데이터를 전송하기 위한 높은 대역폭이 불필요하여 비용을 크게 절감할 수 있다.",
                "d) 엣지 AI는 기업이 가지고 있는 각각의 로컬 장치에서 데이터를 주고 받아, 프라이버시 이슈를 해결할 수 있다."
            ],
            "answer": "d",
            "topic": [
                "엣지 AI의 장점"
            ]
        },
        "true_false": {
            "question": "엣지 AI는 수많은 데이터를 전송하기 위해 높은 대역폭을 사용한다.",
            "answer": "FALSE",
            "topic": [
                "엣지 AI의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:15:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "트랜스포머(Transformer) “NLP에서 컴퓨터 비전까지 영역 확장” o 트랜스포머는 언어처리의 병렬화를 통해 계산 효율성 향상 등 그간 순차적으로 단어를 학습하는 알고리즘의 한계를 극복 - 트랜스포머(구글, 2017)가 등장하기 이전에는 데이터를 순차적으 로(단어의 순서) 처리하는 순환신경망(RNN4)) 방식을 활용 - 트랜스포머의 병렬화로 인해 대규모 데이터셋을 학습할 수 있게 되었고, GPT-3의 경우 약 5천억 토큰(단어)들로 훈련 o 트랜스포머 공개 이후 글로벌 테크 기업들은 모두 트랜스포머 기반의 언어모델을 앞다투어 연구하고 공개하기 시작 - 언어모델의 표준처럼 불리는 구글의 BERT5), 오픈AI의 GPT6) 등은 트랜스포머 기반으로 개발된 언어모델 - 현재는 대부분의 언어모델이 BERT, GPT의 사전학습모델을 활용하여, 각 과제(Task)를 수행하는 모델을 생산하는 형태",
                "provenance": {
                    "doc_id": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:15:0001",
                    "page": 15
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "2017년 구글의 트랜스포머는 순차적 학습이 가진 한계를 극복하고 병렬 처리를 통해 대규모 데이터 학습을 가능하게 하였다는 점에서 NLP의 혁신을 이끌었다. 이후 BERT와 GPT 등 주요 언어모델이 트랜스포머 기반으로 개발되며, 다양한 과제 수행의 표준 모델로 자리 잡았다.",
        "long_answer": {
            "question": "트랜스포머의 등장으로 이후 언어모델이 변화하게 된 점에 대해 예를 들어 설명하라.",
            "answer": "트랜스포머가 나타나기 이전에는 데이터를 순차적으로 처리하는 순환신경망(RNN) 방식을 활용하였다. 그러나 구글에서 2017년 트랜스포머의 방식을 발표하므로서 트랜스포머를 병렬적으로 사용할 수 있게 되고, 대규모의 데이터셋을 학습할 수 있게 되었다. 예를 들어 GPT-3의 경우, 트랜스포머를 활용하여 5천억 토근들로 훈련하였다.",
            "rubric": [
                "트랜스포머; 순환신경망; 데이터의 병렬화; GPT-3"
            ]
        },
        "short_answer": {
            "question": "언어 처리의 병렬화를 통해 계산 효율성이 향상되어 순차적으로 단어를 학습하는 알고리즘의 한계를 극복하게 한 학습 방식은?",
            "answer": "트랜스포머",
            "topic": [
                "트랜스포머의 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 트랜스포머의 특징과 장점에 대한 설명으로 가장 적합한 것은?",
            "choices": [
                "a) 트랜스포머의 공개 이후 구글에서는 GPT를 개발하여 언어모델을 선보였다.",
                "b) 트랜스포머는 데이터를 순차적으로 처리하는 순환신경망 방식을 활용하였다.",
                "c) 트랜스포머는 언어처리의 병렬화를 통해 계산의 효율성을 향상시켰다.",
                "d) 현재 대부분의 언어모델은 순환신경망 방식을 활용하여 개발되었다."
            ],
            "answer": "c",
            "topic": [
                "트랜스포머의 특징과 장점"
            ]
        },
        "true_false": {
            "question": "GPT-3의 경우 순환신경망방식을 활용하여 개발된 언어모델이다.",
            "answer": "FALSE",
            "topic": [
                "GPT-3의 학습 모델"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:16:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": " 시스템2 AI(System2 AI) “단순 이해를 넘어 인과적 이해를 하는 AI” o 인공지능이 단순 인식이 가능한 ‘시스템 1’ 수준에서 인과관계 파악이 가능한 ‘시스템 2’ 수준으로의 이동을 위한 연구 활발 ※ ‘시스템 1’ 사고: 주변 인식, 직감적 위험 회피 등과 같이 인간이 무의식적 으로 처리 가능한 과정으로, 뇌의 빠르고 자동적인 접근 방식 ※ ‘시스템 2’ 사고: 추상적인 문제를 다루거나 새로운 상황을 처리하기 위한 추론이 필요할 때 주로 사용되는 분석적인 과정 - 요슈아 벤지오(Yoshua Bengio)는 인공지능이 학습되지 않은 상 황에서도 맥락을 이해하는 ‘시스템 2’ 추론 중요성을 강조 ※ 최근 단순한 인과관계 인식이 가능한 딥러닝 접근 방식을 설명한 논문 발표(‘19.1) - 그리고 인과관계에 대한 추론 영역의 성능 향상 없이는 인간 지능 수준의 접근은 어려울 것이라고 언급 o 인공지능의 기대에 비해 현재 인공지능 시스템은 활용 분야가 제한적이고 인과관계 설명이 불충분한 점 등 한계 보유 - 이미지에서 고양이를 인식하거나 음성 명령을 인식하는 것과 같이 ‘시스템 1’ 사고적인 작업에 대해서만 구체적이고 뛰어난 성능 발휘 - 인공지능은 근본적으로 원인과 결과를 알 수 없는 블랙박스가 있어 처리 과정의 설명이 중요한 상황에서 활용이 어려움 ※ 인공지능이 학습할 때 입력 변수는 수십, 수백 단계의 변형을 거쳐서 최종 모 델에 반영되므로, 입력 변수와 결과의 직접적인 관계 추적이 어려운 상황 ※ 의료 분야의 경우 질병 진단의 결과가 어떤 과정을 거쳤는지 파악이 안 되므로 활용에 제한",
                "provenance": {
                    "doc_id": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:16:0001",
                    "page": 16
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "시스템2 AI는 단순한 인식 수준의 '시스템1'에서 벗어나 인과관계와 맥락을 추론할 수 있는 고차원적 사고를 목표로 하며, 요수아 벤지오 등이 이를 핵심 연구과제로 제시하고 있다. 그러나 현재 인공지능은 여전히 인과적 설명이 부족한 블랙박스 구조로, 의료 등 설명이 중요한 분야에서 활용에는 한계를 보인다.",
        "long_answer": {
            "question": "시스템 1'의 사고방식과 '시스템 2'의 사고 방식에 대해 설명해 보라.",
            "answer": "시스템 1'의 사고는 주변을 인식하고 직감적 위험 회피 등과 같이 인간이 무의식적으로 처리 가능한 과정으로, 뇌의 빠르고 자동적인 접근 방식이다. 반면에 '시스템 2' 사고는 추상적인 문제를 다루거나 새로운 상황을 처리하기 위한 추론이 필요할 때 사용되는 분석적인 과정이다. '시스템 1'과 '시스템 2' 사고는 결국 무엇을 처리하는 것인가에 따라 상이함을 보인다.",
            "rubric": [
                "시스템 1 사고; 시스템 2 사고; 인간의 무의식적 처리 과정; 추론"
            ]
        },
        "short_answer": {
            "question": "추상적인 문제를 다루거나 새로운 상황을 처리하기 위한 상황에서 주로 사용되는 사고방식을 무엇이라 하는가?",
            "answer": "시스템 2 사고",
            "topic": [
                "시스템 2 사고의 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음은 시스템 1과 시스템 2 사고 방식에 대한 내용이다. 이 설명 중 가장 적절한 것은 무엇인가?",
            "choices": [
                "a) 시스템 1 사고는 인공지능이 인과관계를 파악하여 추론할 수 있는 사고 방식이다.",
                "b) 시스템 2 사고는 인공지능이 인간의 지능에 근접할 수 있는 최선의 사고 방식이다.",
                "c) 시스템 2 사고는 주변을 인식하고 직감적으로 위험을 회피하는 등 인간이 가진 무의식적 처리 과정을 따라한 사고 방식이다.",
                "d) 현재의 인공지능 시스템은 활용 분야가 무궁무진하며 인과관계에 대한 설명도 인간의 사고 수준과 동일하다."
            ],
            "answer": "b",
            "topic": [
                "시스템 1과 시트템 2 사고 방식의 특징"
            ]
        },
        "true_false": {
            "question": "현재의 인공지능 시스템은 활용 분야가 제한적이고 인과관계 설명이 불충분하는 것이 한계이다.",
            "answer": "TRUE",
            "topic": [
                "인공지능 시스템의 한계점"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:17:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "자기지도학습(Self supervised learning) “데이터 라벨링의 한계 극복” o 지도학습은 지난 10년 동안 자율주행차, 음성 비서 등 인공지능 분야에서 괄목할만한 발전을 주도했으나, 심각한 한계도 존재 - 지도학습의 원천이 되는 데이터를 수작업으로 라벨링을 해야하는 번거로움과 비용 부담이 발생하므로 인공지능 개발의 주요 한계 - 지도학습은 주어진 데이터셋에 포함된 함축된 정보, 관계 및 의 미를 탐색하는 대신 연구자들이 미리 식별한 개념과 범주에 의존 o 얀 르쿤은 비지도 학습의 의미적 모호성 때문에 자기지도학습이라 명명하고, 향후 자기지도학습이 미래 AI 혁신을 주도할 것이라 전망 - 얀 르쿤은 현재 비지도학습 방법이, 실제 지도(supervision)가 없는 것이 아니므로 의미적 모호성 발생한다고 언급 - 자기지도학습은 입력 값의 일정 부분으로 입력 값의 다른 부분 을 예측하며, 입력 값의 자체로 지도(supervision)를 만들어 학습",
                "provenance": {
                    "doc_id": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:17:0001",
                    "page": 17
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "지도학습의 한계점을 극복하고자 나온 자기지도학습은 데이터의 일부를 이용해 스스로 학습 신호를 생성하는 방식이다. 얀 르쿤은 이를 비지도학습의 대안이자 미래 AI 혁신의 핵심으로 제시했다.",
        "long_answer": {
            "question": "지도 학습의 한계점을 언급하며 자기지도학습의 특징을 설명하라.",
            "answer": "지도학습은 데이터를 수작업으로 라벨링 해아하는 번거로움과 비용 부담이 발생하여 인공지능 개발의 주요한 한계점이었다. 그러나 이를 극복하기 위해 나타난 자기지도학습은 비지도학습의 의미적 모호성으로 학습하는 방식을 가지고 있다. 이를 통해 인공지능 개발의 한계점을 극복하였다.",
            "rubric": [
                "지도학습; 자기지도학습; 라벨링의 번거로움; 비용 부담; 학습의 의미적 모호성; 한계점 극복"
            ]
        },
        "short_answer": {
            "question": "입력 값의 일정 부분으로 입력 값의 다른 부분을 예측하는 학습 방법을 무엇이라 하는가?",
            "answer": "자기지도학습",
            "topic": [
                "자기지도학습의 개념"
            ]
        },
        "multiple_choice": {
            "question": "지도학습과 자기지도학습의 특징에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) 자기지도학습은 데이터를 수동으로 라벨링하는 등 시간과 비용이 많이 드는 학습 방식이다.",
                "b) 지도학습은 주어진 데이터셋에 포함된 함축된 정보, 관계 및 의미를 탐색하지 못한다.",
                "c) 자기지도학습은 입력 값 자체로도 지도를 만들어 학습하는 방식이다.",
                "d) 자기지도학습은 비지도학습 방식에서 나타나는 의미적 모호성을 활용하는 것이다."
            ],
            "answer": "a",
            "topic": [
                "지도학습과 자기지도학습의 특징"
            ]
        },
        "true_false": {
            "question": "지도학습은 특정 데이터셋에 나타나는 함축된 정보를 탐색하는 대신 연구자들이 미리 식별한 개념과 범주에 의존한다.",
            "answer": "TRUE",
            "topic": [
                "지도학습의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:18:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": " 생성적 AI(Generativa AI) “(사물 등) 인식을 위한 AI가 아닌 창조를 하는 AI” o 인공지능이 텍스트, 이미지 등 기존 콘텐츠를 사용해 자체적으로 새로운 콘텐츠를 만드는 생성적 AI(Generative AI) 분야가 빠르게 성장 - 인공지능이 단순히 인지(판별)하는 것을 넘어 입력된 학습 데이 터의 패턴을 익혀 해당 데이터 분포와 유사한 콘텐츠를 생성 - 2014년 이안 굿펠로우(Ian Goodfellow)가 소개한 변증법적 인공지능 알고리즘 ‘생성적 적대 신경망(GAN)’이 대표적 핵심 기술 ※ GAN(Generative Adversarial Network) : 실제 데이터와 유사하게 새로운 것을 만들어내는 생성자와 만들어진 것을 평가하는 판별자가 끊임없이 서로 대립하며 성능을 개선해나가는 방식 o 인공지능 모델을 학습할 때, 부족한 데이터셋을 인위적으로 생성하는 데이터 증강(Data Augmentation)분야에 활용 - 데이터의 클래스(개, 비행기, 자동차)의 불균형으로 인해 데이터의 추가적인 확보가 필요할 때, GAN을 활용하여 부족한 데이터 생성 - 또한 원본 데이터에 민감한 정보가 포함된 경우, GAN을 통해 합성 데이터를 생성하여 민감한 정보를 우회",
                "provenance": {
                    "doc_id": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:18:0001",
                    "page": 18
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "생성적 AI는 학습 데이터의 패턴을 바탕으로 새로운 텍스트나 이미지를 창조하는 기술로, 2014년 이안 굿펠로우의 GAN이 대표적 핵심 기술이라 할 수 있다. 이는 콘텐츠 생성뿐만 아니라 데이터 증강과 민감 정보 대체 등 다양한 분야에서 활용되고 있다.",
        "long_answer": {
            "question": "인공지능 모델 활용에 대한 장점을 설명해 보라.",
            "answer": "인공지능 모델은 부족한 데이터셋을 인위적으로 생성하는 데이터 증강 분야에 활용할 수 있다. 이는 데이터의 클래스의 불균형으로 인해 데이터의 추가 확보가 필요한 상황일 때 주로 많이 사용되는 것이다. 또한 원본 데이터에 민감 정보가 포함된 경우, 합성 데이터를 생성하여 민감 정보를 우회할 수 있다.",
            "rubric": [
                "데이터 증강; GAN; 민감 정보 우회"
            ]
        },
        "short_answer": {
            "question": "실제 데이터와 유사하게 새로운 것을 만들어내는 생성자와 만들어진 것을 평가하는 판별자가 끊임없이 서로 대립하여 성능을 개선해나가는 방식을 무엇이라 하는가?",
            "answer": "생성적 적대 신경망(GAN)",
            "topic": [
                "생성적 적대 신경망(GAN)의 개념"
            ]
        },
        "multiple_choice": {
            "question": "다음은 생성적 AI에 대한 전반적인 설명이다. 설명 중에서 가장 정확한 것은?",
            "choices": [
                "a) 인공지능은 입력된 학습데이터의 패턴을 읽어 데이터를 분석하는 쪽에 더욱더 특화되었다.",
                "b) 생성적 적대 신경망은 데이터 간의 상호보완성을 강조하는 방식이다.",
                "c) 생성적 AI는 이미지 데이터보다는 텍스트 데이터를 생성하는 데에 더 유리하다.",
                "d) 인공지능 모델의 활용으로 데이터의 불균형 문제를 해결할 수 있게 되었다."
            ],
            "answer": "d",
            "topic": [
                "생성적 AI의 특징"
            ]
        },
        "true_false": {
            "question": "생성적 AI의 활용은 민감 정보에 대해서는 우회하지 못하여 여러가지 사회적 문제점을 야기하고 있다.",
            "answer": "FALSE",
            "topic": [
                "생석적 AI의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:19:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": " 전이학습(Transfer learning) “누구나 딥러닝을 할 수 있는 환경 확산”  o 전이학습(Transfer learning)은 기존에 학습된 모델의 신경망 일부 를 재학습 하여 원하는 Task에 맞는 모델을 재생성하는 방법 - 원하는 Task에 대한 데이터가 부족하거나, 컴퓨팅 자원의 효 율적 활용을 위해 기존 모델을 재활용하여 학습 - 기업에서 인공지능 모델 개발 시 데이터 부족, 컴퓨팅 자원 부족 등의 한계를 극복할 수 있도록 지원하는 응용 기술(Gartner) o 최근 트렌드는 글로벌 테크 기업들이 컴퓨팅 성능을 바탕으로 성능 좋은 모델을 공개하면, 그 모델을 미세 조정하여 사용 ※ 구글-Big transfer(컴퓨터 비전), BERT(언어 모델), 오픈AI-GPT 모델 - 사업 초기 단계, 마이크로서비스 개발 시 경제성‧효율성 측면을 고려하여, 중소‧스타트업들은 기존 모델을 전이학습하여 개발 ※ 전이 학습을 통해 파일럿이 검증되고, 타당성 검증 후 본 서비스 개발 - GPT-3는 API를 통해 수많은 인공지능 서비스를 개발할 수 있도록 지원하는 등 인공지능 모델에서 플랫폼의 역할로 진화 중",
                "provenance": {
                    "doc_id": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:19:0001",
                    "page": 19
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "전이학습은 기존에 학습된 모델을 재활용해 새로운 과제에 맞게 미세 조정함으로써 데이터나 자원이 부족한 환경에서도 효율적인 인공지능 개발을 가능하게 하는 기술이다. 최근에는 대형 기술 기업의 공개 모델을 기반으로 중소기업이나 스타트업이 전이학습을 활용해 경제적이고 신속한 AI 서비스를 구축하는 추세이다.",
        "long_answer": {
            "question": "전이학습의 개념과 특징에 대해서 기술하여라.",
            "answer": "전이학습은 기존에 학습된 모델의 신경망 일부를 재학습하여 원하는 태스크에 맞는 모델을 재생성하는 방식이다. 원하는 태스크에 데이터가 부족하거나 컴퓨팅 자원의 효율적 활용을 위해 기존의 언어모델을 재활용하여 학습하는 것이 특징이다. 특히 기업에서 인공지능 모델을 개발 할 때, 데이터 부족 현상을 해결할 수 있는 응용 기술로 각광받고 있다.",
            "rubric": [
                "전이학습; 언어모델의 재활용; 데이터 부족 현상 해결"
            ]
        },
        "short_answer": {
            "question": "특정한 태스크를 수행할 때, 데이터가 부족할 경우 활용할 수 있는 학습 방법은 무엇인가?",
            "answer": "전이학습",
            "topic": [
                "전이학습의 개념"
            ]
        },
        "multiple_choice": {
            "question": "전이학습에 대한 개념과 특징에 대한 설명으로 바르지 않은 것을 찾아라.",
            "choices": [
                "a) 전이학습은 기존에 학습된 모델의 신경망 일부를 재학습하는 방식이다.",
                "b) 전이학습으로 데이터 부족 현상을 해결할 수 있어 비용면에서 절약되었다.",
                "c) 전이학습의 등장으로 성능 좋은 모델을 가지고 미세조정하여 사용할 수 있게 되었다.",
                "d) 데이터가 오염되어 있을 경우, 전이학습으로 인해 다른 데이터도 오염될 가능성이 있다."
            ],
            "answer": "d",
            "topic": [
                "전이학습의 개념과 특징"
            ]
        },
        "true_false": {
            "question": "전이학습은 사업 초기 단계에 있는 중소기업이나 스타트업에 많이 활용하고 있는 학습방식이다.",
            "answer": "TRUE",
            "topic": [
                "전이학습의 활용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:21:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "AutoML “AI도 AI가 만들어 낸다” o 머신러닝 개발 과정에서 소모적이고 반복되는 작업을 자동화하는 프로세스인 AutoML(Automated machine learning)의 지속적 부상 - 현재 인공지능 개발을 위해서는 지속적으로 발생하는 데이터 관리, 모델 학습 및 관리 등 많은 자원과 시간이 필요 - AutoML은 노동집약적 과정인 머신러닝 모델 개발 작업의 상당 부분을 자동화하며 모델 개발자의 개입을 최소화 ※ ML 표준 작업 과정 : 데이터 수집→점검 및 탐색→전처리→모델링 및 훈련→평가→배포 o AutoML의 최적의 알고리즘 선정 등을 통해 모델의 성능 향 상을 도모할 수 있고, 효율적으로 머신러닝 모델 구축 가능 - AutoML은 모델의 성능 최적화 관점에서 데이터의 특징 추출, 최적의 알고리즘 아키텍처 구성, 초매개변수 설정 등으로 구성 - AutoML의 수행 영역은 숙련된 데이터 과학자가 수행하는 영역 이므로 향후 데이터 과학 분야 인재 부족에 대한 대안으로 언급",
                "provenance": {
                    "doc_id": "[IF_2021-1]_주목받는_인공지능_9대_핵심_기술_분석_및_주요_시사점.pdf:21:0001",
                    "page": 21
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "AutoML은 머신러닝 개발 과정의 반복적이고 복잡한 작업을 자동화해 모델 성능을 최적화하고 개발 효율을 높이는 기술이다. 데이터 관리부터 모델 선정과 훈련까지 최소한의 인력이 개입되므로 숙련된 데이터 과학자 부족 문제의 대안점으로 주목받고 있다.",
        "long_answer": {
            "question": "AutoML이 가지고 있는 장점과 이러한 장점을 극대화할 수 있는 방법론에 대해 설명하라.",
            "answer": "AutoML은 최적의 알고리즘을 선정하여 모델의 성능 향상을 도모할 수 있고 효율적으로 머신모델 구축이 가능하다. AutoML이 최적의 알고리즘을 선정하는 방법에는 데이터에서 특징을 추출하여 이에 맞는 최적의 알고리즘 아키텍처를 구성한다. 또한 초매개변수 설정 등으로 구성되어 있어 여러 면에서 각광받고 있는 머신러닝의 일종이다.",
            "rubric": [
                "AutoML; 높은 효율성; 최적의 알고리즘 아키텍쳐; 초매개변수"
            ]
        },
        "short_answer": {
            "question": "ML의 표준 작업 과정을 순서대로 나열하라.",
            "answer": "데이터 수집, 점검 및 탐색, 전처리, 모델링 및 훈련, 평가, 배포",
            "topic": [
                "ML의 표준 작업 과정"
            ]
        },
        "multiple_choice": {
            "question": "아래의 보기 중 AutoML과 가장 밀접한 설명은 무엇인가?",
            "choices": [
                "a) AutoML은 노동집약적 과정인 머신러닝 모델 개발 작업을 그대로 활용하였다.",
                "b) AutoML에서 최적의 알고리즘 선정은 연구자의 수동적인 데이터 라벨링 영역이 필수적이다.",
                "c) 인공지능 개발에 있어 지속적으로 발생하는 데이터 관리, 모델 학습 및 관리에 대한 자원과 시간 감축에 큰 영향을 미친다.",
                "d) AutoML의 수행으로 인해 신인 데이터 과학자의 역할이 사라지게 되었다."
            ],
            "answer": "c",
            "topic": [
                "AutoML의 특징"
            ]
        },
        "true_false": {
            "question": "AutoML이 등장하였으나 여전히 소모적이고 반복적인 작업에 있어 자동화는 이루어지지 못했다.",
            "answer": "FALSE",
            "topic": [
                "AutoML의 등장 배경"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:21:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "- 지도 학습에 적합한 데이터 Ÿ 충분한 양의 정답(Label) 데이터 Ÿ 특정한 분포나 특징에 편향되지 않고, 다양한 조건과 환경에서 수집된 다양한 데이터 Ÿ 노이즈가 적고, 정확한 정답(Label) 데이터",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:21:mh: 00001",
                    "page": 21
                }
            },
            {
                "context_id": "2",
                "text": "- 비지도 학습용 데이터 특성 Ÿ 군집화(Clustering) 또는 차원 축소(Dimensionality Reduction)와 같은 기법을 적용할 수 있게 그룹화할 수 있는 구조적 특징이 존재하는 데이터 Ÿ 패턴을 추출하고 군집을 형성하기 위한 충분한 양의 데이터 Ÿ 특정한 분포나 특징에 편향되지 않고, 다양한 조건과 환경에서 수집된 다양한 데이터 Ÿ 노이즈가 최소화된 데이터 - 강화 학습용 데이터 특성 Ÿ 강화 학습용 데이터는 상태(State) - 행동(Action) - 보상(Reward)으로 구성 Ÿ 데이터는 미리 주어진 데이터셋이 아니라, 에이전트와 환경 간 상호작용을 통해 축적됨 Ÿ 현재 상태(State)와 행동(Action)이 다음 상태(State)와 보상(Reward)에 영향을 미치는 시계열적 데이터 구조 Ÿ 독립적이지 않고, 과거 경험이 학습에 중요한 역할을 함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:21:mh: 00001",
                    "page": 22
                }
            }
        ],
        "summarization": "지도 학습은 정확하고 다양한 레벨 데이터가 필요하며, 비지도학습은 구조적 패턴이 존재하고 노이즈가 적은 대규모 데이터에 적합하다. 강화학습은 에이전트와 환경의 상호작용을 통해 시계열적으로 축적된 상태, 행동, 보상 데이터로 학습이 이루어진다.",
        "long_answer": {
            "question": "강화 학습용 데이터의 특성에 대해서 서술하라.",
            "answer": "강화 학습용 데이터는 상태, 행동, 보상으로 구성된다. 즉, 현재 상태와 행동이 다음 상태와 보상에 영향을 미치는 시계열적 데이터 구조 데이터가 적합하다고 할 수 있다. 또한 데이터는 이미 주어진 데이텟이 아니며, 에이전트와 환경 간 상호작용으로 축적되는 것이다.",
            "rubric": [
                "강화 학습용 데이터; 상태, 행동, 보상; 시계열적 데이터 구조; 에이전트와 환경 간의 상호작용"
            ]
        },
        "short_answer": {
            "question": "군집화 또는 차원 축소와 같은 기법을 적용할 수 있는 학습 데이터를 활용하는 학습 방식을 무엇이라 하는가?",
            "answer": "비지도학습",
            "topic": [
                "비지도학습의 학습용 데이터 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음은 학습용 데이터의 특징에 대한 설명이다. 설명 중 바르지 않는 것을 골라라.",
            "choices": [
                "a) 비지도 학습은 패턴을 추출하고 군집화를 형성하기 위한 데이터에 적합한 학습 방식이다.",
                "b) 지도학습의 학습용 데이터는 노이즈 있거나 정확한 정답 데이터가 아니어도 학습에 유리하다.",
                "c) 지도학습은 특정한 분포나 특징에 편향되어서는 안 된다.",
                "d) 강화학습의 학습용 데이터는 독립적이지 않고 과거 경험이 학습에 중요한 역할을 한다."
            ],
            "answer": "b",
            "topic": [
                "학습용 데이터의 특징"
            ]
        },
        "true_false": {
            "question": "지도 학습에 적합한 데이터는 최소한의 조건과 특정 분포를 가진 데이터여야 하는 것이 특징이다.",
            "answer": "FALSE",
            "topic": [
                "지도 학습의 학습용 데이터 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:13:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "1.1 생성형AI 1.1.1 생성형AI의 개념 l 텍스트나 이미지, 음성 등을 생성하는 데 특화된 인공지능으로 ‘생성(Generative)’이란 AI에게 일일이 지시하거나 학습시키지 않아도, AI가 스스로 이용자가 요구하는 바를 만들어 내는 범용 AI를 의미 - 새로운 정보, 콘텐츠 또는 데이터를 생성하고 구축하는 능력을 가지고 있으며, 과거의 데이터를 기반으로 예측, 창조, 모델링 등을 통해 새로운 결과를 도출하거나 문제를 해결",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:13:mh: 00001",
                    "page": 13
                }
            },
            {
                "context_id": "2",
                "text": "1.1.2 생성형AI 개발 l 생성형AI 개발은 기반모델(Foundation Model)이라고 하는 생성형AI 모델을 구축하고 파인 튜닝(Fine-Tuning) 등의 과정을 통해 여러 업무와 서비스에 적용을 가능케 함 - 기반 모델(Foundation Model)은 대규모 데이터를 자기지도학습(Self-Supervised Learning) 방식으로 사전 학습하여, 다양한 환경에 적용될 수 있도록 함 - 기반 모델(Foundation Model)의 확장성으로 인해 생성형AI는 여러 산업과 사회 분야에서 AI의 영향력을 확장하고 변화시키는 잠재력을 지님",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:13:mh: 00001",
                    "page": 14
                }
            }
        ],
        "summarization": "생성형 AI는 텍스트나 이미지, 음성 등 다양한 형태의 콘텐츠를 스스로 생성하는 범용 인공지능으로 예측, 창조, 모델링을 통한 새로운 결과를 도출한다. 이러한 생성형 AI는 대규모 데이터를 자기지도학습으로 학습한 기반 모델을 중심으로 개발되어, 다양한 산업과 사회 분야로 그 영향력이 점차 확대되고 있다.",
        "long_answer": {
            "question": "생성형 AI의 개념과 그 개발 과정을 간결하게 기술하여라.",
            "answer": "텍스트나 이미지, 음성 등을 생성하는 특화된 인공지능을 생성형 AI라고 한다. 이 인공지능은 일일이 지시하거나 학습시키지 않아도 사용자가 요구하는 바를 만들어내는 범용 AI라 할 수 있다. 생성형 AI는 기반모델이라고 할 수 있는 생셩형 AI 모델을 구축하고 파인튜닝을 통해 여러 업무와 서비스에 적용할 수 있게끔 만들어졌다.",
            "rubric": [
                "생성형 AI; 범용 모델; 비지도학습; 파인튜닝; 기반모델"
            ]
        },
        "short_answer": {
            "question": "대규모 데이터를 자기지도학습 방식으로 사전 학습하여 다양한 환경에 적용할 수 있도록 하는 모델을 무엇이라 하는가?",
            "answer": "기반 모델(Foundation Model)",
            "topic": [
                "기반 모델의 개념"
            ]
        },
        "multiple_choice": {
            "question": "생성형 AI의 특징과 그 개발 과정에 대해 나열한 것이다. 이 중에서 옳은 설명을 찾아라.",
            "choices": [
                "a) 생성형 AI는 새로운 정보, 콘텐츠 또는 데이터를 생성할 수 있으며 과거의 데이터를 통해 새로운 결과를 도출할 수 있는 모델이다.",
                "b) 생성형 AI는 사용자가 스스로 요구한 바를 지시하거나 학습시켜야 한다.",
                "c) 생성형 AI는 범용 AI이므로 파인튜닝없이 사용이 가능하다.",
                "d) 기반 모델은 대규모 데이터를 지도학습 방식으로 사전 학습하였다."
            ],
            "answer": "a",
            "topic": [
                "생성형 AI의 특징과 개발 과정"
            ]
        },
        "true_false": {
            "question": "생성형 AI를 기반 모델로 구축하여 파인 튜닝을 통해 여러 분야에 활용할 수 있는 가능성을 가지고 있다.",
            "answer": "TRUE",
            "topic": [
                "생성형 AI와 기반 모델의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1.1.3 생성형AI의 활용 분야 l 생성형AI는 텍스트, 이미지, 음악, 영상 등 다양한 미디어 형식에서 고유의 생성 능력을 발휘하여, 인공지능의 새로운 패러다임을 제시하고 있으며 기술의 발전과 응용 확대를 통해 앞으로 더욱 다양한 산업 분야로의 확장을 기대 Ÿ 텍스트 생성: GPT-4를 비롯한 거대 언어모델(LLM)은 인간 수준의 텍스트 생성 능력을 보여주며, 창작, 번역, 코딩 등 다양한 분야에서 활용되고 있음 Ÿ 이미지 생성: Stable Diffusion, DALL·E 2 등은 텍스트 설명만으로도 고품질의 이미지를 생성하며, 디자인, 예술 분야에서 새로운 가능성 제시 Ÿ 음악 생성: MusicLM과 같은 모델은 텍스트 설명이나 멜로디를 기반으로 새로운 음악을 작곡하며, 음악 산업에 변화가 진행되고 있음 Ÿ 영상 생성: VideoGPT와 같은 모델은 텍스트 설명이나 이미지 시퀀스를 기반으로 영상을 생성하며, 영화, 게임 등 다양한 분야에서 활용될 가능성 확대",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "생성형 AI는 텍스트, 이미지, 음악, 영상 등 다양한 매체에서 창의적인 결과물을 만들어내며, 인공지능의 활용 범위를 혁신적으로 확장하고 있다. GPT-4, DALL·E 2, MusicLM, VideoGPT 등은 각각 언어, 디자인, 음악, 영상 산업에서 새로운 가능성을 제시하고 있다.",
        "long_answer": {
            "question": "생성형AI의 활용 분야 중 텍스트와 이미지 생성에서 어떻게 활용되고 있는지 구체적인 모델명을 예로 들어 설명하라.",
            "answer": "텍스트 영역에서는 GPT-4를 비롯한 거대 언어모델로 발전하였으며 인간 수준의 텍스트 생성 능력은 물론, 창작, 번역, 코딩 등 다양한 분야에서 활용되고 있다. 반면에 이미지 생성에서는 Stable Diffusion, DALL·E 2과 같은 모델이 개발 되었다. 이런 모델들은 텍스트 설명만으로도 고품질의 이미지를 생성하고 디지인이나 예술 분야에서 새로운 가능성을 제시하고 있다.",
            "rubric": [
                "텍스트 생성; 이미지 생성; GPT-4; Stable Diffusion, DALL·E 2"
            ]
        },
        "short_answer": {
            "question": "생성형AI가 활용되고 있는 분야를 2가지만 나열하여라.",
            "answer": "이미지 생성, 영상 생성",
            "topic": [
                "생성형AI의 활용 분야"
            ]
        },
        "multiple_choice": {
            "question": "다음은 생성형AI가 활용되고 있는 분야에 대한 설명이다. 설명 중 바른 것은?",
            "choices": [
                "a) 영상 생성은 VideoGPT와 같은 모델을 사용하여 텍스트 설명이나 이미지 시퀀스로 영상을 생성한다.",
                "b) GPT-4를 활용하여 텍스트 설명만으로도 고품질의 이미지를 생성할 수 있다.",
                "c) DALL·E 2는 특정 멜로디만 입력한다면 풍부한 음악을 작곡할 수 있는 최신 모델이라 할 수 있다.",
                "d) Stable Diffusion를 통해 이미지를 생성하기 위해서는 원하는 이미지를 사용자가 학습시켜야 한다."
            ],
            "answer": "a",
            "topic": [
                "생성형AI의 활용 분야와 모델명"
            ]
        },
        "true_false": {
            "question": "생성형AI는 텍스트뿐만 아니라, 이미지, 음악, 영상 생성 등 다양한 분야에서 생성 능력을 발휘하여 그 활용성이 점점 커지고 있다.",
            "answer": "TRUE",
            "topic": [
                "생성형AI의 활용 분야 확대"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:15:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1.2 생성형AI의 주요 모델 1.2.1 거대 언어 모델(LLM) l 거대 언어 모델(LLM, Large Language Model)은 자연어처리 분야에서 사용되는 모델로, 대규모의 텍스트 데이터를 학습하여 더 높은 성능의 언어 이해와 생성 능력을 갖춘 AI모델을 제공 - 많은 양의 데이터를 기반으로 학습되며, 다양한 주제와 문맥에서 자연스러운 언어 생성을 가능하게 하고, 이는 대화 시스템, 기계 번역, 요약, 질의응답 등 다양한 자연어 처리 작업에 유용하게 사용 매개변수의 규모 Ÿ 다수의 매개변수를 가지고 있어 복잡한 언어 패턴을 학습하고 더욱 정교한 작업을 수행할 수 있음 방대한 양의 데이터 학습 Ÿ 웹 페이지, 책, 논문 등 인터넷상의 방대한 양의 텍스트 데이터를 학습하여 폭넓은 지식을 습득함 다양한 언어 지원 Ÿ 다양한 언어의 텍스트 데이터를 학습하여 번역, 요약 등 다국어 지원이 가능 문맥 이해능력 Ÿ 문맥을 파악하여 상황에 맞는 응답을 생성 가능 창의적인 텍스트 생성 Ÿ 새로운 아이디어를 제시하거나 창의적인 글쓰기 생성 가능 지속적인 학습 Ÿ 새로운 데이터를 지속적으로 학습하여 성능을 향상시킴",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:15:0001",
                    "page": 15
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "거대 언어 모델은 방대한 텍스트 데이터를 학습하여 문맥을 이해하고 언어 생성 능력까지 갖춘 AI이다. 대규모 매개변수와 지속적인 학습을 통해 대화, 번역, 요약, 질의 응답, 창의적 텍스트 생성 등을 수행할 수 있다.",
        "long_answer": {
            "question": "거대 언어 모델의 특성에 대해서 설명하라.",
            "answer": "거대 언어 모델은 다수의 매개변수를 가지고 있어 복잡한 언어 패턴을 학습하고 더욱 정교한 작업을 수행할 수 있다. 또한 학습한 데이터 양이 방대하고 지속적으로 학습하기 때문에 성능을 향상시킬 수 있다. 또한 다양한 언어의 텍스트 데이터를 학습으로 번역, 요약 등이 다국어 지원이 가능하고, 창의적인 텍스트를 생성할 수 있다.",
            "rubric": [
                "거대 언어 모델; 다수의 매개변수; 대규모 데이터 학습; 지속적 학습; 다국어 언어 지원; 번역, 요약, 창의적 텍스트 생성"
            ]
        },
        "short_answer": {
            "question": "자연어 처리분야에 사용되는 모델 중 하나로, 대규모의 텍스트 데이터를 학습하여 더 높은 성능의 언어 이해와 생성 능력을 갖춘 AI 모델을 무엇이라 하는가?",
            "answer": "거대 언어 모델(LLM)",
            "topic": [
                "거대 언어 모델의 개념"
            ]
        },
        "multiple_choice": {
            "question": "아래는 거대 언어 모델의 개념과 특징을 설명한 것이다. 기술한 내용 중 올바르게 작성한 것이 아닌 것은?",
            "choices": [
                "a) 거대 언어 모델은 자연어 처리 분야에 사용되는 모델이다.",
                "b) 소규모의 데이터를 기반으로 학습한 모델로, 대화 시스템, 기계번역, 요약, 질의 응답 등 다양한 자연어 처리 작업에 유용하게 사용된다.",
                "c) 거대 언어 모델은 지속적인 학습을 통해 성능을 향상시킨다.",
                "d) 매개변수의 규모가 크기 때문에 문맥을 파악하여 상황에 맞는 응답을 제시하는 데에 탁월하다."
            ],
            "answer": "b",
            "topic": [
                "거대 언어 모델의 개념과 특징"
            ]
        },
        "true_false": {
            "question": "거대 언어 모델은 특정 분야에서 대규모의 데이터를 학습시킨 AI 모델이다.",
            "answer": "FALSE",
            "topic": [
                "거대 언어 모델의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:15:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1.2.2 거대 멀티모달 모델(LMM) l 거대 멀티모달 모델(LMM, Large Multimodal Model)은 텍스트, 이미지, 음성 등 두 가지 이상의 유형의 데이터를 이해하고 연관 지어 처리할 수 있는 대규모 인공지능 모델 - LMM은 멀티모달 데이터를 사전학습하고, 명령어 조정(Instruction Tuning)이나 맥락 내 학습(In-Context Learning) 등의 기법을 통해 활용 - 주요 예시로는 시각-언어 모델(VLM, Vision Language Model)이 있으며, 이를 통해 시각 질의응답, 이미지 캡셔닝, 비디오 요약, 텍스트 기반 이미지 생성 등의 작업을 수행할 수 있음 범용성 Ÿ 다양한 분야에 적용될 수 있는 범용적인 모델로, 다양한 분야에 활용 가능 다양한 모달리티 통합 Ÿ 텍스트, 이미지, 음성뿐만 아니라, 비디오, 센서 데이터 등 다양한 형태의 데이터를 통합하여 학습 복잡한 패턴 학습 Ÿ 단순한 패턴뿐만 아니라, 데이터 간의 복잡한 상호작용과 의미를 학습하여 더욱 정확하고 심층적인 이해 가능 높은 표현력 Ÿ 다양한 모달리티의 정보를 효과적으로 결합하여 더욱 풍부하고 정확한 표현 생성 새로운 작업 학습 능력 Ÿ 기존에 학습하지 않은 새로운 작업에 대해서도 적응력이 뛰어나며, 적은 양의 데이터로 빠르게 학습 가능",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:15:0001",
                    "page": 15
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "거대 멀티모델 모델(LMM)은 텍스트, 이미지, 음성 등 다양한 형태의 데이터를 통합적으로 이해하고 처리하는 대규모 인공지능으로, 시각 질의응답, 이미지 캡셔닝, 비디오 요약 등 복합 작업을 수행한다. 이 모델은 멀티모달 학습과 명령어 조정 등을 통해 높은 표현력과 범용성을 지니며 새로운 작업에도 빠르게 적용할 수 있다.",
        "long_answer": {
            "question": "거대 멀티모달 모델의 정의와 활용 방법에 대해 서술하라.",
            "answer": "거대 멀티모달 모델은 텍스트, 이미지, 음성 등 두 가지 이상의 유형의 데이터를 이해하고 연관 지어 처리할 수 있는 대규모 인공지능 모델이다. 거대 멀티모달 모델은 텍스트데이터 뿐만 아니라 멀티모달 데이터를 사전학습한다. 더 나아가 명령어 조정이나 맥락 내 학습 등의 기법을 활용하여 사용이 가능하다.",
            "rubric": [
                "거대 멀티모달 모델; 멀티모달 데이터; 사전학습; 명령어 조정; 맥락 내 학습"
            ]
        },
        "short_answer": {
            "question": "시각 질의응답, 이미지 캡셔닝, 비디오 요약, 텍스트 기반 이미지 생성이 가능한 모델을 무엇이라 하는가?",
            "answer": "시각-언어모델(VLM, Vision Language Model)",
            "topic": [
                "시각-언어모델의 정의"
            ]
        },
        "multiple_choice": {
            "question": "아래 보기는 거대 멀티모달 모델에 대한 특징을 기술한 것이다. 기술한 내용 중 가장 적합한 내용을 찾아라.",
            "choices": [
                "a) 거대 멀티모달 모델은 대량의 텍스트 데이터를 사전학습하여 영상, 이미지 생성 등이 가능한 모델이다.",
                "b) 이미지, 영상 제작에만 사용할 수 있는 모델로서 LLM보다는 범용성이 적다고 할 수 있다.",
                "c) 기존에 학습하지 않은 새로운 작업에도 적응력이 뛰어나 적은 데이터로도 빠르게 학습이 가능하다.",
                "d) 이미지를 생성할 때, 특정한 이미지를 입력시켜야 하는 단점을 지니고 있다."
            ],
            "answer": "c",
            "topic": [
                "거대 멀티모달 모델의 특징"
            ]
        },
        "true_false": {
            "question": "거대 멀티모달 모델은 텍스트, 이미지, 음성뿐만 아니라 비디오, 센서 데이터 등 다양한 형태의 데이터를 통합하여 학습한 모델이다.",
            "answer": "TRUE",
            "topic": [
                "거대 멀티모달 모델의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:16:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1.2.3 소형 거대 언어 모델(sLLM) l 소형 거대 언어 모델(sLLM, small Large Language Model)은 거대 언어모델의 파라미터 수를 줄여, 모델 경량화를 통해 경제성과 실용성을 강화한 AI모델 - 출현 배경: LLM의 예시로 ChatGPT는 하드웨어 관련 비용만 하루 운영비용이 약 70만 달러 정도 발생하는데, 이런 비용 문제를 해결하기 위해 sLLM 모델이 등장 - 소형 모델이라도 미세조정 및 고품질 데이터를 이용한 학습이 중요하며, 많은 기업들이 최적화된 맞춤형 경량 모델을 구축하고 있음 경량화 및 효율성 Ÿ sLLM은 파라미터 수와 모델 크기를 크게 줄여, 메모리 사용량과 저장 공간 요구사항을 낮춤 Ÿ 연산량이 줄어들어, CPU나 GPU와 같은 하드웨어 자원 소모가 적고 모바일 기기나 임베디드 시스템 등 자원이 제한된 환경에서 활용하기에 적합  빠른 학습 및 추론 속도 Ÿ 경량화된 구조 덕분에 학습 및 추론 속도가 향상되어, 실시간 응답이 필요한 애플리케이션(예: 챗봇, 실시간 번역)에서 활용  응용 범위의 다양성 Ÿ 특정 도메인이나 업무에 최적화된 sLLM을 개발함으로써, 특화된 언어 처리 작업에서 높은 효율성과 성능을 달성 가능 Ÿ 소형 모델은 클라우드 서버에 의존하지 않고도 로컬 환경에서 실행할 수 있어, 사용자 데이터의 프라이버시 보호 및 네트워크 지연 문제를 최소화함 실시간 및 저전력 운영 Ÿ 빠른 추론 속도와 낮은 연산 요구 덕분에, 전력 소모가 적음  개발 및 배포 용이성 Ÿ 모델 크기가 작아 업데이트와 유지보수가 비교적 간편하며, 다양한 플랫폼에 이식 및 적용 용이 Ÿ 경량화된 모델은 클라우드 비용 절감에도 기여하여, 경제적인 AI 솔루션 구축이 가능 성능과 정확성의 균형 Ÿ 최신 압축 및 최적화 기술을 통해 거대 모델과 유사한 언어 이해 및 생성 능력을 유지할 수 있도록 설계",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:16:0001",
                    "page": 16
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "소형 거대 언어 모델(sLLM)은 거대 언어 모델의 파라미터를 줄여 효율성을 높인 모델로, 비용이 적게 들고 저전력 환경에서도 빠른 추론과 실시간 응답이 가능하다. 또한 도메인 특화 학습이 가능하고 최적화된 기술을 통해 선응과 정확성의 균형을 유지할 수 있어 다양한 플랫폼에서 경제적으로 유연하게 활용될 수 있다.",
        "long_answer": {
            "question": "소형 거대 언어 모델이 출현하게 된 배경에 대해서 기술하라.",
            "answer": "거대 언어 모델은 하드웨어 관련 비용만 하여 하루 운영 비용이 약 70만 달러 정도 발생 하는 등, 비용적인 부분에서 큰 손실이 있었다. 또한 소형 모델이라도 미세조정 및 고품질의 데이터를 이용하는 학습이 중요하다는 점이 대두되었다. 이러한 배경으로 인해 거대 언어모델의 파라미터 수를 줄여 등장한 모델이 소형 거대 모델이라 할 수 있다.",
            "rubric": [
                "소형 거대 언어 모델; 거대 언어모델의 단점; 고비용의 문제; 미세조정 및 고품질의 데이터 요구"
            ]
        },
        "short_answer": {
            "question": "거대 언어 모델의 파라미터 수를 줄여 모델 경량화를 통해 경제성과 실용성을 강화한 AI 모델을 무엇이라 하는가?",
            "answer": "소형 거대 언어 모델(sLLM)",
            "topic": [
                "소형 거대 언어 모델의 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음의 보기 중 소형 거대 언어모델의 특징과 가장 거리가 먼 것은?",
            "choices": [
                "a) 특정 도메인이나 업무에 최적화되었기 때문에 높은 효율성과 성능 달성이 가능해졌다.",
                "b) 경량회된 구조로 인해 학습 및 추론 속도가 향상되었으며 애플리케이션 등 실시간 응답이 필요한 영역에서 활발히 사용하게 되었다.",
                "c) 클라우드 서버에 의존하지 않고도 로컬 환경에서 실행할 수 있다.",
                "d) 파라미터의 수와 모델의 크기를 줄였으나 필요한 데이터의 양은 거대 언어 모델과 동일하다."
            ],
            "answer": "d",
            "topic": [
                "소형 거대 언어 모델의 특징"
            ]
        },
        "true_false": {
            "question": "소형 거대 언어 모델은 모델 크기가 작은 한편, 업데이트와 유지보수에는 비교적 복잡하다.",
            "answer": "FALSE",
            "topic": [
                "소형 거대 언어 모델의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:17:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1.2.5 버티컬AI(Vertical AI) l 버티컬(Vertical, 수직적)AI란, 특정 산업 및 분야에 맞춰진 특정 데이터를 활용하는 것에 중점을 두고 도메인의 심층적인 지식을 학습하는 기술 - 기존의 LLM은 다양한 데이터를 학습하여 범용성을 제공했지만, 버티컬AI는 특정 산업의 심층 지식에 맞추어 학습함 - LLM은 범용성에 비해 인간의 역량을 뛰어넘는 깊이가 부족한 상황이며, 이런 깊이를 채우는 것이 바로 버티컬AI로 기존 범용 LLM과 달리, 특정 산업이나 분야에 특화되고 맞춤형 솔루션으로 각 산업의 디지털 전환을 가속화하고 있음 - 한국지능정보사회진흥원(NIA)는 버티컬AI가 각 산업의 특화된 문제를 해결하고, 기업의 경쟁력을 강화하는 핵심 기술로 자리 잡고 있다고 분석 산업 최적화 Ÿ 특정 산업 분야의 요구사항과 데이터를 기반으로 개발되기 때문에 해당 산업이나 업무 분야의 특수한 특성과 문제를 고려하여 학습되며, 그 분야에서 가장 효과적으로 작동할 수 있도록 설계됨 문제 해결과 혁신 Ÿ 해당 산업 분야에서 발생하는 문제를 해결하고 새로운 혁신을 이끌어내기 때문에 기존에는 불가능하거나 어려웠던 작업을 가능하게 하고, 새로운 비즈니스 모델과 서비스를 발굴함 다양한 산업 분야 적용 Ÿ 의료, 제조, 금융, 물류 등 다양한 산업 분야에 적용될 수 있으며, 각 분야의 고유한 요구사항과 데이터에 맞게 개발되기 때문에 효율성 향상, 비용 절감, 위험관리 등 다양한 측면에서 경쟁력을 강화할 수 있고, 각 산업 분야의 특정 문제를 해결하고 최적의 성과를 달성하는데 기여할 수 있음 전문성 및 정확성 Ÿ 해당 산업 분야의 전문성을 갖추고 있어, 특정 분야의 데이터와 규칙을 더욱 깊게 이해하고 활용할 수 있으며, 이를 바탕으로 높은 정확성과 신뢰성을 갖춘 솔루션을 제공할 수 있음",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:17:0001",
                    "page": 17
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "버티컬AI(Veritcal AI)는 특정 산업의 전문 데이터와 요구에 맞춰 학습하여 높은 정확도와 전문성을 갖춘 맞춤형 인공지능으로, 의료, 금융, 제조 등 다양한 분야의 문제해결과 혁신을 촉진한다. 이는 범용 LLM의 한계를 보완하며, 각 산업의 효율성 향상과 디지털 전환을 가속화하는 핵심 기술로 주목받고 있다.",
        "long_answer": {
            "question": "버티컬AI가 앞으로의 인공지능 발전에 주목을 받는 이유에 대해 설명하라.",
            "answer": "기존의 LLM은 범용성에 비해 인간의 역량을 뛰어넘는 깊이가 부족한 상황이다. 즉 다양한 데이터를 학습하여 범용성을 제공할 순 있지만 특정 산업의 심층 지식까지 해결하지 못한다. 그러나 버티컬AI는 LLM이 가지고 있는 단점을 극복할 수 있다. 따라서 특정 산업이나 분야에 특화되고 맞춤형 솔루션을 제공하여 각 산업의 디지털 전환을 가속화시킬 수 있다.",
            "rubric": [
                "버티컬 AI; 기존 LLM의 한계; 특회된 지식; 맞춤형 솔루션; 각 산업의 디지털 전환"
            ]
        },
        "short_answer": {
            "question": "특정 산업 및 분야에 맞춰진 특정 데이터를 활용하는 것에 중점을 두고 도메인의 심층적인 지식을 학습하는 기술을 무엇이라 하는가?",
            "answer": "버티컬AI",
            "topic": [
                "버티컬AI의 개념"
            ]
        },
        "multiple_choice": {
            "question": "다음 보기는 버티컬AI의 적용하였을 때 나타나는 현상이다. 이에 대한 현상으로 맞지 않은 것은?",
            "choices": [
                "a) 해당 산업이나 업무 분야의 특수한 특성과 문제를 고려하여 학습되어 그 분야에 효과적으로 작동할 수 있다.",
                "b) 해당 산업 분야에 특화되어 있으므로 다양한 데이터를 학습하지 못하므로 범용 거대 모델보다는 전문성이 낮다.",
                "c) 각 분야의 고유한 요구 사항과 데이터에 맞게 개발되므로 효율성이 향상되고 위험 관리에 탁월하다.",
                "d) 특정 분야에 특화되어 있는 모델이므로 기존에 불가능했던 작업이 가능해지고 새로운 비즈니스 모델과 서비스를 발굴할 수 있다."
            ],
            "answer": "b",
            "topic": [
                "버티컬AI의 장점"
            ]
        },
        "true_false": {
            "question": "버티컬AI의 등장으로 각 산업 분야의 특정 문제를 해결하고 최적의 성과를 달성하는 데 기여할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "버티컬AI의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:20:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1 K-Means Ÿ 데이터를 K개의 클러스터로 그룹화하는 비지도 학습 알고리즘으로, 데이터 포인트 간의 거리 기준으로 그룹을 형성 Ÿ 클러스터의 중심점(Centroid)을 가지고, 클러스터를 할당하거나 중심점을 업데이트하는 방식으로 작동 2 DBSCAN Ÿ DBSCAN은 보통 관측된 데이터의 범위에서 많이 벗어난 값인 이상치(노이즈)가 있는 대규모 데 이터에 적용할 수 있는 밀도 기반의 클러스터링 Ÿ 밀도 기반의 군집 알고리즘의 가장 대표적인 알고리즘이며 K-Means 알고리즘이 적용되지 못하 는 문제를 해결 가능",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:20:0001",
                    "page": 20
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "K-Means는 데이터 간 거니를 기반으로 K개의 클러스터를 형성하는 비지도 학습 알고리즘이며, 중심점을 반복적으로 갱신해 군집을 최적화한다. 반면 DBSCAN는 밀도 기반 알고리즘으로, 이상치가 포함된 대규모 데이터에서도 유효하게 작동하여 K-Means의 한계를 보완한다.",
        "long_answer": {
            "question": "비계층적 군집분석인 K-Means와 DBSCAN의 특징을 각각 서술하라.",
            "answer": "K-Means는 데이터를 K개의 클러스트로 그룹화하는 비지도학습 알고리즘으로 데이터 포인트 간의 거리 기준으로 그룹을 형성한다. 반면 DESCAN은 보통 관측된 데이터의 범위에서 많이 벗어난 값인 이상치가 있는 대규모 데이터에 적용할 수 있는 밀도 기반 클러스트링이다. K-Means가 클러스트의 중심점을 가지고 있고 이 중심점을 기반으로 업데이트를 하는 방식이라면, DBSCAN는 K-Means가 가지고 있는 단점을 극복한 클러스터링 기법이라 할 수 있다.",
            "rubric": [
                "K-Means; 중심점; 데이터 간 거리 기준; DBSCAN; 이상치"
            ]
        },
        "short_answer": {
            "question": "클러스터의 중심을 가지고 클러스터를 할당하거나 중심점을 업데이트하는 방식으로 작동하는 클러스터링 기법은 무엇인가?",
            "answer": "K-Means",
            "topic": [
                "K-Means의 작동 방식"
            ]
        },
        "multiple_choice": {
            "question": "아래는 K-Means와 DBSCAN의 정의와 작동 방식을 서술한 것이다. 이 중에서 옳은 것을 선택하라.",
            "choices": [
                "a) DBSCAN는 노이즈가 있는 대규모 데이터에 적용할 수 있는 밀도 기반 클러스터링 기법이다.",
                "b) K-Means는 밀도 기반 군집 알고리즘의 대표적인 알고리즘이다.",
                "c) DBSCAN는 데이터를 K개의 클러스터로 그룹화하는 작업이 가장 우선이다.",
                "d) K-Means는 관측된 데이터 범위를 벗어난 이상치를 감지하는 알고리즘이다."
            ],
            "answer": "a",
            "topic": [
                "K-Means와 DBSCAN의 정의와 작동 방식"
            ]
        },
        "true_false": {
            "question": "DBSCAN는 클러스터를 할당하거나 중심점을 업데이트하는 방식으로 작동한다.",
            "answer": "FALSE",
            "topic": [
                "DBSCAN의 작동 방식"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:19:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "1.3.2.2 비지도 학습모델 주요 알고리즘 l 클러스터링 - 비지도 학습에는 정답 데이터, 라벨링 데이터와 분류기준(클래스 혹은 카테고리)이 없기 때문에 클러스터링을 통해 분류작업을 수행 - 클러스터링은 데이터 내 유사한 특성을 가진 항목들을 그룹으로 묶는 작업을 의미하며, 분류 기준(클래스 또는 카테고리)이 사전에 정의되지 않은 데이터 분석에 적합",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:19:mh: 00001",
                    "page": 19
                }
            },
            {
                "context_id": "2",
                "text": "3 계층적 클러스터링 Ÿ 데이터를 계층적으로 클러스터링하는 알고리즘 Ÿ 계층적 클러스터링은 거리가 많은 데이터를 그룹으로 묶는 방법 Ÿ 데이터 포인트들을 계층적인 구조로 묶는 알고리즘으로 마치 가계도를 그리듯이, 가장 가까운 데 이터끼리 먼저 묶고, 그 묶음들을 다시 더 큰 묶음으로 합치는 방식으로 진행됨",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:19:mh: 00001",
                    "page": 21
                }
            }
        ],
        "summarization": "비지도 학습에서는 정답 라벨이 없기 때문에, 유사한 특성을 가진 데이터를 그룹화하는 클러스터링이 활용된다. 그 중 계층적 클러스터링은 가까운 데이터끼리 순차적으로 묶어 계층 구조를 형성하는 방식이라 할 수 있다.",
        "long_answer": {
            "question": "비지도 학습에서 클러스터링이 주요 알고리즘인 이유를 설명하여라.",
            "answer": "비지도학습은 지도학습과 달리 정답 데이터나, 라벨링된 데이터를 활용하지 않는다. 그러므로 데이터를 분석하기 위해서는 군집화, 즉 클러스터링을 통해 분류작업을 수행하게 된다. 클러스터링은 데이터 내에서 유사한 특성을 가지고 있는 항목들을 그룹으로 묶는 작업이며 분류 기준이 사전에 정의되어 있지 않은 것이 특징이다.",
            "rubric": [
                "클러스터링; 군집화; 분류 기준; 비지도학습 데이터의 특징"
            ]
        },
        "short_answer": {
            "question": "데이터를 계층적으로 클러스터링 하는 알고리즘을 무엇이라 하는가?",
            "answer": "계층적 클러스터링",
            "topic": [
                "계층적 클러스터링의 특징"
            ]
        },
        "multiple_choice": {
            "question": "아래 보기는 클러스터링에 대한 특징이다. 이 중에서 클러스터링의 특징과 거리가 먼 것을 찾아라.",
            "choices": [
                "a) 계층적 클러스터링은 거리가 많은 데이터를 그룹으로 묶는 방법에 많이 활용된다.",
                "b) 클러스터링은 비지도학습에 특화된 알고리즘이다.",
                "c) 클러스터링으로 데이터 내에 유사한 특성을 가진 항목을 그룹화하기 위해 사전에 분류기준을 세워야 한다.",
                "d) 계층적 클러스터링은 가장 가까운 데이터부터 시작하여 더 큰 범주로 확대하며 그룹화하는 방식이다."
            ],
            "answer": "c",
            "topic": [
                "클러스터링과 계층적 클러스터링의 특징"
            ]
        },
        "true_false": {
            "question": "계층적 클러스터링은 거리가 가장 먼 데이터부터 그룹을 묶는 것이 특징이다.",
            "answer": "FALSE",
            "topic": [
                "계층적 클러스터링의 군집화 방법"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:21:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "l 차원 축소(Dimensionality Reduction) - 고차원 데이터를 저차원 공간으로 변환하여 시각화하거나 노이즈를 제거하는 알고리즘 - 차원 축소는 특정 데이터 세트의 기능 또는 차원이 너무 많을 때 사용되는 기법으로, 데이터 입력 횟수를 관리 가능한 크기로 줄이면서 데이터 세트의 무결성을 최대한 보존함 1 PCA(Principal Component Analysis) Ÿ 데이터의 분산이 가장 큰 방향을 찾아 차원을 축소하는 알고리즘 Ÿ 차원 축소는 많은 정보 속에서 가장 중요한 요소가 뭔지를 알게 해주는 방법",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:21:mh: 00001",
                    "page": 21
                }
            },
            {
                "context_id": "2",
                "text": "2 T-SNE(T-Stochastic Neighbor Embedding)  Ÿ 고차원 데이터의 국소적인 구조를 보존하면서 저차원 공간으로 매핑하는 알고리즘 Ÿ 데이터 탐색 및 고차원 데이터 시각화를 위한 비지도 비선형 차원 감소 기술로 비선형 차원 감소는 알고리즘을 통해 직선으로 분리할 수 없는 데이터를 분리할 수 있다는 것을 의미",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:21:mh: 00001",
                    "page": 22
                }
            }
        ],
        "summarization": "차원 축소는 고차원 데이터를 저차원 공간으로 변환해 시각화하거나 노이즈 제거에 활용하는 기접으로, 데이터의 핵심 구조를 유지하며 복잡도를 낮춘다. 주요 알고리즘으로는 분산이 큰 방향을 찾아 차원을 축소하는 PCA와 고차원 데이터의 국소 구조를 보존하며 시각화하는 T-SNE가 있다.",
        "long_answer": {
            "question": "차원 축소에 해당하는 알고리즘을 예로 들어 그 특징을 설명하라.",
            "answer": "차원 축소는 고차원의 데이터를 저차원의 공간으로 변환하여 시각화를 하거나 노이즈를 제거하는 알고리즘이다. 차원을 축소하는 알고리즘의 종류에는 PCA와 T-SNE가 있다. PCA는 데이터의 분산이 가장 큰 방향을 찾아 차원을 축소하는 알고리즘이며 T-SNE는 고차원 데이터의 국소적인 구조를 보존하며 저차원 공간으로 매핑하는 알고리즘이다.",
            "rubric": [
                "차원 축소; 고차원 데이터; 저차원 공간; PCA; T-SNE; 시각화; 노이즈 제거"
            ]
        },
        "short_answer": {
            "question": "데이터의 분산이 가장 큰 방향을 찾아 차원 축소를 하는 알고리즘은?",
            "answer": "PCA",
            "topic": [
                "PCA의 개념"
            ]
        },
        "multiple_choice": {
            "question": "다음은 차원 축소와 주요 알고리즘에 대한 내용이다. 내용 중 가장 적합한 것을 골라라.",
            "choices": [
                "a) 차원 축소는 특정 데이터 세트의 기능 또는 차원이 너무 적을 때 사용하는 기법이다.",
                "b) 차원 축소의 가장 큰 장점은 데이터 입력 횟수를 무제한으로 늘리는 것이다.",
                "c) T-SEN은 많은 정보 속에서 가장 중요한 요소가 무엇인지 알게 해주는 방법이다.",
                "d) PCA는 데이터가 어느 쪽에 많이 분산되어 있는지를 찾아 차원을 축소하는 알고리즘이다."
            ],
            "answer": "d",
            "topic": [
                "차원 축소와 주요 알고리즘의 특징"
            ]
        },
        "true_false": {
            "question": "데이터 탐색 및 고차원 데이터 시각화를 위해 비지도 비선형 차원 감소 기술을 의미하는 것이 T-SNE이다.",
            "answer": "TRUE",
            "topic": [
                "T-SNE의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:22:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "3 연관 규칙 학습(Association Rule Learning) Ÿ 연관 규칙은 특정 데이터 세트에서 변수 간의 관계를 발견하기 위한 규칙기반 학습 방법 Ÿ 데이터 항목 간의 관계를 규칙 형태로 추출하는 알고리즘 Ÿ 둘 이상의 거래, 사건에 포함된 항목들의 관련성을 파악하는 탐색적 데이터 분석 기법 Ÿ Apriori: 후보 항목을 생성하고 지지도와 신뢰도를 계산하여 규칙을 추출하는 알고리즘 Ÿ FP-growth: 빈번한 항목 집합을 효율적으로 찾는 알고리즘 Ÿ Eclat: Eclat 알고리즘은 Equivalence Class Transformation의 약자로, Apriori 알고리즘이 그래프의 Breadth-First Search를 모방하여 수평적으로 작동하는 반면, ECLAT 알고리즘은 그래프의 Depth-First Search와 마찬가지로 수직적으로 작동",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:22:mh: 00001",
                    "page": 22
                }
            },
            {
                "context_id": "2",
                "text": "4 이상 감지 모델(Anomaly Detection Model) Ÿ 이상 감지(Anomaly Detection) 알고리즘은 데이터셋에서 변칙적인 것이나 이례적인 것을 감지 하여, 사기 거래, 하드웨어 결함 등을 발견하는데 유용한 모델 5 잠재 변수 모델(Latent Variable Model) Ÿ 데이터가 매우 복잡하여 학습이 어려운 상황에서 데이터셋에서 불량(Noise) 데이터를 제거하고 차원 축소(Dimensionality Reduction) 기법을 통해 데이터 단순화하여 학습을 용이하게 함 Ÿ 즉, 데이터가 엄청나게 복잡한 경우에는 데이터를 통한 학습이 어려울 수 있는데, 우선 '불량 (Noisy)' 데이터를 제거하여 단순화함으로써 학습을 용이하게 하고, 데이터에서 의미 있는 인사 이트를 찾을 수 있게 함",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:22:mh: 00001",
                    "page": 23
                }
            }
        ],
        "summarization": "연관 규칙 학습은 데이터 내 변수 간의 관계를 규칙 형태로 찾아내는 탐색적 분석 기법으로, Apriori, FP-growth 등의 알고리즘을 사용한다. 반면, 이상 감지 모델은 비정상적인 패턴을 식별하는 방식으로 주로 사기 거래나, 하드웨어 결함 등을 발견하는데 유용한 모델이며 잠재 변수 모델은 복잡한 데이터에서 노이즈를 제거하고 차원을 축소해 학습을 단순화하는데 활용할 수 있다.",
        "long_answer": {
            "question": "이상 감지 모델과 잠재 변수 모델이 학습하는 데이터에는 어떤 차이를 보이는지 설명하라.",
            "answer": "이상 감지 알고리즘의 데이터셋은 변칙적인 것이나 이례적인 것을 감지하는 것에 유용하다. 그래서 사기 거래나 하드웨어 결함과 같은 문제점을 찾는 분야에서 효용성을 지닌다. 반면에 잠재 변수 모델의 경우 데이터가 매우 복잡하여 학습이 어려운 상황일 때, 데이터셋에서 노이즈를 제거하고 차원 축소 기법을 통해 데이터를 단순화하는 알고리즘이다. 즉, 이상 감지 알고리즘은 문제점을 찾는 것이지만 잠재 변수 모델은 문제가 되는 데이터를 제거하는 것이 핵심적 차이라 할 수 있다.",
            "rubric": [
                "이상 감지 알고리즘; 문제점 감지; 잠재 변수 모델; 불량 변수 제거; 데이터 단순화"
            ]
        },
        "short_answer": {
            "question": "연관 규칙 학습에 사용되는 알고리즘을 3가지 나열하라.",
            "answer": "Apriori, FP-growth, Eclat",
            "topic": [
                "연관 규칙 학습의 알고리즘 종류"
            ]
        },
        "multiple_choice": {
            "question": "다음은 차원 축소와 관련된 알고리즘의 종류에 대한 특징을 나열한 것이다. 이 중에서 정답에 가장 가까운 것을 찾아라.",
            "choices": [
                "a) Apriori는 빈번한 항목 집합을 효율적으로 찾는 알고리즘이다.",
                "b) Eclat는 후보 항목을 생성하고 지지도와 신뢰도를 계산하여 규칙을 추출하는 알고리즘이다.",
                "c) 잠재 변수 모델은 대규모의 데이터셋에서 노이즈를 제거하여 차원 축소를 통해 데이터를 단순화하여 학습하는 방식이다.",
                "d) 이상 감지 모델은 특정 데이터 세트에서 변수 간의 관계를 발견하기 위한 규칙기반 학습 방법이다."
            ],
            "answer": "c",
            "topic": [
                "연관 규칙 학습, 이상 감지 모델, 잠재 변수 모델의 특징"
            ]
        },
        "true_false": {
            "question": "Eclat는 데이터셋에서 이례적인 것들을 감지하는 알고리즘으로 사기 거래나 하드웨어 결함을 찾는 분야에서 활용된다.",
            "answer": "FALSE",
            "topic": [
                "Eclat의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:24:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "1.3.3 강화 학습(Reinforcement Learning) l 강화 학습은 에이전트가 환경과 상호 작용하며 보상을 최대화하는 행동을 학습하는 방법 - 주어진 환경 안에 정의된 에이전트(Agent)가 현재의 상태(State)를 인식하여, 선택 가능한 행동(Action) 중 보상(Reward)을 최대화하는 행동 혹은 행동 순서를 선택하는 방법을 학습 1.3.3.2 강화 학습 모델 주요 알고리즘 - 강화 학습에서 에이전트(Agent) 역할을 하는 AI모델은 가치 기반(Value-Based), 정책 기반(Policy-Based), 그리고 모델 기반(Model-Based)으로 구분되며 가치기반 에이전트로 Q-learning, DQN(Deep Q-Network)이 있고, 정책 기반 에이전트로는 PPO(Proximal Policy Optimization), REINFORCE와 같은 모델로 구성",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:24:mh: 00001",
                    "page": 24
                }
            },
            {
                "context_id": "2",
                "text": "1.3.4 적응 학습(Adaptation Learning) l 사전에 훈련된 AI모델을 새로운 작업이나 데이터에 맞게 미세조정하는 학습 - 특정 도메인의 데이터나 특수한 작업 요구사항에 맞게 모델을 미세조정 미세조정 (Fine-Tuning)  모델의 모든 파라미터를 미세조정하는 방법으로, 새로운 데이터에 대한 적응력이 뛰어나지만 과적합의 위험 존재  특징추출 (Feature Extraction)  사전학습 모델의 특징추출 부분을 고정하고 새로운 분류기반 학습하는 방법으로 계산량이 적고 과적합의 위험이 낮음  전이학습 (Transfer Learning)  소스 도메인에서 학습된 지식을 타겟 도메인으로 전달하는 방법으로 다양한 형태의 적응 학습을 포함함",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:24:mh: 00001",
                    "page": 25
                }
            }
        ],
        "summarization": "강화학습은 에이전트가 환경과 상호작용하며 보상을 최대화하는 행동을 학습하는 방법으로, 가치 기반(Value-Based)과 모델 기반으로 구분된다. 반면에 적응 하가습은 사전 학습된 모델을 새로운 작업에 맞게 미세조정하는 방식으로 미세조정, 특징 추출, 전이학습으로 나눌 수 있다.",
        "long_answer": {
            "question": "적응학습의 알고리즘에는 무엇이 있으며, 종류에 대해 간단히 기술하라.",
            "answer": "적응 학습은 사전에 훈련된 AI모델을 새로운 작업이나 데이터에 맞게 미세조정하는 학습이다. 적응학습의 주요 기법에는 미세조정, 특징 추출, 전이 학습으로 나눌 수 있다. 미세조정은 모델의 모든 파라미터를 미세조정하는 방법이며, 특징 추출은 사전 학습 모델의 특징추출 부분을 고정하고 새로운 분류기반 학습하는 방법을 말한다. 마지막으로 전이학습은 소스 도메인에서 학습된 지식을 타겟 도메인으로 전달하는 방법이다.",
            "rubric": [
                "적응 학습; 미세조정; 특징 추출; 전이학습;"
            ]
        },
        "short_answer": {
            "question": "강화 학습에 사용되는 알고리즘 중 가치 기반(Value-Based) 에이전트에는 무엇이 있는가?",
            "answer": "Q-learning, DQN(Deep Q-Network)",
            "topic": [
                "강화 학습 모델의 주요 알고리즘"
            ]
        },
        "multiple_choice": {
            "question": "강화 학습과 적응 학습의 주요 알고리즘에 대한 특징으로 옳지 않은 것은?",
            "choices": [
                "a) 강화 학습에서 정책 기반 에이전트로는 Q-learning, DQN(Deep Q-Network)와 같은 모델로 구성된다.",
                "b) 강화 학습의 에이전트 역할을 하는 AI 모델은 가치 기반(Value-Based), 정책 기반(Policy-Based), 모델 기반(Model-Based)로 나눌 수 있다.",
                "c) 적응 학습 중 전이 학습은 소스 도메인에서 학습된 지식을 타겟 도메인에 전달하기 때문에 다양한 형태에 적응이 가능하다.",
                "d) 적응 학습 중 특징 추출은 사전학습 모델은 계산량이 적고 과적합의 위험이 낮다."
            ],
            "answer": "a",
            "topic": [
                "강화 학습과 적응 학습의 주요 알고리즘"
            ]
        },
        "true_false": {
            "question": "강화 학습에서 에이전트 역할을 하는 정책 기반 에이전트는 PPO, REINFORCE와 같은 모델로 구성되어 있다.",
            "answer": "TRUE",
            "topic": [
                "강화 학습에서의 정책 기반 에이전트 종류"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:28:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.3 합성데이터 l 실제 데이터(Real Data)와 통계적 특성이 유사하여, 실제 데이터 분석결과와 유사한 결과를 얻을 수 있도록 새롭게 생성해 낸 가상의 데이터 - 개인정보보호, 보안등의 사유로 실제 데이터의 활용이 어렵거나, 활용할 수 있는 데이터의 양이 부족한 경우에 주로 활용되며 실제 데이터와 유사할수록 활용 가치가 높음 2.3.1 합성데이터의 특성 - 가상 생성: 실제 데이터와 유사한 특징을 가지도록 설계되었지만, 실제 데이터가 아닌 가상으로 생성된 데이터 - 데이터 증강: 실제 데이터가 부족하거나 다양성이 떨어질 때, 합성데이터를 생성하여 데이터 증강 - 개인정보보호: 가상의 데이터로 개인정보 유출 위험 최소화 - 특정 조건 생성: 실제 환경에서 구하기 어려운 특정 조건의 데이터 생성 가능 - 비용 효율성: 실제 데이터 수집 시 발생되는 비용과 시간을 절약할 수 있음 - 유연성: 필요에 따라 다양한 종류의 데이터 생성 가능 - 재현성: 동일한 조건에서 동일한 데이터를 반복적으로 생성할 수 있음",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:28:0001",
                    "page": 28
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "합성데이터는 실제 데이터와 통계적 특성이 유사하도록 인공적으로 생성된 가상의 데이터로, 개인정보보호나 데이터 부족 시 활용된다. 실제 데이터와 유사한 특징을 가지며 데이터 증강, 개인정보보호, 특정 조건 생성, 비용 효율성, 유연성, 재현성 등의 특성을 지닌다.",
        "long_answer": {
            "question": "합성 데이터가 무엇이며, 활용 시 기대효과를 작성하라.",
            "answer": "합성데이터는 실제 데이터와 통계적 특성이 유사하여, 실제 데이터 분석결과와 유사한 결과를 얻을 수 있도록 새롭게 생성해낸 가상의 데이터이다. 합성데이터는 개인정보보호, 보안 등의 사유로 실제 데이터의 활용이 어려운 경우에 활용할 수 있다. 또한 데이터 양이 부족한 경우, 실제 데이터와 유사하게 생성할 수 있으므로 그 활용가치가 높다고 할 수 있다.",
            "rubric": [
                "합성데이터; 실제데이터와의 통계적 유사성; 가상의 데이터; 개인정보보호, 보안 등에서 자유로움; 데이터 부족 현상 해결"
            ]
        },
        "short_answer": {
            "question": "합성데이터의 특성을 3가지 이상 제시하여라.",
            "answer": "가상 생성, 데이터 증강, 특정 조건 생성, 재현성",
            "topic": [
                "합성데이터의 특성"
            ]
        },
        "multiple_choice": {
            "question": "다음은 합성 데이터와 그 특성에 대해서 기술한 것이다. 내용을 보고 사실에 가장 부합하는 것을 골라라.",
            "choices": [
                "a) 합성데이터는 실제 데이터와 유사하게 만들어지는 것이므로 윤리적으로 어긋나는 행위이다.",
                "b) 합성데이터는 데이터가 부족한 현상을 해결하며, 이를 통해 데이터를 증강할 수 있다는 특성을 지닌다.",
                "c) 합성데이터는 실제 데이터와 유사하지만 가상의 데이터이므로 실효성이 떨어진다.",
                "d) 합성데이터를 사용하여도 개인정보보호나 보안과 같은 민감 사항을 완전히 해결하기가 어렵다."
            ],
            "answer": "b",
            "topic": [
                "합성데이터의 특성"
            ]
        },
        "true_false": {
            "question": "합성데이터를 가지고 필요에 따라 다양한 종류로 데이터를 생성할 수 있는 특성을 재현성이라 한다.",
            "answer": "FALSE",
            "topic": [
                "합성데이터의 특성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:29:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "2.3.3 합성데이터 생성모델 1 GAN(Generative Adversarial Networks): 가짜데이터를 생성하는 생성자(Generator)와 가짜데이터를 판별하는 구분자(Discriminator)로 구성된 AI모델이 서로 대립하며 각각의 성능을 개선해나가는 방식으로 학습해가며 최적의 합성데이터를 생성함",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:29:mh: 00001",
                    "page": 29
                }
            },
            {
                "context_id": "2",
                "text": "2 Stable Diffusion: 텍스트를 이미지로 변환(Text-to-Image)하여 이미지를 생성하는 대표적인 생성모델로, 원본 이미지의 확률 분포를 랜덤하게 샘플링하여 노이즈를 더하거나 제거하는 과정을 학습하면서 합성데이터 생성 3 SH-GAN(Spectral Hint GAN): 고해상도 합성 이미지를 생성할 수 있는 모델로, 이미지 분석 및 진단의 정확성을 향상시킬 수 있는 강점을 제공 고해상도의 이미지는 구조와 특징을 더욱 세밀하게 분석할 수 있도록 더 정밀한 정보를 제공하며, 이는 다양한 도메인에서 중요한 시각적 통찰력을 제공",
                "provenance": {
                    "doc_id": "250523_[제3권]_생성형AI_데이터_품질관리_가이드_v2.0.pdf:29:mh: 00001",
                    "page": 30
                }
            }
        ],
        "summarization": "합성 데이터 생성 모델은 GAN, Stable Diffusion, SH-GAN 등으로 구성된다. GAN은 생성자와 구분자의 경쟁을 통해 최적의 데이터를 생성하며, Stable Diffusion은 텍스트를 이미지로 변환하여 합성데이터를 만든다. SH-GAN의 경우, 고해상도 합성 이미지를 생성해 구조와 특징을 정밀하게 분석할 수 있는 시각적 통찰력을 제공한다.",
        "long_answer": {
            "question": "합성데이터 생성모델 중 SH-GAN과 Stable Diffusion의 차이점을 설명하라.",
            "answer": "SH-GAN와 Stable Diffusion은 입력 데이터가 무엇이냐에 따라 다르다. SH-GAN의 경우, 고해상도 합성 이미지를 생성할 수 있는 모델로, 고해상도 이미지의 구조와 특징을 더욱 세밀하게 분석할수록 더 정밀한 정보를 제공할 수 있는 장점이 있다. 반면 Stable Diffusion인 경우, 입력값이 텍스트이며 이를 다시 이미지로 생성하는 모델이라고 할 수 있다.",
            "rubric": [
                "SH-GAN; Stable Diffusion; 텍스트로 이미지 변환; 고해상도 이미지 분석"
            ]
        },
        "short_answer": {
            "question": "가짜 데이터를 생성하는 생성자와 가짜데이터를 판별하는 구분자로 구성된 AI모델은?",
            "answer": "GAN(Generative Adversarial Networks)",
            "topic": [
                "GAN(Generative Adversarial Networks)의 개념"
            ]
        },
        "multiple_choice": {
            "question": "합성데이터 생성모델에 대한 설명이다. 이 설명 중 맞지 않은 것은?",
            "choices": [
                "a) GAN은 가짜데이터로 서로 대립하며 각각의 성능을 개선해나가는 방식으로 학습하는 모델이다.",
                "b) Stable Diffusion은 원본이미지의 확률 분포를 랜덤하게 샘플링한다.",
                "c) SH-GAN은 고해상도 이미지의 구조와 특징을 면밀히 분석할 수 있으므로 다양한 도메인에서 중요한 시각적 통찰력을 제공한다.",
                "d) GAN은 실제 데이터를 가지고 정오 판정을 하며 학습해가는 모델이라 할 수 있다."
            ],
            "answer": "d",
            "topic": [
                "합성데이터 생성모델의 특징"
            ]
        },
        "true_false": {
            "question": "GAN의 가장 큰 핵심은 가짜 데이터를 생성하는 것과 이를 판별하는 구분자가 있다는 것이다.",
            "answer": "TRUE",
            "topic": [
                "GAN의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:30:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1. 인공지능(AI)의 개념 첫 번째 범주인 ‘인간처럼 생각하는(Thinking Humanly)’이란 인간의 사고 과정을 모방하여 인간의 인지 과정을 이해하고 이를 시스템에 재현 하려는 인지 모델링 접근 방식으로, 대표적인 연구 분야로는 문제 해결과 추론(Problem Solving and Reasoning), 기억과 학습(Memory and Learning) 등이 있다. 두 번째 범주인 ‘인간처럼 행동하는(Acting Humanly)’이란 튜링테스 트(turing test)와 같이 시스템이 인간처럼 행동할 수 있는지를 평가하는 접근 방식으로, 대표적인 연구 분야로는 자연어 처리(Natural Language Processing), 지식 표현(Knowledge Representation), 자동화된 추론 (Automated Reasoning), 머신러닝(Machine Learning), 컴퓨터 비전 (Computer Vision), 로봇공학(Robotics) 등이 있다.",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:30:0001",
                    "page": 30
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능의 범주는 인간의 사고 과정을 모방하는 '인간처럼 생각하는' 범주와 인간의 행동을 재현하는 '인간처럼 행동하는' 범주로 구분된다. 전자는 문제 해결과 학습 등 인지 과정을 모델링하며, 후자는 자연어 처리, 추론, 머신러닝, 컴퓨터 비전, 로봇공학 등의 연구 분야를 포함한다.",
        "long_answer": {
            "question": "인공지능의 정의를 내릴 수 있는 범주에서 '인간처럼 생각하는' 범주와 '인간처럼 행동하는' 범주가 각각 무엇을 의미하는 것인지 서술하시오.",
            "answer": "인공지능를 정의할 수 있는 범주 중에서 '인간처럼 생각하는' 범주는 인간의 사고 방식을 따라하며 인간의 지각 과정을 이해하고 이를 컴퓨터 시스템으로 재현하는 인지 모델링 접근 방식이다. 반면 '인간처럼 행동하는' 범주는 시스템이 인간처럼 행동할 수 있는지를 평가하는 접근 방식이다. 즉, 인공지능이 '인간'이 가지고 있는 고유한 영역을 잘 수행할 수 있는지를 판단하는 범주인 것이다.",
            "rubric": [
                "인공지능의 범주; 인간처럼 생각하는 범주; 인간처럼 행동하는 범주; 인지 모델링 접근 방식; 행동 평가 모델링 접근 방식"
            ]
        },
        "short_answer": {
            "question": "인공지능의 정의 범주 중 '인간처럼 생각하는' 범주에 속하는 대표적인 연구 사례를 2가지 제시하라.",
            "answer": "문제 해결과 추론, 기억과 학습",
            "topic": [
                "인간처럼 생각하는' 범주의 대표적 연구 사례"
            ]
        },
        "multiple_choice": {
            "question": "아래 보기는 인공지능의 정의 범주 일부분을 설명한 내용이다. 설명 중 다른 것은?",
            "choices": [
                "a) 인간처럼 생각하는' 범주는 인간의 인지 과정을 이해하고 이를 시스템적으로 구현한 것이다.",
                "b) 인간처럼 행동하는' 범주에 속하는 대표적 연구 사례는 자연어 처리, 지식 표현, 자동화된 추론 등이 있다.",
                "c) 인간처럼 생각하는' 범주는 시스템이 인간처럼 행동할 수 있는지를 평가하는 접근 방식이다.",
                "d) 인간처럼 행동하는' 범주는 일종의 튜링테스트와 비슷하다."
            ],
            "answer": "c",
            "topic": [
                "인공지능의 정의 범주에 대한 특징"
            ]
        },
        "true_false": {
            "question": "인간처럼 생각하는' 범주의 대표적인 연구 사례로는 머신러닝, 컴퓨터 비전, 로봇 공학 등이 있다.",
            "answer": "FALSE",
            "topic": [
                "인간처럼 생각하는' 범주의 대표적 연구 사례"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:31:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "세 번째 범주인 ‘합리적으로 생각하는(Thinking Rationally)’이란 인 간 사고와는 무관하게 논리적 추론과 합리적 사고에 초점을 맞춰 이성적 인 방식으로 문제를 해결하는 접근 방식으로, 대표적인 연구 분야로는 규칙 기반 시스템(rule-based Systems), 자동 추론 (Automated Reasoning), 지식 표현 및 추론(Knowledge Representation and Reasoning), 계 획 및 추론 (Planning and Reasoning) 등이 있다. 다만 이 접근 방식에 는 2가지 문제점이 있는데, 비형식적인 지식을 취합해 논리적 표기법에 필요한 형식으로 표현하기 어렵다는 점과 원칙적으로 문제를 해결하는 것과 실제로 문제를 해결하는 것에는 큰 차이가 있다는 점이다. 네 번째 범주인 ‘합리적으로 행동하는(Acting Rationally)’이란 최상 의 결과를 달성하거나, 불확실성이 있는 경우 최상의 예상 결과를 달성하 기 위해 행동하는 접근 방식으로, 대표적인 연구 분야는 에이전트 기반 시스템(Agent-Based Systems), 강화 학습(Reinforcement Learning), 계획 및 탐색(Planning and Search), 의사결정 이론(Decision Theory) 등이 있다.",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:31:0001",
                    "page": 31
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "합리적으로 생각하는' 접근은 논리적 추론과 합리적 사고를 통해 문제를 해결하는 방식으로, 규칙 기반 시스템, 자동 추론, 지식 표현 및 추론, 계획 및 추론 등이 포함된다. 반면에, '합리적으로 행동하는' 접근 방식은 최상의 결과를 달성하기 위해 행동하는 방식으로 에이전트 기반 시스템, 강화학습, 계획 및 탐색, 의사결정 이론 등이 있다.",
        "long_answer": {
            "question": "합리적으로 생각하는' 범주의 2가지 문제점을 작성하라.",
            "answer": "합리적으로 생각하는' 범주는 인간 사고와는 무관하게 논리적 추론과 합리적 사고에 초점을 맞춘 이성적 문제 해결 접근 방식이다. 그러나 이런 접근 방식에는 2가지 문제점이 있는데, 첫째는 비형식적인 지식을 취합해 논리적 표기법에 필요한 형식으로 표현하기 어렵다는 것이다. 두번째로는 원칙적으로 문제를 해결하는 것과 실제로 문제를 해결하는 것에는 큰 차이가 있다는 것이다.",
            "rubric": [
                "합리적으로 생각하는 범주; 비형식적인 지식; 논리적 표기법의 형식; 원칙적 문제 해결과 실제 문제 해결 사이의 괴리"
            ]
        },
        "short_answer": {
            "question": "최성의 결과를 달성하기 위해 행동으로 접근하는 방식을 무엇이라 하는가?",
            "answer": "합리적으로 행동하는' 범주",
            "topic": [
                "합리적으로 행동하는' 범주의 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음은 '합리적으로 생각하는' 범주와 '합리적으로 행동하는' 범주의 설명을 나타낸 것이다. 내용 중 가장 적절한 것은?",
            "choices": [
                "a) 합리적으로 생각하는' 범주의 대표적 연구 사례는 규칙 기반 시스템, 자동 추론, 지식 표현 및 추론 등이 있다.",
                "b) 합리적으로 행동하는' 범주를 대표할 수 있는 연구 사례는 머신러닝, 자연어처리 등이다.",
                "c) 합리적으로 행동하는' 범주는 비형식적인 지식을 취합해 논리적 표기법으로 필요한 형식으로 표현하는데 어려움이 있다.",
                "d) 합리적으로 생각하는' 범주는 불확실성이 있는 경우, 최상의 예상 결과를 달성하기 위한 접근 방식이다."
            ],
            "answer": "a",
            "topic": [
                "합리적으로 생각하는' 범주와 '합리적으로 행동하는' 범주의 특징"
            ]
        },
        "true_false": {
            "question": "에이전트 기반 시스템, 강화학습, 의사결정 이론 등은 '합리적으로 행동하는' 범주에 속하는 대표적 연구 사례이다.",
            "answer": "TRUE",
            "topic": [
                "합리적으로 행동하는' 범주의 대표적 연구 사례"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:32:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "인공지능(AI)의 개념은 목적에 따라 분류되기도 한다. 1999년 존 설(John Searle)은 인공지능(AI)을 목적 측면에서 특정한 문제의 해결을 위해 필요한 지능을 의미하는 ‘약 인공지능(Weak AI)’과 인간의 지능과 유사하거나 더 나은 지능을 의미하는 ‘강 인공지능(Strong AI)’으로 구분 하였다(김명철, 양기철, 2017).7) ‘약 인공지능(Weak AI)’은 특정 문제를 해결하기 위한 단일 기능을 지녔으며, 인간이 직접 설계해야 하고 확장이 어렵다는 특징이 있는 반면, ‘강 인공지능(Strong AI)’은 컴퓨터에 인간 수준의 지성을 구현하는 것으로 스스로 학습하고 확장이 용이한 특징이 있다. 다만 ‘약 인공지능(Weak AI)’에서 ‘강 인공지능(Strong AI)’으로 발전하였다는 것을 의미하는 것은 아니다.",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:32:0001",
                    "page": 32
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능은 목적에 따라 특정 문제를 해결할 수 있는 '약 인공지능(Weak AI)'과 인간 수준의 지능을 구현하는 '강 인공지능(Strong AI)'으로 구분된다. 약 인공지능은 단일 기능 중심으로 확장이 어렵고, 강 인공지능은 스스로 학습하며 확장이 용이하지만 두 개념은 발전 단계의 관계를 의미하지 않는다.",
        "long_answer": {
            "question": "약 인공지능과 강 인공지능의 차이점에 대해서 설명해 보라.",
            "answer": "약 인공지능은 특정 문제를 해결하기 위한 단일 기능을 지녔으며, 인간이 직접 설계해야 하고 확장이 어렵다는 특징이 있다. 반면, 강 인공지능은 컴퓨터에 인간 수준의 지성을 구현하는 것으로 자기학습하고 확장이 용이하다는 특징이 있다. 결국, 문제를 해결하기 위해 데이터를 누가 설계하느냐에 따라 서로 차이가 난다고 할 수 있다.",
            "rubric": [
                "약 인공지능; 강 인공지능; 인간 직접 설계; 스스로 학습"
            ]
        },
        "short_answer": {
            "question": "특정한 문제 해결을 위해 필요한 지능을 사용하는 것을 무엇이라 하는가?",
            "answer": "약 인공지능",
            "topic": [
                "약 인공지능의 특성"
            ]
        },
        "multiple_choice": {
            "question": "약 인공지능과 강 인공지능에 대한 설명으로 바른 것은?",
            "choices": [
                "a) 인공지능의 방법론적 측면에서 약 인공지능과 강 인공지능으로 구분지을 수 있다.",
                "b) 강 인공지능은 인간의 지능과 유사하거나 더 나은 지능을 보인다.",
                "c) 강 인공지능은 특정 문제의 해결에 필요한 지능을 의미하는 것이다.",
                "d) 약 인공지능은 컴퓨터에 인간 수준의 지성을 구현하는 것으로 스스로 학습하는 것이 핵심이다."
            ],
            "answer": "b",
            "topic": [
                "약 인공지능과 강 인공지능의 특징"
            ]
        },
        "true_false": {
            "question": "약 인공지능과 강 인공지능은 성능의 차이를 보이며 결국은 강 인공지능으로 발전하는 것이 인공지능의 목표라 할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "약 인공지능과 강 인공지능의 관계"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:36:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "지도 학습 방법 및 응용 사례 선형 회귀 (linear regression) - 종속변수와 하나 이상의 독립변수 간의 관계를 모델링하고 분석하는 통계 방법 - 예측 분석 - 추세 예측 - 재무 모델링  로지스틱 회귀 (logistic regression) - 하나 이상의 기준을 바탕으로 이진 결과의 확률을 예측하는 데 사용되는 분류 기술 - 의료 진단 - 사기 탐지  의사결정나무 (Decision Trees) - 예측변수를 만드는 데 사용되는 트리 구조 모델로 특성 값을 기준으로 데이터를 분기 하여 결정을 내리고 결과를 예측 - 리스크 관리 - 분류 업무  Support Vector Machines(SVM) - 데이터 포인트를 다양한 카테고리로 분류하기 위해 최적의 초평면을 찾는 지 도 학습 알고리즘 - 이미지 인식 - 텍스트 분류  KNN(K-Nearest Neighbors) - 새로운 데이터 포인트를 훈련 데이터 세트의 가장 가까운 포인트와 비교하여 분류 및 회귀에 사용되는 간단한 비모수 적 알고리즘 - 추천 시스템 - 패턴 인식  Naive Bayes - 베이즈 정리를 기반으로 예측 변수 간의 독립성을 가정하는 확률적 분류 방법 - 스팸 필터링 - 감성 분석  랜덤 포레스트 (Random Forest) - 보다 정확하고 안정적인 예측을 위해 여러 의사결정나무를 구성하고 그 결과를 병합 하는 앙상블 학습 방법 - 사기 탐지 - 특성 선택  GBM(Gradient Boosting Machine) - 일반적으로 의사결정나무로 된 약한 모델 을 연속적으로 결합하여 예측 정확도를 향 상시키는 방법 - 웹 검색 순위 - 추천 시스템",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:36:0001",
                    "page": 36
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "지도 학습 방법과 응용 사례를 보면 선형회귀, 로지스틱 회귀, 의사결정나무, Support Vector Machines(SVM), KNN(K-Nearest Neighbors), Naive Bayes, 랜덤 포레스트, GBM(Gradient Boosting Machines)로 설명할 수 있다. 각각의 응용 사례는 순서대로 예측 분석, 의료진단, 리스크 관리, 이미지 인식, 추천 시스템, 스팸 필터링, 사기 탐지, 웹 검색 순위 등으로 설명할 수 있다.",
        "long_answer": {
            "question": "선형 회귀와 로지스틱 회귀에 대한 설명을 응용 사례로 들어가며 설명하라.",
            "answer": "선형 회귀는 예측 분석과 추세 예측, 재무 모델링에 주로 사용하는 지도 학습의 일부이다. 즉, 종속변수와 하나 이상의 독립 변수 간의 관계를 모델링하고 분석하는 통계방법이다. 반면에, 로지스틱 회귀는 의료 진단이나 사기 탐지에 주로 사용이 된다. 진단이나 사기 탐지 등에 쓰이는 것은 로지스틱 회귀는 하나 이상의 기준을 바탕으로 이진 결과의 확률을 예측하는 데 사용되는 분류 기술이기 때문이다.",
            "rubric": [
                "선형 회귀; 예측 분석, 추세 예측, 재무 모델링; 종속 변수와 독립 변수간의 관계; 로지스틱 회귀; 의료 진단, 사기 탐지; 이진 결과의 확률"
            ]
        },
        "short_answer": {
            "question": "데이터 포인트를 다양한 카테고리로 분류하기 위해 최적의 초평면을 찾는 지도 학습 알고리즘의 명칭은?",
            "answer": "Support Vector Machiens(SVM)",
            "topic": [
                "Support Vector Machiens(SVM)의 정의"
            ]
        },
        "multiple_choice": {
            "question": "아래의 보기는 지도 학습 방법 및 응용 사례들을 나열한 것이다. 나열한 내용 중 적절하지 않는 것은?",
            "choices": [
                "a) 의사결정나무는 예측 변수를 만드는 데 사용되는 트리 구조 모델로 리스크 관리나 분류 업무에 많이 활용된다.",
                "b) KNN은 추천 시스템이나 패턴 인식에 주로 응용되는 학습 방법이다.",
                "c) Naive Bayes는 베이즈 정리를 기반으로 예측 변수 간의 독립성을 가정하는 확률적 분류 방법을 말한다.",
                "d) 랜덤 포레스트는 이미지를 인식하거나 텍스트를 분류하는 작업에 주로 활용하는 학습 방법이다."
            ],
            "answer": "d",
            "topic": [
                "지도 학습 방법 및 응용 사례"
            ]
        },
        "true_false": {
            "question": "GBN은 의사결정나무로 된 약한 모델을 연속적으로 결합해 예측 정확도를 향상시키는 방법이다.",
            "answer": "TRUE",
            "topic": [
                "GBN의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:37:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "비지도 학습 방법 및 응용 사례 K‐평균 클러스터링 (K‐Means Clustering) - 데이터를 k개의 클러스터로 분할하고, 각 데이터 포인트가 가장 가까운 평균을 갖 는 클러스터에 속하는 클러스터링 기법 - 고객 분할 - 이미지 압축  계층적 클러스터링 (Hierarchical Clustering) - 기존 클러스터를 병합하거나 분할하여 클 러스터 계층을 구축하는 클러스터링 방법 - SNS 분석 - 게놈 데이터 분석  주성분 분석 (Principal Component Analysis) - 데이터를 주성분이라 불리는 상관관계가 없는 변수들의 집합으로 변환하고, 각 변 수가 포착하는 분산의 양에 따라 정렬하 는 차원 축소 기법 - 데이터 시각화 - 노이즈 감소  독립성분 분석 (Independent Component Analysis) - 다변량 신호를 추가적인 독립 성분 요소 로 분리하는 계산 방법 - 시그널 처리 - 뇌영상  오토인코더 (Autoencoders) - 차원 축소 또는 특성 학습을 위해 레이블 이 지정되지 않은 데이터의 효율적인 코 딩을 학습하는 데 사용되는 신경망 유형 - 이상 탐지 - 데이터 노이즈 제거",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:37:0001",
                    "page": 37
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "비지도 학습의 응용 사례에는 K-평균과 계층적 클러스터링이 있다. 이는 데이터 분류에 사용되는 응용 사례라 할 수 있다. 또한 주성분 및 독립성분 분석은 차원 분석과 신호 분리에 활용될 수 있으며, 오토인코더는 이상 탐지와 노이즈 제거에 활용된다.",
        "long_answer": {
            "question": "비지도 학습의 응용 사례인 독립성분 분석과 오토 인코더의 학습 방법을 설명하고 그 응용 사례에 대해 기술하라.",
            "answer": "비지도 학습 방법 중 하나인 독립성분 분석은 다변량 신호를 추가적인 독립 성분 요소로 분리하여 계산하는 방법이다. 이 학습을 활용한 사례로는 시그널 처리와 뇌영상 등을 들 수 있다. 반면, 오토인코더는 차원 축소 또는 특성 학습을 위해 레이블이 지정되지 않은 데이터의 효율적인 코딩을 학습하는 데 사용되는 신경망 유형이라 할 수 있다. 오토인코더를 응용한 사례로는 이상 탐지, 데이터 노이즈 제거 등을 들 수 있다.",
            "rubric": [
                "독립성분 분석; 다변량 신호의 분리; 시그널 처리; 뇌영상; 오토인코더; 효율적인 코딩 학습; 레이블 비지정; 이상탐지; 노이즈 제거"
            ]
        },
        "short_answer": {
            "question": "데이터를 주성분이라 분리는 상관관계가 없는 변수들의 집합으로 변환하고, 각 변수가 포착하는 분산의 양에 따라 정렬하는 차원 축소 기법을 무엇이라 하는가?",
            "answer": "주성분 분석",
            "topic": [
                "주성분 분석의 개념과 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음은 비지도 학습 방법 및 응용 사례에 대한 설명이다. 옳지 않은 것은?",
            "choices": [
                "a) 오토인코더는 기존 클러스터를 병합하거나 분할하여 클러스터 계층을 구축하는 방법을 말한다.",
                "b) 계층적 클러스터링의 응용 사례에는 SNS 분석이나 게놈 데이터 분석 등이 있다.",
                "c) K-평균 클러스터링인 데이터를 K개의 클러스터로 분할에 각 데이터 포인트가 가장 가까운 평균값을 찾는 것이다.",
                "d) 주성분 분석은 주로 데이터 시각화나 노이즈 감소에 활용된다."
            ],
            "answer": "a",
            "topic": [
                "비지도 학습 방법 및 응용 사례"
            ]
        },
        "true_false": {
            "question": "K-평균 클러스터링은 주로 고객 분할이나 이미지 압축하기 위해 주로 사용하는 기법이다.",
            "answer": "TRUE",
            "topic": [
                "K-평균 클러스터링의 응용 사례"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:39:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "머신러닝(ML) 기법 중 하나인 딥러닝(DL)은 머신러닝(ML)보다 전문화 된 분야이며, 여러 계층의 신경망을 활용하여 복잡한 데이터 패턴을 모델 링한다. 인간의 뇌 구조에서 시냅스(Synapse)의 중첩을 흉내 낸 인공신 경망(Artificial Neural Network, ANN) 알고리즘에 기반한 방법론으로 딥러닝(DL)의 기본 구조들은 1980년대에 정립되었으나, 알고리즘적으로 과적합(overfitting), 기울기 소멸(vanishing gradient) 등의 문제점이  존재하였고, 성능을 높이기 위해서는 충분한 수의 은닉계층(hidden lay- er)이 필요하고 그만큼 학습에 필요한 데이터와 계산량이 증가한다는 문  제점을 갖고 있었다(최예림, 김관호, 2016).13) 하지만 2000년대 중반부 터 드랍아웃(Dropout), ReLU(Rectifier Neural Unit), 배치 정규화 (Batch Normalization) 같은 새로운 기법들의 소개와 데이터 수집 및 연산 능력의 발달로 그 성능이 확인되고 있다(최예림, 김관호, 2016).14) 딥러닝 구조로는 입력 계층(Input Layer)과 출력 계층(Output Layer) 사이에 복수의 은닉 계층(Hidden Layer)이 존재하는 심층 신경 망(Deep Neural Network, DNN), 은닉계층 앞에 요인 추출에 필요한 필터를 두고 필터를 함께 학습하는 합성곱 신경망(Convolutional Neural Network, CNN), 각 시간의 인공신경망을 적층해 시계열 데이 터 처리가 가능한 재귀 신경망(Recurrent Neural Network, RNN) 등 이 있다(최예림, 김관호, 2016).",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:39:0001",
                    "page": 39
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "딥러닝(DL)은 인공신경망에 기반한 머신러닝의 세부 분야로, 다층 신경망을 통해 복잡한 패턴을 학습하지만 초기에는 과적합과 기울기 소멸 등의 문제가 있었다. 이러한 문제는 드랍아웃, ReLU, 배치 정규화 같은 기법과 데이터 및 연산 능력 향상으로 성능이 개선되었다. 딥러닝의 구조로는 DNN, CNN, RNN 등이 있다.",
        "long_answer": {
            "question": "딥러닝의 구조에 대해서 설명하라.",
            "answer": "딥러닝의 구조로는 심층 신경망, 합성신경망, 재귀 신경망 등이 있다. 심층 신경망은 입력 계층과 출력 계층 사이에 복수의 은닉 계층이 존재하는 하는 신경망 구조를 말한다. 합성곱 신경망의 경우, 은닉계층 앞에 요인 추출에 필요한 필터를 두고 필터를 함께 학습하는 구조를 가지고 있다. 이 외에도 각 시간의 인공신경망을 적층해 시계열 데이터 처리가 가능한 재귀 신경망 등이 있다.",
            "rubric": [
                "딥러닝의 구조; 입력 계층; 출력 계층; 은닉 계층; 심층 신경망; 필터; 합성곱 신경망; 시계열 데이터 처리; 재귀 신경망"
            ]
        },
        "short_answer": {
            "question": "딥러닝이 가지고 있는 주요 문제점 2가지를 나열하라.",
            "answer": "과적합, 기울기 소멸",
            "topic": [
                "딥러닝의 문제점"
            ]
        },
        "multiple_choice": {
            "question": "아래 보기는 딥러닝에 대한 전반적인 설명이다. 이에 대한 설명으로 바른 것은?",
            "choices": [
                "a) 딥러닝은 머신러닝보다 단순화된 구조이며 여러 계층의 신경망을 활용하는 모델이다.",
                "b) 시냅스의 중첩을 흉내낸 인공신경망 알고리즘에 기반하였다.",
                "c) 딥러닝의 기본 구조들은 2000년대에 정립되었다.",
                "d) 딥러닝은 어떤 모델링보다 완벽한 기법이라, 많은 분야에서 활용되었다."
            ],
            "answer": "b",
            "topic": [
                "딥러닝의 특징"
            ]
        },
        "true_false": {
            "question": "딥러닝의 성능을 높이기 위해서는 적은 수의 은닉계층을 활용하는 것이 핵심이다.",
            "answer": "FALSE",
            "topic": [
                "딥러닝의 성능 향상 방법"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:39:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "심층 신경망(DNN)은 이미지 인식, 자연어 처리, 음성 인식 등의 분야 에서 탁월한 성과를 거두었다. 하지만 최근에는 합성곱 신경망(CNN), 순 환 신경망(RNN)이 기계의 기능을 크게 발전시켜 이전에는 인간 지능에 만 국한되었던 작업을 획기적으로 개선했다. 합성곱 신경망(CNN)은 의료 영상에서 인간 전문가와 동등한 수준 또 는 그 이상의 이상 식별, 금융 분야에서는 사기 탐지 시스템 개선, 자율 분야에서는 자율 주행 자동차, 드론, 로봇 공학을 위한 고급 알고리즘 개 발로 자율 기술 기능 확장 등에 활용되고 있으며, 순환 신경망(RNN)은 언어 이해 및 생성을 혁신하여 실시간 번역 및 정교한 챗봇과 같은 애플 리케이션에 활용되고 있다(Rane et al., 2024).",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:39:mh: 00001",
                    "page": 39
                }
            },
            {
                "context_id": "2",
                "text": "합성곱 신경망(CNN)과 순환 신경망(RNN) 설명 및 응용 사례 합성 신경망 (CNN) - 격자 형태의 데이터 구조(예: 이미지)를 처리 하는 데 주로 사용되는 딥러닝 모델의 한 종 류로, 특징의 공간적 계층 구조를 학습 - 이미지 및 비디오 인식 - 의료 이미지 분석  순환 신경망(RNN) - 시간적 순서를 따라 노드 간의 연결이 방향 그래프를 형성하는 시퀀스 데이터를 위해 설계된 신경망의 한 종류 - 시계열 분석 - 언어모델링 - 음성 인식",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:39:mh: 00001",
                    "page": 40
                }
            }
        ],
        "summarization": "심층 신경망은 이미지, 음성, 언어 처리 등에서 뛰어난 성과를 거두었으며, 그 중 합성 신경망은 이미지나 의료 영상 분석과 같은 자료 기술에 많이 활용되었다. 또한 순환 신경망은 시계열 분석과 언어모델링, 음성 인식 등 실시간 언어 응용에 탁월한 성능을 보이는 구조라 할 수 있다.",
        "long_answer": {
            "question": "심층 신경망, 합성곱 신경망, 순환 신경망의 성과 사례를 설명하라.",
            "answer": "심층 신경망은 이미지 인식이나 자연어 처리, 음성 인식 등의 분야에서 탁월한 성과를 거두었다. 또한 합성곱 신경망의 등장은 의료 영상에서 전문가와 동등한 수준 또는 그 이상의 이상 식별을 해내었다. 순환 신경망 역시 언어 이해 및 생성을 혁신하여 실시간 번역 및 정교한 챗봇과 같은 애플리케이션에 활용되고 있다.",
            "rubric": [
                "심층 신경망; 이미지 인식, 자연어 처리, 음성 인식 개선; 합성곱 신경망; 의료 분야의 이상 식별; 순환 신경망; 언어 이해 및 생성; 실시간 번역, 챗봇 활용"
            ]
        },
        "short_answer": {
            "question": "순환 신경망의 응용 사례를 3가지로 기술하라.",
            "answer": "시계열 분석, 언어모델링, 음성 인식",
            "topic": [
                "순환 신경망의 응용 사례"
            ]
        },
        "multiple_choice": {
            "question": "다음은 심층 신경망, 순환 신경망, 합성곱 신경망에 대한 설명이다. 이 설명 중 올바르지 않은 것을 골라라.",
            "choices": [
                "a) 합성곱 신경망은 격자 형태의 데이터 구조를 처리하는 데 주로 사용되는 딥러닝 모델의 일종이다.",
                "b) 합성곱 신경망은 이미지 및 비디오 인식, 의료 이미지 분석에 주로 활용된다.",
                "c) 심층 신경망은 시간적 순서를 따라 노드 간의 연결이 방향 그래프를 형성하는 시퀀스 데이터를 위해 설계된 모델링이다.",
                "d) 순환 신경망에는 시계열 분석, 언어모델링, 음성 인식 등에 활용된다."
            ],
            "answer": "c",
            "topic": [
                "심층 신경망, 순환 신경망, 합성곱 신경망의 특징"
            ]
        },
        "true_false": {
            "question": "합성곱 신경망은 자율 주행 자동차, 드론, 로봇 공학을 위한 고급 알고리즘 개발에도 활용된다.",
            "answer": "TRUE",
            "topic": [
                "합성곱 신경망의 활용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:41:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1) 엣지 AI(Edge AI)와 연합학습(Federated Learning) 엣지 AI와 연합학습은 최근 부상하고 있는 머신러닝(ML) 기술이다. 엣지 AI는 중앙 집중화된 클라우드 서버가 아닌 장치에서 로컬로 데이 터를 처리하는 것으로, 이러한 추세는 실시간 처리, 지연 시간 단축, 향상 된 개인정보 보호 및 사물인터넷(Internet of Things, IoT) 장치의 확산 에 대한 수요 증가에 의해 주도되고 있다(Rane et al., 2024). 연합 학습은 데이터를 로컬화하면서 여러 분산 장치에서 모델을 학습 할 수 있도록 하여 이를 보완하는데, 이 접근 방식은 데이터 개인정보 보 호 및 보안을 개선하고 여러 소스의 데이터를 활용하여 보다 강력한 모델 을 구축할 수 있다(Rane et al., 2024).",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:41:0001",
                    "page": 41
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "엣지 AI는 클라우드 대신 로컬 장치에 데이터를 처리하는 실시간성, 지연 시간 단축, 개인정보보호를 강화한다. 연합학습은 분산된 장치에서 데이터를 로컬에 두고 모델을 공동학습하여 보안성과 성능을 향상시키는 기술이다.",
        "long_answer": {
            "question": "연합 학습 모델링이 각광받는 이유에 대해서 설명하라.",
            "answer": "연합 학습은 데이터를 로컬화하여 여러 분산 장치에서 모델을 학습하는 방법이다. 이러한 접근 방식은 데이터의 개인정보 보호와 보안을 개선할 수 있게 한다. 또한 여러 소스의 데이터를 활용하기 때문에 보다 강력한 모델을 구축할 수 있다.",
            "rubric": [
                "연합 학습 모델; 데이터의 로컬화; 개인정보 보호 및 보안 강화; 여러 소스의 데이터 활용"
            ]
        },
        "short_answer": {
            "question": "엣지 AI의 장점에 대해서 3가지로 나열하라.",
            "answer": "실시간 처리, 지연 시간 단축, 사물인터넷 장치 확산에 대한 수요 증가",
            "topic": [
                "엣지 AI의 장점"
            ]
        },
        "multiple_choice": {
            "question": "아래는 엣지 AI와 연합 학습에 대한 활용 사례이다. 이에 대한 내용 중 가장 적절한 것은?",
            "choices": [
                "a) 엣지 AI는 데이터를 로컬화하여 여러 분산 장치에서 모델을 학습하는 방식이다.",
                "b) 연합 학습은 중앙 집중화된 클라우드 서버에서 학습하는 방식이다.",
                "c) 데이터의 개인정보 보호 및 보안을 좀더 개선하는 방식은 엣지 AI이다.",
                "d) 엣지 AI는 실시간 처리가 가능하고 지연 시간을 단축시킨다는 점에서 각광받고 있는 모델링이다."
            ],
            "answer": "d",
            "topic": [
                "엣지 AI와 연합 학습에 대한 특징"
            ]
        },
        "true_false": {
            "question": "연합 학습은 중앙 집중화된 클라우드 서버에서 데이터를 처리하는 방식이다.",
            "answer": "FALSE",
            "topic": [
                "연합 학습의 학습 방식"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:41:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2) 설명 가능한 AI(Explainable AI, XAI) 머신러닝(ML) 및 딥러닝(DL) 모델이 더욱 복잡해짐에 따라 투명성과 설명 가능성에 대한 필요성이 증가하고 있으며, 설명 가능한 AI(XAI)는 이러한 모델의 의사 결정 프로세스를 인간이 이해할 수 있도록 하는 것을 목표로 한다(Rane et al., 2024). 이러한 추세는 특히 의료, 금융, 자율 주행 같은 중요한 애플리케이션에서 인공지능(AI) 시스템에 대한 신뢰를 얻는 데 중요한데, SHAP(SHapley Additive exPlanations) 및 LIME(Local Interpretable Model-agnostic Explanations) 같은 기 술이 인기를 얻고 있으며, 이를 통해 이해 관계자가 모델 예측을 해석하 고 기본 메커니즘을 이해할 수 있다(Rane et al., 2024).",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:41:0001",
                    "page": 41
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "머신러닝과 딥러닝 모델의 복잡성이 증가함에 따라 투명성과 설명 가능성이 중요해졌다. 설명 가능한 AI는 인간이 모델의 의사 결정 과정을 이해하도록 돕기 위해 개발되었다. 이는 의료나 금융, 자율 주행 등에서 신뢰 학보를 위해 활용되는 SHAP나 LIME와 같은 기술로 응용되기도 한다.",
        "long_answer": {
            "question": "머신 러닝과 딥러닝의 최종적인 목표에 대해서 설명하라.",
            "answer": "인공지능의 등장으로 의료나 금융, 자율 주행과 같은 중요한 애플리케이션에서 인공지능 시스템에 대한 신뢰성이 중요하게 되었다. 이에 따라 머신러닝이나 딥러닝 모델들은 설명 가능한 AI로 발전하여 모델의 의사 결정 프로세스를 인간이 이해할 수 있도록 하는 것이 목표로 하였다. 이러한 목표로 개발된 기술이 SHAP나 LIME 등이 있다.",
            "rubric": [
                "인공지능 시스템의 신뢰성; 설명 가능한 AI; 의사 결정 프로세스; SHAP, LIME"
            ]
        },
        "short_answer": {
            "question": "이해 관계자가 모델 예측을 해석하고 기본 매커니즘을 이해할 수 있도록 나온 기술 명칭을 2가지 써라.",
            "answer": "SHAP, LIME",
            "topic": [
                "SHAP, LIME의 기술 특징"
            ]
        },
        "multiple_choice": {
            "question": "머신러닝과 딥러닝 모델의 필요성에 대한 설명이다. 이 설명 중에서 거리가 가장 먼 것은?",
            "choices": [
                "a) 설명 가능한 AI는 모델의 의사 결정 프로세스를 인간이 이해할 수 있게끔 하는 것이다.",
                "b) 머신러닝과 딥러닝 모델이 복잡해짐에 따라 연속성과 프로세스 생략에 대한 필요성이 증가하고 있다.",
                "c) 설명 가능한 AI는 의료, 금융, 자율 주행과 같은 분야에서의 필요성이 대두되어 나온 모델이다.",
                "d) SHAP는 이해 관계자가 모델 예측을 해석하고 기본 메커니즘을 이해할 수 있는 기술을 말한다."
            ],
            "answer": "b",
            "topic": [
                "머신러닝과 딥러닝 모델의 필요성"
            ]
        },
        "true_false": {
            "question": "머신러닝 및 딥러닝 모델이 더욱 복잡해짐에 따라 투명성과 설명 가능성에 대한 필요성이 증가하고 있다.",
            "answer": "TRUE",
            "topic": [
                "머신러닝과 딥러닝 모델의 필요성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:42:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5) 윤리적 AI(Ethical AI) 및 편견 완화(Bias Mitigation) 인공지능(AI) 머신러닝(ML)의 윤리적 의미에 대한 관심이 높아지면서, 편견, 공정성, 책임성에 대한 우려가 편견 탐지 및 완화 기술에 대한 연구 를 주도하고 있다. 조직은 모델이 기존 편견을 영속화하거나 악화시키지 않도록 보장하기 위해 윤리적 AI 프레임워크를 점점 더 많이 채택하고 있 으며, 이러한 추세는 편향된 모델이 사회적으로 상당한 영향을 미칠 수 있는 고용, 대출 및 법 집행 같은 분야에서 특히 중요하다(Rane et al., 2024).",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:42:0001",
                    "page": 42
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능과 머신러닝의 윤리적 문제에 대한 관심이 증가하면서 편견 탐지 및 완화 기술 연구가 활발해지고 있다. 이러한 노력은 편향된 모델이 사회적 영향을 크게 미칠 수 있는 고용 환경이나, 대출 및 법 집행과 같은 분야에서 특히 중요하다고 할 수 있다.",
        "long_answer": {
            "question": "윤리적 AI의 연구에 대한 연구가 증가하는 이유에 대해 설명하라.",
            "answer": "인공지능 머신러닝의 윤리적 의미에 대한 관심이 높아지는 이유는 편견, 공정성, 책임성을 확보하기 위해서이다. 즉, 편향된 모델은 사회적으로 상당햔 영향을 미칠 수 있기 때문이다. 따라서 조직은 모델이 기존 편견을 영속화하거나 악회시키지 않도록 보장하기 위해 힘써야 한다.",
            "rubric": [
                "윤리적 AI; 공정성, 책임성의 확보; 편향된 모델의 위험성"
            ]
        },
        "short_answer": {
            "question": "윤리적 AI 연구를 위해 필수로 가져야 하는 요소를 2가지로 나열하라.",
            "answer": "공정성, 책임성",
            "topic": [
                "윤리적 AI 연구의 필수 요소"
            ]
        },
        "multiple_choice": {
            "question": "아래는 윤리적 AI 연구에 대한 설명이다. 이에 대한 설명으로 적합한 것은?",
            "choices": [
                "a) 인공지능 머신러닝의 윤리적 의미는 다른 문제들이 비해 크게 중요하지 않다.",
                "b) 윤리적 AI는 특정 데이터를 활용한다는 시점에서 편향성을 해결할 수 없다.",
                "c) 인공지능 머신러닝은 고용이나 대출, 법 집행과 같은 부분에서 윤리적으로 중요하다.",
                "d) 조직에서도 모델의 편향성에 대해서는 어쩔 수 없는 문제로 이해한다."
            ],
            "answer": "c",
            "topic": [
                "윤리적 AI 연구의 필요성"
            ]
        },
        "true_false": {
            "question": "인공지능 머신러닝에서 윤리적 문제를 해결하는 방법으로 편견을 영속화하는 것에 초점을 두고 있다.",
            "answer": "FALSE",
            "topic": [
                "윤리적 AI 연구의 필요성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:43:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "6) 자동화된 머신러닝(Automated Machine Learning, AutoML)  자동화된 머신러닝(AutoML) 플랫폼은 머신러닝(ML)을 실제 문제에 적용하는 엔드 투 엔드(end-to-end) 프로세스를 자동화하는 것을 목표 로 하고 있으며, 여기에는 데이터 전처리, 기능 엔지니어링, 모델 선택 및 하이퍼파라미터 튜닝이 포함된다. 자동화된 머신러닝(AutoML)은 이러 한 작업을 자동화함으로써 비전문가가 머신러닝(ML) 모델을 효율적으로 구축할 수 있도록 하고 전문가는 모델 개발의 더 복잡한 측면에 집중할 수 있도록 한다. Google AutoML, H2O.ai, DataRobot 같은 플랫폼이 이 분야를 선도하고 있다(Rane et al., 2024).",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:43:0001",
                    "page": 43
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "자동화된 머신러닝은 데이터 전처리, 기능 엔지니어링, 모델 선택, 하이퍼파라미터 튜닝 등 머신러닝의 전체 과정을 자동화하여 비전문가도 효율적으로 모델을 구축할 수 있게 하는 것이다. 전문가가 복잡한 기술 개발에 집중할 수 있도록 지원해주는 플랫폼으로는 Google AutoML, H2O.ai, DataRobot 등이 있다.",
        "long_answer": {
            "question": "자동회된 머신러닝의 지향하고자 하는 바에 대해 설명하라.",
            "answer": "자동화된 머신러닝 플랫폼은 머신러닝을 실제 문제에 적용하는 엔드 투 엔드 프로세스를 자동화하는 것을 목표로 한다. 여기에는 데이터 전처리, 기능 엔지니어링, 모델 선택 및 하이퍼파라미터의 튜닝이 포함될 수 있다. 결국 자동화된 머신러닝은 비전문가가 머신러닝 모델을 효율적으로 구축할 수 있도록 하는 것에 초점을 두고 있는 것이다.",
            "rubric": [
                "자동화된 머신러닝; 엔드 투 엔드 프로세스; 데이터 전처리, 기능 엔지니어링, 모델 선택 및 하이퍼파라미터의 튜닝; 머신러닝의 효율적 구축"
            ]
        },
        "short_answer": {
            "question": "비전문가도 머신러닝을 구축할 수 있게 도와주는 플랫폼의 예시를 3가지로 제시하라.",
            "answer": "Google AutoML, H2O.ai, DataRobot",
            "topic": [
                "머신러닝 구축 플랫폼의 종류"
            ]
        },
        "multiple_choice": {
            "question": "아래 보기 중 자동화된 머신러닝의 내용으로 설명이 다른 것은?",
            "choices": [
                "a) 머신러닝이 자동화가 된다고 하더라도 비전문가는 활용하기 어렵다는 측면이 있다.",
                "b) 실제 문제에 적용하는 엔드 투 엔드 프로세스를 자동화하는 것을 목표로 한다.",
                "c) 자동화된 머신러닝은 전문가 역시 복잡한 측면의 모델을 개발할 수 있도록 도와준다.",
                "d) Google AutoML, H2O.ai, DataRobot 등은 자동화된 머신러닝 구축에 도움을 주는 플랫폼 종류이다."
            ],
            "answer": "a",
            "topic": [
                "자동화된 머신러닝의 특징"
            ]
        },
        "true_false": {
            "question": "자동회된 머신러닝에는 데이터 전처리, 기능 엔지니어링, 모델 선택 및 하이퍼파라미터 튜닝이 포함된다.",
            "answer": "TRUE",
            "topic": [
                "자동화된 머신러닝의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:43:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "7) 신경 구조 탐색(Neural Architecture Search, NAS)  신경망 구조 탐색(NAS)은 신경망 구조 설계를 자동화하는 데 중점을 둔 새로운 분야로, 신경망 구조 탐색(NAS) 알고리즘은 네트워크 구조를 수동으로 설계하는 대신 특정 작업에 맞는 최적의 아키텍처를 검색하는 것이다. 이 접근 방식은 수동으로 설계된 모델보다 성능이 뛰어난 새로운 아키텍처를 발견하는 데 도움이 되었다. EfficientNet 및 DARTS (Differentiable Architecture Search)와 같은 기술은 모델 성능과 효 율성에서 상당한 개선을 보였습니다(Rane et al., 2024).",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:43:0001",
                    "page": 43
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "신경망 구조 탐색은 특정 작업에 맞는 최적의 신경망 아키텍처를 자동으로 검색하게 하는 새로운 분야이다. 수동 설계보다는 효율적이고 성능이 뛰어난 모델을 찾아주는 기술이며 이에 대한 예로는 EfficientNet과 DARTS 등이 있다.",
        "long_answer": {
            "question": "신경 구조 탐색을 간략하게 서술하라.",
            "answer": "신경 구조 탐색은 네트워크 구조를 수동으로 설계하는 대신, 특정 작업에 맞는 최적의 아키텍처를 검색하는 방식을 말한다. 이는 신경망 구조 설계를 자동으로 할 수 있다는 장점이 있다. 또한 자동으로 설계를 하기 때문에 수동으로 설계된 모델보다 성능이 뛰어나다고 할 수 있다.",
            "rubric": [
                "신경 구조 탐색; 수동 네트워그 구조의 단점 해결; 신경망 구조 자동 설계"
            ]
        },
        "short_answer": {
            "question": "신경 구조 탐색의 기술 2가지를 예로 들어라.",
            "answer": "EfficientNet, DARTS",
            "topic": [
                "신경 구조 탐색 기술의 예시"
            ]
        },
        "multiple_choice": {
            "question": "다음 설명은 신경 구조 탐색에 관한 것이다. 설명에 가장 부합하는 것을 골라라.",
            "choices": [
                "a) 신경망 구조 탐색은 수동으로 신경망을 설계하는 작업이다.",
                "b) 신경망 구조 탐색은 자동화보다 수동으로 설계한 모델 성능이 더 뛰어나다.",
                "c) 신경망 구조 탐색은 신경망 구조 설계를 수동화하는 데에 중점을 둔 새로운 분야다.",
                "d) 신경망 구조 탐색 알고리즘은 특정 작업에 맞는 최상의 아키텍처를 검색하는 것이다."
            ],
            "answer": "d",
            "topic": [
                "신경 구조 탐색의 특징"
            ]
        },
        "true_false": {
            "question": "신경 구조 탐색 알고리즘은 범용적인 분야에 활용하는데 적합하다.",
            "answer": "FALSE",
            "topic": [
                "신경 구조 탐색 알고리즘의 활용 분야"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:44:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "8) 양자 머신러닝(Quantum Machine Learning, QML) 양자 머신러닝(QML)은 양자 역학의 원리를 활용하여 고전적 알고리즘 보다 특정 문제를 더 빨리 해결할 수 있는 알고리즘을 개발하는 것으로 아직 초기 단계지만 최적화, 데이터 분류 및 생성 모델에서 잠재력을 보여 주었고, 양자 하드웨어가 계속 발전함에 따라 복잡한 머신러닝(ML) 문제 에 접근하는 방식을 혁신할 수 있을 것으로 기대된다(Rane et al., 2024).",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:44:0001",
                    "page": 44
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "양자 머신러닝은 양자 역학의 원리를 활용해 고전적 알고리즘보다 빠르게 문제를 해결할 수 있는 알고리즘을 개발하는 기술이다. 아직 초기 단계이나, 데이터 분류, 생성 모델 분야에서 잠재력을 보이고 있다. 양자 하드웨어 발전에 따라 복잡한 머신러닝 문제 해결 방식의 혁신을 불러 일으킬 것으로 기대된다.",
        "long_answer": {
            "question": "양자 머신러닝의 의미와 그 기대 효과에 대해 설명하라.",
            "answer": "양자 머신러닝은 양자 역학 원리를 이용하여 고전적인 알고리즘에서 벗어나 특정 문제를 보다 빨리 해결할 수 있는 알고리즘을 의미한다. 이 머신러닝은 아직 개발 초기 단계이나, 최적화나 데이터 분류에 잠재력을 보여주었다. 양자 하드웨어가 계속 발전함에 따라 복잡한 머신러닝 문제를 해결할 수 있어 그 가치가 점점 중요해지고 있다.",
            "rubric": [
                "양자 머신러닝; 양자 역학 원리; 최적화나 데이터 분류 활용; 복잡한 문제 해결"
            ]
        },
        "short_answer": {
            "question": "양자 역학 원리를 이용하여 기존의 알고리즘에서 벗어나기 위한 모델을 무엇이라고 부르는가?",
            "answer": "양자 머신러닝",
            "topic": [
                "양자 머신러닝의 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음 보기 내용은 양자 머신러닝에 대한 것이다. 이 내용 중에서 가장 부적합한 것은?",
            "choices": [
                "a) 양자 머신러닝은 물리학자들에게 주로 활용할 수 있는 분야이다.",
                "b) 양자 하드웨어가 계속 발전함에 따라 같이 발전할 수 있는 머신러닝의 일종이다.",
                "c) 양자 머신러닝의 개발은 아직 초기 단계일 뿐이다.",
                "d) 양자 머신러닝의 개발은 특정 문제를 더 빨리 해결할 수 있다는 장점이 있다."
            ],
            "answer": "a",
            "topic": [
                "양자 머신러닝의 특징"
            ]
        },
        "true_false": {
            "question": "양자 머신러닝은 최적화나 데이터 분류, 생성에 주로 활용할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "양자 머신러닝의 활용 양상"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:44:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "9) 의료용 AI(AI for Healthcare)  머신러닝(ML)과 딥러닝(DL)이 적용은 빠르게 확대되고 있는 의료 분 야에서는 진단 및 개인화된 의학에서 약물 발견 및 환자 치료에 이르기까 지 인공지능(AI)은 의료전달체계를 혁신하고 있다. 딥러닝(DL)은 의료 이 미지를 분석하고, 환자의 결과를 예측하고, 잠재적인 치료법을 식별하는 데 사용되고 있으며, 머신러닝(ML)과 웨어러블 기기를 통합하면 지속적 인 건강 모니터링과 건강 문제의 조기 진단이 가능해져 환자의 결과가 개 선된다(Rane et a.l, 2024).",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:44:mh: 00001",
                    "page": 44
                }
            },
            {
                "context_id": "2",
                "text": "12) 금융 분야의 인공지능(AI) 금융 부문에서 머신러닝(ML)과 딥러닝(DL)은 사기 탐지, 알고리즘 거 래, 위험 관리, 고객 서비스를 포함한 광범위한 애플리케이션에 활용되고 있다. 방대한 양의 재무 데이터를 분석하고 패턴을 감지하는 능력은 금융 기관이 더 나은 정보에 입각한 결정을 내리고 개인화된 서비스를 제공하 는 데 도움이 되고 있고, 규제 준수(RegTech)에 인공지능(AI)을 사용하 면 회사가 복잡한 규제 환경을 보다 효율적으로 탐색하는 데 큰 도움이 된다.",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:44:mh: 00001",
                    "page": 45
                }
            }
        ],
        "summarization": "의료 분야에서는 머신러닝과 딥러닝의 활용은 진단, 약물 발견, 개인 맞춤 치료, 건강 모니터링 등 의료 전달 체계에 혁신을 가져올 수 있다. 또한 금융 분야에서는 사기 탐지, 알고리즘 거래, 위험 관리, 고객 서비스, 규제 준수 등에서 방대한 데이터를 분석할 수 있으며 이를 통해 의사결정과 개인화 서비스를 제공할 수 있다.",
        "long_answer": {
            "question": "의료 분야에서 머신러닝과 딥러닝이 어떤 역할을 할 수 있는지 기술하라.",
            "answer": "의료 분야에서 머신러닝과 딥러닝은 진단 및 개인화된 의학에서 주로 활용할 수 있다. 즉, 약물을 발견하거나 환자를 츼료하는 등 의료전달체계를 혁신하고 있다. 특히 딥러닝은 의료 이미지를 분석하여 환자의 결과를 예측하는 데에 사용되어 그 가치가 중요해지고 있다.",
            "rubric": [
                "의료 분야에서의 머신러닝과 딥러닝; 개인화된 의학; 의료전달체계 향상; 의료이미지 분석; 환자의 결과 예측"
            ]
        },
        "short_answer": {
            "question": "금융 부문에서 머신러닝과 딥러닝의 활용 사례를 3가지 이상 작성하라.",
            "answer": "사기 탐지, 알고리즘 거래, 위험 관리, 고객 서비스 등의 애플리케이션 개발",
            "topic": [
                "금융 부분에서의 머신러닝과 딥러닝의 활용 사례"
            ]
        },
        "multiple_choice": {
            "question": "의료와 금융 부문에서 머신러닝과 딥러닝이 가지는 활용에 대한 서술 중 그 내용이 옳은 것은?",
            "choices": [
                "a) 금융 부문에서 머신러닝과 딥러닝은 고객이 가진 정보가 너무 다양하기 때문에 일괄적으로 적용하기에 어렵다는 단점을 가지고 있다.",
                "b) 머신러닝과 딥러닝은 의료나 금융 부문에서 데이터가 편향될 수 있어 활용할 수 없다.",
                "c) 아직까지 머신러닝이나 딥러닝을 활용하여 개인화된 의료 진단을 하기에는 위험요소가 존재한다.",
                "d) 금융 부문에서는 회사가 복잡한 규제 환경을 효율적으로 탐색하는데 데 큰 도움을 받을 수 있다."
            ],
            "answer": "d",
            "topic": [
                "의료와 금융 부문에서 머신러닝과 딥러닝의 활용"
            ]
        },
        "true_false": {
            "question": "의료 부문에서 머신러닝과 딥러닝의 적용은 개인 진료 기록을 저장하고 분석하는 것에 국한되어 사용할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "의료 부문에서 머신러닝과 딥러닝의 활용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:44:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "10) 지속 가능한 AI  인공지능(AI) 모델, 특히 딥러닝(DL)이 환경에 미치는 영향이 분명해 짐에 따라 지속 가능한 AI에 대한 관심이 증가하고 있는데, 이러한 추세 에서는 인공지능(AI) 애플리케이션의 탄소 발자국(carbon footprint)을 줄이는 에너지 효율적인 알고리즘과 아키텍처를 개발하는 것이 필요하 다. 모델 가지치기(model pruning), 양자화(quantization), 효율적인 신경망(efficient neural network) 같은 기술이 인공지능(AI)을 더욱 지 속 가능하게 만들기 위해 탐구되고 있으며, 대규모 모델을 훈련하기 위해 재생 에너지원을 사용하는 방향으로 나아가고 있다.",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:44:0001",
                    "page": 44
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "딥러닝을 포함한 인공지능의 환경 영향이 커지면서 탄소 배출을 줄이기 위한 에니저 효율적 알고리즘과 아키텍처 개발이 중요해졌다. 이를 위해 모델의 가지치기, 양자화, 효율적인 신경망 같은 기술을 활용하여 지속 가능한 AI를 만들고자 노력하고 있다.",
        "long_answer": {
            "question": "지속 가능한 AI가 미래 사회에 필요한 이유에 대해서 서술하라.",
            "answer": "딥러닝이 환경에 미치는 영향이 크다라는 점을 바탕으로 지속 가능한 AI의 실현 가능성에 대해 지속적인 연구가 되고 있다. 탄소 발자국을 줄이기 위한 노력으로 에너지 효율이 극대화된 알고리즘이나 아키텍처를 개발하는 것이 필요해진 것이다. 이를 위해서 모델 가지치기나 양자화, 효율적인 신경망 같은 기술이 등장하고 있는 추세이다.",
            "rubric": [
                "지속 가능한 AI가 필요한 이유; 탄소 발자국 줄이기; 환경 문제; 모델 가지치기; 양자화; 효율적인 신경망"
            ]
        },
        "short_answer": {
            "question": "머신러닝과 딥러닝의 발달로 인해 환경에 가장 영향을 주는 요소는 무엇인가?",
            "answer": "탄소 발생",
            "topic": [
                "머신러닝과 딥러닝으로 인한 환경적 영향"
            ]
        },
        "multiple_choice": {
            "question": "다음은 지속 가능한 AI에 대한 설명 중 일부이다. 내용 중 가장 적절한 것은?",
            "choices": [
                "a) 인공지능 모델이 계속 개발과 환경 오염과는 서로 관련이 없다.",
                "b) 인공지능 모델의 지속적인 개발은 환경 문제를 해결할 수 있는 하나의 핵심 기술이다.",
                "c) 지속 가능한 AI로 활용하기 위해 모델 가지치기, 양자화 등의 기술이 개발되고 있다.",
                "d) 지속 가능한 AI를 위해서는 인공지능 애플리케이션을 개발하는 것이 핵심이다."
            ],
            "answer": "c",
            "topic": [
                "지속 가능한 AI의 특징"
            ]
        },
        "true_false": {
            "question": "지속 가능한 AI는 대규모 모델을 훈련하기 위한 재생 에너지원을 사용하는 것을 말한다.",
            "answer": "TRUE",
            "topic": [
                "지속 가능한 AI의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:45:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "11) 멀티모달 러닝(Multimodal Learning) 여러 모달리티(텍스트, 이미지, 오디오 등)의 정보를 통합하는 멀티모 달 러닝이 인기를 얻고 있으며, 이러한 접근 방식을 통해 모델은 보다 포 괄적이고 섬세한 데이터 표현을 학습할 수 있다. 예를 들어 OpenAI의 CLIP 같은 모델은 시각과 언어를 결합하여 이미지 캡션 및 시각적 질의  응답과 같은 작업을 수행하는데, 멀티모달 러닝은 콘텐츠 생성에서 인간- 컴퓨터의 상호 작용에 이르기까지 다양한 응용 분야에서 인공지능(AI) 시  스템의 역량을 향상시키고 있다.",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:45:0001",
                    "page": 45
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "멀티모달 러닝은 텍스트, 이미지, 오디오 등 다양한 모달리티 정보를 통합하여 포괄적이고 섬세한 데이터 표현을 학습하는 방식을 말한다. OpenAI의 CLIP처럼 시각과 언어를 결합해 이미지 캡션 및 시각적 질의응답을 수행하는 등 콘텐츠 생성뿐만 아니라 인간과 컴퓨터 간의 상호작용 역량을 향상시켜 준다.",
        "long_answer": {
            "question": "멀티모달 러닝의 학습 데이터에 대한 특징을 서술하라.",
            "answer": "멀티모달 러닝은 텍스트뿐만 아니라, 오디오나 이미지 등 여러 모달리티가 결합된 정보를 활용하여 다양한 컨텐츠를 생성하는 것이 핵심이다. 이를 통해서 시각과 언어를 결합한 이미지 캡션이나 시각적 질의 응답이 가능해졌다. 이는 단순한 컨텐츠 생성이 아닌, 인간과 컴퓨터 간의 상호 작용을 할 수 있는 분야까지 그 활용 가능성을 넓혀가고 있다.",
            "rubric": [
                "멀티모달 러넝; 텍스트, 이미지, 오디오 등의 모달리티 결합 정보; 이미지 캡션, 시각적 질의 생성; 인간과 컴퓨터의 상호작용"
            ]
        },
        "short_answer": {
            "question": "멀티모달 러닝을 하여 기존의 모델보다 포괄적이고 좀더 섬세한 데이터를 표현할 수 있는 모델로, OpenAI에서 개발한 모델 이름은 무엇인가?",
            "answer": "CLIP",
            "topic": [
                "멀티모달 러닝의 예"
            ]
        },
        "multiple_choice": {
            "question": "아래 내용은 멀티모달 러닝 학습에 대한 설명이다. 보기 내용 중 가장 부적절한 것을 골라라.",
            "choices": [
                "a) 멀티모달 러닝의 예시로는 OpenAI에서 개발한 CLIP가 이에 해당한다.",
                "b) 멀티모달 러닝에는 텍스트 데이터가 중요하며, 텍스트 안에 다양한 모달리티를 표현하는 것이 핵심이다.",
                "c) 멀티모달 데이터의 학습으로 인해서 기존의 모델보다 좀더 섬세한 컨텐츠를 생성할 수 있다.",
                "d) 멀티모달 러닝은 이미지, 오디오 등의 생성 및 인간과 컴퓨터가 상호작용해야하는 분야에서도 활발히 활용되고 있다."
            ],
            "answer": "b",
            "topic": [
                "멀티모달 러닝 학습의 특징"
            ]
        },
        "true_false": {
            "question": "OpenAI의 CLIP는 시각과 언어를 결합한 모델로 시각적 질의 응답 같은 작업 수행이 가능하다.",
            "answer": "TRUE",
            "topic": [
                "CLIP의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:47:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "14) 사이버 보안(Cybersecurity)을 위한 인공지능(AI) 사이버 공격의 위협이 증가함에 따라 인공지능(AI)과 머신러닝(ML)은 사이버 보안을 강화하는 데 중요한 역할을 하고 있으며, 머신러닝(ML) 알 고리즘은 이상을 탐지하고 잠재적 위협을 예측하며 실시간으로 보안 사 고에 대응하는 데 사용되고 있다. 특히 딥러닝(DL) 모델은 사이버 위협을 나타내는 복잡한 패턴을 식별하는 데 효과적인 것으로 입증되었으며, 인 공지능(AI) 기반 사이버 보안 솔루션은 민감한 데이터를 보호하고 디지털 시스템의 무결성을 보장하는 데 필수적이 되고 있다.  15) 개인화 및 추천 시스템  머신러닝(ML)과 딥러닝(DL)으로 구동되는 개인화 및 추천 시스템은 전자상거래부터 스트리밍 서비스에 이르기까지 온라인 플랫폼에서 널리 사용되고 있으며, 이러한 시스템은 사용자 행동과 선호도를 분석하여 개 인화된 콘텐츠와 추천을 제공한다. 특히 협업 필터링 및 시퀀스 모델링 분야에서 심층 학습의 발전은 추천의 정확성과 관련성을 향상시키고 있 으며, 개인화된 경험은 경쟁 시장에서 기업을 위한 핵심 차별화 요소가 되고 있다.",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:47:0001",
                    "page": 47
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능과 머신러닝은 이상 탐지와 사이버 공경에 대한 위협에 대한 실시간 대응 등을 통해 사이버 보안을 강화하고 있으며 민감한 데이터를 보호하고 시스템적인 무결성을 보장해야 한다. 이러한 방향은 점차 개인에 맞춘 추천 시스템으로의 발전과도 관련이 있다. 또한 추천 시스템은 사용자 행동과 선호도를 분석해 맞춤형 콘텐츠를 제공함으로써 추천의 정확성과 기업 경쟁력을 높이고있다.",
        "long_answer": {
            "question": "사이버 보안을 위해 인공지능이 할 수 있는 역할이 무엇인지 기술하라.",
            "answer": "사이버 공격의 위협이 증대됨에 따라 인공지능의 역할 역시 중요해지고 있다. 보안을 위해서 머신러닝의 알고리즘을 활용하여 이상을 탐지하고 잠재적 위협을 예측하여 실시간 보안에 대응이 가능하다. 특히 딥러닝의 경우, 사이버 위협을 나타나는 복잡한 패턴을 식별하는 데 효과적임이 입증되었다. 이로 인해 머신러닝과 딥러닝 등 인공지능의 활용 영역이 극대화되고 있다.",
            "rubric": [
                "머신러닝의 알고리즘; 이상 탐지; 잠재적 위협에 대한 예측; 신속 대응; 복잡한 패턴 식별"
            ]
        },
        "short_answer": {
            "question": "머신러닝과 딥러닝으로 구동되는 개인화 및 추천시스템이 활용될 수 있는 분야를 2가지만 나열하라.",
            "answer": "전자상거래, 스트리밍 서비스",
            "topic": [
                "개인화 및 추천시스템에 대한 활용 분야"
            ]
        },
        "multiple_choice": {
            "question": "사이버 보안과 개인화 및 추천 시스템에서의 인공지능이 가진 역할에 대한 설명이다. 해당 설명 중 바르지 못한 것은?",
            "choices": [
                "a) 사이버 보안과 관련하여 인공지능의 활용은 사이버 위협의 복잡한 패턴을 식별할 수 있어 보안 솔루션을 제시할 수 있다.",
                "b) 개인화 및 추천시스템에 동기화된 인공지능은 사용자의 행동과 선호도를 분석할 수 있다.",
                "c) 개인화 및 추천 시스템에서 개인 경험의 중요성은 경쟁 시장에서 기업을 위한 핵심 차별화 요소가 된다.",
                "d) 사이버 공격은 언제든지 있을 수 있으므로 인공지능은 이에 대한 대응이 아직은 취약하다."
            ],
            "answer": "d",
            "topic": [
                "사이버 보안과 개인화 및 추천 시스템에서의 인공지능 활용"
            ]
        },
        "true_false": {
            "question": "개인화 및 추천시스템에서 협업 필터링과 시퀀스 모델링 분야의 성장은 추천의 정확성이나 관련성을 저하시키는 요인이다.",
            "answer": "FALSE",
            "topic": [
                "개인화 및 추천시스템에서의 심층 분야에 대한 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "연구보고서 2025-04.pdf:47:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "16) 대형 언어모델(Large Language Model, LLM) 대형 언어모델(LLM)은 딥러닝의 한 분야로, 방대한 양의 텍스트 데이 터를 학습하여 인간과 유사한 수준의 자연어 처리(NLP) 기능을 수행하도 록 설계된 모델을 의미한다(Bhunia & Jamieson, 2025). 이러한 모델은 다층 신경망을 기반으로 하며, 문맥을 이해하고 자연스러운 텍스트를 생 성할 수 있는 것이 주요 특징이다. 대형 언어모델은 자기회귀 기법(Self-attention mechanism)을 활용한 Transformer 모델(Vaswani et al., 2017)을 기반으로 한다. Transformer 는 문장 내 단어 간 관계를 효율적으로 분석할 수 있도록 설계되었으며, 기존 순환신경망(Recurrent Neural Network, RNN) 모델들이 겪었던 기울기 소멸(Vanishing gradient) 문제를 해결한 것이 핵심적인 차별점 이다. 이러한 모델들은 단순한 텍스트 예측을 넘어 다양한 자연어 처리 작업 에 적용된다. 대표적인 예로는 사전에 학습된 모델이 추가적인 훈련 없이 도 새로운 작업을 수행하는 제로샷(Zero-shot) 방식과, 소량의 예제를 제공한 후 학습하여 문제 해결 능력을 향상시키는 퓨샷(Few-shot) 방식 이 있다(Cyrta, P., 2024, Brown et al., 2020). 이러한 접근법을 통해, 대형 언어모델은 별도의 파인튜닝 없이도 높은 성능을 발휘할 수 있다.",
                "provenance": {
                    "doc_id": "연구보고서 2025-04.pdf:47:0001",
                    "page": 47
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "대형 언어모델은 방대한 텍스트 데이터를 학습해 인간 수준의 자연어 처리 능력을 수행하는 딥러닝 기반 모델로, 자기회기 기법을 활용한 Transformer 구조를 통해 문맥 이해와 자연스러운 텍스트 생성을 가능하게 한다. 또한 제로샷과 퓨샷 학습을 통해 별도의 파인튜닝없이도 다양한 작업에서 높은 성능을 발휘한다.",
        "long_answer": {
            "question": "기존의 언어모델과 달리 대형 언어모델이 가지는 차별점이 무엇인지 써라.",
            "answer": "대형 언어모델은 자기회귀 기법을 활용한 Trasformer 모델을 기반으로 한다. Transformer은 문장 내 단어 간의 관계를 효과적으로 분석할 수 있도록 설계되어 있다. 그래서 기존의 순환신경망 모델들이 겪었던 기울기 소멸 등의 문제를 해결하였다.",
            "rubric": [
                "대형 언어모델; 자기회기 기법; Trassformer 모델; 문장 내 단어 관계 분석; 기울기 소멸 등 문제 해결"
            ]
        },
        "short_answer": {
            "question": "딥러닝의 한 분야료, 방대한 양의 텍스트 데이터를 학습하여 인간과 유사한 수준의 자연어 처리가 가능한 모델을 무엇이라 하는가?",
            "answer": "대형 언어 모델",
            "topic": [
                "대형 언어 모델의 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음 보기는 대형 언어모델에 대한 설명이다. 보기 중 가장 적합한 것을 찾아라.",
            "choices": [
                "a) 대형 언어모델은 단순한 텍스트 예측에 주로 활용된다.",
                "b) 대형 언어모델은 다층 신경망을 기반으로 하여, 문맥을 자연스럽게 이해한다.",
                "c) 기존 모델이 겪은 기울기 소멸 등의 문제는 해결하지 못한다.",
                "d) 사전에 학습된 모델이 추가적인 훈련 없이도 새로운 작업을 수행하는 것을 퓨샷 방식이라고 한다."
            ],
            "answer": "b",
            "topic": [
                "대헌 언어모델의 특성"
            ]
        },
        "true_false": {
            "question": "소량의 예제를 제공한 후 학습하여 문제 해결 능력을 향상시키는 것을 제로샷 방식이라 한다.",
            "answer": "FALSE",
            "topic": [
                "제로샷 방식의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "A Tale of Two Structures_ Do LLMs Capture the Fractal Complexity of Language__ko_translation.pdf:2:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "LLM은  교육  중에  교사  강제를  사용하는데,  이때  항상  올바른  이전  토 큰이  제공됩니다.  이를  통해 훈련  중에는  오류가  누적되지  않지만  추론  중에는  모델이  자체  예측에  의존 해야  하므로 프랙탈  구조를  왜곡할  수  있는  복합  오류로  이어질  가능성이  있습니다 .  공 식적으로  말하면  LLM은 다음  토큰  레벨에서  잘  교정되어  더  긴  시퀀스에  걸쳐  분포를  정확하게  예 측하는  능력이  있습니다. 토큰은  추론  중에  저하될  수  있습니다. 또  다른  잠재적  과제는  인간이  언어를  생성하는  방식에  있습니다 .  인간은   일반적으로  먼저  텍스트를  생성합니다. 하나의  토큰을  즉흥적으로  사용하는  것보다  기본  '맥락'을  개념화한  다 음  이를  기반으로  문장을  구성하는  것  입니다. 전체적인  의도를  고려하지  않은  시점에.  이것은  포착됩니다. 그림  1의  인과  모델에  따르면  잠재적인  '컨텍스트'  '접두사'(텍스트의  시작)를  생성하고, 이  접두사를  사용하면  둘  다  '접미사'(계속)를  생성합니다",
                "provenance": {
                    "doc_id": "A Tale of Two Structures_ Do LLMs Capture the Fractal Complexity of Language__ko_translation.pdf:2:0001",
                    "page": 2
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "LLM은 교사 강제 방식을 통해 학습 중 오류 누적을 방지하지만, 추론 시 자체 예측에 의존하면서 누적 오류가 발생해 긴 시퀀스 예측 정확도가 저하될 수 있다. 인간은 이러한 방식과 달리 먼저 맥락을 개념화하고 이를 기반으로 문장을 구성하는 인과적 언어 생성 과정을 따른다.",
        "long_answer": {
            "question": "언어 모델 훈련 과정에서 교사 강제 방식의 사용 이유와 한계를 설명하라.",
            "answer": "훈련 과정에서 LLM은 항상 올바른 토큰이 이전에 제공되는 교사 강제 방식을 사용한다. 이로 인해서 학습 중에 오류가 누적되지 않도록 방지할 수 있다. 그러나 추론 시, 모델이 자체 예측에 의존하게 됨으로써 프랙탈 구조를 왜곡할 수 있는 복합 오류로 이어질 가능성이 있다.",
            "rubric": [
                "교사 강제 방식; 학습 중 오류 누적 방지; 자체 예측 의존; 프랙탈 구조의 왜곡; 복합 오류 발생"
            ]
        },
        "short_answer": {
            "question": "LLM에 훈련 과정 중, 항상 정답과 가까운 토큰을 제공하는 방식을 무엇이라 하는가?",
            "answer": "교사 강제 방식",
            "topic": [
                "교사 강제 방식의 정의"
            ]
        },
        "multiple_choice": {
            "question": "LLM 학습 과정 중에 나타나는 현상에 대한 기술이다. 기술한 내용 중 적절한 것은?",
            "choices": [
                "a) 교사 강제 방식은 올바른 토큰을 학습하기 때문에 자체 추론에도 크게 문제가 되지 않는다.",
                "b) 교사 강제 방식을 통한 추론 과정과 인간의 추론 과정은 일치한다.",
                "c) 훈련 과정 중에 교사 강제 방식은 올바른 토큰을 학습하여 이를 통해 오류가 누적되지 않게 하는 것이다.",
                "d) 인간이 언어를 생성하는 방식은 전체적으로 의도를 고려하지 않은 채 한 번에 하나의 토큰을 생성하는 과정이다."
            ],
            "answer": "c",
            "topic": [
                "LLM의 학습 과정에 나타나는 특징"
            ]
        },
        "true_false": {
            "question": "LLM과 달리, 인간이 언어를 생성하는 과정은 기저에 있는 맥락을 먼저 개념화하고 문장을 구성한다는 것이다.",
            "answer": "TRUE",
            "topic": [
                "LLM과 인간의 언어 생성 방식"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "A Tale of Two Structures_ Do LLMs Capture the Fractal Complexity of Language__ko_translation.pdf:3:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "비록  우리  연구가  LLM  생성  콘텐츠를  탐지하는  데  영향을  미칠  수  있지만 ,  탐지가   이  작업의  주요  초점은  아닙니다.  그러나  LLM  생성  콘텐츠를  탐지하는  것이  중요 하며  여러  주목할  만한  연구의  주제였다는  점을  인정하는  것이  중요합니다.  여기에 는  위에서  언급한  복잡도  기반  탐지  방법과  지도  분류  접근  방식  (Verma  et  al.,   2024;  Pu  et  al.,  2022;  Jawahar  et  al.,  2020;  Ghosal  et  al.,  2023;  Tang   et  al.,  2024;  Dhaini  et  al.,  2023;  Guo  et  al.,  2023)이  포함되며,  사전  학습 된  모델의  미세  조정이  특히  효과적  입니다  (Zellers  et  al.,  2020;  Solaiman  et   al.,  2019  Fagni  et  al.,  2021).  이러한  콘텐츠를  감지하는  데는  내재적인  한계가  있지만   (Varshney  et  al.,  2020;  Sadasivan  et  al.,  2024),  LLM은  인간  언어의  완전 한  공동  분포를  모델링하도록  훈련되기  때문에 ,  이  분야의  지속적인  발전은  사회 적  위험을  완화하는  데  필수적입니다.  여기에는  잘못된  정보의  확산  (Zellers  et   al.,  2020),  가짜  온라인  리뷰  (Yao  et  al.,  2017),  잠재적으로  해로운  의학적  조 언  (Guo  et  al.,  2023),  학문적  부정직  ( Susnjak,  2022),  극단주의  선전   (McGuffie  &  Newhouse,  2020)  등이  포함되지만  이에  국한되지는  않습니다.  이 러한  노력의  중요성은  LLM에서  생성한  뉴스  기사  가  사실과  다른  내용을  담고  있 지만  최소한의  인적  감독만  거친  채  게재된  사례에서  더욱  두드러집니다  (Christian,   2023).  저희의  연구가  이러한  방향에  도움이  되기를  바랍니다 .",
                "provenance": {
                    "doc_id": "A Tale of Two Structures_ Do LLMs Capture the Fractal Complexity of Language__ko_translation.pdf:3:0001",
                    "page": 3
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "LLM 생성 콘텐츠 탐지의 시사점은 탐지 자체뿐만 아니라, 복잡도 기반 및 지도 학습 접근법과 사전 학습 모델의 미세 조정이 효과적임을 밝히는 것이다. 그럼에도 내재적인 한계가 존재하며, 그 한계에는 허위 정보, 가짜 리뷰, 유해한 의학 정보, 학문적 부정행위, 극단주의 선전 등 사회적 위험 등이 있다. 이런 위험을 완화하기 위한 지속적인 발전이 필요함을 강조한다.",
        "long_answer": {
            "question": "LLM의 생성 콘텐츠 탐지 영역이 가지는 의의를 예를 들어 서술하라.",
            "answer": "LLM의 생성 콘텐츠 탐지 영역은 인간 언어의 공동 분포를 모델링하도록 학습된 만큼, 이 분야에 대한 지속적인 발전이 필요하다. 예를 들어, LLM이 사실과 다른 뉴스 기사를 생성하여 이를 제대로 확인하지 않고 게재한 일이 있었다. 이러한 예로 보았을 때, 해당 분야에서의 발전은 LLM이 가짜 온라인 리뷰, 학문의 부정행위, 극단주의 선전 등 사회에 위험 요소로 활용될 수 있다는 것을 미연에 방지할 수 있다.",
            "rubric": [
                "가짜 뉴스의 생산; 학문적 부정행위 방지; 극단주의 선전 방지; LLM 생성 콘텐츠 탐지 영역의 발전 이유"
            ]
        },
        "short_answer": {
            "question": "LLM 생성 콘텐츠 탐지의 중요한 연구 주제로는 무엇이 있는지 2가지만 제시하라.",
            "answer": "복잡도 기반 탐지 방법, 지도 학습 분류 접근법",
            "topic": [
                "LLM 생성 콘텐츠 탐지의 연구 주제"
            ]
        },
        "multiple_choice": {
            "question": "아래는 LLM 생성 콘텐츠 탐지에 대한 설명이다. 해당 설명 중 바르지 않은 것은?",
            "choices": [
                "a) LLM 생성 콘텐츠의 위험 요소를 감소하기 위해서는 사전 학습 데이터가 올바르면 문제는 크게 없다.",
                "b) LLM 생성 콘텐츠의 탐지의 주된 목표는 가짜 뉴스와 같은 사회적 위험 요소를 완화하는 것이다.",
                "c) LLM 생성 콘텐츠의 탐지는 지속적으로 더 발전을 해야한다.",
                "d) LLM이 콘텐츠를 생성할 때, 사회적 위험 요소를 탐지할 수 있는 인간의 사고 영역도 필수적이다."
            ],
            "answer": "a",
            "topic": [
                "LLM 생성 콘텐츠의 탐지 중요성"
            ]
        },
        "true_false": {
            "question": "LLM 생성 콘텐츠 탐지의 시사점은 완벽한 학습데이터를 구축해야한다는 것이다.",
            "answer": "FALSE",
            "topic": [
                "LLM 생성 콘텐츠 탐지의 시사점"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "A Tale of Two Structures_ Do LLMs Capture the Fractal Complexity of Language__ko_translation.pdf:3:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "본  연구에서는  모델  크기를  포함한  다양한  요인의  영향을  검토합니다.  기존  문헌에  서는  모델  크기가  클수록  성능이  더  우수하며,  확장의  이점은  경험적으로  예측  가능  하다는  점을  일관되게  보여주고  있습니다  (Hestness  et  al.,  2017;  Kaplan  et    al.,  2020;  Alabdulmohsin  et  al.,  2022;  Zhai  et  al.,  2022).  이러한  개선은    복잡도  점수에만  국한되지  않습니다.  예를  들어,  Dou  et  al.,  2022는  더  큰  모델  이  사실  및  일관성  관련  문제가  적은  텍스트를  생성한다는  것을  발견했습니다 .  놀  랍지  않게도,  사전  학습된  더  큰  모델이  자연어의  프랙탈  매개변수에  더  가까운  프  랙탈  매개변수를  생성한다는  사실도  확인했습니다  (그림  3  참조).  또한,  온도  설정과  같은  다른  요인들도  조사합니다 .  이전  연구에  따르면  향상된  디  코딩  방법이  사람을  속일  수는  있지만,  동시에  탐지  가능한  통계적  이상  현상도  유  발할  수  있습니다  (Ippolito  et  al.,  2020).  본  연구는  프랙탈  관점에서  이러한  효  과를  자세히  탐구하여  모델  매개변수가  LLM  출력에  미치는  영향에  대한  더  폭넓은 이해에 기여합니다.",
                "provenance": {
                    "doc_id": "A Tale of Two Structures_ Do LLMs Capture the Fractal Complexity of Language__ko_translation.pdf:3:0001",
                    "page": 3
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "모델 크기와 디코딩 온도 등 다양한 요인은 LLM 성능과 출력에 미치는 영향이 크다. 모델이 클수록 사실성과 일관성이 향상되고 자연어의 프랙탈 매개변수에 근접함을 확인하는 것이 필요하다. 또한 디코딩 기법이 자연스러운 출력을 생성하는 동시에 통계적 이상 현상을 유발할 수 있음을 프랙탈 관점에서 연구할 수 있다.",
        "long_answer": {
            "question": "언어 모델의 크기이 성능에 미치는 영향에 대해서 간략히 서술하라.",
            "answer": "언어 모델의 성능은 크기와 관련이 있다. 즉. 모델 크기가 크면 클수록 그 성능이 향상되며, 이에 대한 증명은 경험적으로 예측 가능함을 일관되게 보여준다는 점에서 알 수 있다. 즉, 단순한 퍼플렉서티 점수에 국한된 것이 아니며 사실적이고 일관적인 텍스트를 생성한다는 것이 증명을 뒷받침 한다.",
            "rubric": [
                "언어 모델의 성능; 모델의 크기와 비례; 사실성 및 일관성; 경험적 예측 가능함"
            ]
        },
        "short_answer": {
            "question": "언어 모델의 크기와 성능의 상관 관계를 파악하기 위해 반드시 필요한 요소는 무엇인가?",
            "answer": "생성된 텍스트의 사실성, 일관성",
            "topic": [
                "언어 모델의 크기와 성능 상관 관계의 필수 요소"
            ]
        },
        "multiple_choice": {
            "question": "다음은 언어 모델의 성능에 영향을 미치는 요인에 대한 설명이다. 이 중 바르게 설명한 것은?",
            "choices": [
                "a) 언어 모델의 성능을 판단하는 여러 요인 중 하나로 편향성을 들 수 있다.",
                "b) 언어 모델의 성능은 모델의 크기가 크면 클수록 그 성능이 높아진다는 것을 알 수 있다.",
                "c) 언어 모델의 성능은 자연어의 프랙탈 매개변수에 멀수록 그 성능이 뛰어남을 알 수 있다.",
                "d) 언어 모델의 성능의 판단 지표는 퍼플렉서티 점수에 국한되어 있다."
            ],
            "answer": "b",
            "topic": [
                "언어 모델의 성능 향상 요인"
            ]
        },
        "true_false": {
            "question": "디코딩 기법의 활용은 인간을 속일 수 있는 자연스러운 출력은 물론, 통계적 이상 현상을 탐지할 수 있다는 것이다.",
            "answer": "TRUE",
            "topic": [
                "디코딩 기법의 효과"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "A Tale of Two Structures_ Do LLMs Capture the Fractal Complexity of Language__ko_translation.pdf:6:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": " Q6.  프랙탈  매개변수는  출력  품질과  어떤  관련이  있습니까?  이  질문에  답하기  위해  먼  저  홀더  지수  S가  확률  과정  에서  자기  유사성  수준을  정량화한다는  점을  상기해  보겠습  니다.  값이  작을수록  자기  유사성이  높은  구조(더  두꺼운  꼬리)를  나타냅니다.  즉 ,  모든    세분성  수준에서  복잡하고  풍부한  세부  정보가  있습니다.  따라서  S  값이  낮을수록  좋습  니다.  반대로  허스트  지수  H는  시간에  따른  종속성을  정량화합니다 .  H  ≈  0.5  에  가까  운  값은  종속성이  없음(즉,  과정이  무작위적임)을  나타내는  반면  H  ≈  1.0  에  가까운  값  은  예측  가능성이  높음(예:  동일한  텍스트가  계속  반복되는  경우)을  나타냅니다.  자연어    는  H  ≈  0.65  에  가까운  값을  갖습니다 .  실제로  LLM은  단어를  완전히  무작위로  생성하  지  않으므로  H  와  모델  품질  간의  상관관계는  음수입니다.  이러한  이유로  H는  S  와도  강  력하고  양의  상관관계를  가지며  피어슨  계수는  0.68이고  p값은  <  10 15  입니다 .",
                "provenance": {
                    "doc_id": "A Tale of Two Structures_ Do LLMs Capture the Fractal Complexity of Language__ko_translation.pdf:6:0001",
                    "page": 6
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "홀더 지수(S)는 값이 낮을수록 자기유사성이 높고 복잡한 구조를 나타내며, 바람직하다고 볼 수 있다. 반면 허스트 지수(H)는 시간 종속성을 나타내며 자연어에서 약 0.65의 값을 가진다. LLM은 무작위로 단어를 생성하지 않기 때문에 허스트 지수와 모델 품질 간에는 음의 상관관게가 있고, 홀더 지수와 허스트 지수의 피어슨 상관 계수는 0.68(p < 10⁻¹⁵)의 강한 양의 상관관계를 보인다.",
        "long_answer": {
            "question": "출력 품질을 홀더지수로 판단할 수 있는 기준은 무엇인가?",
            "answer": "홀더 지수는 확률과정에서 자기유사성의 정도를 정량화한다. 즉, S값이 작을수록 구조가 더 자기유사적이다. 그래서 꼬리가 두껍게 나타나며 모든 세분화 수준에서 복잡하고 풍부한 정보를 담고 있다고 본다. 따라서 자기유사성 정도인 S값이 낮을수록 출력 품질이 바람직하다고 판단할 수 있다.",
            "rubric": [
                "홀더지수; 자기유사성; S값의 작음; 바람직한 품질"
            ]
        },
        "short_answer": {
            "question": "허스트 지수를 통해 알 수 있는 지표는 무엇인가?",
            "answer": "시간의 종속성",
            "topic": [
                "허스트 지수를 통한 판단 지표"
            ]
        },
        "multiple_choice": {
            "question": "다음은 홀더지수와 허스트지수에 대한 설명이다. 설명 중 틀린 것은?",
            "choices": [
                "a) 홀더 지수는 시간에 따른 종속성을 나타내는 지수이다.",
                "b) 자연어에서의 허스트 지수는 대체적으로 0.65의 값을 지니고 있다.",
                "c) 홀더 지수는 그 숫자가 적을수록 출력 품질이 좋다고 판단할 수 있다.",
                "d) 허스트 지수와 모델의 품질 간의 관계는 보통 음의 상관관계로 존재한다."
            ],
            "answer": "a",
            "topic": [
                "홀더 지수와 허스트 지수의 특징"
            ]
        },
        "true_false": {
            "question": "허스트 지수에서 그 값이 0.5에 가까울수록 종속성이 있다고 판단한다.",
            "answer": "FALSE",
            "topic": [
                "허스트 지수의 기준값"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:3:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "3.2.  활성  정책  미세  조정 본  연구에서는  다중  작업  정책에  대한  능동적  미세  조정  기법을  고려합니다 .  목표는   가능한  한  적은  전문가  시연을  사용하여  원하는  작업  분포  µc  에서  잘  수행되도록   사전  훈련된  정책을  미세  조정하는  것입니다.  에이전트는  미세  조정  예산  에  따라  시 연을  위한  N개의  순차적  쿼리를  허용받습니다 .  n번째  쿼리는  작업  cn  ∈  C로  구성 되어야  합니다.  에이전트가  작업을  선택하면  S  ×  C  →  A  (즉,  최적  정책  π  시연자로 부터  최적값)의  피드백을  받습니다.  각  라운드에서  에이전트는  선택한  작업  cn에  따 라  H‑단계  시연을  받습니다.  이는  궤적  τ :  C  →  ∆((S  ×  A)  H)  에  대한  확률  과정 의  단일  측정값으로  볼  수  있습니다 .  라운 드  n  까지  관찰된  각  궤적은  데이터   집합  (c1:n,  τ 1:n)에  저장됩니다. 정책을  미세  조정하고  n+  1  단계에서  에이전트의  질의를  조건화하는  데  사용할  수  있습니다.   이  프로세스는  N  라운드  동안  반복되며,  원하는  작업  분포  µc에  대한  기대  수익을  극대화하 는  미세  조정된  정책을  생성하는  것을  목표로  합니다 .  미세  조정  프로세스는  사전  학습  데이 터  분포에  대한  접근을  가정하지  않습니다.  이러한  설정은  대규모  사전  학습  데이터  세트가  공 개적으로  제공되는  경우가  드물다는  점에서  현실적이지만 ,  단순한  데이터  재조정  전략을  금지 한다는  점에서  까다롭습니다",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:3:0001",
                    "page": 3
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "사전 학습된 정책을 최소한의 전문가 시연으로 목표 작업 분포에서 최적 성능을 내도록 능동적으로 미세 조정하는 기법을 제안하며, 에이전트가 반복적인 쿼리와 시연을 통해 기대 수익을 극대화하는 정책을 학습하도록 한다. 이 과정은 사전 학습 데이터에 접근하지 않은 현실적이지만 데이터 재균형이 불가능한 도전적 설정에서 수행된다.",
        "long_answer": {
            "question": "활성 정책 미세 조정의 기법에서 에이전트는 어떤 역할을 하는 것인지 설명하라.",
            "answer": "에이전트는 미세 조정 예산에 따라 총 N회의 순차적 쿼리를 수행할 수 있다. n번째 쿼리 작업은 cn∈C로 구성된다. 에이전트가 특정 작업을 선택하면, 최적의 정책 'π⋆: S × C → A'로 부터 피드백을 받을 수 있다. 각각의 라운드에서 에이전트는 선택한 작업 cn에 따라 H단계 시연을 제공받아, 확률적 궤적 과정의 하나의 샘플로 형성된다.",
            "rubric": [
                "활성 정책 미세조정; 에이전트; π⋆: S × C → A; 확률적 궤적 과정"
            ]
        },
        "short_answer": {
            "question": "활성 정책 미세 조정의 가장 큰 단점은 무엇인가?",
            "answer": "단순한 데이터 재균형",
            "topic": [
                "활성 정책 미세 조정의 단점"
            ]
        },
        "multiple_choice": {
            "question": "활성 정책 미세 조정에 대한 설명이다. 이 설명으로 틀린 것은?",
            "choices": [
                "a) 가장 적은 수의 전문가 시연을 통해 목표 작업 분포(µc)에서 높은 성능을 발휘하도록 미세조정 하는 것이다.",
                "b) 에이전트는 미세 조정 예산에 따라 총 N회로 순차적 쿼리를 수행할 수 있다.",
                "c) 이 미세조정 과정은 사전 학습 데이터 분포에 접근할 수 있음을 가정한다.",
                "d) N라운드를 걸쳐 반복되는 과정 속에서 목표 작업 분포에 대한 기대 수익을 극대화하는 것이 핵심이다."
            ],
            "answer": "c",
            "topic": [
                "활성 정책 미세 조정의 특징"
            ]
        },
        "true_false": {
            "question": "라운드 n까지 관찰된 모든 궤적은 데이터셋에 저장되고, 이는 정책을 미세 조정하여 다시 롤백하여 에이전트의 쿼리를 처음부터 수행하게끔 만든다.",
            "answer": "FALSE",
            "topic": [
                "활성 정책 미세 조정의 핵심 과정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:5:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "커널  근사   정책이  신경망을  통해  매개변수화될  때,  조건부  엔트로피  추정은  훨씬  더  복잡합니다.    첫째,  불확실성  추정을  위한  임시  기법(예:  드롭아웃  (Srivastava  et  al.,  2014;  Gal  &    Ghahramani,  2016)  또는  앙상블  (Lakshminarayanan  et  al.,  2017))  의  가용성을  가정  할  수  없습니다.  이러한  기법  은  사전  학습된  모델에  포함되지  않을  수  있기  때문입니다  사전  학습된  모델이  미세  조정을  위해  섭동되고  앙상블화되더라도 ,  앙상블  불일치는  사전  학습    데이터  분포를  포착하지  못할  것입니다.  둘째,  사전  학습  데이터에  대한  접근은  일반적으로  비현  실적이거나  대규모  로봇  데이터  세트의  크기와  소유권으로  인해  관리하기  어렵습니다   그럼에도  불구하고,  우리는  신경망의  근사를  임베딩  공간  π(s,  c;  θ)  =  β  θ(s,  c)에  대한  선  형  함수로  활용할  수  있습니다.  여기서  가중치  β  와  임베딩  θ(·)는  모두  p차원  잠재  공간  에    존재합니다  (Lee  et  al.,  2019;  Khan  et  al.,  2019).  이  기법은  위에  나열된  실질적인  제약을    위반하지  않으며,  GP  설정에  도입된  기법을  적용할  수  있습니다 .  여러  임베딩  전략이  존재하지  만  (Jacot  et  al.,  2018;  Devlin  et  al.,  2019;  Holzmuller  et  al. ,  2023),  본  연구에서는  손  실  그래디언트  임베딩  (Ash  et  al.,  2020)을  채택합니다 .  사전  확률  β      정책  π(s,  c;  θ)  는  커널  kθ((s,  c),(s  c′ ))  =  θ(s,  c),    N  (0,  I)을  가정하면,    θ(s  c  ′ )을  갖는  가우시안  프로세  ¨  스로  모델링될  수  있습니다 .  이  근사치와  결합하면 ,  방정식  2  의  조건부  엔트로피  목적은  다음  과  같이  다시  공식화  될  수  있습니다 . ",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:5:0001",
                    "page": 5
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "커널 근사에서 신경망으로 매개변수화된 정책의 조건부 엔트로피 추정은 불확실성 추정 기법의 부재와 사전 학습 데이터의 접근 한계로 복잡한 문제라 할 수 있다. 그러나 이를 임베딩 공간에서 선형 함수로 근사하여 가우시안 프로세스 기법을 적용할 수 있다. 즉, 손실 그래디언트 임베딩을 사용해 정책을 가우시안 프로세스로 모델링하고 조건부 엔트로피 목적식을 재정의하였다.",
        "long_answer": {
            "question": "커널 근사에서 조건부 엔트로피 추정이 복잡한 이유를 두 가지로 들어 설명하라.",
            "answer": "커널 근사에서 정책이 신경망으로 매개변수화가 된다면 조건부 엔트로피 추정이 복잡해진다. 그 이유로는 첫째, 불확실성 추정을 위한 임시 기법이나 앙상블의 사용 가능성을 가정할 수 없기 때문이다. 둘째, 사전 학습 데이터에 접근하는 것이 일반적으로 비현실적이거나 대규모의 로봇 데이터셋의 크기 및 소유권 문제가 있어 관리가 어렵기 때문이다.",
            "rubric": [
                "커널 근사; 조건부 엔트로피 추정; 불확실성 추정; 임시 기법; 앙상블; 사전 학습 데이터의 접근성; 소유권의 문제"
            ]
        },
        "short_answer": {
            "question": "신경망을 임베딩 공간상 '선형 함수'로 근사할 때, 'π(s,c;θ)=β⊤ϕθ​(s,c)'의 표현에서 가중치 β와 임베딩 ϕ_θ(·)는 어느 차원에 존재하는가?",
            "answer": "p차원 잠재 공간",
            "topic": [
                "임베딩 공간 상 신경망의 차원 존재"
            ]
        },
        "multiple_choice": {
            "question": "다음은 커널 근사에 대한 설명을 나타낸 것이다. 설명 중 바른 것은?",
            "choices": [
                "a) 커널 근사는 사전 학습 데이터에 직접 접근하여 신경망의 비선형 구조를 복원하는 방법이다.",
                "b) 신경망 정책은 임베딩 공간에서 비선형 함수로 근사되며, 가우시안 프로세스와는 무관하다.",
                "c) 손실 그래디언트 임베딩은 사전 학습 데이터 분포를 재현하기 위한 데이터 복구 기법이다.",
                "d) 신경망 정책은 임베딩 공간 상의 선형 함수로 근사할 수 있으며, 이때 가우시안 프로세스 설정이 적용될 수 있다."
            ],
            "answer": "d",
            "topic": [
                "커널 근사의 특징"
            ]
        },
        "true_false": {
            "question": "신경망을 임베딩 공간에서 선형함수로 나타낼 때, 적용할 수 있는 기법은 가우시안 프로세스이다.",
            "answer": "TRUE",
            "topic": [
                "커널 근사에서 가우시안 프로세스의 활용법"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:5:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "망각  처리하기  재앙적  망각은  새로운  데이터에  대한  최적화가  비국소적이어서  학습  진행을  무효  화할  수  있기  때문에  훈련  분포로의  변화  에  따른  신경  기능  근사에  내재된  문제  입니다  (Mc‑    Closkey  &  Cohen,  1989;  French,  1999).  이  문제는  우리의  설정에서  중요한데,  미세  조정    분포를  적극적으로  안내하면  필연적으로  사전  훈련에서의  분포  변화가  강조되기  때문입니다 .  이  를  완화하기  위한  일반적인  전략에는  종종  리허설  (Atkinson  et  al.,  2021;  Verwimp  et  al.,    2021)  이나  정규화  (Kirkpatrick  et  al.,  2017)가  포함됩니다.  안타깝게도  전자는  사전  훈련    데이터에  대한  접근성이  부족하여  이  설정에서  불가능  하고  후자는  경험적으로  효과적이지  않은    것으로  나타났습니다(부록  H  참조).  규모와  다양한  사전  학습  데이터  세트도  망각을  완화할  수    있지만  (Ramasesh  et  al.,  2022),  미세  조정  중에는  둘  다  제어할  수  없습니다",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:5:0001",
                    "page": 5
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "재앙적 망각은 훈련 분포의 변화로 인해 새로운 데이터 최적화 과정에서 이전 학습이 무효화되는 신경망의 고유한 문제로, 미세 조정 시 분포 차이가 커질수록 심화된다. 이를 완화하기 위한 리허설과 정규화 기법은 각각 데이터에 대한 접근 불가와 낮은 효과로 한계가 있다. 또한 대규모 사전 학습데이터셋이 도움은 되지만, 미세조정 과정에서는 제어할 수 없다.",
        "long_answer": {
            "question": "망각 처리 과정에서 재앙적 망각이 문제가 되는 이유를 설명하라.",
            "answer": "재앙적 망각은 새로운 데이터에 대한 최적화의 범위가 넓어 나타나는 문제이다. 즉, 이전 학습을 무효화할 수 있는 '훈련 분포 변화에 대한 신경망 근사'에 대한 고유한 문제점이라 할 수 있다. 이 문제는 미세 조정 분포를 적극적으로 조정할수록 사전 학습 분포와의 차이가 커지는 문제점을 가지고 있다.",
            "rubric": [
                "재앙적 망각; 최적화의 범위; 이전 학습의 무효화; 훈련 분포 변화에 대한 신경망 근사"
            ]
        },
        "short_answer": {
            "question": "재앙적 망각 문제를 해결하기 위한 가장 일반론적인 접근법은 무엇이 있는지 2가지로 나열하라.",
            "answer": "리허설, 정규화",
            "topic": [
                "재앙적 망각 문제 해결을 위한 일반론적 접근법"
            ]
        },
        "multiple_choice": {
            "question": "재앙적 망각과 관련된 내용을 기술한 것이다. 내용 중 올바른 것은?",
            "choices": [
                "a) 재앙적 망각은 새로운 데이터에 대한 최적화가 국소적이어서 나타나는 문제이다.",
                "b) 재앙적 망각은 미세 조정 분포를 적극적으로 조정할수록 사전 학습과의 분포에서 차이를 보인다.",
                "c) 재앙적 망각의 완화 방법으로는 소규모의 데이터를 활용하는 것이다.",
                "d) 재앙적 망각을 해결하기 위해서는 새로운 데이터를 학습시키지 않으면 된다."
            ],
            "answer": "b",
            "topic": [
                "재앙적 망각에 대한 특징"
            ]
        },
        "true_false": {
            "question": "재앙적 망각을 완화하기 위한 방법으로 대규모의 학습데이터를 활용하면 미세조정 과정에서도 조정할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "재앙적 망각 완화를 위한 대규모 학습 데이터의 활용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:5:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "따라서  우리는  멀티태스킹  정책을  미세  조정할  때  발생하는  치명적인   망각을  완화하기  위한  실용적인  알고리즘  솔루션을  제안합니다 . 직관적으로,  우리는  정책이  사전  훈련  과정에서  습득한  기술을  유지하는  동시에  미세  조정  과정에 서  새로운  과제에  집중하기  를  원합니다 .  행동  신경망  분야의  이전  연구에서  영감을  얻었습니다.  사전  확률  (Bagatella  et  al.,  2022)  과  오프라인  RL  (Kumar  et  al.,  2020)  을  사용하는  경우,  사전  학습된  정책의  사본을  보존하는  것을  제안하며,  이를    사전  확률  (πp)이라고  합니다.  주어진  상태  s  ∈  S  와  작업  c  ∈  C  에  대해 ,    미세  조정된  정책  π  에서  샘플링된  동작  과  사전  확률에서  샘플링된  동작을  선  형적으로  결합할  수  있습니다.  a  =  α(c) a  +  (1      α(c))¯a,  여기서  a      π(·|s,  c),  a¯      πp(·|s,  c).  결정적으로,  α(c)  ∈  [0,  1]  은  대리  행동  복제    손실에  대한  경사  하강법을  통해  학습된  작업  종속  가중치  이며,  0에  근접하도  록  유도하는  추가적인  보수적  페널티가  적용됩니다.  결과적으로,  특정  작업에  서  사전  학습  성능을  강건하게  능가하는  즉시,  행동은  미세  조정된  정책의  출  력으로  이동합니다 .  미세  조정  과정에서  개선되지  않은  작업은  사전  학습  샘플  에  의존하며 ,  잊혀지지  않습니다.  이  기법을  적응적  사전  학습(Adaptive    Prior)이라고  하며,  부록  H  에서  자세한  설명과  연속  학습  기법과의  비교를  제  시합니다",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:5:mh: 00001",
                    "page": 5
                }
            },
            {
                "context_id": "2",
                "text": " AMF‑GP에서  요구하는  근사치를  엔트로피  추정  및  재앙적  망각  방지를  위한    설명된  솔루션과  결합함으로써  우리는  신경망을  통해  매개변수화된  정책의  능  동적  멀티태스크  미세  조정을  위한  방법을  얻습니다 .  이를  AMF‑NN이라고  합  니다",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:5:mh: 00001",
                    "page": 6
                }
            }
        ],
        "summarization": "사전 학습된 정책의 사본을 활용해, 미세 조정 중 발생하는 재앙적 망각을 완화하는 적응적 사전 기법을 제안한다. 이는 작업별 가중치 α(c)를 통해 사전 정책과 미세 조정 정책의 출력을 선형 결합하여 학습 성능을 유지하고 향상시킨다. 또한 이 접근법을 엔트로피 추정 및 근사 기법과 결합해 '신경망 기반 능동형 다중 작업 미세 조정 방법'을 제시한다.",
        "long_answer": {
            "question": "적응적 사전 기법의 핵심이 무엇인지 설명하시오.",
            "answer": "특정 작업에서 미세 조정된 정책이 사전 학습 성능을 확실히 능가하면 행동은 점진적으로 미세 조정된 정책의 출력으로 전이된다. 반면 미세 조정 과정에서 개선되지 않은 작업은 사전 정책 샘플에 의존해서 망각되지 않는다. 이러한 기법을 적응적 사전이라 부르며, 경사 하강법을 적용한 것이다.",
            "rubric": [
                "적응적 사전 기법; 미세조정된 정책으로의 점진적 전이; 경사 하강법"
            ]
        },
        "short_answer": {
            "question": "대리 행동 복제 손실에 대해 경사 하강법으로 학습된 가중치를 무엇이라 부르는가?",
            "answer": "작업 종속적 가중치",
            "topic": [
                "작업 종속적 가중치에 대한 정의"
            ]
        },
        "multiple_choice": {
            "question": "아래는 재앙적 망각을 완화하기 위한 실용적 알고리즘 솔루션에 대한 설명이다. 이 솔루션과 관련된 내용 중 옳지 않은 것은?",
            "choices": [
                "a) 사전 확률이란 사전 학습된 정책의 사본을 유지하는 것을 말한다.",
                "b) 작업 종속적 가중치는 보수적 패널티를 통해 0에 가까워지도록 유도된다.",
                "c) 엔트로피 추정 및 재앙적 망각 완화 솔루션을 결합한 것을 신경망 기반 능동형 다중 작업 미세 조정 방법이라 한다.",
                "d) 실용적 알고리즘 솔루션에는 대리 행동 복제 손실에 대한 기울기 소멸이 적용되었다."
            ],
            "answer": "d",
            "topic": [
                "재앙적 망각을 완화하기 위한 실용적 알고리즘 솔루션의 특징"
            ]
        },
        "true_false": {
            "question": "적응적 사전은 행동 사전과 오프라인 강화학습에 영감을 받은 것이다.",
            "answer": "TRUE",
            "topic": [
                "적응적 사전의 사용 배경"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:6:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "연속  작업  공간을  정의할  수  있습니다.  각  작업은  원점을  중심으로  하는  원  위의    한  지점에  도달하는  것으로  구성되며 ,  에이전트는  해당  지점까지의  음의  유클리  드  거리를  보상으로  받습니다.  평가  분포  µc는  서로  다른  방향의  12개  지점에  동  일한  확률을  할당합니다.  초기  상태  분포는  결정론적이고,  동역학은  결정론적  이  며  매끄럽습니다.  반면  전문가  정책은  매끄럽고  iid  가우시안  잡음으로  손상되었  습니다.  정책을  RBF  커널을  사용하는  가우시안  프로세스로  모델링하고 ,  12개  의  잡음이  있는  사전  학습  데이터셋을  조건으로  적용합니다.  그런  다음  AMF‑GP  와  균일  샘플링을  모두  실행하여  40개의  추가  데모를  수집합니다 .",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:6:0001",
                    "page": 6
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "연속적인 작업 공간에서 에이전트는 원 위의 지점에 도달하여 음의 유클리드 거리로 보상을 받고, 정책은 RBF 커널 기반 가우시안 프로세스로 모델링되어 12개의 잡음 시연 데이터를 학습한 뒤 AMF-GP와 균일 샘플링으로 40개의 추가 시연을 수집한다.",
        "long_answer": {
            "question": "연속적인 작업 공간에 대한 정의를 서술하라.",
            "answer": "연속적인 작업 공간은 원점을 중심으로 한 원 위의 한 지점에 도달하는 것으로 구성된다. 에이전트는 그 지점까지의 유클리드 거리의 음수값을 가진다. 그렇게 되면 평가 분포 µc는 서로 다른 방향에 위치하여 12개의 지점에 동일한 확률을 할당받는다.",
            "rubric": [
                "연속적인 작업 공간; 원점; 유클리드 거리의 음수값; 평가 분포µc; 동일한 확률"
            ]
        },
        "short_answer": {
            "question": "12개의 잡음이 포함된 시연 데이터를 조건으로 적용하고 RBF 커널을 사용할 경우, 사용할 수 있는 모델링은 무엇인가?",
            "answer": "가우시안 프로세스",
            "topic": [
                "가우시안 프로세스의 활용"
            ]
        },
        "multiple_choice": {
            "question": "다음은 연속적 작업 공간에 대한 설명이다. 이에 대한 설명으로 가장 적절한 것은?",
            "choices": [
                "a) 연속적 작업 공간은 기준이 되는 지점 없이 원 위의 분포된 점들로 구성된다.",
                "b) 에이전트는 원 위의 한 지점에 도달하는데까지 유클리드 거리의 양수값을 보상받는다.",
                "c) 평가분포 µc는 서로 다른 방향에 위치한 12개의 지점에 동일한 확률을 할당받는다.",
                "d) 초기 상태분포와 동역학은 모두 비결정론적이고 불연속적으로 정의된다."
            ],
            "answer": "c",
            "topic": [
                "연속적 작업 공간에 대한 정의"
            ]
        },
        "true_false": {
            "question": "연속적 작업 공간에서 전문가 정책은 매끄러운 형태를 유지하지 못한다.",
            "answer": "FALSE",
            "topic": [
                "연속적 작업 공간에서 전문가 정책의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:6:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "건전성  검증을  위해,  각  평가  작업이  정확히  한   번만  시연되는  완벽하게  균일한  사전  학습  체계 를  먼저  고려합니다 .  따라서  사전  학습  작업  분 포  µD  ∈  ∆(C)  는  평가  작업  분포  µC  와  완벽 하게  일치합니다  (그림  2 ,  왼쪽).  AMF‑GP는  정 책의  엔트로피를  적극적으로  최소화하므로,  균일 한  시연  샘플링에  비해  정책의  수익률을  약간  더   빠르게  증가시킵니다.  그런  다음  이  평가를  더욱   확장하여 영어 :  평가  분포에  대한  불일치가  특징인  획일적  사전  학습  분포 :   µC ≠ µD  (그림  2,  가운 데)  및  사전  학습  예산이  감소하는  수의  작업에  할당됨에  따라  두  방법  의  최종  성능을  비교 합니다 .사전  학습  분포가  µC  에서  벗어나  면  (예:  그림  2,  오른쪽에서  12개  작업  중  6개만  시 연하는  경우)  균일  작업  샘플링과  AMF‑GP  간의  성능  격차가  커지는  것을  관찰합니다 .이는   예상할  수  있는  일인데,  이  경우  다음  시연의  정보  이득은  쿼리된  작업에  크게  의존하고  방정 식  1  의  기준의  arg  max를  취하는  것이  무작위  작업을  선택하는  것보다  훨씬  낫기  때문입니 다.직관적으로  이  경우  작업의  균일  샘플링은  사전  학습  중에  덜  자주  관찰  된  작업에  대한  시 연을  안정적으로  제공하지  못합니다.",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:6:0001",
                    "page": 6
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "AMF-GP는 균일한 사전 학습 체계에서 정책의 엔트로피 최소화하여 균일 샘플링보다 수익을 더 빠르게 높이며, 평가 분포와 불일치하는 조건에서 사전 학습 분포가 평가 분포에서 멀어질수록 두 방법 간 성능 격차가 커지고 이는 정보 이득이 쿼리된 작업에 크게 의존하기 때문이다.",
        "long_answer": {
            "question": "건전성 검증에서의 고려 사항과 그 결과를 서술하라.",
            "answer": "건전성 검증을 하기 위해서는 먼저 각 평가 작업이 정확히 한 번씩만 시연되는 완전한 균일 사전 학습 체계여야 하는지 확인해야 한다. 이때 사전 학습 작업 분포 µD ∈ ∆(C)는 평가 작업 µc와 완전히 일치해야 한다. 이러한 검증의 결과는 엔트로피를 적극적으로 최소화할 수 있어, 균일 샘플링에 비해 정책의 수익이 약간 더 빠르게 증가한다.",
            "rubric": [
                "건전성 검증; 완전한 균일 사전 학습 체계; µD ∈ ∆(C)와 µc의 완전 일치; 엔트로피의 최소화; 정책 수익 빠르게 증가"
            ]
        },
        "short_answer": {
            "question": "건전성 검증을 위해서 무엇을 가장 먼저 고려해야하는가?",
            "answer": "완전한 균일 사전 학습 체계",
            "topic": [
                "건전성 검증을 위한 조건"
            ]
        },
        "multiple_choice": {
            "question": "아래는 건전성 검증에 대한 설명이다. 건전성 검증과 부합하지 않는 것은?",
            "choices": [
                "a) 건전성 검증으로 AMF-GP는 정책의 엔트로피를 최대화할 수 있다.",
                "b) 현실적인 조건을 반영하기 위해서는 평가 분포와 불일치하는 사전 학습 분포를 고려할 수 있다.",
                "c) 건전성 검증으로는 다음 시연으로부터의 정보 이득이 쿼리된 작업게 크게 의존한다는 것을 알 수 있다.",
                "d) 완전한 균일 사전 학습 체계를 고려하면, 사전 학습 작업 분포와 평가 작업 분포는 완전히 일치한다."
            ],
            "answer": "a",
            "topic": [
                "건전성 검증의 특징"
            ]
        },
        "true_false": {
            "question": "평가 분포와 불일치하는 사전 학습 분포를 고려할 때, 사전 학습 분포가 평균 작업 분포에서 멀어질수록 균일 작업 샘플링과 AMF-GP 간의 성능 격차가 점점 커진다.",
            "answer": "TRUE",
            "topic": [
                "평가 작업 분포와 사전 학습 분포 간의 상관관계"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:7:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": " 5.2.  AMF는  고차원  작업에도  확장될  수  있나요? 현실적인  환경에서는  AMF의  형식적  분석을  가능하게  하는  가정들이  곧  위반됩니다.  관심  환 경의  복잡성이  증가함에  따라,  대부분의  최신  행동  복제  애플리케이션은  정책  매개  변수화를   위해  신경망에  의존합니다  (Reed  et  al.,  2022;  Chi  et  al.,  2023).  이러한  패턴을  바탕  으 로,  본  연구에서는  AMF‑NN의  두  번째  버전인  AMF‑NN을  연구하고 ,  복잡하고  고차원적인   작업  에  대한  확장성을  평가합니다 .  두  가지  공통적인  문제를  고려합니다. 다중  작업  학습을  위한  벤치마크로,  둘  다  유한한  작업  집합을  사용합니다.   •  Metaworld  (Yu  et  al.,  2020)  에서는  로봇  팔,  컵,  수도꼭지가  있는    장면을  만들고 ,  컵을  두  개의  다른  위치로  옮기고,  수도꼭지를  열고    닫는  4가지  작업을  정의합니다.   •  FrankaKitchen  (Fu  et  al.,  2020)  에서는  손잡이를  켜거나  끄는    것,  회전식  또는  슬라이딩  캐비닛을  여는  것,  전자레인지  문을  여는    것  등  5가지  작업을  고려합니다 .  두  환경  모두에서,  상태  측정값과  원시  픽셀을  통해  학습할  때  AMF‑NN을  평가합니다 .  첫    번째  경우,  정책은  MLP를  통해  간단히  매개변수화되는  반면,  두  번째  경우  MLP는  사전  훈련  된  시각  인코더  (Nair  et  al.,  2022)의  임베딩을  받습니다.  정책은  약  15개의  총  데모를  통해    사전  훈련되며,  모든  작업에  균등하게  할당하거나  절반에만  할당하여  이전  실험에서  불일치  하지  않는  모드와  불일치하는  모드를  재현합니다 .  이후,  상태  측정값을  통해  학습할  때  AMF  NN을  20  번  반복하여  적용하고,  각  반복마다  하나의  데모를  수집합니다.  증가된  복잡성을    보상하기  위해,  시각  설정에서는  선택된  각  작업당  2개의  데모를  제공  하고  10번의  반복만  평  가합니다.",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:7:0001",
                    "page": 7
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "AMF의 형식적 가정이 현실 환경에서 위반됨에 따라 신경망 기반 정책을 사용하는 AMF-NN을 제안하였다. 이는 Metaworld와 FrankaKitchen 두 벤치마크 환경에서 상태값과 원시 픽셀 입력을 이용해 MLP 및 사전 훈련된 시각 인코더 기반으로 고차원 작업 확장성을 평가하였다.",
        "long_answer": {
            "question": "AMF-NN이 제안된 이유와 이를 평가하기 위한 실험 환경을 간결하게 기술하라.",
            "answer": "현실적 환경에서 AMF의 형식적 가정이 쉽게 위반되기 때문에, 복잡하고 고차원적인 작업에 대응할 수 있는 신경망 기반 확장 모델 AMF-NN이 제안되었다. AMF-NN은 로봇 조작 과제를 포함한 두 다중 작업 학습 환경인 Metaworld와 FrankaKitchen에서 평가되었다. 또한 상태 기반 학습에서는 MLP을, 시각 입력 기반 학습에서는 사전 훈련된 시각 인코더의 임베딩을 사용하는 방식으로 성능을 검증하였다.",
            "rubric": [
                "형식적 가정 위반; 신경망 기반 확장; AMF-NN; Metaworld; FrankaKitchen; 상태 기반 학습; 시각 기반 학습"
            ]
        },
        "short_answer": {
            "question": "로봇의 팔, 컵, 수도꼭지가 있는 장면을 구성하고 컵을 두 위치로 옮기거나 수도꼭지를 여닫는 등 총 4가지 작업을 정의한 벤치마크 데이터셋 명칭은?",
            "answer": "Metaworld",
            "topic": [
                "Metaworld의 데이터셋 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음은 AMF와 AMF-NN에 대한 내용이다. 기술한 내용 중 설명이 옳지 못한 것은?",
            "choices": [
                "a) 현실적 환경에서 AMF는 형식적 분석 가정이 쉽게 위배가 된다.",
                "b) AMF의 형식적 분석 가정이 위배되는 것은 현실에서의 환경 조건이 단순하기 때문이다.",
                "c) Metaworld와 FrankaKitchen는 모두 상태 측정값과 원시 픽셀 입력을 기반으로 학습되었다.",
                "d) 상태 기반 학습에서 정책을 단순화하기 위해 MLP로 매개변수화하였다."
            ],
            "answer": "b",
            "topic": [
                "AMF와 AMF-NN의 특징"
            ]
        },
        "true_false": {
            "question": "시각 입력 기반 학습은 MLP가 사전 훈련된 시각 인코더의 임베딩을 입력값으로 받는다.",
            "answer": "TRUE",
            "topic": [
                "시각 입력 기반 학습의 임베딩 방식"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:8:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "엔트로피  추정이  AMF‑NN의  핵심이므로,  우리는  손실  그래디언트  임베딩을  사 용한  채택된  GP  근사를  문헌의  다른  접근  방식과  추가로  비교합니다.특히,  우 리는  마지막  계층  임베딩  (Holzmuller  등 ,  2023)  을  사용하는  대체  GP  근 사  및  테스트  시간  드롭아웃  (Loquercio  등,  2020)도  고려합니다.  후자는  단 순히  사전  H(π(st,  c)  |  τ1:n 1),  엔트로피를  최대화하는  작업을  선택합니다 . 즉,  argc∈Cmax​Eτ1:n−1​∼τ(c1:n−1​),(s0​,…)∼τ(c)​t=0∑H−1​H(π(st​,c)∣τ1:n−1​)입니 다.  이  두  가지  계획은  모두  작업  레이블에  액세스할  필요가  없으므로  실제로   바람직합니다.그러나  우리는   H 1   t=0 이  두  가지  계획이  작업  선택을  주도하 는  데  덜  효과적이라는  것을  관찰했습니다.  따라서  그림  5  (및  부록  G)  에  표시 된  대로  멀티태스크  성능은  일반적으로  낮으며,  이는  엔트로피  추정  기술이   AMF‑NN에  중요하다는  것을  시사합니다",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:8:0001",
                    "page": 8
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "AMF-NN의 핵심인 엔트로피 추정을 검증하기 위해 손실 그래디언트 임베딩 기반 GP 근사를 다른 방법들과 비교하였다. 그 결과, 마지막 계층 임베딩과 테스트 시 드롭아웃 방식은 작업 레이블이 필요 없다는 장점이 있으나 작업 선택 효율이 낮아 전반적인 멀티태스크 성능이 떨어졌다. 이는 엔트로피 추정이 AMF-NN의 핵심 요소임을 보여준다.",
        "long_answer": {
            "question": "다른 접근들과 비교하여 AMF-NN에서 불확실성 추정이 어떤 차이를 보이며, 그 의미는 무엇인지 설명하라.",
            "answer": "AMF-NN은 손실 그래디언트 임베딩을 활용한 GP 근사 방식을 사용하여 불확실성을 추정하였다. 이는 마지막 계층 임베딩이나 테스트 시 드롭아웃을 사용하는 기존 방식보다는 작업 선택을 더 효과적으로 유도하는 결과를 도출하였다. AMF-NN에서 엔트로피 추정이 멀티태스크의 성능을 전반적으로 향상시켰기 때문에 반드시 필요한 요소로 입증된 것이다.",
            "rubric": [
                "AMF-NN; 손실 그래디언트 임베딩; 대체 기법 비교; 멀티태스크 성능"
            ]
        },
        "short_answer": {
            "question": "AMF-NN에서 엔트로피 추정이 핵심 요소임을 파악하기 위해 사용한 기법은 무엇인가?",
            "answer": "손실 그래디언트 임베딩을 활용한 GP 근사 방식",
            "topic": [
                "AMF-NN에서의 엔트로피 추정 파악을 위한 핵심 기법"
            ]
        },
        "multiple_choice": {
            "question": "AMF-NN에서 엔트로피 추정을 위한 방법을 서술한 것이다. 서술한 내용 중 적합한 것을 골라라.",
            "choices": [
                "a) 다른 접근 방식과 달리 손실 그래디언트 임베딩을 활용한 GP 근사를 활용하였다.",
                "b) 엔트로피 추정을 위해 마지막 계층 임베딩을 사용하여 대체 GP 근사와만 비교하였다.",
                "c) 마지막 계층 임베딩이나 드롭아웃 접근법은 모두 작업 레이블이 필요했다.",
                "d) 마지막 계층 임베딩과 드롭아웃 접근법은 작업 선택을 유도하는 데 탁월한 성능을 보였다."
            ],
            "answer": "a",
            "topic": [
                "AMF-NN에서의 엔트로피 추정 방법"
            ]
        },
        "true_false": {
            "question": "멀티태스크 성능을 전반적으로 향상시키기 위해 엔트로피 추정 기법은 AMF-NN에서 필수 조건은 아니다.",
            "answer": "FALSE",
            "topic": [
                "AMF-NN에 대한 엔트로피 추정의 기여도"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:8:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": " 5.4.  AMF를  기성품  모델에도  적용할  수  있나요?  AMF‑NN은  최소한의  요구사항(기본적으로  미분  가능한  사전  훈련된  사 전  확률  분포에  대한  접근만으로도  충분함)을  가지므로  광범위하게  적용 될  수  있을  것입니다 .  이  섹션에서는  더  복잡한  작업,  다중  모드  시연  모 델,  그리고  최신  정책  클래스  로의  평가  확장을  추가로  살펴봅니다 . 로보미믹  벤치마크는  네  개의  장거리  정밀  조작  작업(최대  약  700단계)  을  포함합니다.  이전  섹션의  실험은  스크립트화된  정책  또는  강화학습    에이전트가  수집한  시연에  의존하는  반면,  본  실험에서는  전문가  궤적을    사람이  제공합니다.  규모가  커짐에  따라  각  반복에서  선택된  작업에  대  해  20개의  시연을  샘플링합니다 .  마지막으로,  AMF‑NN과  호환  되는  더    큰  생성  모델  인  확산  정책  (Chi  et  al.,  2023)  을  미세  조정  합니다. 데이터  소스와  아키텍처가  변경되었음에도  불구하고  그림  6  에서  관찰한  결과  는  이전  설정에서  보고된  결과와  일치합니다.  즉,  능동적  미세  조정과  적응적  사  전  학습은  전반적으로  도움이  되며,  특히  사전  학습  분포가  평가  분포  µC와  일  치하지  않을  때  유용  합니다 .",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:8:0001",
                    "page": 8
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "AMF-NN은 미분 가능한 사전 학습 분포로만으로도 다양한 모델에 적용이 가능하다. 로보미믹 벤치마크의 인간 시연 기반 장기 조작 작업과 확산 정책을 활용한 실험 결과, 데이터 소스와 아키텍처 변화에도 불구하고, 사전 학습 분포가 평가 분포가 불일치할 때, 능동적 미세 조정과 적응형 사전 학습의 성능 향상에 도움을 줄 수있다는 것을 밝힐 수 있었다.",
        "long_answer": {
            "question": "AMF-NN이 사전 학습된 모델에 어떻게 적용될 수 있으며, 그 실험 결과가 시사하는 바를 간결하게 기술하라.",
            "answer": "AMF-NN에서 미분이 가능한 사전 학습 분포에 접근할 수 있게 되면, 다양한 기성 모델에 적용이 가능하다. 로보미믹 벤치마크 데이터셋에서 인간 전문가 시연과 확산 정책을 활용한 실험에서도 일관된 성능 향상 추세를 보였기 때문이다. 특히 사전 학습 분포와 평가 분포가 일치하지 않는 경우도 능동적 미세 조정과 적응형 사전 학습이 성능 개선에 효과적이었음을 알 수 있다.",
            "rubric": [
                "AMF-NN; 적용 가능성; 로보미믹 벤치마크; 인간 전문가 시연; 확산 정책; 사전 학습 분포와 평가 분포의 불일치; 성능 향상"
            ]
        },
        "short_answer": {
            "question": "AMF-NN의 범용적 사용을 위한 필수 조건은 무엇인가?",
            "answer": "미분 가능한 사전 하긋 분포에 대한 접근성",
            "topic": [
                "AMF-NN의 범용적 적용을 위한 요건"
            ]
        },
        "multiple_choice": {
            "question": "다음은 AMF의 적용 가능성에 대한 실험 내용이다. 설명된 내용 중 가장 적절한 것을 찾아라.",
            "choices": [
                "a) AMF의 적용 가능성을 살펴보기 위해서 스크립트화된 정책이나 강화학습 에이전트가 수집한 시연에 의존했다.",
                "b) AMF-NN의 확대 적용은 사전 학습 분포와 평가 분포가 일치할 때 그 효과가 뚜렷해진다.",
                "c) AMF 적용 가능성 실험에서 가장 달랐던 점은 전문가 궤적을 기계가 제공했다는 것이다.",
                "d) AMF 적용 가능성을 살펴보기 위해 다중 모달 시연자, 최신 정책 클래스로 평가를 확장했다."
            ],
            "answer": "d",
            "topic": [
                "AMF의 적용 가능성에 대한 실험"
            ]
        },
        "true_false": {
            "question": "AMF-NN이 대규모 생성 모델에 호환될 수 있게 국소 정책과 미세 조정을 하였다.",
            "answer": "FALSE",
            "topic": [
                "AMF-NN의 대규모 생성 모델 호환 실험"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:24:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": " F.  일반주의  정책을  가진  AMF  이  섹션에서는  최근  발표된  오픈소스  일반  정책에  대한  평가  확장을    살펴봅니다 .  이를  위해  Octo  (Octo  Model  Team  et  al.,  2024)  를  선택했습니다.  이  모델은  다중  모드  정보(상태  센서,  카메라  이미지,  텍스트  또는    RGB  작업  설명  형식 )를  통합하기  위해  변환기  백본에  의존하며 ,  행  동  예측을  위해  확산  기반  정책  헤드를  사용합니다  (Chi  et  al.,    2023).  계산상의  이유로,  행동  헤드만  미세  조정하는  데  중점을  둘  것  입니다.  Octo는  대규모  실제  로봇  데이터셋  (Collaboration,  2023)  을  기반으로  사전  학습되었으며,  따라서  물리적  하드웨어에서의  추론  을  위해  설계되었습니다.  그럼에도  불구하고,  최근  제안된  평가  스위  트는  통계적으로 실제  결과와  상관관계를  가집니다  (Li  et  al.,  2024).  따라서  WidowX  작업에  대한  사전  훈련된  Octo  에이전트의  롤아웃  데이터를  수집하고,  자가  증류    방식( Self‑distillation  scheme)과  유사하게  성공한  롤아웃만  포함하도록  필터링합니다  (Bousmalis  et  al.,  2024).  이러한  자가  지도  학습  데모가    제공되는  경우 ,  AMF‑NN을  5  회  반복하여  적용하고  각  라운드마다  2개의  데모를  제공합니다 .  결과는  그림  10  에  보고되어  있습니다 .  모든  평가  작업은    사전  훈련  데이터셋  (Collaboration,  2023)에서  대부분  시연되었으며,  다른  벤치마크에  비해  평가  노이즈가  상당히  높기  때문에,  AMF‑NN의  성능이  균  일한  작업  수집의  신뢰  구간  내에  있음을  확인했습니다.  이는  그림  4에서  관찰된  균일한  사전  훈련  분포의  경향을  확인시켜  줍니다.  그럼에도  불구하고,    AMF‑NN은  데이터  선택에  효과적인  방법이며,  기성  모델의  미세  조정을  위한  드롭인(drop‑in)  대체  방법으로  적용될  수  있음을  관찰  했습니다.3",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:24:0001",
                    "page": 24
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "AMF-NN은 오픈소스 일반 정책인 Octo 모델을 대상으로 다중 모달 입력과 학산 기반 정책 헤드를 활용해 평가하였다. 그 결과, 인간 시연 데이터를 사용한 자기지도학습 실험에서도 균일한 작업 수집과 유사한 성능을 보 였다. 이는 AMF-NN이 기성 모델의 미세조정을 위한 효과적인 데이터 선택 대안임을 보여준다.",
        "long_answer": {
            "question": "Octo 모델을 대상으로 AMF-NN 실험은 어떻게 진행되었으며, 그 결과는 무엇이었는지 서술하라.",
            "answer": "AMF-NN은 변환기 백본과 확신 기반 정책 헤드를 사용하는 Octo 모델의 행동 헤드에 적용하였다. WindowX 작업에서 수집된 롤아웃 데이터를 자가 증류 방식으로 필터링해 5회 반복 미세 조정을 수행한 결과, 성능은 균일한 작업 수집의 신뢰 구간 내에 유지되었다. 이를 통해 AMF-NN이 데이터 선택에 효과적이며, 기성 모델의 미세 조정을 위한 대체 방법으로 활용될 수 있음을 확인하였다.",
            "rubric": [
                "Octo 모델; 자가 증류; 대체 가능성"
            ]
        },
        "short_answer": {
            "question": "대규모 실제 로보 데이테셋을 기반으로 사전학습되었으며 물리적 하드웨어에서의 추론을 위해 설계된 모델은 무엇인가?",
            "answer": "Octo",
            "topic": [
                "Octo 모델의 특징"
            ]
        },
        "multiple_choice": {
            "question": "AMF-NN과 Octo 모델을 비교 실험한 결과이다. 그 결과 내용으로 바르지 않는 것은?",
            "choices": [
                "a) 계산 효율상의 이유로 인해 행동 헤드만을 미세 조정 대상으로 삼았다.",
                "b) 사전 학습된 Octo 에이전트의 WindowX 작업 롤아웃 데이터를 수집하였다.",
                "c) 다른 벤치마크에 비해 평가 잡음이 많아 AMF-NN에서의 성능 역시 신뢰 구간 밖에 존재하였다.",
                "d) 실험 결과, 균일 사전 학습 분포의 경향과 일치함을 알 수 있었다."
            ],
            "answer": "c",
            "topic": [
                "AMF-NN과 Octo 모델의 비교 실험 결과"
            ]
        },
        "true_false": {
            "question": "Octo 모델은 시뮬레이션 평가와 실재 결과 간의 통계적 상관관계를 보인다.",
            "answer": "TRUE",
            "topic": [
                "Octo 모델의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:25:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "H.  망각  완화 신경망이  학습  분포의  변화에  적응하면서  정보를  유지하는  능력은  평생  학습  및  지속적  학습에서  중요 한  관심  대상입니다  (Wang  et  al.,  2024).  일반적  으로  학습된  모델은  새로운  정보를  통합하는  능력 과  이전에  관찰된  학습  샘플에  대한  기억력  사이에  상충  관계를  보입니다 .  일반적인  신경망  아키텍처는   가소성  손실  (Lyle  et  al.,  2023)을  제외하고는  새로운  데이터에  쉽게  적응할  수  있지만,  이전  정보를   잊어버리는  경우가  많으며 ,  이는  종종  심각한  결과를  초래합니다.  이  문제는  사전  학습된  신경망이  유 용한  초기화  도구로  활용될  뿐만  아니라  이미  일부  과제를  해결할  수  있는  능력을  갖추고  있는  상황에 서  매우  중요합니다 .  따라서  미세  조정  절차는  이러한  능력을  저해하지  않도록  주의해야  합니다 망각을  완화하기  위한  여러  방법은  리허설  (Riemer  et  al.,  2019;  Chaudhry  et  al.,  2019)  과  정규화  (Kirkpatrick  et  al.,  2017)  전략  에서  유래되었 습니다 .  리허설  방식은  종종  효과적이지만,  사전  훈련  데이터에  대한  접근이  필요하기  때문에  우리의  환경에서는  비현실적입니다.  따라서  두  가지  일반적인   정규화  기법을  고려합니다 즉,  사전  훈련된  가중치에  대한  L2  정규화와  EWC  (Kirkpatrick  et  al.,  2017)입니다.  후자는  손실  지형의  곡률에  따라  정규화  강도를  적응적으로  조정 하는  L2  정규화의  더  미묘한  버전으로  볼  수  있습니다 .  하지만  그림  12  에서  보고된  바와  같이,  이러한  방법들은  본  연구에서는  충분하지  않습니다.  큰  정 규화  가중치와  결합될  경우 ,  L2  정규화와  EWC의  점근적  성능은  상당히  제한됩니다.",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:25:0001",
                    "page": 25
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "신경망의 망각 문제를 완화하기 위해 L2 정규화와 EWC 같은 정규화 기법을 적용했으나, 정규화 강도에 따라 성능이 제한되거나 기준선 수준으로 회귀하며 망각을 근본적으로 해결하지 못했다. 또한 정책이 사전 학습 과제 정보를 빠르게 읽고 적응적 데이터 선택의 효과도 감소했다.",
        "long_answer": {
            "question": "AMF 연구에서 다룬 망각 완화 실험의 목적과 그 한계를 설명하라.",
            "answer": "기존 연구에서 신경망이 새로운 정보를 학습하면서 기존 지식을 잃는 재앙적 망각 현상을 겪기 때문에, 이를 완화하기 위해 정규화 기반 접근을 시도하였다. AMF 연구에서 사전 학습된 가중치에 대한 L2 정규화와 손실 곡률을 반영한 EWC 기법을 적용해보았다. 그러나 두 방법 모두 정규화 강도에 따라 성능이 제한되거나 기준선 수준으로 회귀해, 망각 문제를 근본적으로 해결하지는 못했다.",
            "rubric": [
                "재앙적 망각; 정규화 기반 완화; L2 정규화; EWC 기법; 정규화 강도에 따른 성능 저하; 기준선 수준 회귀"
            ]
        },
        "short_answer": {
            "question": "대부분의 신경망 아키텍처가 가지고 있는 단점이 무엇인가?",
            "answer": "재앙적 망각",
            "topic": [
                "신경망 아키텍처의 한계"
            ]
        },
        "multiple_choice": {
            "question": "다음은 재앙적 망각과 그 완화를 위한 방법론적 설명이다. 이 설명 중 틀린 것을 골라라.",
            "choices": [
                "a) 대부분의 신경망 아키텍처는 기소성 손실을 제외하면 새로운 데이터에 잘 적응한다.",
                "b) 신경망 아키텍처에서의 재앙적 망각은 절대적이므로 미세 조정만으로는 해결할 수 없다.",
                "c) 망각을 완화하는 방법에는 리허설과 정규화 전략으로 나눌 수 있다.",
                "d) 사전 학습된 신경망은 초기화 도구뿐만 아니라 일부 과제를 해결할 수 있는 능력을 갖추고 있어야 한다."
            ],
            "answer": "b",
            "topic": [
                "재앙적 망각과 완화를 위한 방법론"
            ]
        },
        "true_false": {
            "question": "대부분 학습 모델은 새로운 정보를 통합하는 능력과 기존 학습 샘플에 대한 기억력 사이에 상충 관계를 이룬다.",
            "answer": "TRUE",
            "topic": [
                "학습 모델의 정보 기억에 대한 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:26:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "정규화  가중치가  너무  낮으면  순수  기준선의  성능을  회복합니다.  중간값은  두  동작  사이를  보간하는  것으로  나타났지만,  망각  문제는  해결되지  않았습니다.  결과적으로  정책 은  사전  학습  작업에  대한  정보를  빠르게  잃어버려  적응형  데이터  선택  전략이  비효율적으로  됩니다. 이는  망각을  완화하기  위한  새로운  기법을  채택하게  된  동기가  되었으며,  이를  적응적  사전(Adaptive  Prior)이라고  합니다.  행동  사전  (Bagatella  et  al.,  2022)   및  오프라인  RL  (Kumar  et  al.,  2020)  의  이전  연구에서  영감을  얻어,  정책의  출력을  사전(실제로는  사전  훈련된  정책의  고정된  사본  πp )의  출력과  선형적으로   결합합니다.  행동을  샘플링해야  하는  경우,  미세  조정된  정책  π  와  사전  πp에서  샘플링된  행동의  선형  조합을  대신  출력합니다.  주어진  상태‑작업  쌍 (s, c) ∈ S × C  에  대해  선택된  행동은 a=α(c)a^+(1−α(c))aˉ,wherea^∼π(⋅∣s,c),aˉ∼πp​(⋅∣s,c) 입니다. 가중치  α(c)  ∈  [0,  1]  은  작업에  따라  달라지며  학습  가능합니다.  이상적으로는  미세  조정된  정책이  작업에  더  적합할  때  가중치  α(c)  ∈  [0,  1]이  높고,  사전  추 정이  더  선호될  때는  가중치  α(c)가  낮을  것입니다.  실제로는  유한  작업  공간에서는  작업별  학습  가능한  매개변수이거나,  연속  작업  공간에서는  매개변수화된  함수 (예:  신경망)의  출력일  수  있습니다.  이  공식은  정책과  사전  추정을  혼합하여  동작을  샘플링하는  기존  공식  (Bagatella  et  al.,  2022)  과는  다르지만,  α에  대한  간 단한  업데이트  규칙을  사용할  수  있으며 ,  이는  정책  클래스가  간단한  우도  평가를  허용하지  않는  경우(예:  확산  정책)에도  적용  가능합니다.  π  와  πp가  모두  등방 성  가우시안이라는  가정  하에 ,  동작의  선형  조합에  대해  계산된  BC  손실은  단순  평균  제곱으로  단순화됩니다.",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:26:0001",
                    "page": 26
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "정책이 사전 학습 정보를 빠르게 잃는 문제를 해결하기 위한 제안된 적응적 사전은 미세 조정된 정책과 사전 학습된 정책의 출력을 선형 결합하여 행동을 생성한다. 가중치 α(c)를 작업별로 학습해 두 정책 간 균형을 조정하고, 명시적 우도 평가가 어려운 정책에도 적용 가능한 단순한 갱신 규칙을 제공하였다.",
        "long_answer": {
            "question": "적응적 사전 기법의 핵심 원리와 기존 접근법과의 차이를 설명하라.",
            "answer": "적응적 사전은 미세 조정된 정책과 사전 학습된 정책의 출력을 선형적으로 결합하여 망각을 완화하는 기법이다. 작업별 가중치 α(c)는 학습 가능한 파라미터로 설정되어, 각 작업의 특성에 따라 두 정책의 비중을 조절한다. 이는 정책과 사전 혼합 분포에서 직접 샘플링하는 기존 방식과는 차이를 보인다. 즉, 간단한 업데이트 규칙을 제공하여 확산 정책처럼 우도 평가가 어려운 모델에도 적용할 수 있게 되었다.",
            "rubric": [
                "적응적 사전 기법; 망각 완화 기법; 작업 종속 가중치; 혼합 분포 샘플링; 단순한 업데이트 규칙; 우도 평가"
            ]
        },
        "short_answer": {
            "question": "적응적 사전 기법은 어떤 선행 연구에 영향을 받은 것인가?",
            "answer": "행동 사전, 오프라인 RL",
            "topic": [
                "적응적 사전 기법의 등장 배경"
            ]
        },
        "multiple_choice": {
            "question": "다음은 적응적 사전 기법에 대한 설명이다. 이 기법에 가장 부합하는 설명을 찾아라.",
            "choices": [
                "a) 적응적 사전 기법은 정책의 출력을 사전의 출력과 비선형적으로 결합하는 기법니다.",
                "b) 가중치 α(c) ∈ [0, 1]은 작업에 따라 동일한 학습 가능한 파라미터를 말한다.",
                "c) 특정 작업에 대해 미세 조정된 정책이 더 적합한 경우 가중치 α(c)가 높아진다.",
                "d) 기존 연구에서와 마찬가지로 정책과 사전의 혼합 분포로부터 행동을 직접 샘플링하는 것은 동일하다."
            ],
            "answer": "c",
            "topic": [
                "적응적 사전 기법의 특징"
            ]
        },
        "true_false": {
            "question": "π와 πₚ가 모두 등방성 가우시안이라면, 동작 선형 조합에 대해 계산된 BC 손실은 단순 평균세제곱으로 단순화된다.",
            "answer": "FALSE",
            "topic": [
                "동작 선형 조합에 대한 계산된 BC 손실의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:27:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "I.  AMF  재조정  시범  카운트가  적용되나요?  이산  작업  공간에서는  각  작업에  대한  시연  횟수를  세는  것이  가능합니다.  이  경우,  단순한  데이터  선택  전략은  과거에  시연  횟수가  가장  적었던  작업에  대한  시연을  요청  하는  것입니다.  모든  작업에  비슷한  양의  시연이  필요하다면,  경험적으로  매우  좋은  성능을  보일  것입니다.  그러나  본  연구에서는  데이터  선택  알고리즘이  사전  학습  데이  터에  대한  정보를  가지고  있지  않습니다.  따라서  미세  조정  시연에  대한  시연  횟수만  계산할  수  있었습니다.  이  시연  횟수를  능동적으로  조정하면  거의  균일한  작업  선택  이  이루어지고,  균일한  샘플링의  기대  성능을  회복할  수  있습니다.  그럼에도  불구하고,  우리는  이  '재균형화'  기준을  사전  학습  작업  분포에  대한  접근을  가정하는  특권  기반  기준선으로  구현합니다.  그림  4의  AMF  NN  표준  설정에서  이를  평가합니다.  그림  14  에서  AMF‑NN은  사전  학습  분포에  대한  지식이  없음에도  불구하고  이  특권  기반  기준선의  성능을  따  라잡을  수  있음  을  관찰합니다 .  이는  AMF가  정책  불확실성  추정을  통해  사전  학습  단계에  대한  정보를  추론할  수  있으며,  '재균형'  전략을  자동으로  복구할  수  있음을  의미합니다.  더욱이,  AMF‑NN  은  여러  과제에  걸쳐  엔트로피  감소를  고려합니다.  따라서  학습하기  어렵거나  이론적으로  다른  과제에서  학습  진전을  이룰  수  있는  과제에  집중할  수  있습니다 .  이러한    행동에  대한  추가적인  경험적  증거는  부록  J  에  제시되어  있습니다. ",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:27:0001",
                    "page": 27
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "AMF는 사전 학습 데이터에 대한 정보 없이도 정책의 불확실성 추정을 통해 시연 횟수를 재균형화하여 특권 기반 기준선과 유사한 성능을 보인다. 엔트로피의 감소를 고려해 학습이 어려운 작업이나 다른 과제의 학습 진전에 도움이 되는 작업에 집중할 수 있다.",
        "long_answer": {
            "question": "AMF-NN이 시연 횟수 재균형화를 어떻게 처리하며, 그 결과가 시사하는 바는 무엇인가?",
            "answer": "AMF-NN은 사전 학습 데이터에 접근하지 않기 때문에, 시연 횟수를 직접 재균형화하지 않는다. 다만, 불확실성 추정을 통해 사전 학습 분포의 정보를 내재적으로 추론하여 특권 기반 기준선과 유사한 성능을 달성할 수 있다. 따라서 AMF가 학습 난이도나 과제 간 연관성을 고려해 자동으로 균형 잡힌 작업 선택을 수행할 수 있음을 의미한다.",
            "rubric": [
                "AMF-NN; 재균형화; 북확실한 추정; 내재적 추론; 균일한 작업 선택 수행"
            ]
        },
        "short_answer": {
            "question": "시연 횟수를 능동적으로 조정하게 되면 어떤 부분에서의 기대 성능을 회복할 수 있는가?",
            "answer": "균일한 작업 선택, 균일 샘플링",
            "topic": [
                "능동적 시연 횟수 조정에 대한 효과"
            ]
        },
        "multiple_choice": {
            "question": "AMF 재조정 실험과 관련된 내용이다. 이 내용에서 가장 부적합한 것을 선택하라.",
            "choices": [
                "a) 이산 작업 공간에서는 각 작업의 시연 횟수를 세는 것이 가능하다.",
                "b) 모든 작업이 유사한 양의 시연을 필요로 하면, 경험적으로 매우 우수한 성능을 보일 수 있다.",
                "c) AMF 재조정 실험에서는 재균형화를 활용하였다.",
                "d) AMF-NN의 재조정 실험에서 사전 학습 분포에 대한 사전 지식 없어 특권 기반 기준선의 성능을 따라잡지 못한다."
            ],
            "answer": "d",
            "topic": [
                "AMF 재조정 실험의 특징"
            ]
        },
        "true_false": {
            "question": "이론적으로 AMF-NN은 여러 과제에 걸쳐 엔트로피 감소를 고려하므로 학습이 어려운 상황에서도 작업에 집중할 수 있는 모델이다.",
            "answer": "TRUE",
            "topic": [
                "AMF-MM의 엔트로피 감소 조정에 대한 효과"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:32:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "M.3.3.  중요도  샘플링  가중치 GP  설정에서  중요도  가중치는  가우시안  정책  분포에서  계산되고  로그  확률은  [-12,  0]  범위  로  클리핑됩니다.  NN  설정에서  결정론적  정책의  경우  정책의  출력을  고정된  표준  편차  σ  =  1.0을  갖 는  가우시안의  평균으로  해석  하고  수치적  안정성을  위해  로그  확률만  클리핑합니다.  사전  훈련된  Octo  정책을  포함하는  실험에서  두  가지  솔루션을  평가했습니다.  한  가지  옵션은  확산  정책의   샘플에  최대  가능도  방법을  통해  가우시안  분포를  맞추는  것으로  구성되었으며  성능이  떨어지는  것으로  나타났습니다.  따라서  Octo  정책을  엄격하게  결정론적으로  취급합니다.  연속  동작  공간에 서  이는  중요도  샘플링  가중치를  τ가  작업  c  에  대해  정확히  제공된  데모인  경우  w(c,  τ)  =  1  로  단순화하고  그렇지  않은  경우  0  으로  단순화합니다 .  이  솔루션은  아직  관찰되지  않은  작업에  대 한  기준을  평가하는  데  사용할  수  없지만  작업이  유한하고  적은  경우에는  여전히  실행  가능합니다.",
                "provenance": {
                    "doc_id": "Active Fine-Tuning of Multi-Task Policies_ko_translation.pdf:32:0001",
                    "page": 32
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GP 설정에서 가우시안 정책 분포로부터 중요도 가중치를 계산하고 NN 설정에서는 결정론적 정책을 출력을 가우시안 평균으로 해석하였다. Octo 정책 실험에서는 최대 가능도 방법 기반 가우시안 적합이 성능이 낮아 결정론적으로 처리한 결과 연속 행동 공간에서 시연 여부에 따라 w(c, τ)=1 또는 0으로 단순되었다. 이는 비관찰적 작업에는 적용할 수 없지만, 작업 수가 적을 때는 유효한 방법이라고 할 수 있다.",
        "long_answer": {
            "question": "AMF 연구에서 중요도 샘플링 가중치가 GP 설정과 NN 설정에 어떻게 처리되었는지와 그 이유를 기술하라.",
            "answer": "GP 설저에서는 가우시안 정책 분포로부터 중요도 가중치를 계산하고 로그 확률을 [-12,0] 범위로 클리핑하였다. 반면 NN 설정에서는 결정론적 정책 출력을 표준편차 1.0을 갖는 가우시안 평균으로 해석하고, 로그 확률만 안정화 목적으로 클리핑하였다. 특히 Octo 정책의 경우, 결정론적 정책으로 처리하여 중요도 가중치를 단순화하였다. 이는 작업 수가 제한된 연속 행동 공간에서 실질적으로 적용 가능한 접근으로 평가되었다.",
            "rubric": [
                "로그 확률 클리핑; 결정론적 정책; 가우시한 평균; 단순화된 중요도 가중치; 제한된 연속 행동 공간"
            ]
        },
        "short_answer": {
            "question": "GP 설정에서 가우시안 정책 분포로 중요도 가중치를 계산할 때, 클리핑한 로그 확률 범위는?",
            "answer": "[-12, 0]",
            "topic": [
                "GP 설정에서 가우시안 정책 분포의 중요도 가중치 계산"
            ]
        },
        "multiple_choice": {
            "question": "중요도 샘플링 가중치에 대한 설명이다. 이 가중치와 일치하는 내용은?",
            "choices": [
                "a) NN 설정에서 결정론적 정책에 따라 표준 편차 1.0을 갖는 가우시안 분포의 평균으로 해석하였다.",
                "b) NN 설정에서 수치적 불안정성을 위해 로그 확률만 클리핑했다.",
                "c) 사전 학습된 Octo 정책은 최대 가능도 방법만 가우시안 분포에 맞췄다.",
                "d) 사전 학습된 Octo 정책에 의해 성능이 향상되었다."
            ],
            "answer": "a",
            "topic": [
                "중요도 샘플링 가중치의 특징"
            ]
        },
        "true_false": {
            "question": "중요도 샘플링 가중치는 연속적 행동 공간에서 매우 복잡해진다.",
            "answer": "FALSE",
            "topic": [
                "연속적 행동 공간에서 중요도 샘플링 가중치의 특성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Adaptive Estimation and Learning under Temporal Distribution Shift_ko_translation.pdf:1:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "추정치  ˆθ1   자체를  구성하는  것만으로는  충분하지  않다는  점에  유의하세요. 많은  시나리오에서  우리는  또한  이러한  추정자에  대한  통계적  보장 을  제공해야  합니다 .  예를  들어  위험을  계산하기  위해서입니다. 주가  추정을  위한  주식  선택  전략의  프로필. 매우  높은  추정  품질을  달성하기  위해  우리는  다음을  원합니다. 견적에  대한  지점별  성과  보장을  얻으십시오. 즉,  가능한  한  작은  |ˆθ1 −θ1|  에  대한  경계입니다 . 요구  사항은  통제에  비해  더  엄격합니다. 시퀀스  θn, . . . ,  θ1  에  대한  추정  오차는  다음과  같습니다. 일부  집계  성능  지표.  예를  들어,  점별  경계는  누적  성능에  대한  제어를   의미합니다. 평균  제곱  오차(MSE)  또는  후회와  같은  측정  항목 온라인  학습  (Hazan,  2016)  은  통제됩니다.  θ1을  추정하기  위한  자연스러운  알고리즘은  가장  많은  것을  평균화하는  것입니다. 슬라이딩  윈도우  내에서  최근  관측치를  사용합니다.  그러나  완전히  데이 터  적응적인  방식으로  최적의  윈도우  크기를  결정하는  것은  쉽지  않습니 다.  작은  윈도우를  선택하는  것은 크기가  작을수록  편향은  작지만  분산은  큰  추정치가  도출됩니다.  윈도우   크기가  클수록  분산이  감소합니다. 큰  편견을  도입하는  대가로.  따라서  달성하기  위해 정확한  지점별  추정  오차  보장은  필수입니다. 최적의  편향‑분산  트레이드  오프를  갖는  창  크기를  선택합니다.",
                "provenance": {
                    "doc_id": "Adaptive Estimation and Learning under Temporal Distribution Shift_ko_translation.pdf",
                    "page": 1
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "추정치에 대한 통계적 보장을 통해 점별 오차 |ˆθ1 −θ1|를 최소화하는 것이 중요하다. 이는 MSE나 후회와 같은 측정 항목을 제어하는 것보다 엄격한 요구이며, 슬라이딩 윈도우 평균 방식에서 최적의 편향-분산 균형을 달성하기 위한 핵심 과제이다.",
        "long_answer": {
            "question": "추정치 ˆθ1의 통계적 보장을 제공해야하는 이유와 슬라이딩 윈도우 접근에서 발생하는 편향-분산 간의 균형 문제를 설명하라.",
            "answer": "단순히 추정치를 계산하는 것만으로는 충분하지 않으며, 모델의 신뢰성을 확보하기 위해 점별 성능 보장과 같은 통계적 근거가 필요하다. 예를 들어 주가 예측 모델의 경우, 위험 프로파일 계산을 위해 개별 추정 오차의 신뢰 구간이 중요하다. 그러나 슬라이딩 윈도우의 크기 선택은 편향과 분산 간의 상충 관계를 초래하며, 최적의 균형을 위해 정교한 오차 보장이 요구된다.",
            "rubric": [
                "추정치의 신뢰성과 안정성 확보; 점별 오차 한계 제공; 슬라이딩 윈도우; 편향-분산 균형"
            ]
        },
        "short_answer": {
            "question": "높은 추정 정확도를 달성하기 위해 |ˆθ1 −θ1|에서 무엇을 확보해야 하는가?",
            "answer": "점별 성능",
            "topic": [
                "높은 추정 정확도 달성을 위한 방안"
            ]
        },
        "multiple_choice": {
            "question": "다음은 추정치 θ1 확보를 위한 방안들이다. 이 방안들 중 거리가 가장 먼 것은?",
            "choices": [
                "a) θ1를 추정하기 위한 가장 자연스러운 방법은 슬라이딩 윈도우 내의 최근 관측값에 대한 평균을 구하는 것이다.",
                "b) θ1를 추정하기 위한 최적의 편향 - 분산 균형을 달성하기 위해서는 정확한 점별 추정 오차 보장이 필요하다.",
                "c) 점별 성능 보장은 단순히 θ의 시퀀스 추정 오차를 평균제곱오차나 후회와 같은 측정 지표를 활용하는 것과 유사하다.",
                "d) 추정치 θ1을 높이기 위해서는 많은 시나리오를 통한 통계적 보장이 필요하다."
            ],
            "answer": "c",
            "topic": [
                "추청치 θ1 확보를 위한 방안"
            ]
        },
        "true_false": {
            "question": "큰 윈도우를 선택하면 분산을 늘지만 편향은 줄어든다.",
            "answer": "FALSE",
            "topic": [
                "슬라이딩 윈도우의 특성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Adaptive Estimation and Learning under Temporal Distribution Shift_ko_translation.pdf:2:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "Mazzetto와  Upfal  (2023)  의  솔루션은  국소  안정성을  활용하여  비정상성을  포착합니다.즉,  알 고리즘은  지상  진실  시퀀스( 시간  1  에서  시작  하여  덜  최근의  인덱스로  이동  하는  시퀀스를  기억하 세요 )의  변동이  적고  상수  신호에  가까운  가장  큰  창을  효과적으로  선택합니다.이러한  창이  클수 록  추정  오류율이  작아지는데,  이러한  창으로  평균화하면  약간의  편향만  도입하면서  분산을  크게   줄일  수  있기  때문입니다 .  다른  각도에서  문제에  접근하면  웨이블릿  소프트  임계값을  기반으로   하는  추정자는  지상  진실  시퀀스의  웨이블릿  계수의  희소성  과  강하게  상관관계가  있는  추정  오류 를  발생시킨다는  것을  보여줍니다 .이  관점에서  지상  진실의  정상성  수준은  웨이블릿  계수의  희소 성  수준과  강하게  연결됩니다.웨이블릿  계수의  희소성에  기반한  우리의  접근  방식은  국소  안정성 의  개념보다  더  일반적입니다 .  예를  들어,  더  높은  순서의  Daubechies  웨이블릿을  사용하면  잠 재적으로  복잡한  추세를  포착할  수  있습니다. 희소한  웨이블릿  계수  집합을  갖는  기준  진위  시퀀스의  진화는  빠른  추정  보장 /경계로  이어진다(그 림  1  참조).  반면,  복잡한  시간적  진화  패턴이  존재하는  경우 ,  국소적  안정성  개념에  기반하여  선 택된  최적의  윈도우는  잠재적으로  작을  수  있으며,  이는  높은  분산으로  인해  이동  평균  추정치에   더  큰  오차를  발생시킬  수  있다 .",
                "provenance": {
                    "doc_id": "Adaptive Estimation and Learning under Temporal Distribution Shift_ko_translation.pdf:2:0001",
                    "page": 2
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "국소 안정성을 이용해 비정상성을 포착하는 반면, 웨이블릿 계수의 희소성에 기반한 접근법은 더 일반회되어 복잡한 추세를 효과적으로 포착하고 빠른 추정 보장을 제공한다. 복잡한 시간적 패턴에서는 국소 안정성 기반 윈도우가 작아져 분산 증가로 인한 오차가 커질 수 있다.",
        "long_answer": {
            "question": "국소 안정성 접근법과 웨이블릿 희소성 기반 추정법의 차이를 설명하라.",
            "answer": "국소 안정성 접근법은 비정상성을 포착하기 위해 변동이 작은 구간, 즉 국소적으로 안정적인 창을 선택하여 평균화함으로써 분산을 줄이는 방식이다. 그러나 웨이블릿 소프트 임계값 기반 추정법은 지상 진실 시퀀스의 웨이블릿 계수 희소성을 이용해 보다 일반적인 형태의 신호 변화와 추세를 포착한다. 특히 고차 Daubechies 웨이블릿을 사용하면 복잡한 시간적 패턴에서도 빠른 추정 보장과 오차 경계를 제공할 수 있다.",
            "rubric": [
                "국소 안정성; 비정상성 포착; 웨이블릿 희소성; 복잡한 추세 포착; 추정 보장"
            ]
        },
        "short_answer": {
            "question": "큰 창일 때의 해당 구간 평균화을 위해 약간의 편향만 도입하면, 무엇이 줄어들게 되는가?",
            "answer": "분산",
            "topic": [
                "구간별 평균화를 위한 조절 요소"
            ]
        },
        "multiple_choice": {
            "question": "다음은 국소 안정성과 웨블릿 소프트 임계값 기반 추정에 대한 설명이다. 이 설명 중 올바르게 기술된 것은?",
            "choices": [
                "a) 지상 진실의 정상성 수준은 웨이블릿 계수의 희소성 수준과 밀접한 관계가 있다.",
                "b) 웨이블릿 계수의 희소성에 기반한 접근법은 국소 안정성의 개념보다 특수적이다.",
                "c) 시간적 진화 패턴이 복잡한 경우, 국소 안정성 개념에 기반하여 선택된 최적의 윈도우는 상대적으로 클 수 있다.",
                "d) 과거로 갈수록 최근의 인덱스로 확장되는 지상진실 시퀀스 중, 변동이 크고 상수 신호에 가장 먼 작은 창을 선택한다."
            ],
            "answer": "a",
            "topic": [
                "국소 안정성과 웨이블릿 계수 희소성의 특징"
            ]
        },
        "true_false": {
            "question": "고차 Daubechies 웨이블릿을 사용하면 빠른 추정 보장과 경계를 얻을 수 있다.",
            "answer": "TRUE",
            "topic": [
                "웨이블릿 계수의 희소성에 기반한 접근법의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "Adaptive Estimation and Learning under Temporal Distribution Shift_ko_translation.pdf:3:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 과학 기초"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.1.  알고리즘 본  연구에서는  잘  알려진  웨이블릿  평활화  (Donoho,  1995)  개념을  차용한  웨이블릿  잡음  제거   기반  알고리즘을  제안한다.  알고리즘은  완전성을  위해  알고리즘  1  에  제시되어  있다.  웨이블릿  기 반  솔루션과  기존  연구  (Mazzetto  and  Upfal,  2023;  Han  et  al.,  2024)  의  알고리즘  간의   근본적인  차이점은  웨이블릿  기반  솔루션은  관련  과거  관측치의  평균화를  위해  적응적  윈도우  크 기를  유지하는  반면,  웨이블릿  기반  솔루션은  그러한  윈도우  크기를  유지하지  않는다는  것이다. 대신  가장  관련성  있는  데이터  부분을  암묵적으로  사용하여  최종  시간  단계에서의   기준  진실을  추정합니다.   2.2.  분석 위  정리는  추정  문제에  대한  웨이블릿  기반  방법의  다재다능함을  입증 하지만,  이는  보조  정리  1  에서  제시된  일반적인  상한  에  대한  상한일  뿐 임을  상기시켜  드립니다.  보조정리  1은  사용자가  지정한  웨이블릿  변환   공간에서  웨이블릿  계수의  희소성을  활용하여  더  빠른  추정  오류율을   달성할  수  있는  잠재력을  가지고  있습니다 .",
                "provenance": {
                    "doc_id": "Adaptive Estimation and Learning under Temporal Distribution Shift_ko_translation.pdf:3:0001",
                    "page": 3
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "웨이블릿 평활화 개념을 확장한 웨이블릿 잠음 제거 기반 알고리즘을 제안한다. 적응적 윈도우를 사용하지 않고 관련성이 높은 데이터 구간을 통해 기준 진실을 추정하고, 웨이블릿 계수의 희소성을 활용하여 더 빠른 추정 오차율을 달성할 잠재력을 가지게 할 것이다.",
        "long_answer": {
            "question": "웨이블릿 제거 기반 기반 알고리즘이 기존 적응적 윈도우 접근법과의 다른 점과, 그 분석 결과의 의미를 설명하라.",
            "answer": "웨이블릿 기반 알고리즘은 기존 방법처럼 명시적인 윈도우 크기를 유지하지 않고, 웨이블릿 변환을 통해 관련성이 높은 구간을 암묵적으로 활용한다. 이를 통해 최종 시점의 기준 진실을 효율적으로 추정하고, 웨이블릿 계수의 희소성을 이용해 빠른 추정 오차율을 달성할 수 있다. 이러한 결과는 웨이블릿 기반 접근이 추정 문제에 있어 더 높은 다재다능성과 이론적 효율성을 지니고 있음을 보여줄 수 있다.",
            "rubric": [
                "웨이블릿 잡음 제거 기반 알고리즘; 적응적 윈도우 크기 유지; 희소성; 빠른 추정 오차율"
            ]
        },
        "short_answer": {
            "question": "웨이블릿 평활화의 개념을 확장한 알고리즘을 무엇이라 부르는가?",
            "answer": "웨이블릿 잡음 제거 기반 알고리즘",
            "topic": [
                "웨이블릿 잡음 제거 기반 알고리즘의 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음은 웨이블릿 제거 기반 알고리즘에 대한 특징이다. 이 특징에 대한 설명으로 바른 것은?",
            "choices": [
                "a) 기존에 연구된 알고리즘에 기반하여 적응적 윈도우의 크기는 동일하게 유지하였다.",
                "b) 이전 알고리즘들은 과거 관측값을 평균화하기 위해 적응적 윈도우 크기를 유지하였다.",
                "c) 웨이블릿 잡음 제거 기반 알고리즘은 기존 연구에 없었던 것으로 새롭게 탄생한 알고리즘이다.",
                "d) 웨이블릿 제거 기반 알고리즘의 가장 큰 목적은 웨이블릿 계수의 보편성을 활용하는 것이다."
            ],
            "answer": "b",
            "topic": [
                "웨이블릿 제거 기반 알고리즘의 특징"
            ]
        },
        "true_false": {
            "question": "웨이블릿 제거 기반 알고리즘은 가장 관련성이 높은 데이터 구간을 암묵적으로 활용하여 최종 시점에서 기준 진실을 추정하는 것이 핵심이다.",
            "answer": "TRUE",
            "topic": [
                "웨이블릿 제거 기반 알고리즘의 목표"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:26:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "3.2 생애주기 기반 품질관리 체계 l 고품질의 인공지능 학습용 데이터를 확보하고, 지속적인 품질을 유지하거나 품질향상을 위한 인공지능 학습용 데이터의 품질관리 체계를 생애주기 기반으로 제시하면 다음과 같음 (품질관리 대상) 인공지능 학습용 데이터 구축사업 및 AI-Hub를 통해 민간에 개방하는 인공지능 학습용 데이터셋 대상 l (품질관리 기준) 품질관리 원칙의 준수에 대한 객관적인 검증지표를 말하며, 구축 공정 품질기준과 데이터 자체의 품질기준으로 나눔 l (품질관리 조직) 인공지능 학습용 데이터의 품질확보 및 품질관리 활동을 수행하는 조직을 의미하며, 역할 및 책임을 부여하고 품질관리 활동을 수행 l (품질관리 절차) 인공지능 학습용 데이터의 품질을 검사하고, 저품질이나 오류 등의 원인을 분석해서 개선조치를 하는 일련의 활동을 의미 l (생애주기별 품질관리 활동) 계획 단계, 구축 단계, 운영·활용 단계의 각 영역에서 수행해야 할 품질관리 활동 정의 l (품질관리 도구 및 지원 인프라) 품질검사나 품질관리 활동을 수행하는 데 사용하는 도구(Tool)나 기술(Technology), 플랫폼(Platform) 등을 의미",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:26:0001",
                    "page": 26
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능 학습용 데이터의 품질을 확보하고 향상하기 위해, 계획, 구축, 운영 및 활용 단계에 걸친 생애주기 기반의 품질관리 체계를 마련한다. 이 체계는 품질관리 대상, 기준, 조직, 절차, 도구 및 인프라로 구성하며 체계적이고 지속적인 품질관리 활동을 수행하는 것을 목표로 한다.",
        "long_answer": {
            "question": "생애주기 기반 인공지능 학습데이터 품질관리 체계에서 품질관리 원칙의 준수여부 확인에 필요한 것과 그 종류를 서술하라.",
            "answer": "인공지능 학습을 위한 학습데이터를 데이터 생애주기 기반으로 품질관리할 때, 품질관리 원칙 준수 여부 확인에는 객관적인 검증지표인 품질관리 기준이 필요하다. 품질관리 기준은 구축 공정 품질기준과 데이터 자체 품질기준으로 나눌 수 있다.",
            "rubric": [
                "데이터 품질관리; 생애주기 기반; 품질관리 기준; 구축 공정 품질기준; 데이터 자체 품질기준"
            ]
        },
        "short_answer": {
            "question": "인공지능 학습용 데이터의 생애주기별 품질관리 활동은 어떤 단계에 맞춰 진행되어야 하는가?",
            "answer": "계획, 구축, 운영 및 활용 단계",
            "topic": [
                "생애주기별 품질관리 활동 단계"
            ]
        },
        "multiple_choice": {
            "question": "생애주기 기반 인공지능 학습데이터 품질관리 체계에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) 인공지능 학습용 데이터 구축사업에 들어가는 데이터셋은 품질관리 대상이다.",
                "b) 품질관리 조직은 인공지능 학습용 데이터의 품질확보만을 중점으로 진행한다.",
                "c) 인공지능 학습용 데이터의 품질을 검사하는 것부터 오류 등의 개선조치까지가 모두 품질관리 절차이다.",
                "d) 품질관리 도구 및 지원 인프라에는 도구 뿐만 아니라 플랫폼도 포함될 수 있다."
            ],
            "answer": "b",
            "topic": [
                "생애주기 기반 인공지능 학습데이터 품질관리 체계"
            ]
        },
        "true_false": {
            "question": "AI-Hub를 통해 대중에게 개방되는 인공지능 학습용 데이터셋은 품질관리의 대상이 된다.",
            "answer": "TRUE",
            "topic": [
                "인공지능 학습용 데이터셋의 품질관리 대상"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:28:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "l 인공지능 학습용 데이터 구축 과정은 다양한 유형의 데이터가 사전에 정의된 목적에 따라 구축되기 때문에 세부적으로는 상이할 수 있으나, 구축계획 수립, 데이터 획득/수집, 데이터 정제, 데이터 가공, 데이터 학습 순서로 반복하여 진행 l 인공지능 학습용 데이터 구축 과정에서 확보된 품질이 학습데이터 전체의 품질을 결정하기 때문에, 인공지능 학습용 데이터의 품질관리를 위해서는 데이터 구축 시 수행되는 구축공정의 이해 필요 l 구축계획 수립 단계 - 인공지능이 기계학습을 통해 해결하고자 하는 문제를 명확하게 정의하고, 문제 해결에 필요한 인공지능 학습용 데이터를 구체적으로 정의하고 설계하는 활동 - 구축계획서에는 ‘구축 개요’, ‘데이터 구축’, ‘품질 자가점검 계획’ 등 데이터 구축 목적과의 일관성 확보를 위한 세부내용을 작성하고, 특히 사업공고문의 요구사항을 반영하여 명확하고 구체적으로 작성 l 데이터 획득/수집 단계 - 인공지능의 기계학습에 필요한 데이터를 현실 세계에서 직접 생산하거나, 이미 보유하고 있는 조직이나 시스템 등으로부터 인공지능 학습에 필요한 데이터를 확보하는 등, 법률적 제약이 없도록 목적에 따른 ‘원시데이터’를 확보하는 활동 수행 - 데이터 획득/수집 시 일부 범주에만 치우치지 않도록 다양한 시간, 공간, 집단 수준 등이 포함되어야 함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:28:mh: 00001",
                    "page": 28
                }
            },
            {
                "context_id": "2",
                "text": "- 원시데이터를 직접 획득하거나 수집하는 경우, 특성을 고려하여 원시데이터의 품질을 확보 - ‘원시데이터’는 기계학습을 목적으로 획득 또는 수집한 ‘이미지’, ‘비디오’, ‘오디오’, ‘텍스트’ 등의 데이터를 의미 l 데이터 정제 단계 - 획득한 원시데이터를 학습에 필요한 형식 및 크기로 조정하고, 데이터 중복제거, 개인 정보 비식별화 처리 등의 과정을 통해 ‘원천데이터’를 확보하는 활동 수행 - 이 단계에서 확보된 ‘원천데이터’는 데이터 가공되지 않은 상태의 데이터이며, 원천데이터는 원시데이터를 데이터 가공작업을 수행하기 위해 정제 작업을 수행한 데이터를 의미 l 데이터 가공 단계 - 인공지능의 학습에 활용할 수 있도록 기능이나 목적에 부합하는 라벨을 원천데이터에 부착하는 ‘라벨링’ 작업 수행 - 여기서 생성된 ‘가공데이터’는 원천데이터에 부여한 ‘참값(Ground Truth)’, 파일 형식, 해상도 등의 데이터 속성과 설명, 주석 등이 포함된 ‘어노테이션’의 집합을 의미 - 어노테이션 정보는 데이터 확장을 고려하여 라벨링 용어 정의 및 분류체계의 표준을 준수 ※ 데이터 구축 시 임무 유형 및 목적에 따라 가공단계를 생략할 수 있음 l 데이터 학습 단계 - ‘학습 데이터셋’을 이용하여 사전에 정의된 인공지능 모델을 학습시키고, 학습된 AI모델의 성능을 향상시키거나 보정하는 활동 수행 - ‘학습 데이터셋’은 ‘원천데이터’와 ‘가공데이터’ 쌍을 의미 - 데이터 학습 유효성 평가를 위한 정확도, 정밀도, 재현율 등 성능지표 확인",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:28:mh: 00001",
                    "page": 29
                }
            }
        ],
        "summarization": "인공지능 학습용 데이터 구축 과정은 구축 계획 수립 단계, 데이터 획득 및 수집 단계, 데이터 정제 단계, 데이터 가공 단계, 데이터 학습 단계를 반복하여 진행한다. 인공지능 학습용 데이터 구축 과정에서 확보된 품질이 학습데이터 전체의 품질을 결정하기 때문에, 품질관리를 위해 데이터 구축공정의 이해가 필요하다.",
        "long_answer": {
            "question": "인공지능 학습용 데이터 구축 과정 중 데이터 정제 단계에서 하는 일에 대해 서술하라.",
            "answer": "인공지능 학습을 위한 데이터 구축 과정 중 데이터 정제 단계에서는 획득한 원시데이터를 학습에 필요한 형식 또는 크기 등으로 조정하고, 개인정보 비식별화, 데이터 중복 제거 등의 처리 과정을 통해 '원천데이터'를 확보한다.",
            "rubric": [
                "학습용 데이터; 데이터 정제; 원시데이터; 원천데이터"
            ]
        },
        "short_answer": {
            "question": "원천데이터에 해상도나 형식 등의 속성 정보값을 부여한 데이터를 무엇이라 하는가?",
            "answer": "가공데이터",
            "topic": [
                "가공데이터의 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 인공지능 학습용 데이터셋 구축 관련 용어에 대한 설명이 올바르게 된 것을 고르시오.",
            "choices": [
                "a) 학습 데이터셋은 원시데이터와 가공데이터의 쌍이다.",
                "b) 원시데이터는 데이터의 중복 등을 제거한 데이터 셋이다.",
                "c) 가공데이터는 라벨링 작업의 결과물로 생성된다.",
                "d) 원천데이터가 될 수 있는 것은 텍스트와 이미지뿐이다."
            ],
            "answer": "c",
            "topic": [
                "원천데이터; 원시데이터; 가공데이터; 라벨링; 학습 데이터셋"
            ]
        },
        "true_false": {
            "question": "인공지능 기계학습을 목적으로 원시데이터를 확보하는 경우 법률적 제약 없이 자유롭게 수집이 가능하다.",
            "answer": "FALSE",
            "topic": [
                "원시데이터 수집의 법률적 제약"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:44:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "l 사업수행기관은 구축되는 인공지능 학습용 데이터의 실질적 품질관리 실무를 담당하는 ‘품질관리 조직’ 구성 l 구성되는 ‘품질관리 조직’은 작업자, 모델설계자, 외부기관 또는 전문가 등으로 구성하며 각 수행조직의 역할과 책임을 공식화하고, 품질관리 업무가 원활히 수행되는지 ‘총괄책임자’ 또는 ‘실무책임자’ 주도하에 수시로 확인 및 관리  3.1 품질관리 조직 구성 시 고려사항 - 사업수행기관(주관기관, 참여기관)의 유기적인 관계를 지닌 조직 구성 - 명확한 업무 분장을 통한 책임 소재를 파악할 수 있는 업무수행조직 구성 - 사업수행기관(주관기관, 참여기관) 간의 보고체계 구축 - 데이터 획득/수집 기관, 정제 및 가공(라벨링) 기관, 데이터 학습모델 기관 등이 상이할 경우, 각 공정별로 참여 조직 구성 - 특히 인공지능 학습용 데이터 학습모델을 담당하는 기관의 참여는 필수 - 구축 후 데이터 운영·활용 체제로의 원활한 전환 - 인공지능 학습용 데이터의 품질확보  3.2 품질관리 조직의 주요 업무 내용 - 품질관리 계획의 수립 및 보완 - 품질관리를 위한 협의체 구성 및 운영 - 구축 프로세스의 품질검사 및 개선 - 인공지능 학습용 데이터의 품질검사 및 개선 - 사업수행기관의 품질관리 역량 강화를 위한 품질관리 교육 실시 - 데이터 운영・활용 단계에서 발견된 품질 개선의견 조치",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:44:0001",
                    "page": 44
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능 학습 데이터 구축 시 사업수행기관은 품질관리 조직을 구성해야한다. 품질관리 조직은 작업자, 모델 설계자, 외부기관, 전문가 등으로 구성하며 총괄책임자 또는 실무책임자 주도하에 수시로 품질관리 업무 수행 확인 및 관리가 필요하다.",
        "long_answer": {
            "question": "품질관리조직의 주요 업무 내용을 두가지 이상 쓰시오.",
            "answer": "AI 학습데이터 품질관리조직은 품질 관리 계획을 세우고, 이를 보완하며 품질 관리를 위한 협의체를 구성하고 운영합니다. 또한 학습 데이터의 품질검사를 통해 데이터의 품질을 개선하고 사업 수행기관의 품질관리 역량 강화를 위해 품질관리 교육을 실시합니다.",
            "rubric": [
                "품질관리조직; 품질검사; 품질관리 교육"
            ]
        },
        "short_answer": {
            "question": "인공지능 학습용 데이터의 실질적 품질관리를 담당하는 품질관리 조직을 구성하는 주체는 누구인가?",
            "answer": "사업수행기관",
            "topic": [
                "인공지능 학습용 데이터 품질관리 조직 주체; 사업수행기관"
            ]
        },
        "multiple_choice": {
            "question": "AI 학습데이터 품질관리 조직에 대한 설명으로 적합한 것을 고르시오.",
            "choices": [
                "a) 품질관리 조직 구성에는 작업자가 포함될 수 있다.",
                "b) 품질관리 조직 구성 시 데이터 학습모델 담당 기관은 선택적 참여가 가능하다.",
                "c) 품질검사 진행은 품질관리 조직이 아닌 타 조직에서 진행한다.",
                "d) 품질관리는 사업 수행 계획이 종료된 뒤 사업 최종 보고시기에 진행한다."
            ],
            "answer": "a",
            "topic": [
                "AI 학습데이터 품질관리 조직"
            ]
        },
        "true_false": {
            "question": "인공지능 학습을 위한 데이터셋 구축에서 품질관리 조직 구성 시 데이터 학습모델 담당 기관은 반드시 조직에 포함되어야 한다.",
            "answer": "TRUE",
            "topic": [
                "인공지능 학습용 데이터 품질관리 조직의 필수 구성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:45:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "총괄책임자   Ÿ 해당 인공지능 학습용 데이터 구축사업의 공모과제 책임자가 되며, 구축사업 착수 이전에데이터 품질관리 실무를 총괄하는 ‘실무책임자’ 지정  실무책임자  Ÿ 인공지능 학습용 데이터 구축사업의 품질관리 실무를 총괄하며, 타 업무와 겸직을 하지 않고, 품질관리 업무만을 전담하여 수행 Ÿ 구축하는 인공지능 학습용 데이터의 품질관리 계획을 수립하고, 품질관리 실무 수행조직을 운영하여 품질관리 활동을 수행하고, 품질관리 실무와 관련된 협의체 구성 및 운영 담당  품질관리 실무 협의회  Ÿ 인공지능 학습용 데이터의 품질관리 관련 실무차원의 주요사항을 검토하고, 조직간 협의 사항 조정, 조율 등을 위한 ‘품질관리 실무 협의회’를 설치·운영 Ÿ 사업수행기관의 품질관리 계획의 적정성 등을 평가하여 보완하고, 구축과정에서 발견된 데이터 품질 이슈를 논의하여 해결방안을 제시하는 등 상호 간의 의사소통 및 품질관리 실무를 협의하는 역할 담당 Ÿ 구축공정별 실무 담당자, AI모델 설계자, 외부 품질전문가 등 참여  구축 프로세스 품질담당  Ÿ 데이터 획득/수집, 정제, 가공 등 구축과정별로 구분하여 담당자를 지정할 수 있으며, 인공지능 학습용 데이터의 구축과정이나 구축 규모, 구축 난이도 등을 고려해서 담당자 지정 Ÿ 품질관리계획에 명시된 품질관리 활동의 준수 여부를 확인하고, 품질 이슈 발생 시 이를 기록하고 개선하는 활동을 수행하며, 즉각적인 조치가 불가능하거나 협의가 필요한 사항은 실무책임자에게 보고하는 등 역할 수행",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:45:mh: 00001",
                    "page": 45
                }
            },
            {
                "context_id": "2",
                "text": "구축 데이터 품질담당  Ÿ 구축과정에서 생성되는 ‘원시데이터’, ‘원천데이터’, ‘가공데이터’의 품질을 확보하기 위해 품질계획에 수립된 검사기준과 절차 등에 따라 품질을 검사하고, 개선하는 활동 수행  활용 품질담당  Ÿ 구축 이후에 AI-Hub를 통해 민간에 개방한 인공지능 학습용 데이터의 품질오류가 발견된 경우, 이를 전달받아 조치하는 역할 수행 Ÿ ‘활용 품질담당’은 구축과정에서 ‘구축 데이터 품질담당’의 역할을 지원하며, 실제 구축과정에서의 품질관리 경험을 통해 활용 단계에서도 품질 활동을 지원할 수 있도록 ‘품질관리계획서’ 및 사용자에게 제공되는 ‘활용 가이드라인’에 담당자 명시",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:45:mh: 00001",
                    "page": 46
                }
            }
        ],
        "summarization": "인공지능 구축사업 사업수행기관 품질관리 조직은 총괄책임자, 실무책임자, 품질관리 실무 협의회, 구축 프로세스 품질담당, 구축 데이터 품질담당, 활용 품질담당으로 구성된다.",
        "long_answer": {
            "question": "인공지능 학습용 데이터 구축사업의 사업수행기관 품질관리 조직에서 품질관리 실무 협의회는 어떤 역할을 하는가?",
            "answer": "품질관리 실무 협의회는 사업수행기관의 품질관리 계획 적정성 평가 및 보완, 구축 시 발견된 품질 이슈에 대해 해결방안 제시 등 상호간의 의사소통과 품질관리 실무 협의의 역할을 맡습니다. 여기에는 실무차원의 주요사항을 검토, 조정, 조율하는 일 또한 포함됩니다.",
            "rubric": [
                "품질관리 실무 협의회;  품질관리 계획; 품질 이슈; 의사소통; 협의"
            ]
        },
        "short_answer": {
            "question": "AI 학습데이터 활용 단계에서 품질활동을 지원하기 위해 품질관리계획서와 활용 가이드라인에 무엇을 명시해야 하는가?",
            "answer": "담당자",
            "topic": [
                "활용 품질담당"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 인공지능 학습용 데이터 구축사업 품질관리 계획 수립, 실무 수행조직 운영, 협의체 구성 등의 역할에 적합한 사람은?",
            "choices": [
                "a) 총괄책임자",
                "b) 구축 프로세스 품질담당",
                "c) 활용 품질담당",
                "d) 실무책임자"
            ],
            "answer": "d",
            "topic": [
                "인공지능 학습용 데이터 구축사업 품질관리 실무책임자"
            ]
        },
        "true_false": {
            "question": "인공지능 학습용 데이터 구축사업 시 품질관리 실무의 총괄은 총괄책임자가 맡는다.",
            "answer": "FALSE",
            "topic": [
                "인공지능 학습용 데이터 구축사업 품질관리 총괄책임자"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:47:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1.1 구축계획 수립(110) l 인공지능 학습용 데이터 유형별로 데이터 구축에 필요한 절차 및 구성요소를 제시하여 데이터 구축과정에서의 시행착오를 줄이고 체계적인 계획을 수립하는 단계 l 구축계획 수립단계에서는 자료 준비 및 사업수행계획서 작성 등 사업수행을 위한 계획과 학습용 데이터를 목적 등에 맞게 구체적으로 설계하는 단계 l 구축목적의 일치성과 일관성 확보를 위한 구축계획문서를 작성하여 사업 종료 시까지 변경 및 현행화 필요",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:47:0001",
                    "page": 47
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "구축계획 수립 단계는 인공지능 학습용 데이터 구축을 위해 절차와 구성요소를 제시하여 시행착오를 줄이고 체계적인 계획을 세우는 단계로, 자료 준비와 사업수행계획서 작성 등을 포함한다. 또한 구축 목적의 일관성, 일치성을 유지하기 위해 구축계획문서를 작성한다.",
        "long_answer": {
            "question": "인공지능 학습용 데이터 구축 과정에서 구축계획 수립 단계의 주 목적에 대해 설명하시오.",
            "answer": "구축계획 수립 단계의 주요 목적은 인공지능 학습용 데이터 구축에 필요한 절차와 구성요소를 미리 제시하여 시행착오를 줄이고, 체계적이고 효율적인 데이터 구축이 이루어지도록 하는 것이다.",
            "rubric": [
                "구축계획 수립 단계; 주요 목적; 제시; 시행착오"
            ]
        },
        "short_answer": {
            "question": "인공지능 학습용 데이터 구축계획 수립 단계에서 구축목적과 관련된 어떤 특성을 확보하기 위해 구축계획 문서를 작성하는가?",
            "answer": "일관성, 일치성",
            "topic": [
                "구축계획수립 단계; 일관성; 일치성"
            ]
        },
        "multiple_choice": {
            "question": "아래의 문서 중 데이터 구축계획 수립 단계에서 작성할 수 없는 것은?",
            "choices": [
                "a) 저작도구 사용설명서",
                "b) 사업수행계획서",
                "c) 구축계획문서",
                "d) 학습용 데이터 목적 설계서"
            ],
            "answer": "a",
            "topic": [
                "데이터 구축 계획 수립 단계 산출물"
            ]
        },
        "true_false": {
            "question": "구축계획 수립 단계에서 작성된 구축계획문서는 사업이 끝날 때까지 변경할 수 없다.",
            "answer": "FALSE",
            "topic": [
                "구축계획 수립 단계의 구축계획문서 수정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:42:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "인공지능 학습용 데이터 구축사업의 조직구조는 사업발주기관인 사업관리기관, 사업수행을 위한 사업수행기관과 제3자 품질검증을 위한 품질검증기관으로 구성되어 있음 사업관리기관 (NIA)  사업담당기관 (PMO) Ÿ 사업자 선정, 과제조정, 협약체결, 사업수행관리, 최종 산출물 관리 등  사업 총괄 관리  품질관리팀 (품질컨설팅)  Ÿ 품질관리팀에 품질컨설팅 조직 구성 Ÿ 품질컨설팅과 품질교육 담당 Ÿ 사업수행기관의 품질관리 역량 강화 및 품질 관련 이슈 사항 해결 Ÿ 사업담당자의 품질관리 지원 Ÿ 수행 업체 품질관리 산출물 가이드 및 검토  사업수행기관 품질관리조직  Ÿ 준비·계획 단계에서 품질조직을 구성 Ÿ 구축단계별 품질관리 활동을 수행하여 관련 산출물 제출 Ÿ 구축공정 가이드라인 현행화 Ÿ 데이터 품질관리 산출물 개선  품질검증기관 제3자 품질검증기관  Ÿ 사업수행기관과 품질지표 기준을 합의하고, 합의된 지표를 기준으로 품질검증을 실시하여 품질검증 결과 확인",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:42:0001",
                    "page": 42
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "인공지능 학습용 데이터 구축사업 품질관리의 이해관계자는 사업관리기관, 사업수행기관과 품질검증기관으로 구성되어 있다. 사업관리기관 내에서는 사업담당기관과 품질관리팀 조직, 사업수행기관 내에는 품질관리조직, 품질검증기관은 제3자 품질검증기관이 품질관리 조직에 해당한다.",
        "long_answer": {
            "question": "인공지능 학습을 위한 데이터 구축사업에서 품질관리 이해관계자 중 사업관리기관 하의 품질관리팀이 하는 일을 세가지 이상 작성하시오.",
            "answer": "인공지능 학습을 위한 데이터 구축사업에서 품질관리 이해관계자 중 사업관리기관 하의 품질관리팀은 품질컨설팅과 품질교육을 담당하며 사업담당자의 품질관리를 지원한다. 그외에도 수행 업체에서 작성한 품질관리 산출물 가이드 및 검토의 역할을 한다.",
            "rubric": [
                "품질컨설팅; 사업담당자; 품질관리팀; 산출물"
            ]
        },
        "short_answer": {
            "question": "AI 학습 데이터 구축사업의 조직구조를 구성하는 세 개의 기관은 무엇입니까?",
            "answer": "사업관리기관, 사업수행기관, 품질검증기관",
            "topic": [
                "AI 학습 데이터 구축사업의 조직구조"
            ]
        },
        "multiple_choice": {
            "question": "인공지능 학습용 데이터 구축사업 품질관리 이해관계자 조직에 대한 설명으로 옳지 않은 것은?",
            "choices": [
                "a) 품질관리팀은 수행기관의 품질관리 역량을 강화한다.",
                "b) 품질검증기관은 합의된 품질지표에 따라 검증을 수행한다.",
                "c) 사업담당기관은 구축단계별 품질관리 활동을 직접 수행한다.",
                "d) 사업수행기관은 품질관리 조직을 구성하고 산출물을 제출한다."
            ],
            "answer": "c",
            "topic": [
                "품질관리 이해관계자 조직"
            ]
        },
        "true_false": {
            "question": "품질관리팀은 품질교육과 컨설팅을 통해 사업수행기관의 품질관리 역량을 높인다.",
            "answer": "TRUE",
            "topic": [
                "품질관리팀의 역할"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:48:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "사업수행계획서 - 구축계획서 - 품질관리계획서  Ÿ 사업수행계획서 : 사업 공모 시 제출한 사업수행계획에 대한 공식 산출물 Ÿ 구축계획서 : 데이터 구축공정, 구축 데이터 정의, 데이터 검사 등 Ÿ 품질관리계획서 : 품질지표 및 기준, 검사절차, 품질교육 등 Ÿ 과제조정위원회 검토의견, 품질지표 합의 등에 따라 구축계획서 및 품질관리계획서 수정",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:48:mh: 00001",
                    "page": 48
                }
            },
            {
                "context_id": "2",
                "text": "품질지표 기준서  Ÿ 품질검증을 위한 필수 산출물로 협약 후 품질검증기관과의 합의에 의한 산출물 Ÿ 최종 제출 시는 사업수행계획서의 품질관리계획서에 붙임으로 제출",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:48:mh: 00001",
                    "page": 49
                }
            }
        ],
        "summarization": "인공지능 학습용 데이터 구축 단계에서는 사업수행계획서, 구축계획서, 품질관리계획서가 주요 산출물로 제시된다. 이들은 데이터 구축 절차와 품질관리를 체계적으로 수행하기 위한 공식 문서들이다.",
        "long_answer": {
            "question": "AI 학습용 데이터 구축 과정에서 사업수행계획서, 구축계획서, 품질관리계획서가 각각 어떤 문서인지 설명하시오.",
            "answer": "사업수행계획서는 사업 공모 시 제출한 수행계획을 공식적으로 정리한 문서이며 구축계획서는 데이터 구축공정, 데이터 정의,데이터 검사 등에 대한 문서이다. 품질관리계획서는 품질지표, 검사절차, 품질교육 등에 대한 문서이다.",
            "rubric": [
                "사업수행계획서; 구축계획서; 품질관리계획서"
            ]
        },
        "short_answer": {
            "question": "품질지표 기준서는 최종제출 시 사업계획서의 어떤 문서에 붙임으로 제출해야 하는가?",
            "answer": "품질관리계획서",
            "topic": [
                "품질지표기준서의 제출형식"
            ]
        },
        "multiple_choice": {
            "question": "아래 중 인공지능 학습용 데이터 구축사업에서 사업 공모단계 시 제출하는 공식문서인 것은?",
            "choices": [
                "a) 품질관리계획서",
                "b) 사업수행계획서",
                "c) 구축계획서",
                "d) 품질지표기준서"
            ],
            "answer": "b",
            "topic": [
                "사업수행계획서"
            ]
        },
        "true_false": {
            "question": "과제조정위원회의 검토의견을 받아보고 구축계획서를 수정할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "구축계획서 수정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:52:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "법・제도 준수  Ÿ 원시데이터 획득 시 관련 법・제도적 규정 등을 반드시 준수하여야 함 Ÿ 개인정보 및 사생활 보호가 필요한 항목 획득 시, 개인정보보호법 등에 따라 적절한 법적, 기술적 절차를 거친 데이터를 활용하며, 그렇지 않은 데이터는 정제 과정에서 처리될 수 있도록 함 Ÿ 의료 데이터의 경우는 IRB(의학연구윤리심의위원회)와 데이터 공개에 대한 해당 기관의 동의(DRB)를 사전에 획득 필요 Ÿ 지적재산권 이슈가 있는 경우 반드시 해결방안을 마련하여 획득해야 함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:52:0001",
                    "page": 52
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "원시데이터 획득 시 법과 제도를 반드시 지켜야한다. 여기에는 개인정보보호, 의료 데이터 심의, 지적재산권 이슈 해결 등이 포함된다.",
        "long_answer": {
            "question": "원시데이터 획득 과정에서 개인정보 보호가 필요한 항목을 획득했다면 어떤 처리를 해야 하는지 서술하시오.",
            "answer": "인공지능 학습데이터 구축을 위한 원시데이터 획득 과정에서 해당 데이터에 개인정보 보호가 필요한 항목이 있다면 우선 개인정보보호법 등에 따라 법적, 기술적 절차를 거친다. 또한 그렇지 않은 데이터는 정제 과정에서 반드시 처리될 수 있도록 한다.",
            "rubric": [
                "원시데이터; 개인정보; 정제; 개인정보보호법"
            ]
        },
        "short_answer": {
            "question": "인공지능 학습 데이터 중 의료 데이터의 경우 어떤 위원회를 거쳐야 하는가?",
            "answer": "IRB(의학연구윤리심의위원회)",
            "topic": [
                "IRB(의학연구윤리심의위원회)"
            ]
        },
        "multiple_choice": {
            "question": "AI 학습을 위한 원시데이터 획득 시 지켜야 할 법 및 제도에 대한 설명으로 틀린 것을 고르시오.",
            "choices": [
                "a) 지적재산권과 관련된 문제가 있는 경우 반드시 해결방안을 찾아 획득해야 한다.",
                "b) 사생활 보호가 필요한 항목을 원시데이터로 획득한다면 개인정보보호법을 지켜야 한다.",
                "c) 개인정보 보호 조치를 하지 않은 원시데이터는 정제 과정에서 처리한다.",
                "d) 의료데이터의 경우는 ARB와 데이터 공개에 대한 해당 기관의 동의를 사전에 획득해야 한다."
            ],
            "answer": "d",
            "topic": [
                "원시데이터의 법과 제도 준수"
            ]
        },
        "true_false": {
            "question": "지적재산권이 있는 데이터는 법적 문제를 해결하지 않아도 원시데이터로 사용할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "원시데이터의 지적재산권"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:55:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.3 데이터 가공(230) l AI모델의 기능이나 목적에 맞게 원천데이터에 적절한 라벨을 추가하는 과정 l 어노테이션 정보는 데이터 확장을 고려하여 항목명, 타입, 필수 구분, 항목 설명을 포함해야 하며 라벨링 용어 및 분류체계는 표준을 준수해야 함 l 가공 방법에 따른 도구 사용 및 작업 방식에 의한 모든 산출 데이터는 CSV, JSON 등 표준화된 포맷으로 제공하며 이에 대한 품질검사 진행",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:55:0001",
                    "page": 55
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 가공은 AI 모델의 목적에 맞게 원천데이터에 라벨을 추가하는 과정으로, 표준화된 어노테이션 체계를 사용하며 표준화된 포맷을 제공한다. 이때 포맷에 대한 품질검사 또한 수행해야 한다.",
        "long_answer": {
            "question": "인공지능 학습 데이터 구축과정 중 데이터 가공 단계에서 어노테이션 정보 구축을 위해 고려해야 할 점을 서술하시오.",
            "answer": "어노테이션 정보에는 항목명, 타입, 필수 구분, 항목 설명 등을 포함해야하는데 이는 추후 데이터 확장 등을 고려해서이다. 어노테이션에서 사용하는 모든 라벨링 용어와 분류체계는 전부 표준을 준수해야한다.",
            "rubric": [
                "어노테이션; 데이터 확장; 라벨링; 분류체계; 표준"
            ]
        },
        "short_answer": {
            "question": "AI 학습 데이터 구축과정에서 제공할 수 있는 표준화된 산출 데이터 포맷의 예를 한가지 쓰시오.",
            "answer": "JSON",
            "topic": [
                "산출 데이터 포맷"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 데이터 가공 단계의 특징으로 옳은 것은?",
            "choices": [
                "a) 데이터 수집을 위한 원천데이터 확보에 중점을 둔다.",
                "b) AI 모델의 목적과 무관하게 데이터를 분류한다.",
                "c) 원천데이터에 라벨링하는 과정이다.",
                "d) 데이터의 양을 늘리는 것을 목표로 한다."
            ],
            "answer": "c",
            "topic": [
                "데이터 가공 단계의 특징"
            ]
        },
        "true_false": {
            "question": "인공지능 학습을 위한 데이터 구축 과정 중 데이터 가공 단계에서는 원시데이터가 아닌 원천데이터에 라벨을 추가한다.",
            "answer": "TRUE",
            "topic": [
                "원천데이터의 라벨링"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:77:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "과제조정위원회 과제조정위원회 자가점검 Ÿ 사업수행계획서 내 구축계획서, 품질관리계획서의 적정성  검토  데이터 설계 시점 샘플데이터 1-Cycle 자가점검  Ÿ 데이터 설계(명세) 적정성 점검 Ÿ 데이터 구축목적과 AI 학습모델 후보군의 합치성 및 준비도 점검 Ÿ 샘플데이터(전체데이터의 1% 이내)  구축 초기 시점 초기데이터 1-Cycle 자가점검  Ÿ 사전 품질검증 전 측정지표 적정성 및 정량목표 달성도 점검 Ÿ 데이터 구축 실행단계에서의 오류 유형에 따른 보완조치방안 마련 및 반영 여부 확인 Ÿ 초기데이터(전체데이터의 10% 이내)",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:77:mh: 00001",
                    "page": 77
                }
            },
            {
                "context_id": "2",
                "text": "중간 시점 중간데이터 1-Cycle 자가점검  Ÿ 구축 초기 단계 품질점검 및 사전품질검증 결과에 따른 개선 여부 점검 Ÿ 중간데이터 기반 구축 목표 달성(다양성, 구문 정확성, 의미 정확성, 유효성) 여부 점검 및 대책 마련 Ÿ 전체 구축량의 30% 이상 데이터  최종 시점 최종데이터 1-Cycle 자가점검  Ÿ 최종 품질검증 대비 구축 데이터 품질오류 최종 보완 확인 Ÿ 최종 품질관리 결과 점검 Ÿ 전체 데이터(100%) 및 산출물",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:77:mh: 00001",
                    "page": 78
                }
            }
        ],
        "summarization": "데이터 구축 과정은 설계, 초기, 중간, 최종 시점으로 구분하며 각 단계별 자가점검을 통해 품질과 적정성을 검토하고 개선하는 체계를 가진다. 각 단계에서는 데이터의 목적 부합성, 품질지표, 오류보완 및 목표 달성 여부를 점검하여 최종 품질 확보를 목표로 한다.",
        "long_answer": {
            "question": "데이터 품질 점검 시 중간 시점과 최종 시점에 진행되는 주요 검토내용에 대해 서술하시오.",
            "answer": "중간 시점의 자가점검은 구축 초기의 품질검증 결과를 바탕으로 개선 여부를 확인하고, 중간데이터를 통해 다양성, 구문 정확성, 의미 정확성, 유효성 등 품질 목표 달성 여부를 점검한다. 최종 시점의 자가점검은 최종 품질검증 대비 오류 보완 여부와 전체 데이터의 품질관리 결과를 확인하여 프로젝트 완료 전 최종 품질 결과를 점검한다.",
            "rubric": [
                "중간 시점; 최종 시점; 품질검증; 품질 목표"
            ]
        },
        "short_answer": {
            "question": "인공지능 학습을 위한 데이터 품질 자가점검 프로세스 중 데이터 명세의 적정성을 점검하는 시기는 어떤 시점인가?",
            "answer": "데이터 설계 시점",
            "topic": [
                "데이터 설계 시점 시 데이터 명세 점검"
            ]
        },
        "multiple_choice": {
            "question": "데이터 품질 자가점검 시 중간 시점에 확인해야하는 데이터의 구축량 퍼센트로 옳은 것은?",
            "choices": [
                "a) 전체 데이터의 1% 이내",
                "b) 전체 데이터의 10% 이내",
                "c) 전체 데이터의 20% 이내",
                "d) 전체 데이터의 30% 이내"
            ],
            "answer": "d",
            "topic": [
                "중간 시점 데이터 점검 대상 구축량"
            ]
        },
        "true_false": {
            "question": "데이터 설계 시점에는 초기데이터를 가지고 품질 점검활동을 진행한다.",
            "answer": "FALSE",
            "topic": [
                "데이터 설계 시점의 샘플데이터 품질 점검"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:91:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "번호 활 동 주 체 주요 내용 1 보완조치 시행 요구  사업관리 기관 (NIA)  Ÿ NIA는 사업수행기관에 품질 보완조치 시행 요구 공문 발송 Ÿ 품질 보완조치 시행 요구 시, 아래 항목 포함 - 품질 보완조치 절차 - 관련 서류 제출 기한 등  2 보완조치 계획 수립  사업수행 기관 Ÿ 사업수행기관은 보완조치 일정·방안에 대한 세부계획 수립  3 보완조치 수행 사업수행 기관 Ÿ 사업수행기관은 ‘품질검증 결과 오류’ 데이터에 대한 보완 수행* * 품질검증 결과서 수령 후 협의한 기간 내 조치를 완료하여야 함  4 보완조치 완료 사업수행 기관 Ÿ 사업수행기관은 보완조치 수행 결과를 ‘품질검증 결과 오류사항 조치결과서*’에 작성 * 과제담당자와 협의한 기간 내 조치 완료 Ÿ 사업수행기관은 보완 완료 데이터 및 결과서를 S3 버킷에 업로드** ** 보완조치에서 제외했던 데이터 포함 전체 데이터를 제출 경로 폴더에 업로드  5 보완결과 확인요청  사업수행 기관 Ÿ 사업수행기관은 NIA에 ‘품질 보완조치 결과 확인요청’ 공문 발송 - 해당 공문에는 ‘품질검증 결과 오류사항 조치결과서’ 첨부  6 결과 확인  사업관리 기관 (NIA)  Ÿ NIA는 사업수행기관의 제출공문(품질검증 결과 오류 사항 조치결과서 등)을 검토 - 보완결과 만족 시, 품질 보완조치 프로세스 종료 - 보완결과 불만족 시, 재보완조치 수행 요구",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:91:0001",
                    "page": 91
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "품질 보완조치 절차는 NIA의 품질 보완조치 시행 요구 공문 발송에서 시작한다. 이후 사업수행기관의 보완조치 계획 수립, 보완조치 수행, 완료, 결과 제출 및 확인요청의 과정을 거친다. 최종적으로 NIA의 제출공문 검토를 통해 만족하는 경우 품질 보완조치 프로세스가 종료된다.",
        "long_answer": {
            "question": "품질 달성 데이터 보완조치에서 보완조치 완료 단계는 어떻게 실행되는지 서술하시오.",
            "answer": "사업수행기관은 보완조치 수행 결과를 품질검증 결과 오류사항 조치결과서에 작성한다. 이와 동시에 보완 완료 데이터 및 결과서를 S3 버킷에 업로드해야한다.",
            "rubric": [
                "품질 달성 데이터 보완조치; 보완조치 완료; 품질검증 결과 오류사항 조치결과서"
            ]
        },
        "short_answer": {
            "question": "사업수행기관은 보완조치 완료 단계에서 보완조치 수행 결과를 어떤 문서에 작성하여야 합니까?",
            "answer": "품질검증 결과 오류사항 조치결과서",
            "topic": [
                "품질검증 결과 오류사항 조치결과서"
            ]
        },
        "multiple_choice": {
            "question": "품질 달성 데이터 보완조치 절차에 관한 설명으로 적합한 것은?",
            "choices": [
                "a) NIA는 사업수행기관에 품질 보완조치 시행 요구 공문을 보낸다.",
                "b) NIA는 품질검증결과 오류 데이터에 대한 보완을 수행한다.",
                "c) 사업수행기관은 NIA에서 품질 보완조치 결과 확인 요청 공문을 받는다.",
                "d) 사업수행기관은 제출공문을 검토한다."
            ],
            "answer": "a",
            "topic": [
                "품질 달성 데이터 보완 조치 절차 및 주체"
            ]
        },
        "true_false": {
            "question": "품질 달성 데이터 보완조치 중 보완결과 확인요청 단계에서 사업수행기관은 품질 보완조치 시행 요구를 별도의 공문으로 발송한다.",
            "answer": "FALSE",
            "topic": [
                "품질 달성 데이터 보완 조치 시행 요구"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:97:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "l 따라서, 데이터 품질관리 지표는 “데이터의 품질 수준을 측정하기 위한 관점을 정의한 것으로 무엇을 측정할 것인가에 대한 기준”이라고 정의할 수 있음  1.2 품질관리 지표 구성 l 데이터 품질관리 지표는 검사기준에 따라 “품질특성, 검사 항목, 측정지표”로 구성 l 품질관리 지표는 데이터 생애주기 분석, 데이터 구축 및 품질 관점에서의 일치성 분석, 데이터 품질관리 기준 분석을 기반으로 구성되며, 구축 및 활용 관점을 반영하여 총 9개의 품질특성으로 구성",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:97:mh: 00001",
                    "page": 97
                }
            },
            {
                "context_id": "2",
                "text": "l 9개의 품질특성은 준비성, 완전성, 유용성, 기준 적합성, 다양성, 구문 정확성, 의미 정확성, 알고리즘 적정성, 유효성으로 정의 l 수립된 데이터 품질의 9개 품질특성은 데이터 생애주기인 계획, 구축, 운영・활용의 전 단계의 품질관리에 활용하여 데이터 품질 수준을 확보하는 기준이 됨",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:97:mh: 00001",
                    "page": 98
                }
            }
        ],
        "summarization": "데이터 품질관리 지표는 데이터의 품질 수준을 측정하기 위한 관점을 정의한 것으로 무엇을 측정할 것인가에 대한 기준이다. 품질관리 지표는 검사기준에 따라 품질특성, 검사 항목, 측정지표로 구성되며 총 9개의 품질특성을 가진다.",
        "long_answer": {
            "question": "데이터 품질관리 지표에 대해 설명하시오.",
            "answer": "데이터 품질관리 지표는 검사기준에 따라 품질특성, 검사항목, 측정 지표로 구성된다. 이는 데이터의 품질 수준을 측정하기 위한 관점을 정의한 것이며, 무엇을 측정할 것인가에 대한 기준이다.",
            "rubric": [
                "데이터 품질관리 지표; 품질특성; 관점"
            ]
        },
        "short_answer": {
            "question": "데이터 품질관리 지표는 어떤 세 가지 구성요소로 이루어져 있는가?",
            "answer": "품질특성, 검사 항목, 측정지표",
            "topic": [
                "데이터 품질관리 지표의 구성요소"
            ]
        },
        "multiple_choice": {
            "question": "아래의 특성 중 데이터 품질특성에 해당하지 않는 것은?",
            "choices": [
                "a) 기준 적합성",
                "b) 구문 정보성",
                "c) 의미 정확성",
                "d) 알고리즘 적정성"
            ],
            "answer": "b",
            "topic": [
                "데이터 품질특성"
            ]
        },
        "true_false": {
            "question": "데이터 품질관리 지표는 데이터 품질 수준을 측정하기 위한 관점을 정의한다.",
            "answer": "TRUE",
            "topic": [
                "데이터 품질관리 지표의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:98:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "구축 공정 적정성  준비성  Ÿ 인공지능 학습용 데이터 품질관리를 위해 기본적으로 관리해야 하는 정책, 규정(저작권, 초상권, 개인정보보호 및 정보보호 등에 대한 검토 결과를 포함), 조직, 절차 등을 마련하고, 최신의 내용으로 충실하게 관리되는지를 검사 완전성 Ÿ 인공지능 학습용 데이터를 구축함에 있어 물리적인 구조를 갖추고, 정의한 데이터 형식 및 데이터값 범위에 맞게 데이터가 저장되도록 설계・구축되었는지를 검사 유용성 Ÿ 발주기관(수요자)의 요구사항이 충분히 반영되었는지, 임무 정의에 적합한 인공지능 학습용 데이터의 범위와 상세화 정도를 충족시키는지를 검사",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:98:0001",
                    "page": 98
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 품질특성 중 준비성, 완전성, 유용성은 구축 공정 적정성에 해당한다. 각각은 데이터 구축을 위한 준비, 형식, 임무 정의 등에 맞춰 충실히 기준을 충족시키는지를 검사한다.",
        "long_answer": {
            "question": "인공지능 학습을 위한 데이터 품질특정 중 준비성과 완전성에 대해 설명하시오.",
            "answer": "데이터 품질특성 중 준비성은 기본적으로 품질관리를 위해 관리해야하는 정책 규정, 조직, 절차 등을 마련했는지와 이것이 최신으로 충실하게 관리되는지를 검사한다. 완전성은 물리적인 구조와 정의한 데이터 형식, 데이터값 범위에 맞게 데이터가 저장되도록 설계 및 구축되었는지를 검사한다.",
            "rubric": [
                "데이터 품질특성; 준비성; 완전성; 데이터 형식"
            ]
        },
        "short_answer": {
            "question": "데이터 품질특성 중 구축 공정 적정성에 해당되는 품질특성 세가지를 쓰시오.",
            "answer": "준비성, 완전성, 유용성",
            "topic": [
                "데이터 품질특성 구축 공정 적정성"
            ]
        },
        "multiple_choice": {
            "question": "데이터 품질 특성 중 인공지능 학습 데이터를 구축함에 있어 물리적인 구조를 갖추었는지를 검사하는 지표에 알맞은 것은?",
            "choices": [
                "a) 다양성",
                "b) 유효성",
                "c) 완전성",
                "d) 유용성"
            ],
            "answer": "c",
            "topic": [
                "데이터 품질특성 중 완전성"
            ]
        },
        "true_false": {
            "question": "유용성은 수요자의 요구사항이 충분히 반영되었는지와 개인정보 보호에 대한 검토에 합당한지를 판단하는 품질 특성이다.",
            "answer": "FALSE",
            "topic": [
                "데이터의 품질특성 중 유용성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:98:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 적합성 기준 적합성 Ÿ 원시데이터가 학습 용도로써 적합한지 기준 충족 여부를 확인하기 위해, 분류 다양성, 신뢰성, 충분성, 균일성, 사실성, 공평성, 형식성을 측정하는 품질특성 다양성 Ÿ 원천/가공데이터의 편향성을 방지하기 위해, 데이터별 분포, 데이터별 수, 토큰수  등을 측정하는 품질특성",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:98:0001",
                    "page": 98
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 품질특성 중 기준 적합성과 다양성은 데이터 적합성에 해당한다. 각각은 데이터가 학습 용도로써 적합한지, 편향성을 가지고 있지 않은지 등을 측정한다.",
        "long_answer": {
            "question": "기준 적합성 품질특성을 가지고 측정하고자 하는 특성은 무엇이 있는지 서술하시오.",
            "answer": "원시데이터가 인공지능의 학습 용도로써 적합한지, 기준을 충족하고 있는지 여부를 확인하기 위해서 분류 다양성, 신뢰성, 충분성, 균일성, 사실성, 형식성을 측정한다.",
            "rubric": [
                "기준 적합성; 분류 다양성; 신뢰성; 충분성; 균일성; 사실성; 형식성"
            ]
        },
        "short_answer": {
            "question": "원천데이터의 편향성을 피하기 위해 데이터별 분포나 수 등을 측정하는 품질특성을 무엇이라 하는가?",
            "answer": "다양성",
            "topic": [
                "데이터 품질특성 중 다양성의 정의"
            ]
        },
        "multiple_choice": {
            "question": "아래의 항목 중 다양성 품질특성에서 측정하지 않는 기준은 무엇인가?",
            "choices": [
                "a) 데이터별 분포",
                "b) 데이터별 수량",
                "c) 토큰 수량",
                "d) 데이터 참값의 정확도"
            ],
            "answer": "d",
            "topic": [
                "데이터 품질특성 중 다양성의 측정 대상"
            ]
        },
        "true_false": {
            "question": "기준 적합성은 원시데이터의 균일성이나 공평성을 측정하는 품질특성이다.",
            "answer": "TRUE",
            "topic": [
                "데이터 품질특성 중 기준 적합성의 측정 대상"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:98:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "가공 데이터 정확성 구문 정확성 Ÿ 어노테이션 데이터를 구성하는 속성값들과 원래 정의한 데이터 형식 및 데이터값  범위와의 일치성을 측정하는 품질특성  의미 정확성 Ÿ 데이터의 참값(GT)을 확인하기 위해, 정확도, 정밀도, 재현율, IoU, ROUGE,  BLEU, Fβ-점수, EM 등을 측정하는 품질특성",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:98:0001",
                    "page": 98
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 품질특성 중 구문 정확성과 의미 정확성은 가공 데이터 정확성에 해당된다. 이는 어노테이션 데이터의 속성값과 사전 정의 형식간의 일치, 데이터 참값 등을 측정하는 특성이다.",
        "long_answer": {
            "question": "구문 정확성과 의미 정확성을 비교하여 각각이 측정하는 대상의 차이를 설명하시오.",
            "answer": "구문 정확성은 데이터의 형식적 일관성에 초점을 맞추며, 속성값이 정의된 형식이나 범위에 부합하는지를 평가한다. 반면 의미 정확성은 데이터가 실제 참값(GT)과 얼마나 일치하는지를 중점적으로 본다. 즉, 구문 정확성은 형식의 맞음을, 의미 정확성은 내용의 맞음을 측정하는 점에서 차이가 있다.",
            "rubric": [
                "구문 정확성; 의미 정확성; 형식; 참값"
            ]
        },
        "short_answer": {
            "question": "데이터 품질특성 중 구문 정확성은 어노테이션 데이터를 구성하는 속성값들과 무엇 간의 일치를 측정하는가?",
            "answer": "원래 정의한 데이터 형식 및 데이터값 범위",
            "topic": [
                "구문 정확성의 대상"
            ]
        },
        "multiple_choice": {
            "question": "품질특성 중 의미 정확성에서 측정하고자 하는 것이 아닌 것은?",
            "choices": [
                "a) 정직도",
                "b) 정확도",
                "c) 정밀도",
                "d) 재현율"
            ],
            "answer": "a",
            "topic": [
                "데이터 품질특성 중 의미 정확성의 대상"
            ]
        },
        "true_false": {
            "question": "데이터 품질특성 중 구문 정확성은 구문을 얼마나 정확히 구사하는지에 대한 것이다.",
            "answer": "FALSE",
            "topic": [
                "데이터 품질특성 중 구문 정확성의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:98:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "학습모델 적합성  알고리즘 적정성  Ÿ 알고리즘을 Task 단위로 구분하여, 사업수행기관이 제시하는 학습모델의 Task가 적정한지 판단하는 품질특성  유효성 Ÿ 학습용 데이터로 학습시키는데 적합한 인공지능 알고리즘의 유효성을 측정하는  품질특성",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:98:0001",
                    "page": 98
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 품질관리 지표 중 학습모델 적합성에는 알고리즘 적정성과 유효성이 있다. 이 특성들은 알고리즘이 실제 학습에 유효한지, 학습모델의 테스크에 적정한지 등을 판단한다.",
        "long_answer": {
            "question": "데이터 품질관리 지표 중 학습모델과 연관되어있는 품질특성에 대해 서술하시오.",
            "answer": "데이터 품질관리 지표 중 학습모델 적합성과 연관된 품질특성으로는 알고리즘 적정성과 유효성이 있다. 알고리즘 적정성은 알고리즘을 테스크 단위로 구분하여 사업수행기관이 제시하는 학습모델의 테스크가 실제로 적정한지 판단하는 특성이고, 유효성은 인공지능 학습용 데이터로 학습시키는데에 인공지능 알고리즘이 적합한지 유효성을 측정하는 특성이다.",
            "rubric": [
                "데이터 품질관리 지표; 학습모델 적합성; 알고리즘 적정성; 유효성"
            ]
        },
        "short_answer": {
            "question": "데이터 품질특성 중 학습모델 적합성에는 유효성 외에 어떤 품질특성이 있는가?",
            "answer": "알고리즘 적정성",
            "topic": [
                "데이터 품질특성 중 알고리즘 적정성"
            ]
        },
        "multiple_choice": {
            "question": "학습용 데이터로 학습시키기에 적합한 인공지능 알고리즘의 유효성을 측정하는 품질 특성을 무엇이라 하는가?",
            "choices": [
                "a) 유별성",
                "b) 유효성",
                "c) 유일성",
                "d) 유행성"
            ],
            "answer": "b",
            "topic": [
                "데이터 품질특성 중 유효성의 정의"
            ]
        },
        "true_false": {
            "question": "알고리즘 적정성은 Task 단위로 학습모델의 적정성을 판단하는 품질특성이다.",
            "answer": "TRUE",
            "topic": [
                "데이터 품질특성 중 알고리즘 적정성의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:100:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.1 준비성 l 인공지능 학습용 데이터 품질관리를 위해 기본적으로 관리해야 하는 정책, 규정(저작권, 초상권, 개인정보보호 및 정보보호 등에 대한 검토 결과를 포함), 조직, 절차 등을 마련하고, 최신의 내용으로 충실하게 관리되는지를 검사 l ‘준비성’은 ‘계획 수립성’과 ‘체계 준수성’으로 구성되며, 검사 항목은 계획 수립성은 절차준비, 조직준비, 도구준비, 위험관리의 4개 항목으로 구성되고, 체계 준수성은 보안준수, 법·제도 준수의 2개 항목으로 구성",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:100:0001",
                    "page": 100
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "준비성은 인공지능 학습용 데이터 품질관리를 위해 기본적으로 관리해야하는 것들을 마련하고, 이것이 잘 관리되는지를 검사하는 지표이다.",
        "long_answer": {
            "question": "데이터 구축 공정 적정성 품질관리 지표 중 준비성의 구성과 검사 항목에 대해 서술하시오.",
            "answer": "준비성은 다시 계획 수립성과 체계 준수성으로 구성된다. 각각의 특성에는 이를 충실하게 측정하는데 필요한 검사 항목이 있는데, 먼저 계획 수립성에는 절차준비, 조직준비, 도구준비, 위험관리의 4개 항목이 있고 체계 준수성에는 보안준수, 법·제도 준수의 2개 항목이 있다.",
            "rubric": [
                "준비성; 계획 수립성; 체계 준수성; 4개; 2개"
            ]
        },
        "short_answer": {
            "question": "데이터 품질관리 지표 중 체계 준수성에 해당되는 검사 항목을 두가지 쓰시오.",
            "answer": "보안준수, 법·제도 준수",
            "topic": [
                "데이터 품질특성 중 체계 준수성의 검사 항목"
            ]
        },
        "multiple_choice": {
            "question": "데이터 품질특성 중 준비성의 검사 항목으로 부적합한 것은?",
            "choices": [
                "a) 절차준비",
                "b) 조직준비",
                "c) 도구준비",
                "d) 데이터준비"
            ],
            "answer": "d",
            "topic": [
                "데이터 품질특성 중 준비성의 검사 항목"
            ]
        },
        "true_false": {
            "question": "계획 수립성은 4개의 하위 검사 항목으로 구성되어있다.",
            "answer": "TRUE",
            "topic": [
                "데이터 품질특성 중 계획 수립성의 검사 항목"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:102:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "2.1.2 계획 수립성 – 조직준비 l 검사기준 및 방법 분류 검사기준 및 방법 검사상세 Ÿ 인공지능 학습용 데이터 구축을 위한 조직 구성, 역할 및 책임을 체계적으로 수립하여 관리 및 운영하고 있는지 확인 검사 대상  산출물 Ÿ 사업수행계획서(구축계획서, 품질관리계획서) 등 공정 Ÿ 구축계획수립, 데이터 획득/수집, 데이터 정제, 데이터 가공 검사방법 Ÿ 체크리스트",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:102:mh: 00001",
                    "page": 102
                }
            },
            {
                "context_id": "2",
                "text": "2.1.3 계획 수립성 – 도구준비 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 인공지능 학습용 데이터 구축을 위한 도구와 환경 구성 계획을 수립하여 관리 및  운영하고 있는지 확인 검사 대상  산출물 Ÿ 사업수행계획서(구축계획서, 품질관리계획서) 등 공정 Ÿ 구축계획수립, 데이터 획득/수집, 데이터 정제, 데이터 가공 검사방법 Ÿ 체크리스트",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:102:mh: 00001",
                    "page": 103
                }
            }
        ],
        "summarization": "데이터 품질특성 중 계획수립성의 검사항목 중 조직준비는 인공지능 학습용 데이터 구축을 위한 조직 구성, 역할 및 책임을 체계적으로 수립하여 관리 및 운영하고 있는지 확인한다. 도구준비는 구축을 위한 도구와 환경 구성 계획을 수립하여 관리 및 운영한다.",
        "long_answer": {
            "question": "데이터 품질특성과 중 계획 수립성의 조직준비와 도구준비 검사에 대해 설명하여라.",
            "answer": "조직준비는 인공지능 학습용 데이터 구축을 위해 필요한 조직의 구성과 각 구성원의 역할 및 책임을 체계적으로 수립하여 이를 관리하고 운영하고 있는지를 확인하는 검사이다. 도구준비는 인공지능 학습용 데이터 구축에 필요한 도구와 환경을 적절히 계획하고 이를 관리·운영하고 있는지를 확인하는 항목이다.",
            "rubric": [
                "조직준비; 도구준비"
            ]
        },
        "short_answer": {
            "question": "인공지능 데이터 품질특성 중 계획수립성의 조직준비 검사에서 검사 대상이 되는 품질관리 관련 산출물은?",
            "answer": "품질관리계획서",
            "topic": [
                "계획수립성 조직준비 검사 대상 산출물"
            ]
        },
        "multiple_choice": {
            "question": "데이터 품질특성 중 계획 수립성의 도구준비 검사에 해당되는 공정이 아닌 것은?",
            "choices": [
                "a) 데이터 획득 및 수집",
                "b) 구축계획 수립",
                "c) 데이터 활용",
                "d) 데이터 정제"
            ],
            "answer": "c",
            "topic": [
                "계획 수립성 내 도구준비 검사 대상 공정"
            ]
        },
        "true_false": {
            "question": "계획 수립성 내 조직준비 검사 대상에는 사업수행완료보고서가 포함된다.",
            "answer": "FALSE",
            "topic": [
                "계획 수립성 내 조직준비 검사 대상"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:107:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.2 완전성 l 인공지능 학습용 데이터를 구축함에 있어 각 단계별 품질기준에 맞게 설계・구축되었는지를 검사 l ‘완전성’에 대한 검사 항목은 ‘수집 완전성’, ‘정제 완전성’, ‘가공 완전성’으로 구성 2.2.1 수집 완전성 l 검사기준 및 방법 분 류 검사기준 및 방법  검사상세  Ÿ 데이터의 편향성 방지 방안을 수립하여 관리 및 수행하고 있는지 확인 Ÿ 데이터 획득/수집 방법 및 기준, 교육, 검수에 대한 체계를 수립하여 관리 및 수행하 고 있는지 확인 Ÿ 데이터 획득/수집 기준변경을 위한 체계를 수립하여 관리 및 수행하고 있는지 확인  검사 대상  산출물 Ÿ 구축계획서, 품질관리계획서, 구축 가이드라인 등 공정 Ÿ 데이터 획득/수집 검사방법 Ÿ 체크리스트",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:107:0001",
                    "page": 107
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "완전성은 인공지능 학습용 데이터가 각 단계별 품질기준에 따라 설계·구축되었는지를 검사하는 과정이다. 이는 수집 완전성, 정제 완전성, 가공 완전성으로 구성되어있다.",
        "long_answer": {
            "question": "수집 완전성 검사에서 확인해야하는 기준에 대해 상세히 서술하시오.",
            "answer": "수집 완전성 검사는 데이터의 편향성 방지 방안 수립 및 관리 확인합니다. 또한 데이터 획득/수집 방법 및 기준, 교육, 검수에 대한 체계를 수립하여 관리 및 수행하고 있는지와 데이터 획득/수집 기준변경을 위한 체계를 수립하여 관리 및 수행하고 있는지 또한 확인합니다.",
            "rubric": [
                "수집 완전성; 편향성 방지; 기준변경; 검수"
            ]
        },
        "short_answer": {
            "question": "완전성 품질특징을 구성하고있는 검사 항목을 세가지 쓰시오.",
            "answer": "수집 완전성, 정제 완전성, 가공 완전성",
            "topic": [
                "완전성 품질특징의 검사 항목"
            ]
        },
        "multiple_choice": {
            "question": "수집 완전성 검사에 대한 설명으로 올바른 것을 고르시오.",
            "choices": [
                "a) 데이터의 수익성 방안을 고안하였는지 확인한다.",
                "b) 데이터의 편향성 방지 방안을 수립하였는지 확인한다.",
                "c) 데이터 납품을 위한 체계를 수립하였는지 확인한다.",
                "d) 데이터 구축을 위한 도구를 사용하였는지 확인한다."
            ],
            "answer": "b",
            "topic": [
                "수집 완전성 검사의 특징"
            ]
        },
        "true_false": {
            "question": "품질지표 완전성 중 수집 완전성은 데이터 획득 및 수집 공정만을 검사 대상으로 한다.",
            "answer": "TRUE",
            "topic": [
                "수집 완전성의 검사 대상"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:109:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "2.3 유용성 l 발주기관(수요자)의 요구사항이 충분히 반영되었는지, 임무 정의에 적합한 인공지능 학습용 데이터의 범위와 상세화 정도를 충족시키는지를 검사 l ‘유용성’에 대한 검사 항목은 ‘사용 편의성’, ‘유연성’으로 구성 2.3.1 사용 편의성 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 사용자의 요구사항을 만족시킬 수 있는 학습모델과 학습용 데이터셋이 제공되고  있는지 확인",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:109:mh: 00001",
                    "page": 109
                }
            },
            {
                "context_id": "2",
                "text": "2.3.2 유연성 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 사용자 요구사항을 수용할 수 있는 학습모델 선정 및 적용이 유연한지 확인 검사 대상  산출물 Ÿ 구축 가이드라인 공정 Ÿ 데이터 학습 검사방법 Ÿ 체크리스트",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:109:mh: 00001",
                    "page": 110
                }
            }
        ],
        "summarization": "유용성은 발주기관(수요자)의 요구사항이 충분히 반영되었는지, 임무 정의에 적합한 인공지능 학습용 데이터의 범위와 상세화 정도를 충족시키는지를 검사한다. 유용성 검사 항목에는 사용 편의성과 유연성이 있다.",
        "long_answer": {
            "question": "인공지능 학습용 데이터의 유용성은 무엇을 검사하며, 어떤 항목으로 구성되어 있는지 서술하라.",
            "answer": "유용성은 수요자의 요구사항이 충분히 반영되었는지, 그리고 임무 정의에 적합한 인공지능 학습용 데이터의 범위와 세부 수준을 충족하는지를 검사한다. 사용 편의성과 유연성이 유용성 검사 항목이다.",
            "rubric": [
                "유용성; 수요자; 요구사항; 범위; 충족; 사용 편의성; 유연성"
            ]
        },
        "short_answer": {
            "question": "유용성 검사에서는 어떤 대상의 요구사항이 충분히 반영되었는지 여부를 검사하는가?",
            "answer": "발주기관(수요자)",
            "topic": [
                "유용성 검사의 초점"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 데이터 품질지표 유용성에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 사용 편의성은 사용자의 요구사항을 만족시키는 학습모델을 제공하는지 검사한다.",
                "b) 유연성은 데이터 구축 공정을 검사 대상으로 한다.",
                "c) 유연성 검사 대상이 되는 산출물은 사업수행계획서이다.",
                "d) 유용성 검사 항목은 사용 편의성, 유연성, 유동성이다."
            ],
            "answer": "a",
            "topic": [
                "품질지표 유용성의 설명"
            ]
        },
        "true_false": {
            "question": "유연성은 공급자 요구사항을 수용할 수 있는 학습모델이 선정되었는지를 검사하는 것이다.",
            "answer": "FALSE",
            "topic": [
                "유연성의 검사 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:111:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "3.1 기준 적합성 l 구축 데이터가 학습 용도로 적합한지에 대한 기준 충족 여부를 측정하는 품질특성 l ‘기준 적합성’에 대한 검사 항목은 ‘분류 다양성’, ‘신뢰성’, ‘충분성’, ‘균일성’, ‘사실성’, ‘공평성’, ‘형식성’으로 구성 3.1.1 분류 다양성 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 공간, 시간 등 환경조건 및 대상 객체 종류와 속성의 변화 정도를 확인 검사 대상  산출물 Ÿ 구축 공정 가이드라인, 원시데이터 데이터 종류 Ÿ 텍스트, 이미지, 비디오, 오디오, 3D 검사방법 Ÿ 체크리스트, 전수검사",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:111:mh: 00001",
                    "page": 111
                }
            },
            {
                "context_id": "2",
                "text": "3.1.2 신뢰성 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 데이터가 신뢰할 수 있는 사람, 기관, 기업으로부터 수집되었는지를 확인 검사 대상  산출물 Ÿ 구축 가이드라인, 원시데이터 데이터 종류 Ÿ 텍스트, 이미지, 비디오, 오디오, 3D 검사방법 Ÿ 체크리스트  3.1.3 충분성 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 카테고리(분류체계) 및 인스턴스(분류체계별 특성을 갖고 있는 데이터) 등이  학습에 유용한 수량인지를 확인  검사 대상  산출물 Ÿ 구축 가이드라인, 원시데이터 데이터 종류 Ÿ 텍스트, 이미지, 비디오, 오디오, 3D 검사방법 Ÿ 체크리스트   ",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:111:mh: 00001",
                    "page": 113
                }
            }
        ],
        "summarization": "기준 적합성은 구축 데이터가 학습 용도로 적합한지에 대한 기준 충족 여부를 측정하는 품질특성이다. 기준 적합성의 하위 검사 항목은 ‘분류 다양성’, ‘신뢰성’, ‘충분성’, ‘균일성’, ‘사실성’, ‘공평성’,‘형식성’의 검사 항목으로 구성되어있다.",
        "long_answer": {
            "question": "데이터 품질지표 중 기준 적합성의 하위 검사 항목인 분류 다양성과 신뢰성에 대해 설명하라.",
            "answer": "분류 다양성은 공간, 시간 등 환경조건 및 대상 객체 종류와 속성의 변화 정도를 확인하는 검사 항목이다. 신뢰성은 데이터가 신뢰할 수 있는 사람, 기관, 기업으로부터 수집되었는지를 확인하는 검사 항목이다. 두 항목은 모두 기준 적합성의 하위 검사 항목이다.",
            "rubric": [
                "기준 적합성; 분류 다양성; 신뢰성; 수집"
            ]
        },
        "short_answer": {
            "question": "카테고리 및 인스턴스 등이 학습에 유용한 수량인지를 확인하는 검사 항목은?",
            "answer": "충분성",
            "topic": [
                "충분성의 검사 기준"
            ]
        },
        "multiple_choice": {
            "question": "기준 적합성과 그 하위 검사 항목에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) 구축데이터가 학습하는 용도로 적합한지의 기준을 재고자 하는 것이 기준 적합성이다.",
                "b) 분류 다양성의 검사 방법은 체크리스트 외에 전수검사도 있다.",
                "c) 동일성과 형식성은 기준 적합성에 포함되는 검사 항목이다.",
                "d) 데이터의 수집이 신뢰 가능한 기관으로부터 수집되었는지를 확인하는 검사 항목은 신뢰성이다."
            ],
            "answer": "c",
            "topic": [
                "기준 적합성과 하위 검사 항목의 특징"
            ]
        },
        "true_false": {
            "question": "충분성에서 검사하고자 하는 것 중에는 카테고리 수량이 학습에 유용한지가 있다.",
            "answer": "TRUE",
            "topic": [
                "충분성의 검사 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:115:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "3.1.6 공평성 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 데이터 속에 포함될 수 있는 편향된 데이터를 제거하였는지 확인 검사 대상  산출물 Ÿ 구축 가이드라인, 원시데이터 데이터 종류 Ÿ 텍스트, 이미지, 비디오, 오디오, 3D 검사방법 Ÿ 체크리스트",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:115:mh: 00001",
                    "page": 115
                }
            },
            {
                "context_id": "2",
                "text": "3.1.7 형식성 l 원시데이터, 원천데이터의 파일 단위에서 학습 용도로 적합한지 판단하기 위해 측정하는 검사 항목 l ‘형식성’의 세부 검사 항목은 ‘파일 유효성’, ‘파일 포맷 적합성’, ‘파일 속성 적합성’ 등으로 구성 검사항목 세부 검사 항목  형식성  파일 유효성 파일 포맷 적합성 파일 속성 적합성 <표 III-41> 형식성 세부 검사 항목 구성  3.1.7.1 파일 유효성 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 파일이 손상되지 않고 정상적으로 활용 가능한지 확인  검사 대상  산출물 Ÿ 원시데이터 Ÿ 원천데이터  데이터 종류 Ÿ 텍스트, 이미지, 비디오, 오디오, 3D 내용 Ÿ 값  검사방법  Ÿ 인공지능 학습용 데이터 구축 시 데이터의 파일 유효성을 전수검사를 통해 확인 ※ 데이터 확인방식은 전수조사를 기본으로 함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:115:mh: 00001",
                    "page": 116
                }
            }
        ],
        "summarization": "데이터 품질특성 기준 적합성 중 공평성은 데이터 속에 포함될 수 있는 편항된 데이터를 제거하였는지 확인한다. 형식성은 원시데이터, 원천데이터의 파일 단위에서 학습 용도로 적합한지 판단하는 검사 항목으로 파일 유효성, 파일 포맷 적합성, 파일 속성 적합성 등으로 구성된다.",
        "long_answer": {
            "question": "데이터 품질특성 기준 적합성에 속하는 형식성의 정의와 그 세부 검사 항목에 대해 서술하라.",
            "answer": "형식성은 원시데이터 또는 원천데이터의 단위에서 학습 용도에 적합한지 판단을 위해 측정하는 검사 항목이다. 이는 파일 유효성, 파일 포맷 적합성, 파일 속성 적합성으로 세부 검사 항목을 가진다.",
            "rubric": [
                "형식성; 적합; 원시데이터; 원천데이터; 파일 유효성; 파일 포맷 적합성; 파일 속성 적합성"
            ]
        },
        "short_answer": {
            "question": "파일 유효성 검사의 대상이 되는 산출물은 무엇인가?",
            "answer": "원시데이터, 원천데이터",
            "topic": [
                "파일 유효성 검사의 대상"
            ]
        },
        "multiple_choice": {
            "question": "형식성에 대한 질문으로 적합한 것은?",
            "choices": [
                "a) 형식성은 데이터가 얼마나 구체적으로 만들어졌는지를 검사한다.",
                "b) 형식성은 다시 세부 검사 항목을 가진다.",
                "c) 형식성의 세부 검사 항목은 파일 유효성, 파일 포맷 적합성, 파일 보고 정확성이다.",
                "d) 공평성은 형식성의 세부 검사 항목이다."
            ],
            "answer": "b",
            "topic": [
                "형식성의 특징"
            ]
        },
        "true_false": {
            "question": "공평성은 데이터 구축 시 공평정대한 방법으로 데이터를 구축하였는지에 대한 검사이다.",
            "answer": "FALSE",
            "topic": [
                "공평성의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:117:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "3.1.7.2 파일 포맷 적합성 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 대중적으로 널리 사용되는 대표적인 파일 포맷을 사용하였는지 확인  검사 대상  산출물 Ÿ 원시데이터 Ÿ 원천데이터  데이터 종류 Ÿ 텍스트, 이미지, 비디오, 오디오, 3D 내용 Ÿ 값  검사방법  Ÿ 인공지능 학습용 데이터 구축 시 데이터의 파일 포맷이 정의된 기준에 적합한지 전수조사를 통해 확인  <데이터 유형별 권장 파일 포맷> 데이터 유형 파일 포맷 비고 이미지 JPG, PNG, TIFF Ÿ 의료 등 전문분야의 경우 해당 분야 표준 준수 비디오 MP4, AVI Ÿ 무압축 방식으로 프레임 이미지 시퀀스의 묶음 형태 오디오 WAV, PCM - 텍스트 - Ÿ UTF-8 인코딩 준수 정량 수치 CSV Ÿ 산업용 센서의 경우 해당 분야 표준 준수 로그 JSON Ÿ 표준 준수",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:117:0001",
                    "page": 117
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "파일 포맷 적합성은 데이터가 대중적으로 널리 사용되는 파일 포맷을 사용하였는지 확인하는 검사 항목이다. 검사 대상은 원시데이터, 원천데이터이며 데이터 구축 시 데이터의 파일 포맷이 정의된 기준에 적합한지 전수조사를 통해 확인한다.",
        "long_answer": {
            "question": "파일 포맷 적합성 검사의 정의와 검사 범위, 대상 산출물에 대해 서술하라.",
            "answer": "파일 포맷 적합성 검사는 인공지능 학습 데이터 구축 사업에서 만들어진 데이터가 대중적으로 널리 사용되는 대표적인 파일 포맷을 사용했는지 여부를 확인한다. 이때 검사 범위는 전수조사이며 대상은 원시데이터와 원천데이터이다.",
            "rubric": [
                "파일 포맷 적합성; 파일 포맷; 전수조사; 원시데이어; 원천데이터"
            ]
        },
        "short_answer": {
            "question": "파일 포맷 적합성 검사 시 무합축 방식으로 프레임 이미지 시퀀스의 묶음 형태를 갖춰야하는 데이터 유형은 무엇인가?",
            "answer": "비디오",
            "topic": [
                "비디오의 파일 포맷 주의사항"
            ]
        },
        "multiple_choice": {
            "question": "데이터 유형별 권장 파일 포맷으로 올바르지 않은 것은?",
            "choices": [
                "a) 비디오 - AVI",
                "b) 오디오 - WAV",
                "c) 로그 - JSON",
                "d) 이미지 - BMP"
            ],
            "answer": "d",
            "topic": [
                "데이터 유형별 권장 파일 포맷"
            ]
        },
        "true_false": {
            "question": "텍스트로 학습용 데이터를 구축하는 경우 UTF-16 인코딩을 준수해야 한다.",
            "answer": "FALSE",
            "topic": [
                "텍스트 데이터의 학습용 데이터 구축 권장 파일 포맷"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:119:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "3.2 다양성 l 데이터의 충분성과 균일성 확보 및 편향성 방지를 위해 데이터의 수량, 구성비 등을 측정하는 품질특성 l ‘다양성’ 항목은 검사 유형에 따라 ‘다양성(요건)’, ‘다양성(통계)’로 구분 검사 유형 상세 내용  다양성(요건)  Ÿ 다양성(요건)은 인공지능 데이터 구축계획 수립 시 설정된 목표(기준 적합성 등)를 충족하는지 검증 Ÿ 데이터의 수량, 클래스 및 인스턴스별 수량, 클래스 및 인스턴스별 구성비, 연령별 구성비, 문장길이(어절 수, 음절 수), 어휘 빈도 수 등의 기준을 설정하고, 목표 대비 구축된 결과물의 충족 여부를 평가 Ÿ 목표대비 데이터 수량과 구성비가 적절한지 확인하며, 구축된 결과물이 설정된 기준을 만족하는지 검증 Ÿ 데이터 편향을 방지하고, 특정 클래스나 속성이 과소/과대 대표되는 현상을 막기 위해 구성비 중첩률을 활용하여 목표대비 달성도를 측정  다양성(통계)  Ÿ 다양성(통계)은 인공지능 데이터의 특성을 통계적으로 분석한 결과를 확인 Ÿ 데이터의 클래스 및 인스턴스별 구성비, 연령 별 구성비 등을 산출하여 실제 데이터의 분포를 확인 Ÿ 데이터를 직접 평가하는 것이 아니라, 객관적인 수치로 데이터의 구성과 분포를 통계적으로 분 석하여 제공 Ÿ 다양한 통계적 방법을 활용하여 데이터의 균형성과 편향 여부를 확인할 수 있도록 정보를 제공",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:119:0001",
                    "page": 119
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "다양성은 인공지능 학습용 데이터의 충분성과 균일성을 확보하고 편향을 방지하기 위해 데이터의 수량, 구성비 등을 측정하는 품질특성이다. 검사 유형에 따라 ‘다양성(요건)’은 목표 기준 충족 여부를 검증하고, ‘다양성(통계)’는 데이터의 분포를 통계적으로 분석한다.",
        "long_answer": {
            "question": "‘다양성(요건)’과 ‘다양성(통계)’의 목적과 평가 방식의 차이를 비교하여 설명하시오.",
            "answer": "다양성(요건)’은 데이터 구축계획 시 설정된 목표와 기준을 충족하는지를 검증하는 것으로, 목표 대비 데이터 수량과 구성비의 적절성을 평가한다. 반면 ‘다양성(통계)’는 데이터를 직접 평가하지 않고, 통계적 분석을 통해 데이터의 실제 분포와 편향 여부를 확인한다. 즉, 전자는 기준 충족 여부에 중점을 두고, 후자는 객관적인 수치 분석을 통해 데이터 특성을 파악하는 데 초점을 둔다.",
            "rubric": [
                "다양성(요건); 다양성(통계); 충족; 적절성; 분포; 편향"
            ]
        },
        "short_answer": {
            "question": "품질지표 중 다양성 항목을 다양성(요건)과 다양성(통계)로 구분하는 기준은 무엇인가?",
            "answer": "검사 유형",
            "topic": [
                "다양성의 검사 유형"
            ]
        },
        "multiple_choice": {
            "question": "데이터 품질지표 중 다양성에 대한 설명으로 합당한 것을 고르시오.",
            "choices": [
                "a) 다양성(요건)에서는 목표대비 데이터 수량과 구성비가 적절한지를 확인한다.",
                "b) 다양성(통계)에서는 데이터의 수량 충족 여부를 평가한다.",
                "c) 다양성(요건)에서는 실제 데이터의 분포를 확인한다.",
                "d) 다양성(통계)에서는 어휘 빈도 수 등의 기준을 설정하여 충족 여부를 평가한다."
            ],
            "answer": "a",
            "topic": [
                "다양성(요건)과 다양성(통계)의 검사 내용"
            ]
        },
        "true_false": {
            "question": "다양성(통계)는 데이터를 직접 평가하는 검사 유형이다.",
            "answer": "FALSE",
            "topic": [
                "다양성(통계)의 검사 내용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:120:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "3.2.1.1 데이터별 분포(주제분류/클래스 분포) l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 학습에 유용한 분류체계(카테고리)별 클래스 유형 및 요건이 다양하게 분포되어  있는지 검사  검사 대상  산출물 Ÿ 원천데이터, 가공데이터 데이터 종류 Ÿ 텍스트, 이미지, 비디오, 오디오, 3D 내용 Ÿ 값 검사방법  Ÿ 인공지능 학습용 데이터 구축 시 정의한 분류체계(카테고리)를 기준으로 어노테이션 데이터에 포함된 클래스 정보를 추출하여 통계값 산출 ※ 클래스 분포 최소 기준은 전문가 자문 또는 품질검증기관 협의를 통해 결정",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:120:0001",
                    "page": 120
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터별 분포(주제분류/클래스 분포)는 인공지능 학습용 데이터의 분류체계별 클래스가 다양하게 분포되어 있는지를 검사한다. 원천 및 가공데이터의 클래스 정보를 기준으로 통계값을 산출하며, 최소 분포 기준은 전문가 자문 또는 품질검증기관 협의로 결정된다.",
        "long_answer": {
            "question": "데이터별 분포 항목에서는 어떤 기준으로 검사하는지 서술하시오.",
            "answer": "인공지능 학습 데이터 품질관리 지표 중 다양성의 데이터별 분포 항목은 학습에 유용한 분류체계(카테고리)별 클래스 유형 및 요건이 다양하게 분포되어 있는지를 검사한다.",
            "rubric": [
                "데이터별 분포; 클래스 유형; 분류체계; 분포"
            ]
        },
        "short_answer": {
            "question": "데이터별 분포 검사에서 통계값을 산출하는 대상은 어떤 데이터에 포함된 클래스 정보인가?",
            "answer": "어노테이션 데이터",
            "topic": [
                "데이터별 분포 검사의 검사방법"
            ]
        },
        "multiple_choice": {
            "question": "데이터 품질지표 중 데이터별 분포 항목의 검사 대상 산출물에 해당하는 것은?",
            "choices": [
                "a) 원천데이터",
                "b) 원시데이터",
                "c) 학습데이터",
                "d) 지표데이터"
            ],
            "answer": "a",
            "topic": [
                "데이터별 분포의 검사 대상 산출물"
            ]
        },
        "true_false": {
            "question": "데이터별 분포 검사에서 클래스 분포 최소 기준은 사업수행기관이 임의 지정할 수 있다.",
            "answer": "FALSE",
            "topic": [
                "데이터별 분포 검사의 클래스 분포 최소 기준 결정 주체"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:121:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "3.2.2 다양성 측정지표 l ‘다양성’에 대한 측정지표는 수량, 구성비, 구성비 중첩률 등으로 분류 품질특성 측정지표  다양성  다양성(요건)  수량 구성비 구성비 중첩률 다양성(통계) 구성비 <표 III-50> 다양성 측정지표 구성  ※ “수행계획서에 포함된 구성비”일 경우 반드시 ‘통계 항목’이 아닌 ‘요건 항목’에 기재 ※ 구성비 중첩률은 다양성(요건)에만 해당됨",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:121:mh: 00001",
                    "page": 121
                }
            },
            {
                "context_id": "2",
                "text": "3.2.2.1 수량 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 데이터가 학습에 유용한 수량에 대한 기준을 고려했는지 확인  검사 대상  산출물 Ÿ 원천데이터, 가공데이터 데이터 종류 Ÿ 텍스트, 이미지, 비디오, 오디오, 3D 내용 Ÿ 값  검사방법  Ÿ 인공지능 학습용 데이터에서 원천데이터 수량 또는 클래스/인스턴스/속성별 데이터 수량을 원천데이터, 어노테이션 값으로 검사함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:121:mh: 00001",
                    "page": 122
                }
            }
        ],
        "summarization": "다양성 측정지표는 수량, 구성비, 구성 중첩률 등이 있다. 이 중 수량은 데이터가 학습에 유용한 수량에 대한 기준을 고려했는지를 확인한다.",
        "long_answer": {
            "question": "다양성의 측정지표 분류와 측정지표 중 수량이 재고자 하는 것에 대해 설명하시오.",
            "answer": "다양성 측정지표는 통계 항목과 요건 항목에 따라 나뉜다. 다양성(요건)에는 수량과 구성비, 구성비 중첩률이 포함되고 다양성(통계)에는 구성비만 포함된다. 측정지표 중 수량은 데이터가 학습에 유용한 수량에 대한 기준을 설정하여 고려했는지를 검사하는 항목이다.",
            "rubric": [
                "다양성(요건); 수량; 구성비; 구성비 중첩률; 다양성(통계)"
            ]
        },
        "short_answer": {
            "question": "수행계획서에 포함된 구성비의 경우 어떤 항목에 기재해야 하는가?",
            "answer": "요건 항목",
            "topic": [
                "다양성(요건)에 해당하는 수행계획서에 포함된 구성비"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 다양성의 측정지표로 부적합한 것은?",
            "choices": [
                "a) 수량",
                "b) 구성비",
                "c) 구성비 중첩률",
                "d) 중첩 구성비"
            ],
            "answer": "d",
            "topic": [
                "다양성의 측정지표"
            ]
        },
        "true_false": {
            "question": "다양성 측정지표 중 구성비 중첩률은 다양성(통계)에 해당되지 않는다.",
            "answer": "TRUE",
            "topic": [
                "다양성(요건)의 구성비 중첩률"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:126:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "4.1 구문 정확성 l 어노테이션 데이터의 구조와 속성값들이 정의된 규칙에 부합하는지 구조 정확성과 형식 정확성 등을 측정하는 품질특성 l ‘구문 정확성’에 대한 검사 항목은 ‘구조 정확성’, ‘형식 정확성’으로 구성 품질특성 검사 항목 구문 정확성  구조 정확성 - 데이터 구조 형식 정확성 - 데이터 형식, 데이터 값 범위  4.1.1 구조 정확성 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 어노테이션 데이터 구조를 준수하는지 확인 검사 대상  산출물 Ÿ 가공데이터 데이터 종류 Ÿ 텍스트, 이미지, 비디오, 오디오, 3D 내용 Ÿ 구조 검사방법  Ÿ 인공지능 학습용 데이터 구축 시 정의한 데이터 구조에 적합하지 않은 데이터가 있는지 확인 ※ 데이터 구조에 대한 표준화가 필요  ※ 속성: 요구되는 데이터 필드(컬럼, 속성 등)가 적절하게 포함되어 있는지, 각 필드가 미리 정의된 형식(숫자, 문자열, 날짜 등)을 정확히 따르는지, 그리고 필수 필드의 누락 없이 데이터 구조가 올바르게 구성되어 있는지를 평가하는 요소 ",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:126:0001",
                    "page": 126
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "구문 정확성은 어노테이션 데이터의 구조와 속성값들이 정의된 규칙에 부합하는지 구조 정확성과 형식 정확성 등을 측정하는 품질특성이다. 구문 정확성에 대한 검사 항목은 ‘구조 정확성’, ‘형식 정확성’으로 구성된다.",
        "long_answer": {
            "question": "구조 정확성에서 속성이란 어떤 요소를 의미하는지 설명하라.",
            "answer": "구조 정확성에서 속성은 요구되는 데이터 필드(컬럼, 속성 등)가 적절하게 포함되어 있는지, 각 필드가 미리 정의된 형식(숫자, 문자열, 날짜 등)을 정확히 따르는지, 그리고 필수 필드의 누락 없이 데이터 구조가 올바르게 구성되어 있는지를 평가하는 요소이다.",
            "rubric": [
                "구조 정확성; 속성; 데이터 필드; 필수 필드"
            ]
        },
        "short_answer": {
            "question": "어노테이션 데이터의 구조를 준수하는지 확인하는 검사 항목을 무엇이라 하는가?",
            "answer": "구조 정확성",
            "topic": [
                "구조 정확성의 정의"
            ]
        },
        "multiple_choice": {
            "question": "구문 정확성의 검사 항목으로 적절한 것은?",
            "choices": [
                "a) 내용 정확성",
                "b) 배열 정확성",
                "c) 구조 정확성",
                "d) 의미 정확성"
            ],
            "answer": "c",
            "topic": [
                "구문 정확성의 검사 항목"
            ]
        },
        "true_false": {
            "question": "구조 정확성을 검사하기 위해서는 먼저 데이터 구조에 대한 표준화가 필요하다.",
            "answer": "TRUE",
            "topic": [
                "구조 정확성의 사전 단계"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:127:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "4.1.2 형식 정확성 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 어노테이션 데이터를 구성하는 데이터가 형식 및 범위를 준수하는지 확인 검사 대상  산출물 Ÿ 가공데이터 데이터 종류 Ÿ 텍스트, 이미지, 비디오, 오디오, 3D 내용 Ÿ 값  검사방법  Ÿ 인공지능 학습용 데이터 구축 시 정의한 데이터 형식에 적합하지 않은 데이터가 있는지 확인 Ÿ 세부 검사 내용 구분 내용 데이터 형식 가공데이터의 데이터 값 구문이 정의된 형식 규칙에 부합하는지 확인 데이터값 범위 가공데이터의 값이 정의된 범위에 부합하는지 확인 ※ 메타데이터에 대한 표준화가 필요 ※ 텍스트, 오디오는 ETRI 전사 규칙을 준수 ",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:127:0001",
                    "page": 127
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "형식 정확성 검사는 어노테이션 데이터를 구성하는 데이터가 형식 및 범위를 준수하는지 확인한다. 검사의 세부 내용으로는 데이터 형식과 데이터값 범위가 있다.",
        "long_answer": {
            "question": "형식 정확성의 검사 기준과 세부 검사의 내용을 설명하라.",
            "answer": "형식 정확성 검사는 어노테이션 데이터를 구성하는 데이터가 형식 및 범위를 준수하는지 확인하는 것이다. 이 검사는 데이터 형식과 데이터값 범위로 하위 세부검사를 가지는데, 데이터 형식은 가공데이터의 데이터 값 구문이 정의된 형식 규칙에 부합하는지 확인하고 데이터값 범위는 가공데이터의 값이 정의된 범위에 부합하는지 확인한다.",
            "rubric": [
                "형식 정확성; 준수; 데이터 형식; 데이터값 범위"
            ]
        },
        "short_answer": {
            "question": "형식 정확성의 하위 세부 검사 구분 두가지는 무엇인가?",
            "answer": "데이터 형식, 데이터값 범위",
            "topic": [
                "형식 정확성의 하위 세부 검사 구분"
            ]
        },
        "multiple_choice": {
            "question": "아래의 데이터 중 형식 정확성 검사의 대상이 되는 데이터는?",
            "choices": [
                "a) 원시데이터",
                "b) 가공데이터",
                "c) 원천데이터",
                "d) 학습데이터"
            ],
            "answer": "b",
            "topic": [
                "형식 정확성의 검사 대상 데이터"
            ]
        },
        "true_false": {
            "question": "형식 정확성에서 오디오는 ETRI 전사 규칙을 지켜야 한다.",
            "answer": "TRUE",
            "topic": [
                "형식 정확성 검사 방법"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:131:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "4.2.2 측정지표 l ‘유효성’과 측정지표 명은 동일하지만, ‘의미 정확성’은 어노테이션 값과 참값(GT) 간의 차이를 측정하고, ‘유효성’은 학습모델의 예측값과 정답(GT) 간의 차이를 측정함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:131:mh: 00001",
                    "page": 131
                }
            },
            {
                "context_id": "2",
                "text": "4.2.2.1 정확도 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 어노테이션과 참값 간의 중첩률을 확인  검사 대상  산출물 Ÿ 가공데이터  데이터 종류  데이터 종류 어노테이션 예시 텍스트 내용 요약, 번역, 질의응답 이미지/비디오 바운딩 박스, 키포인트, 세그멘테이션 3D 세그멘테이션, 키포인트, 큐보이드, 태깅 오디오 전사  내용 Ÿ 값 검사방법 Ÿ 데이터 종류의 분류를 참조하여 데이터 종류별에 해당하는 어노테이션과 참값 간의  중첩률을 계산하여 의미 정확성의 정확도를 확인",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:131:mh: 00001",
                    "page": 132
                }
            }
        ],
        "summarization": "‘의미 정확성’은 어노테이션 값과 참값(GT) 간의 차이를 측정하고, ‘유효성’은 학습모델의 예측값과 정답(GT) 간의 차이를 측정한다. 의미 정확성의 하위 검사항목인 정확도는 어노테이션과 참값 간의 중첩률을 확인하는 검사이다.",
        "long_answer": {
            "question": "의미 정확성의 정확도 검사 대상과 검사 방법에 대해 설명하라.",
            "answer": "인공지능 학습 데이터 품질관리에서 의미 정확성 품질지표의 정확도 검사는 가공데이터를 검사 대상으로 한다. 검사 방법은 데이터의 종류의 분류를 참조하여 데이터 종류별에 해당하는 어노테이션과 참값 간의 중첩률을 계산하여 의미 정확성의 정확도를 확인한다.",
            "rubric": [
                "의미 정확성; 정확도; 가공데이터; 중첩률"
            ]
        },
        "short_answer": {
            "question": "의미 정확성은 어떤 값과 어노테이션 간의 차이를 측정하고자 하는가?",
            "answer": "참값",
            "topic": [
                "의미 정확성의 차이값 대상"
            ]
        },
        "multiple_choice": {
            "question": "아래의 쌍 중 의미 정확성에서 재고자 하는 차이 값의 쌍으로 적합한 것은?",
            "choices": [
                "a) 어노테이션 값 - 정답",
                "b) 어노테이션 값 - 참값",
                "c) 학습모델의 예측 값 - 참값",
                "d) 학습모델의 예측 값 - 중간값"
            ],
            "answer": "b",
            "topic": [
                "의미 정확성의 차이값 대상"
            ]
        },
        "true_false": {
            "question": "의미 정확성 중 정확도는 어노테이션과 참값 간의 비중을 확인하는 것이다.",
            "answer": "FALSE",
            "topic": [
                "정확도의 검사 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:132:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "4.2.2.2 정밀도 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 생성된 어노테이션 중 참값 어노테이션 비율을 확인  검사 대상  산출물 Ÿ 가공데이터  데이터 종류  데이터 종류 어노테이션 예시 텍스트 말뭉치 태깅 이미지/비디오/센서 바운딩 박스, 키포인트, 세그멘테이션 3D 큐보이드  내용 Ÿ 값 검사방법 Ÿ 데이터 종류의 분류를 참조하여 데이터 종류별로 생성된 어노테이션",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:132:mh: 00001",
                    "page": 132
                }
            },
            {
                "context_id": "2",
                "text": "4.2.2.3 재현율 l 검사기준 및 방법 분 류 검사기준 및 방법 검사상세 Ÿ 모든 가능한 어노테이션 중 참값 어노테이션 비율을 확인  검사 대상  산출물 Ÿ 가공데이터  데이터 종류  데이터 종류 어노테이션 예시 텍스트 말뭉치 태깅 이미지/비디오/센서 바운딩 박스, 키포인트, 세그멘테이션 3D 큐보이드  내용 Ÿ 값 검사방법 Ÿ 데이터 종류의 분류를 참조하여 데이터 종류별로 모든 가능한 어노테이션",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:132:mh: 00001",
                    "page": 133
                }
            }
        ],
        "summarization": "의미 정확성 검사 중 정밀도는 생성된 어노테이션 중 참값 어노테이션 비율을 확인한다. 재현율은 모든 가능한 어노테이션 중 참값 어노테이션 비율을 확인한다.",
        "long_answer": {
            "question": "의미 정확성 검사 중 정밀도 검사와 재현율 검사의 방법을 서술하라.",
            "answer": "의미 정확성 검사 중 정밀도는 데이터 종류의 분류를 참조하여 데이터 종류별로 생성된 어노테이션 중 참값 어노테이션 비율을 계산하여 의미 정확성의 정밀도를 확인한다. 재현율은 같은 분류를 참조하여 데이터 종류별로 모든 가능한 어노테이션 중 참값 어노테이션 비율을 계산하여 의미 정확성의 재현율을 확인한다.",
            "rubric": [
                "정밀도; 생성; 참값 어노테이션; 재현율; 모든"
            ]
        },
        "short_answer": {
            "question": "데이터 품질 지표 중 의미 정확성 관련하여 정밀도와 재현율 검사시 공통으로 참조하는 것은?",
            "answer": "데이터 종류의 분류",
            "topic": [
                "정밀도와 재현율 검사 방법"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 의미 정확성의 정밀도와 재현율에 대한 설명으로 적절하지 않은 것은?",
            "choices": [
                "a) 정밀도는 생성된 어노테이션 중 참값 어노테이션 비율을 확인한다.",
                "b) 정밀도 검사 시 데이터 종류의 분류를 참조한다.",
                "c) 재현율은 일부 어노테이션 중 참값 어노테이션 비율을 확인한다.",
                "d) 재현율은 모든 가능한 어노테이션 중에서 참값 어노테이션 비율을 계산한다."
            ],
            "answer": "c",
            "topic": [
                "정밀도와 재현율의 검사 기준 및 검사방법"
            ]
        },
        "true_false": {
            "question": "의미 정확성의 정밀도와 재현율 모두 가공데이터를 검사 대상으로 한다.",
            "answer": "TRUE",
            "topic": [
                "정밀도와 재현율의 검사 대상"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:134:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "5 학습모델 적합성 품질관리 지표  5.1 알고리즘 적정성 l ‘알고리즘 적정성’에 대한 검사 항목은 데이터 유형 별로 구성되며, 각각의 데이터 유형별 관련 알고리즘을 임무(Task)별로 구분하여 ‘알고리즘 적정성’을 평가",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:134:mh: 00001",
                    "page": 134
                }
            },
            {
                "context_id": "2",
                "text": "5.1.1.1 광학 문자 인식 (OCR, Optical Character Recognition) 구분 내 용 개념 Ÿ 사람이 쓰거나 기계로 인쇄한 문자의 영상을 이미지 스캐너로 획득하여 기계가  읽을 수 있는 문자로 변환하는 작업  세부 내용 Ÿ 기존의 정형화된 숫자나 텍스트 인식에서 벗어나, 인공지능 기술이 접목되어  필기체, 이미지, 비정형데이터까지 인식 범위를 넓히고 있음  5.1.1.2 순차적 레이블링 (Sequence Labeling) 구분 내 용 개념 Ÿ 입력 시퀀스에 대하여 레이블 시퀀스를 각각 부여하는 작업으로, 태깅 작업이  대표적인 순차적 레이블링의 예시임  세부 내용  Ÿ 태깅을 해야 하는 단어 데이터를 X, 레이블에 해당되는 태깅 정보 데이터는 y라고 할 때, X와 y데이터의 쌍(pair)은 병렬 구조를 가지며, 각 데이터는 정수 인코딩 과정을 거친 후, 모든 데이터의 길이를 동일하게 맞춰주기 위한 패딩(Padding) 작업을 거쳐 학습용 데이터로 구축됨 <표 III-69> 순차적 레이블링의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:134:mh: 00001",
                    "page": 135
                }
            }
        ],
        "summarization": "알고리즘 적정성에 대한 검사 항목은 데이터 유형 별로 구성되며, 각각의 데이터 유형별 관련 알고리즘을 임무(Task)별로 구분하여 ‘알고리즘 적정성’을 평가한다. 알고리즘 적정성 관련 TASK 중 광학 문자 인식은 사람이 쓰거나 기계로 인쇄한 문자의 영상을 이미지 스캐너로 획득하여 기계가 읽을 수 있는 문자로 변환하는 작업이다. 순차적 레이블링은 입력 시퀀스에 대하여 레이블 시퀀스를 각각 부여하는 작업이다.",
        "long_answer": {
            "question": "순차적 레이블링에서 데이터가 가져야 하는 구조와 필수 과정에 대해 설명하라.",
            "answer": "순차적 레이블링에서 태깅을 해야 하는 단어 데이터를 X, 레이블에 해당되는 태깅 정보 데이터는 y일 때, X와 y데이터의 쌍(pair)은 병렬 구조를 가진다. 각 데이터는 정수 인코딩 과정을 거친 후, 모든 데이터의 길이를 동일하게 맞춰주기 위한 패딩(Padding) 작업을 거쳐 학습용 데이터로 구축된다.",
            "rubric": [
                "순차적 레이블링; 병렬 구조; 정수 인코딩; 패딩"
            ]
        },
        "short_answer": {
            "question": "알고리즘 적정성에 대한 검사항목은 무엇 별로 구성되는가?",
            "answer": "데이터 유형",
            "topic": [
                "알고리즘 적정성의 검사항목 구성"
            ]
        },
        "multiple_choice": {
            "question": "광학 문자 인식과 순차적 레이블링에 대한 설명으로 부적합한 것은?",
            "choices": [
                "a) 광학 문자 인식은 사람이 쓴 원시데이터에만 해당되는 작업이다.",
                "b) 광학 문자 인식은 기계가 읽을 수 있는 문자로 변환하는 작업이다.",
                "c) 순차적 레이블링은 레이블 시퀀스를 부여하는 작업이다.",
                "d) 순차적 레이블링에는 패딩 작업이 포함된다."
            ],
            "answer": "a",
            "topic": [
                "광학 문자 인식과 순차적 레이블링의 특징"
            ]
        },
        "true_false": {
            "question": "순차적 레이블링은 출력 시퀀스에 대하여 레이블 시퀀스를 각각 부여하는 작업이다.",
            "answer": "FALSE",
            "topic": [
                "순차적 레이블링의 개념"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:135:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.1.3 텍스트 분류 (Text Classification) 구분 내 용 개념 Ÿ 문장이나 문서를 적절한 범주로 지정하는 작업으로, 범주는 선택한 데이터셋에  따라 다르며 주제 범위가 다양할 수 있음  세부 내용  Ÿ 텍스트 분류 문제에는 감정 분류, 뉴스 분류, 인용 의도 분류 등이 있으며, 텍스트 분류 기능을 평가하기 위한 벤치마크 데이터셋에는 GLUE, AGNews 등이 있음 Ÿ 최근 몇 년 동안 XLNet 및 RoBERTa와 같은 딥러닝 기술은 텍스트 분류 문제에서 가장 큰 성능 향상을 달성함 <표 III-70> 텍스트 분류의 개념 및 세부 내용  5.1.1.4 정보 추출 (Information Extraction) 구분 내 용 개념 Ÿ 자연어에서 유용한 정보를 자동으로 수집하기 위해 비정형화된 텍스트 데이터  내에서 정형화된 데이터를 추출하는 작업  세부 내용  Ÿ 고유 명사 등을 판별하는 개체명 인식(Named Entity Recognition), 개체명 간의 관계를 판별하는 관계 추출(Relation Extraction), 중의성 해소(Word sense Disambiguation), 대표 단어/문장 추출 등이 가장 대표적인 정보 추출 문제이며, MRC(Machine Reading & Comprehension)의 기반이 되는 작업이라 할 수 있음",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:135:0001",
                    "page": 135
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "텍스트 분류는 문장이나 문서를 적절한 범주로 지정하는 작업으로, 범주는 선택한 데이터셋에 따라 다르며 주제 범위가 다양할 수 있다. 정보 추출은 자연어에서 유용한 정보를 자동으로 수집하기 위해 비정형화된 텍스트 데이터 내에서 정형화된 데이터를 추출하는 작업이다.",
        "long_answer": {
            "question": "텍스트 분류의 개념과 대표 벤치마크 데이터셋에 대해 설명하라.",
            "answer": "텍스트 분류란 문장이나 문서를 문장이나 문서를 적절한 범주로 지정하는 작업이다. 이때 범주는 선택한 데이터셋에 따라 다르며 주제 범위는 다양할 수 있다. 텍스트 분류 기능을 평가하기 위해 필요한 벤치마크 데이터셋에는 GLUE, AGNews 등이 있다.",
            "rubric": [
                "텍스트 분류; 범주; 벤치마크 데이터셋"
            ]
        },
        "short_answer": {
            "question": "자연어에서 유용한 정보를 자동으로 수집하기 위해 비정형화된 텍스트 데이터 내에서 정형화된 데이터를 추출하는 작업을 무엇이라 하는가?",
            "answer": "정보 추출",
            "topic": [
                "정보 추출의 개념"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 정보 추출 문제에 해당하지 않는 것은?",
            "choices": [
                "a) 개체명 인식",
                "b) 관계 추출",
                "c) 중의성 해소",
                "d) 음성 합성"
            ],
            "answer": "d",
            "topic": [
                "정보 추출 문제의 종류"
            ]
        },
        "true_false": {
            "question": "감정 분류, 인용 의도 분류 등은 텍스트 분류에 해당한다.",
            "answer": "TRUE",
            "topic": [
                "텍스트 분류의 종류"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:136:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.1.5 질의응답 (Question Answering) 구분 내 용 개념 Ÿ 질문(일반적으로 독해 질문)에 답변하는 작업으로서, 제공된 컨텍스트를 기반으로  답변할 수 없는 질문이 제시되면 기권함  세부 내용  Ÿ 질의응답은 커뮤니티 질문 답변 및 지식 기반 질문 답변과 같은 도메인별 작업으로 나눌 수 있음 Ÿ 평가 질문 응답 시스템을 위한 인기 있는 벤치마크 데이터셋에는 SQuAD, HotPotQA, bAbI, TriviaQA, WikiQA 등이 있으며, 질문 답변 모델은 일반적으로 EM 및 F1과 같은 성능지표로 평가함 Ÿ 최근 질의응답 분야 최고 성능 모델은 T5 및 XLNet 등이 있음",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:136:0001",
                    "page": 136
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "질의응답은 주어진 컨텍스트를 기반으로 질문에 답변하는 작업으로, 답변할 수 없는 질문의 경우 기권하도록 설계된다. 이 작업은 커뮤니티 질문 답변이나 지식 기반 질문 답변 등 도메인별로 구분되며, 대표적인 벤치마크 데이터셋으로는 SQuAD, HotPotQA, bAbI, TriviaQA, WikiQA 등이 있다.",
        "long_answer": {
            "question": "질의응답의 개념에 대해 설명하시오.",
            "answer": "질의응답은 질문에 답변하는 작업이다. 제공된 컨텍스트를 기반으로 답변하되, 답변이 불가능한 질문이 제시되면 기권한다. 질의응답은 커뮤니티 질문 답변, 지식 기반 질문 답변 등 도메인별 작업으로 나눌 수 있다.",
            "rubric": [
                "질의응답; 컨텍스트; 도메인별"
            ]
        },
        "short_answer": {
            "question": "질의응답에서는 제공된 무엇을 기반으로 질문에 답변하게 되는가?",
            "answer": "컨텍스트",
            "topic": [
                "질의응답의 개념"
            ]
        },
        "multiple_choice": {
            "question": "아래의 벤치마크 데이터셋 중 평가 질문 응답 시스템과 관련된 것이 아닌 것은?",
            "choices": [
                "a) AGNews",
                "b) bAbI",
                "c) SQuAD",
                "d) TriviaQA"
            ],
            "answer": "a",
            "topic": [
                "평가 질문 응답 시스템의 대표 벤치마크 데이터셋"
            ]
        },
        "true_false": {
            "question": "질문 답변 모델은 EM과 같은 성능지표로 평가한다.",
            "answer": "TRUE",
            "topic": [
                "질문 답변 모델의 성능 지표"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:136:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.1.6 음성 인식 (Speech Recognition) 구분 내 용 개념 Ÿ 사람이 말하는 음성 언어를 인공지능이 해석해 그 내용을 문자 데이터로 전환하는  작업  세부 내용  Ÿ 일반적으로 STT(Speech to Text)와 동일한 Task로 인식되며, Speaker Verification이나 Speaker Recognition과 같이 개별 사용자의 음성을 식별하는 데에 중점을 둔 Task도 존재함 <표 III-73> 음성 인식의 개념 및 세부 내용  5.1.1.7 오디오 분류 (Audio Classification) 구분 내 용 개념 Ÿ 오디오 정보를 특정 시간 단위로 분할(오디오 클립)하여, 신호의 특이점을  분석하고 특정 클래스로 분류하는 작업  세부 내용  Ÿ 소리는 음성과 음향으로 구분이 되며, 일반적으로 오디오 분류(Audio Classification)라고 정의할 때는 음향에 대한 분류를 의미함 Ÿ 오디오 분류 작업은 주석이 달린 오디오 데이터로 시작하며, 기계는 어떻게 듣고 무엇을 들어야 하는지 배우기 위해 이 데이터가 필요함 Ÿ 구글 오디오셋이 오디오 분류의 대표적인 데이터셋임 <표 III-74> 오디오 분류의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:136:0001",
                    "page": 136
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "음성 인식은 사람이 말한 음성을 인공지능이 해석해 문자 데이터로 변환하는 작업이다. 오디오 분류는 오디오 신호를 일정 시간 단위로 나누어 특이점을 분석하고 특정 클래스로 분류하는 작업이다.",
        "long_answer": {
            "question": "음성 인식과 오디오 분류 테스크의 개념에 대해 설명하라.",
            "answer": "음성 인식은 사람이 말하는 음성 언어를 AI가 해석하고, 그 내용을 문자 데이터로 전환하는 테스크이다. 오디오 분류는 오디오 정보를 특정 시간 단위로 잘라서 신호의 특이점을 분석하고 특정 클래스로 분류하는 테스크이다.",
            "rubric": [
                "음성 인식; 오디오 분류; 음성 언어; 문자 데이터; 분류"
            ]
        },
        "short_answer": {
            "question": "오디오 분류에서 오디오 정보를 분할하는 기준은 무엇인가?",
            "answer": "특정 시간 단위",
            "topic": [
                "오디오 분류의 정의"
            ]
        },
        "multiple_choice": {
            "question": "음성 인식 테스크에 대한 설명으로 적합한 것은?",
            "choices": [
                "a) 음성 인식은 주석이 달린 오디오 데이터로 시작한다.",
                "b) 음성 인식은 문자데이터를 음성 언어로 전환하는 작업이다.",
                "c) 음성 인식의 대표적인 데이터셋은 구글 오디오셋이다.",
                "d) 음성 인식은 일반적으로 STT와 동일한 테스크로 인식된다."
            ],
            "answer": "d",
            "topic": [
                "음성 인식 테스크의 특징"
            ]
        },
        "true_false": {
            "question": "일반적으로 오디오 분류를 정의할 때는 음성에 대한 분류를 의미한다.",
            "answer": "FALSE",
            "topic": [
                "오디오 분류의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:137:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.1.8 텍스트 추천 (Text Extraction) 구분 내 용 개념 Ÿ 텍스트를 기반으로 어떤 조건에 적합한 대상을 추천하는 작업  세부 내용  Ÿ 텍스트 데이터를 분석하여 유사한 주제나 관심사를 추천하고, 감정 분석을 통해 사용자의 선호도나 취향을 파악하여 추천 Ÿ 텍스트 데이터에서 키워드나 태그를 추출하여 해당 키워드나 태그와 관련된 대상을 추천 기능으로 사용 <표 III-75> 텍스트 추천의 개념 및 세부 내용  5.1.1.8 텍스트 예측 (Text Prediction) 구분 내 용 개념 Ÿ 텍스트에 대한 미래에 특정한 내용을 예측하여 제공하는 작업  세부 내용  Ÿ 텍스트 자동 완성 기능은 사용자가 입력하는 동안 다음 단어를 예측하여 입력을 보완하고 자동 제공하는 기능으로 사용 Ÿ 기계 번역에서는 주어진 문장을 예측하여 다른 언어로 번역 수행",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:137:0001",
                    "page": 137
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "텍스트 추천 테스크는 텍스트를 기반으로 어떤 조건에 적합한 대상을 추천하는 작업이다. 텍스트 예측 테스크는 텍스트에 대한 미래에 특정한 내용을 예측하여 제공하는 작업이다.",
        "long_answer": {
            "question": "텍스트 추천과 텍스트 예측을 비교하여 설명하라.",
            "answer": "텍스트 추천은 텍스트 데이터를 분석해 유사한 주제나 관심사를 찾아내고, 키워드나 감정 분석을 통해 사용자의 선호에 맞는 대상을 제안하는 기술이다. 반면 텍스트 예측은 입력 중인 문맥을 기반으로 다음 단어나 문장을 예측하거나, 기계 번역과 같이 미래의 텍스트를 생성·제공하는 기능을 수행한다.",
            "rubric": [
                "텍스트 추천; 텍스트 데이터; 분석; 문맥; 다음 단어; 예측"
            ]
        },
        "short_answer": {
            "question": "사용자가 입력하는 동안 다음 단어를 예측하여 입력 보완 및 자동제공하는 기능은 무엇인가?",
            "answer": "텍스트 자동 완성 기능",
            "topic": [
                "텍스트 자동 완성 기능의 정의"
            ]
        },
        "multiple_choice": {
            "question": "텍스트 추천과 텍스트 예측에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 텍스트 추천은 오디오와 텍스트를 기반으로 하는 작업이다.",
                "b) 텍스트 추천은 텍스트 데이터에서 키워드나 태그를 추출하여 추천에 사용한다.",
                "c) 텍스트 예측은 사용자가 입력할 내용을 처음부터 예측할 수 있다.",
                "d) 텍스트 예측은 이전 단어를 예측하는 용도로 쓰인다."
            ],
            "answer": "b",
            "topic": [
                "텍스트 추천과 텍스트 예측의 설명"
            ]
        },
        "true_false": {
            "question": "텍스트 추천 테스크는 유사한 주제나 관심사를 추천하는 데 쓰인다.",
            "answer": "TRUE",
            "topic": [
                "텍스트 추천 테스크의 사용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:138:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.2.1 텍스트 요약 (Text Summary) 구분 내 용 개념 Ÿ 상대적으로 큰 원문을 핵심 내용만 간추려서 상대적으로 작은 요약문으로  변환하는 작업  세부 내용  Ÿ 원문에서 중요한 핵심 문장 또는 단어구를 뽑아 이들로 구성하는 ‘추출적 요약(Extractive Summarization)’과 원문에 없던 문장이라도 핵심 문맥을 반영하여 새로운 문장을 생성해서 요약하는 ‘추상적 요약(Abstractive Summarization)’으로 구분됨",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:138:0001",
                    "page": 138
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "텍스트 요약은 상대적으로 큰 원문을 핵심 내용만 간추려서 상대적으로 작은 요약문으로 변환하는 작업이다. 원문에서 중요한 핵심 문장 또는 단어구를 뽑아 이들로 구성하는 ‘추출적 요약'과 원문에 없던 문장이라도 핵심 문맥을 반영하여 새로운 문장을 생성해서 요약하는 ‘추상적 요약'으로 구분된다.",
        "long_answer": {
            "question": "추출적 요약과 추상적 요약을 비교하여 서술하라.",
            "answer": "추출적 요약은 원문에서 핵심이 되는 문장이나 단어구를 직접 선택하여 요약문을 구성하는 방식으로, 원문의 표현을 그대로 유지한다. 반면 추상적 요약은 원문 내용을 이해하고 재구성하여 새로운 문장을 만들어낸다.",
            "rubric": [
                "추출적 요약; 원문; 선택; 추상적 요약; 새로운"
            ]
        },
        "short_answer": {
            "question": "텍스트 요약 테스크를 둘로 구분하면 무엇과 무엇인가?",
            "answer": "추출적 요약, 추상적 요약",
            "topic": [
                "텍스트 요약 테스크의 구분"
            ]
        },
        "multiple_choice": {
            "question": "텍스트 요약의 구분으로 적합한 것을 고르시오.",
            "choices": [
                "a) 객관적 요약",
                "b) 선택적 요약",
                "c) 추출적 요약",
                "d) 서술적 요약"
            ],
            "answer": "c",
            "topic": [
                "텍스트 요약의 구분 추출적 요약"
            ]
        },
        "true_false": {
            "question": "추상적 요약은 핵심 문맥을 반영하여 원문에서 중요한 핵심 문장 또는 단어구를 뽑아 요약하는 것이다.",
            "answer": "FALSE",
            "topic": [
                "추상적 요약의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:138:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.2.2 텍스트 생성 (Text Generation) 구분 내 용 개념 Ÿ 기계학습을 이용하여 문장을 생성하는 작업  세부 내용  Ÿ LSTM(Long Short Term Memory)/RNN(Recurrent Neural Network) 나 Softmax 알고리즘을 적용하여, 인간이 문장을 만드는 과정을 최대한 구현하는 방향으로 Language Modeling이 발전하고 있음 <표 III-79> 텍스트 생성의 개념 및 세부 내용  5.1.2.3 기계 번역 (Machine Translation) 구분 내 용 개념 Ÿ 인공지능을 이용해 인간이 사용하는 자연어를 다른 자연어로 번역하는 작업  세부 내용  Ÿ 자동 번역이라고도 부르며, 구글 번역, 네이버 파파고, SYSTRAN, 바벨피시, 빙 번역기 등 다양한 기계 번역기가 존재함 Ÿ 최근에는 기계 번역이 스스로 학습하여 자신의 정확도를 향상하는 역 번역(Back Translation)과 디노이징(Denoising) 같은 기술을 적용하여 발전하고 있음 <표 III-80> 기계 번역의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:138:0001",
                    "page": 138
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "텍스트 생성은 기계학습을 이용하여 문장을 생성하는 작업이다. 기계 번역은 인공지능을 이용해 인간이 사용하는 자연어를 다른 자연어로 번역하는 작업이다.",
        "long_answer": {
            "question": "텍스트 생성의 개념을 정의하고 어떻게 발전하고 있는지 서술하시오.",
            "answer": "텍스트 생성은 기계학습을 이용하여 문장을 생성하는 작업이다. 최근에는 LSTM, RNN, Softmax 등의 알고리즘을 적용하여 인간이 문장을 만들어내는 과정을 구현하는 것을 목표로 하여 언어 모델링이 발전하고 있다.",
            "rubric": [
                "텍스트 생성; 기계학습; 알고리즘; 인간"
            ]
        },
        "short_answer": {
            "question": "기계 번역은 인공지능을 이용해 A를 다른 A로 번역하는 작업이라 할 때 A에 들어갈 단어는?",
            "answer": "자연어",
            "topic": [
                "기계 번역의 개념 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 기계 번역기에 해당하지 않는 것은?",
            "choices": [
                "a) 네이버 파파고",
                "b) 구글 번역",
                "c) LSTM",
                "d) SYSTRAN"
            ],
            "answer": "c",
            "topic": [
                "기계 번역의 종류"
            ]
        },
        "true_false": {
            "question": "텍스트 생성은 기계학습을 통해 이루어진다.",
            "answer": "TRUE",
            "topic": [
                "텍스트 생성의 개념"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:139:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.2.4 음성 합성 (Speech Synthesis) 구분 내 용 개념 Ÿ 텍스트나 입술 움직임과 같이 다른 매체 정보로부터 음성을 생성하는 작업  세부 내용  Ÿ 음성 인식에 대응하는 음성 합성은 주로 텍스트 정보를 오디오 정보로 변환하는 데 사용되며 음성 지원 서비스 및 모바일 응용 프로그램과 같은 응용 프로그램에서 사용됨 Ÿ 이 외에도 시각 장애인이 텍스트 콘텐츠를 읽을 수 있도록 돕는 보조 기술에도 사용될 수 있음  5.1.2.6 음성 분리 (Speech Separation) 구분 내 용 개념 Ÿ 다중 음성 신호에서 개별 발화자의 음성 분리  세부 내용  Ÿ 음성 분리는 배경 잡음, 다른 발화자의 목소리 등이 혼합된 환경에서 특정 발화자의 음성을 식별하고 분리 Ÿ 신호 처리 및 기계 학습 방법을 사용하여 복잡한 음향 환경에서 유용하며, 음성 인식, 보청기, 통신 시스템 등에 응용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:139:0001",
                    "page": 139
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "음성 합성은 텍스트나 입술 움직임과 같이 다른 매체 정보로부터 음성을 생성해내는 작업이다. 음성 분리는 다중 음성 신호에서 개별 발화자의 음성을 분리하는 작업이다.",
        "long_answer": {
            "question": "음성 합성의 개념과 함께 음성 합성이 어디에 주로 사용되는지에 대해서 설명하시오.",
            "answer": "음성 합성은 텍스트 또는 입술 움직임처럼 다른 매체 정보로부터 음성을 생성하는 작업이다. 이는 음성 인식에 대응하는 것이며 주로 텍스트 정보를 오디오 정보로 변환하는데 사용된다. 음성 지원 서비스, 모바일 응용 프로그램, 시각 장애인 텍스트 독해 보조 기술 등에도 사용될 수 있다.",
            "rubric": [
                "음성 합성; 생성; 오디오 정보; 응용 프로그램"
            ]
        },
        "short_answer": {
            "question": "여러 사람이 말하는 음성과 배경음 등이 섞인 것에서 특정 발화자의 음성을 식별해 분리하는 것을 무엇이라 하는가?",
            "answer": "음성 분리",
            "topic": [
                "음성 분리의 정의"
            ]
        },
        "multiple_choice": {
            "question": "음성 분리에 대한 설명으로 적합하지 않은 것은?",
            "choices": [
                "a) 음성 분리는 특정 발화자의 음성을 식별한다.",
                "b) 음성 분리는 보청기나 통신 시스템 등에 응용된다.",
                "c) 음성 분리는 복잡한 음향 환경에서 유용하다.",
                "d) 음성 분리 시 배경 잡음이 혼합된 환경이면 분리가 불가능하다."
            ],
            "answer": "d",
            "topic": [
                "음성 분리의 특징"
            ]
        },
        "true_false": {
            "question": "음성 합성 시 제공되는 매체 정보는 텍스트만 가능하다.",
            "answer": "FALSE",
            "topic": [
                "음성 합성의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:139:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.2.5 텍스트 교정 (Text Reconstruction) 구분 내 용 개념 Ÿ 텍스트가 틀어지거나 잘못된 것을 교정하는 작업  세부 내용  Ÿ 문장이나 단어의 맞춤법, 문법, 구문 등을 검사하고 수정하여 텍스트의 품질을 향상시키고, 커뮤니케이션에서 오류를 줄여주는 기능으로 활용 Ÿ 사용자가 작성한 텍스트를 자동으로 검사하여 오류를 찾고 수정하여 제공",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:139:mh: 00001",
                    "page": 139
                }
            },
            {
                "context_id": "2",
                "text": "5.1.2.7 관계 추출 (Relation Extraction) 구분 내 용 개념 Ÿ 텍스트에서 엔티티 간의 의미있는 관계를 식별하고 추출  세부 내용  Ÿ 주로 자연어 처리 분야에서 사용되며, 텍스트 내의 엔티티(예: 사람, 장소, 기관) 간의 관계를 파악 Ÿ 정보 검색, 지식 그래프 구축, 텍스트 마이닝 등에 활용되어, 데이터베이스에 구조화된 형태로 정보를 저장하는데 용이",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:139:mh: 00001",
                    "page": 140
                }
            }
        ],
        "summarization": "텍스트 교정은 텍스트가 틀어지거나 잘못된 것을 교정하는 작업이다. 관계 추출은 텍스트에서 엔티티 간의 의미있는 관계를 식별하고 추출한다.",
        "long_answer": {
            "question": "관계 추출의 개념과 장점에 대해 서술하시오.",
            "answer": "관계 추출은 텍스트에서 엔티티 간의 유의미한 관계를 식별 및 추출하는 것이다. 이는 주로 자연어 처리 분야에서 사용되며, 정보 검색, 지식 그래프 구축, 텍스트 마이닝 등에 활용되어 데이터 베이스에 구조화된 형태로 정보를 저장하는데 용이하다는 장점이 있다.",
            "rubric": [
                "관계 추출; 엔티티; 자연어 처리; 데이터 베이스"
            ]
        },
        "short_answer": {
            "question": "문장이나 단어의 맞춤법, 구문 등을 검사하고 수정하는 테스크를 무엇이라 하는가?",
            "answer": "텍스트 교정",
            "topic": [
                "텍스트 교정의 정의"
            ]
        },
        "multiple_choice": {
            "question": "관계 추출의 활용 분야로 적합한 것은?",
            "choices": [
                "a) 텍스트 마이닝",
                "b) 텍스트 디스커버리",
                "c) 텍스트 파싱",
                "d) 텍스트 스크래핑"
            ],
            "answer": "a",
            "topic": [
                "관계 추출의 활용 분야"
            ]
        },
        "true_false": {
            "question": "관계 추출은 엔티티 간의 관계를 파악하는 것이다.",
            "answer": "TRUE",
            "topic": [
                "관계 추출의 개념"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:141:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.3.1 이미지 분류 (Image Classification) 구분 내 용 개념 Ÿ 특정 이미지를 알고리즘에 입력했을 때, 그 이미지가 어떤 클래스에 속하는지  알려주는 작업  세부 내용 Ÿ 단순히 객체의 큰 범위만 분류하는 것이 아닌, 해당 속성이나 상세한 클래스까지  분류해내는 경우 이미지 인식 또는 객체 인식이라고 할 수 있음 <표 III-86> 이미지 분류의 개념 및 세부내용  5.1.3.2 3D 포인트 클라우드 분류 (3D Point Cloud Classification) 구분 내 용 개념 Ÿ 특정 포인트 클라우드를 알고리즘에 입력했을 때, 그 포인트 클라우드가 어떤  클래스에 속하는지 알려주는 작업  세부 내용 Ÿ 단순히 객체의 큰 범위만 분류하는 것이 아닌, 해당 속성이나 상세한 클래스까지  분류해내는 경우 3D 객체 인식이라고 할 수 있음 <표 III-87> 3D 포인트 클라우드 분류의 개념 및 세부내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:141:0001",
                    "page": 141
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "이미지 분류는 특정 이미지를 알고리즘에 입력했을 때, 그 이미지가 어떤 클래스에 속하는지 알려주는 작업이다. 3D 포인트 클라우드 분류는 특정 포인트 클라우드를 알고리즘에 입력했을 때, 그 포인트 클라우드가 어떤 클래스에 속하는지 알려주는 작업이다.",
        "long_answer": {
            "question": "이미지 분류 테스크와 3D 포인트 클라우드 분류의 공통점에 대해 서술하라.",
            "answer": "이미지 분류와 3D 포인트 클라우드 분류는 각 테스크의 핵심 주제인 이미지와 포인트 클라우드를 알고리즘에 입력했을 때, 그것이 어떤 클래스에 속하는지 알려주는 작업이라는데서 공통점이 있다. 또한 두 테스크 모두 단순히 객체의 큰 범위만 분류하는 것이 아니라 해당 속성과 상세한 클래스까지 분류해냈을 때 이미지 인식, 3D 객체 인식이라고 할 수 있다는 점에서도 비슷하다.",
            "rubric": [
                "이미지 분류; 3D 포인트 클라우드 분류; 클래스; 인식"
            ]
        },
        "short_answer": {
            "question": "이미지 분류는 특정 이미지를 어디에 입력했을 때 그 이미지가 어떤 클래스에 속하는지 알려주는 작업인가?",
            "answer": "알고리즘",
            "topic": [
                "이미지 분류의 개념"
            ]
        },
        "multiple_choice": {
            "question": "이미지 분류와 3D 포인트 클라우드 분류에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) 이미지 분류의 결과물로 속한 클래스를 알 수 있다.",
                "b) 이미지 분류는 객체의 큰 범위만 분류하는 것이다.",
                "c) 3D 포인트 클라우드 분류의 결과물로 속한 클래스를 알 수 있다.",
                "d) 3D 포인트 클라우드 분류 작업과정은 특정 포인트 클라우드를 알고리즘에 입력하는 것이다."
            ],
            "answer": "b",
            "topic": [
                "이미지 분류와 3D 포인트 클라우드 분류의 특징"
            ]
        },
        "true_false": {
            "question": "특정 포인트 클라우드를 알고리즘에 입력했을 때 상세한 클래스까지 분류해내는 경우 3D 객체 인식이다.",
            "answer": "TRUE",
            "topic": [
                "3D 포인트 클라우드 분류의 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:142:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.3.3 객체 인식 (Object Detection) 구분 내 용 개념 Ÿ 이미지 내에서 특정 클래스의 객체 인스턴스를 인식하는 작업  세부 내용  Ÿ 객체 인식을 위한 방법은 1단계 방법과 2단계 방법의 두 가지 주요 유형으로 분류할 수 있음 Ÿ 1단계 방법은 추론 속도를 우선시하며, 대표적인 모델로는 YOLO, SSD, RetinaNet이 있음 Ÿ 2단계 방법은 탐지 정확도를 우선시하며, 대표적인 모델로는 Faster R-CNN, Mask R-CNN, Cascade R-CNN이 있음 Ÿ 객체 인식 작업과 관련된 가장 인기 있는 데이터셋은 MSCOCO 이며, 모델은 일반적으로 평균 정밀도 평가모델에 따라 평가됨 <표 III-88> 객체 인식의 개념 및 세부내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:142:0001",
                    "page": 142
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "객체 인식은 이미지 내에서 특정 클래스의 객체 인스턴스를 인식하는 작업이다.",
        "long_answer": {
            "question": "객체 인식을 위한 방법에 대해 구체적으로 서술하라.",
            "answer": "객체 인식을 위한 방법은 1단계 방법과 2단계 방법의 두 가지 주요 유형으로 분류할 수 있다. 1단계 방법은 추론 속도를 우선시한다. 2단계 방법은 탐지 정확도를 우선시한다. 1단계의 대표 모델은 YOLO, SSD, RetinaNet이 있다. 2단계의 대표 모델로는 Faster R-CNN, Mask R-CNN, Cascade R-CNN이 있다.",
            "rubric": [
                "객체 인식; 1단계; 2단계; 추론 속도; 탐지 정확도"
            ]
        },
        "short_answer": {
            "question": "객체 인식 1단계 방법에서 우선시되는 것은 무엇인가?",
            "answer": "추론 속도",
            "topic": [
                "객체 인식 1단계"
            ]
        },
        "multiple_choice": {
            "question": "객체 인식 방법에 대한 설명으로 올바른 것은?",
            "choices": [
                "a) 객체 인식 1단게 방법은 탐지 속도를 우선시한다.",
                "b) 객체 인식 1단계 방법은 추론 정확도를 우선시한다.",
                "c) 객체 인식 2단계 방법은 탐지 속도를 우선시한다.",
                "d) 객체 인식 2단계 방법은 탐지 정확도를 우선시한다."
            ],
            "answer": "d",
            "topic": [
                "객체 인식 방법"
            ]
        },
        "true_false": {
            "question": "텍스트 내에서 특정 클래스의 객체 인스턴스를 인식하는 작업을 객체 인식이라고 한다.",
            "answer": "FALSE",
            "topic": [
                "객체 인식의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:142:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.3.4 3D 객체 인식 (3D Object Detection) 구분 내 용 개념 Ÿ 3D 영상/이미지 내에서 특정 클래스의 객체 인스턴스를 감지하는 작업  세부 내용  Ÿ 3D 객체 인식은 일반적인 객체 인식과 유사하지만, 입력값으로 RGB 이미지와 함께 depth 값을 받아서 학습하고, 추론 시에는 RGB 이미지만을 입력으로 받아 depth 값을 추정하는 것이 중요한 차이라고 할 수 있음 Ÿ 객체 인식 분야를 3차원 객체 인식으로 범위를 확장하면, 물체의 크기, 위치, 방향 등을 알 수 있으므로 자율주행 및 이미지 검색, 증강 현실에서 다양한 분야에 응용 가능함 <표 III-89> 3D 객체 인식의 개념 및 세부내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:142:0001",
                    "page": 142
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "3D 객체 인식은 3D 영상 또는 이미지 내에서 특정 클래스의 객체 인스턴스를 감지하는 작업이다.",
        "long_answer": {
            "question": "객체 인식 분야를 3차원 객체 인식으로 확장했을 때의 장점에 대해 쓰시오.",
            "answer": "객체 인식 분야를 3차원 객체 인식으로 범위를 확장하면, 물체의 크기, 위치, 방향 등을 알 수 있다. 따라서 이를 자율주행 및 이미지 검색, 증강 현실에서 다양한 분야에 응용할 수 있다는 장점이 있다.",
            "rubric": [
                "3차원 객체 인식; 크기; 위치; 방향; 자율주행; 증강 현실; 이미지 검색"
            ]
        },
        "short_answer": {
            "question": "3D 객체 인식에서 입력 값으로 학습하는 두가지는 무엇인가?",
            "answer": "RGB 이미지, depth 값",
            "topic": [
                "3D 객체 인식의 학습 시 입력값"
            ]
        },
        "multiple_choice": {
            "question": "3D 객체 인식에 대한 설명으로 부적합한 것은?",
            "choices": [
                "a) 3D 객체 인식은 학습 시 입력값으로 RGB 이미지와 뎁스 값을 받는다.",
                "b) 3D 객체 인식은 학습 시 입력값으로 뎁스 값만을 받는다.",
                "c) 3D 객체 인식은 추론 시 RGB 이미지만을 입력으로 받는다.",
                "d) 3D 객체 인식은 추론 시 뎁스 값을 추정한다."
            ],
            "answer": "b",
            "topic": [
                "3D 객체 인식의 과정"
            ]
        },
        "true_false": {
            "question": "3D 객체 인식은 추론 시 CYMK 이미지만을 입력으로 받아 뎁스 값을 추정한다.",
            "answer": "FALSE",
            "topic": [
                "3D 객체 인식의 과정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:142:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.3.5 얼굴 인식 (Face Recognition) 구분 내 용 개념 Ÿ 얼굴을 사용하여 개인의 신원을 식별하거나 확인하는 작업  세부 내용  Ÿ 얼굴 인식 시스템은 사진, 비디오 또는 실시간으로 사람을 식별하는 데 사용할 수 있음 Ÿ 안면 인식은 생체 인식 보안의 범주로서, 다른 형태의 생체 인식 소프트웨어에는 음성 인식, 지문 인식, 눈 망막 또는 홍채 인식 등이 있음 Ÿ 얼굴 인식 Task는 Face Verification과 Face Identification과 같이 세부적인 Task로 구체화 됨 <표 III-90> 얼굴 인식의 개념 및 세부내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:142:0001",
                    "page": 142
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "얼굴 인식은 얼굴을 활용해 개인의 신원을 식별하거나 확인하는 기술로, 사진·영상·실시간 데이터 등 다양한 형태에서 활용된다.",
        "long_answer": {
            "question": "얼굴 인식 테스크의 개념에 대해 설명하라.",
            "answer": "얼굴 인식은 얼굴을 사용하여 개인의 신원을 식별하거나 확인하는 작업이다. 사진, 비디오 또는 실시간으로 사람을 식별하는 데 사용할 수 있으며 생체 인식 보안의 한 범주에 속한다. 얼굴 인식 테스크는 Face Verification과 Face Identification과 같이 세부적인 테스크로 구체화할 수 있다.",
            "rubric": [
                "얼굴 인식; 식별; 생체 인식 보안"
            ]
        },
        "short_answer": {
            "question": "얼굴 인식 시스템의 상위 보안 범주는 무엇인가?",
            "answer": "생체 인식 보안",
            "topic": [
                "얼굴 인식 시스템의 상위 범주"
            ]
        },
        "multiple_choice": {
            "question": "얼굴 인식 시스템에 대한 설명으로 잘못된 것은?",
            "choices": [
                "a) 얼굴 인식 시스템은 실시간으로 사람을 식별하는 데 쓸 수 있다.",
                "b) 얼굴 인식 시스템은 생체 인식 보안에 들어간다.",
                "c) 얼굴 인식은 비디오에만 적용 가능하다.",
                "d) 얼굴 인식은 사진에도 적용 가능하다."
            ],
            "answer": "c",
            "topic": [
                "얼굴 인식 시스템의 설명"
            ]
        },
        "true_false": {
            "question": "음성 인식은 생체 인식 소프트웨어의 한 종류이다.",
            "answer": "TRUE",
            "topic": [
                "생체 인식 소프트웨어의 종류"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:143:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.3.6 키포인트 검출 (Keypoint Detection) 구분 내 용 개념 Ÿ 동작 인식을 위해 필요한 주요 키포인트를 검출하는 작업  세부 내용  Ÿ 키포인트는 관심 포인트라고도 하며, 이미지에서 흥미롭거나 눈에 띄는 것을 정의하는 공간적 위치 또는 이미지의 포인트를 지칭함 Ÿ 특징으로는, 이미지 회전, 축소, 변환, 왜곡 등에 대해 변하지 않음 Ÿ 얼굴을 대상으로 할 때는 Facial Landmark Detection, 신체를 대상으로 할 때는 Pose Estimation이라는 Task로 좀 더 구체화 됨 <표 III-91> 키포인트 검출의 개념 및 세부내용  5.1.3.7 3D 키포인트 검출 (3D Keypoint Detection) 구분 내 용 개념 Ÿ 3D 데이터에서 동작 인식을 위해 필요한 주요 키포인트를 검출하는 작업  세부 내용  Ÿ 키포인트는 관심 포인트라고도 하며, 3D 데이터에서 흥미롭거나 눈에 띄는 것을 정의하는 공간적 위치 포인트를 지칭함 Ÿ 특징으로는, 3D 데이터 회전, 축소, 변환, 왜곡 등에 대해 변하지 않음 <표 III-92> 3D 키포인트 검출의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:143:0001",
                    "page": 143
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "키포인트 검출은 동작 인식을 위해 필요한 주요 키포인트를 검출하는 작업이다. 3D 키포인트 검출은 3D 데이터에서 동작 인식을 위해 필요한 주요 키포인트를 검출하는 작업이다.",
        "long_answer": {
            "question": "키포인트 검출과 3D 키포인트 검출에서 사용되는 키포인트의 정의에 대해 설명하라.",
            "answer": "키포인트는 관심 포인트라고도 하며 이미지 또는 3D 데이터에서 흥미롭거나 눈에 띄는 것을 정의하는 포인트를 말한다. 키포인트 검출에서는 이것이 공간적 위치 또는 이미지 포인트가 될 수 있으며 3D 키포인트 검출에서는 공간적 위치 포인트를 지칭한다.",
            "rubric": [
                "키포인트 검출; 공간적 위치; 이미지 포인트; 3D 키포인트 검출"
            ]
        },
        "short_answer": {
            "question": "3D 데이터에서 동작 인식을 위해 필요한 주요 키포인트를 검출하는 작업을 무엇이라 하는가?",
            "answer": "3D 키포인트 검출",
            "topic": [
                "3D 키포인트 검출의 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 키포인트 검출에 대한 설명으로 올바른 것은?",
            "choices": [
                "a) 키포인트 검출은 동작 인식을 위해 필요한 주요 관심 포인트를 검출하는 것이다.",
                "b) 키포인트는 이미지에서 필수가 되는 포인트를 말한다.",
                "c) 얼굴을 대상으로 하는 키포인트 검출은 현재 기술로 구현되지 않았다.",
                "d) 키포인트 검출은 이미지를 축소하면 변한다."
            ],
            "answer": "a",
            "topic": [
                "키포인트 검출의 특징"
            ]
        },
        "true_false": {
            "question": "키포인트 검출은 이미지를 회전시키면 결과가 변한다.",
            "answer": "FALSE",
            "topic": [
                "키포인트 검출의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:143:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.3.8 행동 인식 (Action Recognition) 구분 내 용 개념 Ÿ 비디오 데이터 스트림에서 객체 행동의 감지 및 인식을 하는 작업  세부 내용  Ÿ 실시간 CCTV 비디오 데이터 스트림에서 객체 행동의 감지 및 인식은, 잠재적으로 위험한 시나리오의 이상 감지를 위해 활용될 수 있음 Ÿ 최첨단 딥러닝 기술과 ‘경로 서명’을 결합하여 객체 행동을 해석하기 위한 일반화된 프레임워크를 개발하며, 문제를 효율적이고 효과적으로 해결하는 것을 목표로 함 <표 III-93> 행동 인식의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:143:mh: 00001",
                    "page": 143
                }
            },
            {
                "context_id": "2",
                "text": "5.1.3.9 자세 추정 (Pose Estimation) 구분 내 용 개념 Ÿ 객체와 객체의 주요 부분에 대한 위치, 방향을 식별하여 클래스를 분류하는 작업  세부 내용  Ÿ 기술적으로 키포인트 검출(Keypoint Detection)이나 행동 인식(Action Recognition) Task와 유사한 문제로 정의됨 Ÿ 게임, 의료, AR 및 스포츠를 포함한 광범위한 분야에서 응용 프로그램을 찾는 확장성으로 인해 많은 연구가 진행되고 있음 <표 III-94> 자세 추정의 개념 및 세부 내용  5.1.3.10 3D 자세 추정 (3D Pose Estimation) 구 분 내 용 개념 Ÿ 3D 데이터에서 객체와 객체의 주요 부분에 대한 위치, 방향을 식별하여 클래스를  분류하는 작업  세부 내용  Ÿ 기술적으로 3D 키포인트 검출(3D Keypoint Detection) Task와 유사한 문제로 정의됨 Ÿ 게임, 의료, AR 및 스포츠를 포함한 광범위한 분야에서 응용 프로그램을 찾는 확장성으로 인해 많은 연구가 진행되고 있음 <표 III-95> 3D 자세 추정의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:143:mh: 00001",
                    "page": 144
                }
            }
        ],
        "summarization": "행동 인식은 비디오 데이터 스트림에서 객체 행동의 감지 및 인식을 하는 작업이다. 자세 추정은 객체와 객체의 주요 부분에 대한 위치, 방향을 식별하여 클래스를 분류하는 작업이다. 3D 자세 추정은 3D 데이터에서 객체와 객체의 주요 부분에 대한 위치, 방향을 식별하여 클래스를 분류하는 작업이다.",
        "long_answer": {
            "question": "자세 추정과 3D 자세 추정의 현재 연구 경향성에 대해 서술하시오.",
            "answer": "자세 추정과 3D 자세 추정은 게임, 의료, AR 및 스포츠를 포함한 광범위한 분야에서 응용 프로그램을 찾는 확장성으로 인해 많은 연구가 진행되고 있다.",
            "rubric": [
                "자세 추정; 3D 자세 추정; 응용 프로그램; 확장성"
            ]
        },
        "short_answer": {
            "question": "행동 인식에서 객체 행동의 감지 및 인식의 대상이 되는 것은 무엇인가?",
            "answer": "비디오 데이터 스트림",
            "topic": [
                "행동 인식의 개념"
            ]
        },
        "multiple_choice": {
            "question": "다음 테스크에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 행동 인식은 이미지를 대상으로 객체의 감지를 하는 작업이다.",
                "b) 행동 인식은 실시간 CCTV 비디오 데이터 스트림에서도 가능하다.",
                "c) 자세 추정은 3D 데이터에서 객체의 위치와 방향을 식별하여 클래스를 분류하는 작업이다.",
                "d) 3D 자세 추정은 방향만을 식별할 수 있다."
            ],
            "answer": "b",
            "topic": [
                "행동 인식의 특징; 자세 추정의 특징; 3D 자세 추정의 특징"
            ]
        },
        "true_false": {
            "question": "자세 추정은 기술적으로 키포인트 검출과 비교해봤을 때 유사하지 않다.",
            "answer": "FALSE",
            "topic": [
                "자세 추정의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:144:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.3.11 비디오 분류 (Video Classification) 구분 내 용 개념 Ÿ 프레임이 주어진 비디오에서 특정 프레임 구간을 선택하고 클래스 레이블을  부여하는 작업  세부 내용  Ÿ 좋은 비디오 레벨 분류기는 정확한 프레임 레이블을 제공할 뿐만 아니라 비디오에 있는 다양한 프레임의 기능과 주석을 고려하여 전체 비디오를 설명할 수 있음 Ÿ 프레임과 비디오를 설명하는 데 필요한 레이블의 세분성은 작업에 따라 다르며, 일반적인 작업에는 비디오에 하나 이상의 전역 레이블을 할당하고 비디오 내부의 각 프레임에 하나 이상의 레이블을 할당하는 것이 포함됨 <표 III-96> 비디오 분류의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:144:mh: 00001",
                    "page": 144
                }
            },
            {
                "context_id": "2",
                "text": "5.1.3.13 비디오 인식 (Video Recognition) 구분 내 용 개념 Ÿ 비디오를 활용하여 실시간 객체 식별 및 비디오 프레임을 분류하는 작업  세부 내용  Ÿ 컴퓨터는 수천 개의 비디오 스트림을 보고 프레임 단위로 수신하는 정보를 이해하는 과정을 거치며, Tracking 하는 업무로 정의될 수 있음 Ÿ 카메라를 사용하여 시간이 지남에 따라 움직이는 물체를 찾아 연속적인 비디오 프레임에서 대상 물체를 연결하는 것으로 구성됨 <표 III-98> 비디오 인식의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:144:mh: 00001",
                    "page": 145
                }
            }
        ],
        "summarization": "비디오 분류는 프레임이 주어진 비디오에서 특정 프레임 구간을 선택하고 클래스 레이블을 부여하는 작업이다. 비디오 인식은 비디오를 활용하여 실시간 객체 식별 및 비디오 프레임을 분류하는 작업이다.",
        "long_answer": {
            "question": "비디오 분류와 비디오 인식에 대해 설명하라.",
            "answer": "비디오 분류는 비디오의 특정 프레임 구간을 선택해 클래스 레이블을 부여하는 작업으로, 좋은 비디오 레벨 분류기는 비디오 내의 다양한 프레임 기능과 주석을 종합해 전체 비디오를 설명하는 것을 목표로 한다. 반면 비디오 인식은 실시간으로 비디오 내 객체를 식별하고 프레임을 분류하는 과정으로, 연속된 프레임에서 움직이는 물체를 트랙킹하여 식별하는 작업이다.",
            "rubric": [
                "비디오 분류; 비디오 인식; 클래스 레이블; 프레임; 객체; 식별"
            ]
        },
        "short_answer": {
            "question": "비디오를 활용하여 실시간 객체 식별 및 비디오 프레임을 분류하는 작업을 무엇이라 하는가?",
            "answer": "비디오 인식",
            "topic": [
                "비디오 인식의 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 비디오 분류와 비디오 인식에 대한 설명으로 거리가 먼 것은?",
            "choices": [
                "a) 비디오 분류는 프레임이 주어진 비디오를 대상으로 한다.",
                "b) 비디오 분류는 프레임이 주어진 비디오에서 특정 프레임 구간을 선택해 진행한다.",
                "c) 비디오 인식은 트랙킹 업무 과정을 거친다.",
                "d) 비디오 인식은 프레임 단위로 송신하는 정보를 이해하는 과정을 거친다."
            ],
            "answer": "d",
            "topic": [
                "비디오 분류와 비디오 인식의 설명"
            ]
        },
        "true_false": {
            "question": "비디오 인식에서 컴퓨터는 수천 개의 비디오 스트림을 본다.",
            "answer": "TRUE",
            "topic": [
                "비디오 인식의 설명"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:145:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.3.14 시멘틱 세그멘테이션 (Semantic Segmentation) 구분 내 용 개념 Ÿ 동일한 객체 클래스에 속하는 이미지 부분을 함께 클러스터링하는 작업  세부 내용  Ÿ 이미지의 모든 픽셀에 클래스를 부여하는 라벨링 방법 Ÿ 물체, 배경 등을 의미적으로 분할하여 자율주행, 의료 영상 분석 기술 개발 등에 사용 <표 III-99> 시멘틱 세그멘테이션의 개념 및 세부 내용 5.1.3.15 인스턴스 세그멘테이션 (Instance Segmentation) 구분 내 용 개념 Ÿ 개체의 감지된 각 인스턴스에 대한 분할 맵을 생성하는 향상된 유형의 세그멘테이션  분할 작업  세부 내용 Ÿ 이미지의 모든 픽셀이 같은 클래스여도 다른 인스턴스를 부여하는 라벨링 방법  Ÿ 객체 인식 시 중첩된 경우 분할하는 기술개발 등에 사용 <표 III-100> 인스턴스 세그멘테이션의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:145:mh: 00001",
                    "page": 145
                }
            },
            {
                "context_id": "2",
                "text": "5.1.3.16 3D 시멘틱 세그멘테이션 (3D Semantic Segmentation) 구분 내 용 개념 Ÿ 실제 객체를 나타내는 포인트 클라우드의 입력을 받아 객체를 다른 부분으로  분할하는 작업  세부 내용  Ÿ 3차원 공간에서 객체를 식별하고 분할하는 작업 Ÿ 자율주행 자동차에서는 도로, 보행자, 차량 등의 객체를 식별하여 사용 Ÿ 의료 분야에서는 CT 스캔이나 MRI 영상에서 조직이나 종양 등을 식별하여 진단 등에 사용 <표 III-101> 3D 시멘틱 세그멘테이션의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:145:mh: 00001",
                    "page": 146
                }
            }
        ],
        "summarization": "시멘틱 세그멘테이션은 동일한 객체 클래스에 속하는 이미지 부분을 함께 클러스터링하는 작업이다. 인스턴스 세그멘테이션은 개체의 감지된 각 인스턴스에 대한 분할 맵을 생성하는 향상된 유형의 세그멘테이션이다. 3D 시멘틱 세그멘테이션은 실제 객체를 나타내는 포인트 클라우드의 입력을 받아 객체를 다른 부분으로 분할하는 작업이다.",
        "long_answer": {
            "question": "시멘틱 세그멘테이션과 인스턴스 세그멘테이션의 개념과 활용 방안에 대해 설명하라.",
            "answer": "시멘틱 세그멘테이션은 이미지의 모든 픽셀에 클래스를 부여하여 동일한 객체 클래스에 속하는 이미지 부분을 함께 클러스터링하는 작업으로 자율주행이나 의료 영상 분석 등에 활용된다. 인스턴스 세그멘테이션은 동일한 클래스 내에서도 각 개체를 구분해 별도의 인스턴스로 라벨링하는 고도화된 작업으로 객체 인식 시 중첩된 이미지를 분할하는 기술 개발 등에 활용한다.",
            "rubric": [
                "시멘틱 세그멘테이션; 클래스; 클러스터링; 인스턴스; 중첩"
            ]
        },
        "short_answer": {
            "question": "객체 인식 시 중첩된 경우 분할하는 기술 개발 등에 사용되는 테스크는 무엇인가?",
            "answer": "인스턴스 세그멘테이션",
            "topic": [
                "인스턴스 세그멘테이션의 특징"
            ]
        },
        "multiple_choice": {
            "question": "각 테스크에 대한 설명으로 잘못된 것은?",
            "choices": [
                "a) 시멘틱 세그멘테이션은 이미지의 모든 픽셀에 클래스를 부여하지 않는다.",
                "b) 시멘틱 세그멘테이션은 동일한 객체 클래스에 속하는 이미지 부분을 함께 클러스터링한다.",
                "c) 인스턴스 세그멘테이션은 이미지의 모든 픽셀이 같은 클래스여도 다른 인스턴스를 부여한다.",
                "d) 3D 시멘틱 세그멘테이션은 3차원 공간에서 객체를 식별하고 분할한다."
            ],
            "answer": "a",
            "topic": [
                "시멘틱 세그멘테이션의 특징; 인스턴스 세그멘테이션의 특징; 3D 시멘틱 세그멘테이션의 특징"
            ]
        },
        "true_false": {
            "question": "3D 시멘틱 세그멘테이션은 특별 객체 클래스에 속하는 이미지 부분의 입력을 받아 클러스터링한다.",
            "answer": "FALSE",
            "topic": [
                "3D 시멘틱 세그멘테이션의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:146:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.3.17 이미지 캡셔닝 (Image Captioning) 구분 내 용 개념 Ÿ 이미지를 캡처하여 이미지에 대한 의미나 특징을 식별하는 작업  세부 내용  Ÿ 이미지에서 객체의 경계를 식별하기 위해 시멘틱 세그멘테이션(Semantic Segmentation) 기술을 사용 Ÿ 이미지에 대한 자연어 처리 기술을 적용하여 이미지의 의미를 수행 <표 III-102> 이미지 캡셔닝의 개념 및 세부 내용  5.1.3.18 재인식 (Re-Identification) 구분 내 용 개념 Ÿ 이전에 관찰되었던 개체를 다른 시간이나 장소에서 다시 인식하는 과정  세부 내용  Ÿ 보안 및 감시 시스템에서 중요하며, 비디오 감시에서 특정 인물이나 물체를 여러 카메라 간에 추적하는 데 사용 Ÿ 얼굴 인식, 차량 번호판 인식, 인물 추적 등 다양한 형태로 응용되며, 고유한 특징을 기반으로 개체를 식별 <표 III-103> 재인식의 개념 및 세부 내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:146:0001",
                    "page": 146
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "이미지 캡셔닝은 이미지를 캡처하여 이미지에 대한 의미나 특징을 식별하는 작업이다. 재인식은 이전에 관찰되었던 개체를 다른 시간이나 장소에서 다시 인식하는 과정이다.",
        "long_answer": {
            "question": "재인식의 개념을 정의하고 어디에 주로 사용되는지 설명하시오.",
            "answer": "재인식은 이전에 관찰되었던 개체를 다른 시간이나 장소에서 다시 인식하는 과정을 말한다. 이는 보안 및 감시 시스템에서 특히 중요한 것으로 비디오 감시에서 특정 인물이나 물체를 여러 카메라 간에 추적하는데 사용한다. 고유한 특징을 기반으로 개체를 식별하는 것으로 얼굴 인식, 차량 번호판 인식, 인물 추적 등 다양한 형태로 응용될 수 있다.",
            "rubric": [
                "재인식; 보안; 감시; 식별; 고유; 인식"
            ]
        },
        "short_answer": {
            "question": "이전에 관찰되었던 개체를 다른 시간에서 다시 인식하는 과정을 무엇이라 하는가?",
            "answer": "재인식",
            "topic": [
                "재인식의 개념"
            ]
        },
        "multiple_choice": {
            "question": "이미지 캡셔닝에서는 이미지에서 객체의 경계를 식별하기 위해 사용하는 기술로 알맞은 것은?",
            "choices": [
                "a) 키포인트 검출",
                "b) 행동 인식",
                "c) 시멘틱 세그멘테이션",
                "d) 이미지 분류"
            ],
            "answer": "c",
            "topic": [
                "이미지 캡셔닝의 설명"
            ]
        },
        "true_false": {
            "question": "이미지 캡셔닝은 이미지에 대한 자연어 처리 기술을 적용하여 이미지의 의미를 수행한다.",
            "answer": "TRUE",
            "topic": [
                "이미지 캡셔닝의 설명"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:147:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.4 시각 생성  알고리즘 Task 분야 데이터 유형 한글명 영문명 텍스트 이미지 비디오 오디오 3D 이미지 생성 Image Generation ● 이미지 합성 Image Synthesis ● 3D 객체 복원 3D Object Reconstruction ○ ○ ○ 2D 이미지를 통한 시점 합성 2D View Synthetic ○ ○ 해상도 개선 Super Resolution  5.1.4.1 이미지 생성 (Image Generation) 구분 내 용 개념 Ÿ 인공지능이 다양한 노이즈(Noise) 입력을 받아, 원하는 카테고리 내 새로운  이미지를 생성하는 작업  세부 내용 Ÿ GAN 기술을 이용하여 이미지 정보들의 변환과 재구축으로 진짜처럼 보이는 가짜  이미지 형성이 가능함 <표 III-105> 이미지 생성의 개념 및 세부내용  5.1.4.2 이미지 합성 (Image Synthesis) 구분 내 용 개념 Ÿ 인공지능이 이미지나 비디오를 입력받아, 다른 형태나 정보를 지닌 이미지 또는  비디오로 변환하는 작업  세부 내용 Ÿ GAN 기술을 이용하여 적은 양의 정보로 원본 이미지를 예측하거나, 사진을  특정한 방식의 이미지로 전환하는 것이 가능함 <표 III-106> 이미지 합성의 개념 및 세부내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:147:0001",
                    "page": 147
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "시각 생성의 알고리즘 테스크 분야에는 이미지 생성, 이미지 합성, 3D 객체 복원, 2D 이미지를 통한 시점 합성, 해상도 개선 등이 있다. 이미지 생성은 인공지능이 다양한 노이즈 입력을 받아 원하는 카테고리 내 새로운 이미지를 생성하는 작업이다. 이미지 합성은 인공지능이 이미지나 비디오를 입력받아 다른 형태나 정보를 지닌 이미지 또는 비디오로 변환하는 작업이다.",
        "long_answer": {
            "question": "이미지 생성과 이미지 합성의 개념을 각각 설명하라.",
            "answer": "이미지 생성은 인공지능이 다양한 노이즈 입력을 받아 GAN 기술을 이용하여 이미지 정보들의 변환과 재구축으로 진짜처럼 보이는 가짜 이미지를 원하는 카테고리 내에서 새롭게 생성하는 작업이다. 이미지 합성은 인공지능이 이미지나 비디오를 입력받아 GAN 기술을 이용하여 다른 형태나 정보를 지닌 이미지 또는 비디오로 변환하는 작업이다.",
            "rubric": [
                "이미지 생성; 이미지 합성; GAN 기술; 변환"
            ]
        },
        "short_answer": {
            "question": "이미지 생성과 이미지 합성 테스크에서 공통으로 사용하는 기술은 무엇인가?",
            "answer": "GAN 기술",
            "topic": [
                "이미지 생성과 이미지 합성의 사용 기술"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 시각 생성의 알고리즘 테스크가 아닌 것은?",
            "choices": [
                "a) 객체 인식",
                "b) 이미지 생성",
                "c) 이미지 합성",
                "d) 3D 객체 복원"
            ],
            "answer": "a",
            "topic": [
                "시각 생성의 하위 테스크"
            ]
        },
        "true_false": {
            "question": "인공지능이 이미지나 비디오를 입력받아 원하는 카테고리 내 새로운 이미지를 생성하는 것을 이미지 합성이라 한다.",
            "answer": "FALSE",
            "topic": [
                "이미지 생성과 이미지 합성의 정의 구분"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:148:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.4.3 3D 객체 복원(3D Object Reconstruction) 구분 내 용 개념 Ÿ 인공지능이 영상/이미지/포인트 클라우드로부터 객체(물체, 사람 등)의 3차원  구조를 복원(reconstruction)하는 작업  세부 내용  Ÿ 3D GAN 기술을 이용하여 영상/이미지/포인트 클라우드 정보들의 변환과 재구축으로, 실제 객체와 기하학적인 정확도뿐만 아니라 현실감이나 사실성 측면에서 매우 유사한 객체 형성이 가능함 <표 III-107> 3D 객체 복원의 개념 및 세부내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:148:0001",
                    "page": 148
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "3D 객체 복원은 인공지능이 영상, 이미지, 포인트 클라우드로부터 물체나 사람 등의 객체 3차원구조를 복원하는 작업이다.",
        "long_answer": {
            "question": "3D 객체 복원 테스크에 대해 설명하라.",
            "answer": "3D 객체 복원은 인공지능이 영상, 이미지, 포인트 클라우드 등의 데이터를 활용해 물체나 사람 등의 3차원 구조를 재구성하는 테스크이다. 3D GAN을 이용하면 다양한 형태의 입력 데이터를 변환 및 재구축하여 실제 객체와 기하학적 정확도뿐 아니라 현실감과 사실성 측면에서도 매우 유사한 객체를 형성할 수 있다.",
            "rubric": [
                "3D 객체 복원; 재구성; 객체; 3차원 구조"
            ]
        },
        "short_answer": {
            "question": "3D 객체 복원은 인공지능이 영상, 이미지, 포인트 클라우드로부터 객체의 무엇을 복원하는 작업인가?",
            "answer": "3차원 구조",
            "topic": [
                "3D 객체 복원의 개념"
            ]
        },
        "multiple_choice": {
            "question": "3D 객체 복원의 대상이 되는 것으로 적합하지 않은 것은?",
            "choices": [
                "a) 영상",
                "b) 이미지",
                "c) 텍스트",
                "d) 포인트 클라우드"
            ],
            "answer": "c",
            "topic": [
                "3D 객체 복원의 대상"
            ]
        },
        "true_false": {
            "question": "3D 객체 복원은 영상 뿐만 아니라 이미지, 포인트 클라우드로부터 객체 등의 3차원 구조를 복원하는 작업이다.",
            "answer": "TRUE",
            "topic": [
                "3D 객체 복원의 설명"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:148:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.1.4.4 2D 이미지를 통한 시점 합성(View Synthetic) 구분 내 용 개념 Ÿ 인공지능을 활용하여 이미지를 인공적으로 3D로 전환하는 작업  세부 내용  Ÿ 서로 다른 시점을 가진 여러 개의 카메라들을 이용하여 객체를 촬영한 뒤, 촬영된 영상들과 각 카메라들의 촬영 정보들을 이용하여 해당 객체에 대한 3차원 정보를 추정 <표 III-108> 2D 이미지 합성의 개념 및 세부내용  5.1.4.5 해상도 개선(Super Resolution) 구분 내 용 개념 Ÿ 저해상도 이미지 또는 동영상을 고해상도로 변환하는 기술  세부 내용  Ÿ 이미지 처리 및 컴퓨터 비전 분야에서 중요한 역할을 하며, 이미지의 세부 사항과 품질을 향상시키는 데 사용 Ÿ 저해상도의 입력 이미지에서 더 높은 픽셀 밀도를 갖는 이미지를 생성하여, 선명도와 디테일을 개선 <표 III-109> 해상도 개선의 개념 및 세부내용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:148:0001",
                    "page": 148
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "2D 이미지를 통한 시점 합성은 인공지능을 활용하여 이미지를 인공적으로 3D로 전환하는 작업이다. 해상도 개선은 저해상도 이미지 또는 동영상을 고해상도로 변환하는 기술이다.",
        "long_answer": {
            "question": "2D 이미지를 통한 시점 합성 방법에 대해 서술하라.",
            "answer": "2D 이미지를 통한 시점 합성은 인공지능을 활용해서 이미지를 3D로 인공적으로 전환하는 작업으로, 먼저 서로 다른 시점을 가진 여러 개의 카메라들을 이용하여 객체를 촬영한다. 이후 촬영된 영상들과 각 카메라들의 촬영 정보들을 이용하여 해당 객체에 대한 3차원 정보를 추정하는 방식으로 진행된다.",
            "rubric": [
                "2D 이미지를 통한 시점 합성; 3D; 전환; 시점; 촬영 정보"
            ]
        },
        "short_answer": {
            "question": "인공지능을 활용하여 이미지를 인공적으로 3D로 전환하는 작업을 무엇이라 하는가?",
            "answer": "2D 이미지를 통한 시점 합성",
            "topic": [
                "2D 이미지를 통한 시점 합성의 정의"
            ]
        },
        "multiple_choice": {
            "question": "해상도 개선에 대한 설명으로 적합한 것은?",
            "choices": [
                "a) 해상도 개선은 이미지에만 해당된다.",
                "b) 해상도 개선은 동영상에만 해당된다.",
                "c) 해상도 개선은 저해상도 이미지 또는 동영상을 고해상도로 변환한다.",
                "d) 해상도 개선에는 서로 다른 시점을 가진 여러 개의 카메라 촬영이 필요하다."
            ],
            "answer": "c",
            "topic": [
                "해상도 개선의 설명"
            ]
        },
        "true_false": {
            "question": "고해상도 이미지를 받아 3D로 전환하는 작업을 해상도 개선이라고 한다.",
            "answer": "FALSE",
            "topic": [
                "해상도 개선의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:149:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2 유효성 l ‘유효성’의 검사 항목은 알고리즘 Task 별로 구성되며, 각 Task에 따른 유효성 측정지표를 사용함 l 본 장에서는 각 Task별 유효성 측정지표를 데이터 유형*에 따라 제시함 * ‘이미지 데이터’, ‘비디오 데이터’, ‘오디오 데이터’, ‘텍스트 데이터’, ‘3D 데이터’, ‘센서 데이터 l 다만, 본 『제1권 AI 데이터 품질관리 가이드라인』에서 제시하는 유효성 측정지표는 한국지능정보사회진흥원에서 공모하는 ‘초거대AI 확산 생태계 조성사업’의 데이터 구축사례들을 기반으로 자주 활용되는 측정지표를 정리한 것으로, 제시하는 것 이외에도 매우 다양하므로 데이터 구축목적에 따라 적절한 측정지표 및 목표를 정의하는 것이 중요함 <유효성 목표 설정 원칙>  Ÿ 최신의 논문, 기고서, 공식 블로그 등에서 공식 보고된 값을 참고하여 유효성 목표치 기준 수립 - 해당 구축사업과 가장 유사한 주제의 SoTA(State of The Art) 자료(논문, 기고서 등)에서 공식 보고되는 값을 기준으로 유효성 목표치를 설정하는 것이 원칙 - 해당 구축사업의 이해관계자 간에 목표치에 대해 논의할 때, 반드시 상기 자료를 근거로 하고 출처를 명확히 제시 - 다만, 선행연구 분야에 해당하는 임무이기 때문에 SoTA의 해당 자료를 참고하기 힘든 경우 이해관계자 및 해당 임무·도메인 관련 전문가 의견을 반영하여 설정  <표 III-110> 유효성 목표 설정 원칙",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:149:0001",
                    "page": 149
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "유효성은 알고리즘 Task별로 구성된 측정지표를 활용하여 각 데이터 유형(이미지, 비디오, 오디오, 텍스트, 3D, 센서 등)에 따라 평가된다.유효성 목표치는 최신 논문이나 공식 자료에 보고된 SoTA(State of The Art) 값을 기준으로 설정하되, 참고 자료가 부족한 경우 전문가의 의견을 반영하여 정한다.",
        "long_answer": {
            "question": "유효성 목표 설정 원칙에 대해 설명하시오.",
            "answer": "유효성 목표치는 최신 논문, 기고서, 공식 블로그 등에서 공식적으로 보고된 SoTA(State of The Art) 자료를 기준으로 설정하며, 이해관계자 간 논의 시 반드시 해당 자료의 근거와 출처를 명확히 제시해야 한다. 다만, 선행연구 분야로 SoTA 자료 참고가 어려운 경우에는 이해관계자 및 관련 전문가의 의견을 반영하여 목표치를 수립한다.",
            "rubric": [
                "유효성 목표; SoTA; 이해관계자"
            ]
        },
        "short_answer": {
            "question": "유효성 목표를 설정할 때 가장 유사한 주제의 어떤 자료를 참고해야 하는가?",
            "answer": "SoTA(State of The Art)",
            "topic": [
                "유효성 목표의 근거 자료"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 유효성 목표 설정 원칙에 대한 설명으로 적합하지 않은 것은?",
            "choices": [
                "a) 유효성 목표치 기준은 최신의 논문, 기고서 등에서 공식 보고된 값을 참고하여 수립한다.",
                "b) SoTA의 해당 자료를 참고하기 힘든 경우 사업 참여자가 임의로 유효성 목표를 정할 수 있다.",
                "c) 해당 구축 사업의 이해관계자 간 목표치에 관해 논의할 때 반드시 SoTA 자료를 근거로 하고 출처를 명확히 제시한다.",
                "d) 해당 구축사업과 가장 유사한 주제의 SoTA 자료에서 공식 보고되는 값을 기준으로 유효성 목표치를 설정한다."
            ],
            "answer": "b",
            "topic": [
                "유효성 목표 설정 원칙"
            ]
        },
        "true_false": {
            "question": "유효성의 검사 항목은 알고리즘 테스크 별로 구성된다.",
            "answer": "TRUE",
            "topic": [
                "유효성의 검사 항목"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:149:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1 유효성 측정지표 5.2.1.1 Accuracy (정확도) 구분 내 용 개념 Ÿ 알고리즘이 데이터 포인트를 올바르게 분류하는 빈도를 측정하는 평가지표  세부 내용  Ÿ 기계 학습 분류 알고리즘의 정확도는 알고리즘이 데이터 포인트를 올바르게 분류하는 빈도를 측정하는 한 가지 방법으로, 정확도는 모든 데이터 포인트 중에서 올바르게 예측된 데이터 포인트의 수라고 할 수 있음 Ÿ 정확도는 다양한 비율의 참/거짓 양성/음성을 사용하는 다른 품질지표인 정밀도 및 재현율과 함께 사용되기도 함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:149:0001",
                    "page": 149
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "정확도(Accuracy)는 알고리즘이 데이터 포인트를 올바르게 분류한 빈도를 측정하는 평가지표이다.",
        "long_answer": {
            "question": "유효성 품질관리 지표 중 정확도의 개념과 측정 방법을 구체적으로 설명하시오.",
            "answer": "정확도는 알고리즘이 데이터 포인트를 올바르게 분류하는 빈도를 나타내는 지표이다. 이는 전체 데이터 포인트 중에서 올바르게 예측된 데이터의 비율을 계산하여 구한다. 정확도는 다양한 비율의 참/거짓 양성/음성을 사용하는 다른 품질지표인 정밀도, 재현율과 함께 사용되기도 한다.",
            "rubric": [
                "정확도; 데이터 포인트; 분류; 예측"
            ]
        },
        "short_answer": {
            "question": "유효성 품질관리 지표 중 정확도와 함께 사용되는 다양한 비율의 참/거짓 양성/음성을 사용하는 다른 품질지표에는 무엇이 있는가?",
            "answer": "정밀도, 재현율",
            "topic": [
                "유효성 품질관리 지표 중 정확도와 함께 사용되는 품질지표"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 유효성 품질관리 지표 중 정확도에 대한 설명으로 옳지 않은 것은?",
            "choices": [
                "a) 정확도는 데이터 포인트를 올바르게 분류하는 빈도를 측정하는 방법 중 하나이다.",
                "b) 정확도는 모든 데이터 포인트 중 올바르게 예측된 데이터 포인트의 수다.",
                "c) 정확도는 정밀도 또는 재현율과 함께 사용되기도 한다.",
                "d) 정확도는 분류 모델에 일반적으로 사용하며 올바르게 분류했는지를 측정하는 평가지표다."
            ],
            "answer": "d",
            "topic": [
                "유효성 품질관리 지표 중 정확도의 설명"
            ]
        },
        "true_false": {
            "question": "유효성 품질관리 지표 중 정확도는 모든 데이터 포인트 중에서 올바르게 예측된 데이터 포인트의 수이다.",
            "answer": "TRUE",
            "topic": [
                "유효성 품질관리 지표 중 정확도의 개념"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:150:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.2 OA (Overall Accuracy) 구분 내 용 개념 Ÿ 각각의 객체에 대한 검출 정확도 총합으로서 표현되는 품질지표  세부 내용  Ÿ Overall Accuracy(OA)는 기본적으로 모든 객체를 대상으로, 각각의 객체 검출이 올바르게 매핑 되었는지 총합으로 계산함 Ÿ 해당 품질지표는 계산 및 이해가 쉽고 전체적인 정확도를 표현하는데 유용하지만, 편향된 정확도에 대해서 편중(bias)이 발생할 수 있음",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:150:0001",
                    "page": 150
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "OA (Overall Accuracy)는 각각의 객체에 대한 검출 정확도 총합으로서 표현되는 품질지표이다.",
        "long_answer": {
            "question": "Overall Accuracy(OA)는 어떤 개념의 품질지표이며, 어떻게 계산되는가?",
            "answer": "Overall Accuracy(OA)는 객체 검출의 정확도를 나타내는 품질지표로, 각각의 객체 검출이 올바르게 매핑되었는지를 기준으로 기본적으로 모든 객체를 대상으로하여 계산된다. 이 지표는 모든 객체에 대한 검출 정확도의 총합으로 표현되며, 계산 및 이해가 쉬워 전체적인 정확도를 쉽게 파악할 수 있다.",
            "rubric": [
                "Overall Accuracy(OA); 객체 검출; 매핑; 총합"
            ]
        },
        "short_answer": {
            "question": "Overall Accuracy(OA)는 각 개체에 대한 검출 정확도의 무엇을 재고자 하는가?",
            "answer": "총합",
            "topic": [
                "OA의 개념"
            ]
        },
        "multiple_choice": {
            "question": "Overall Accuracy(OA)에 대한 설명으로 올바른 것은?",
            "choices": [
                "a) 일부 객체만을 대상으로 검출 정확도를 계산한다.",
                "b) 모든 객체의 올바른 매핑 여부를 기준으로 총합 정확도를 계산한다",
                "c) 계산이 복잡하여 이해하기 어려운 품질지표이다.",
                "d) 편향(bias) 문제와는 무관한 정확도 지표이다."
            ],
            "answer": "b",
            "topic": [
                "OA의 개념"
            ]
        },
        "true_false": {
            "question": "OA는 전체에서 일부 대표성을 가진 객체를 대상으로 검출 정확도를 측정한다.",
            "answer": "FALSE",
            "topic": [
                "OA의 개념"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:151:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.3 Recall (재현율) 구분 내 용 개념 Ÿ 분류 모델에 일반적으로 사용하며, 올바르게 분류했는지 측정하는 평가지표 세부 내용  Ÿ 분류 모델에 일반적으로 사용되는 성능 메트릭인 재현율(Recall)은 올바르게 분류된 양성의 비율로서, 재현율은 일반적으로 “진정한 긍정률”, “민감도” 및 “적중률”이라고도 함  5.2.1.4 Precision (정밀도) 구분 내 용 개념 Ÿ 분류 모델에 일반적으로 사용되며, 정확하게 예측했는지 측정하는 평가지표 세부 내용 Ÿ 분류 모델에 일반적으로 사용되는 성능지표인 정밀도는 정확하게 예측한 양성의  비율로서, 정밀도는 일반적으로 재현율과 반비례 관계임",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:151:0001",
                    "page": 151
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "재현율과 정밀도는 분류모델에 일반적으로 사용된다. 재현율은 올바르게 분류했는지를 측정하는 평가지표이다. 정밀도는 정확하게 예측했는지를 측정하는 평가지표이다.",
        "long_answer": {
            "question": "재현율과 정밀도의 공통점과 차이점에 대해 설명하시오.",
            "answer": "재현율과 정밀도는 분류모델에 일반적으로 사용되는 평가지표라는데 있어서 공통점이 있다. 재현율이 올바르게 분류된 양성의 비율이라면 정밀도는 정확하게 예측한 양성의 비율이다. 둘 간에 가장 큰 차이점은 정밀도가 일반적으로 재현율과 반비례 관계라는 점이다.",
            "rubric": [
                "재현율; 분류모델; 분류; 양성; 예측; 반비례"
            ]
        },
        "short_answer": {
            "question": "정밀도는 정확하게 예측한 무엇의 비율을 뜻하는가?",
            "answer": "양성",
            "topic": [
                "정밀도의 개념"
            ]
        },
        "multiple_choice": {
            "question": "아래의 단어 중 재현율을 뜻하는 의미가 아닌 것은?",
            "choices": [
                "a) 정확도",
                "b) 진정한 긍정률",
                "c) 민감도",
                "d) 적중률"
            ],
            "answer": "a",
            "topic": [
                "재현율의 다른 이름"
            ]
        },
        "true_false": {
            "question": "정밀도는 재현율과 항상 비례 관계를 가지며, 두 지표는 동일한 개념이다.",
            "answer": "FALSE",
            "topic": [
                "정밀도와 재현율의 관계"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:152:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.5 Fβ-점수 구분 내 용 개념 Ÿ 정밀도와 재현율의 가중치 조화 평균으로 정밀도 또는 재현율에 가중치를 주어  계산되는 평가지표  세부 내용  Ÿ 데이터 Label이 불균형 구조일 때, 모델의 성능을 정확하게 평가할 수 있으며, 성능을 하나의 숫자로 표현할 수 있음 Ÿ 매개변수인 베타(beta) 점수로 재현율의 가중치를 결정하며, 정밀도에 가중치를 부여하는 경우 beta < 1, 재현율에 가중치를 부여하는 경우 beta > 1을 적용 계산식(방식)  Predicted Condition Positive(PP) Negative (PN)  Actual Condition  Positive (P) True Positive (TP)  False Negative (FN)  Negative (N) False Positive (FP)  True Negative (TN)  ※ TP: 실제 True인 정답을 True라고 예측 ※ FP: 실제 False인 정답을 True라고 예측 ※ FN: 실제 True인 정답을 False라고 예측 ※ TN: 실제 False인 정답을 False라고 예측",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:152:0001",
                    "page": 152
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "Fβ-점수는 정밀도와 재현율의 가중치 조화 평균으로 정밀도 또는 재현율에 가중치를 주어 계산되는 평가지표이다.",
        "long_answer": {
            "question": "Fβ-점수의 정의와 특징에 대해 설명하라.",
            "answer": "Fβ-점수는 정밀도와 재현율의 가중치 조화 평균으로 정밀도 또는 재현율에 가중치를 주어 계산되는 평가지표이다. 이는 데이터 레이블이 불균형 구조일 때 모델의 성능을 정확하게 평가할 수 있으며 성능을 하나의 숫자로 표현할 수 있다.",
            "rubric": [
                "Fβ-점수; 정밀도; 재현율; 가중치; 불균형 구조"
            ]
        },
        "short_answer": {
            "question": "Fβ-점수는 정밀도 또는 재현율에 무엇을 주어 계산되는 평가지표인가?",
            "answer": "가중치",
            "topic": [
                "Fβ-점수의 개념"
            ]
        },
        "multiple_choice": {
            "question": "Fβ-점수 계산 시 필요한 값에 대한 설명이 올바르게 짝지어진 것은?",
            "choices": [
                "a) TP - 실제 True인 오답을 True라고 예측",
                "b) FP - 실제 False인 정답을 FaLse라고 예측",
                "c) FN - 실제 True인 정답을 True라고 예측",
                "d) TN - 실제 False인 정답을 False라고 예측"
            ],
            "answer": "d",
            "topic": [
                "Fβ-점수 계산 시 필요한 값"
            ]
        },
        "true_false": {
            "question": "Fβ-점수로 모델의 성능을 하나의 숫자로 표현할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "Fβ-점수의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:153:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.6 mAP (mean Average Precision) 구분 내 용 개념 Ÿ 각 쿼리에 대한 평균 정밀도 점수의 평균을 의미하는 평가지표로서, 클래스가 여러 개인 경우 각 클래스당 AP를 구한 뒤 그 합을 클래스의 개수로 나누어 계산함  세부 내용  Ÿ 쿼리 집합의 평균 정밀도(mAP, mean Average Precision)는 각 쿼리에 대한 평균 정밀도 점수의 평균으로서, 아래 수식에서 Q는 쿼리의 수를 의미함 Ÿ 수식이 의미하는 바는, 주어진 쿼리 q에 대해 해당 평균 정밀도(AP)를 계산한 다음, 이러한 모든 AP 점수의 평균을 mAP라는 단일 숫자로 제공하여 모델이 얼마나 좋은지를 수치화함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:153:0001",
                    "page": 153
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "mAP는 각 쿼리에 대한 평균 정밀도 점수의 평균을 의미하는 평가지표이다.",
        "long_answer": {
            "question": "mAP의 계산 방법에 대해 설명하시오.",
            "answer": "mAP는 각 쿼리에 대한 평균 정밀도 점수의 평균으로서, 주어진 쿼리 q에 대해 해당 평균 정밀도(AP)를 계산한 다음, 이러한 모든 AP 점수의 평균을 mAP라는 단일 숫자로 제공한다. 이때 클래스가 여러개인 경우 각 클래스당 AP를 구한 뒤 그 합을 클래스의 개수로 나누어 계산한다.",
            "rubric": [
                "mAP; 평균 정밀도 점수; 평균 정밀도; 클래스"
            ]
        },
        "short_answer": {
            "question": "mAP는 각 쿼리에 대한 무엇의 평균을 의미하는 평가지표인가?",
            "answer": "평균 정밀도 점수",
            "topic": [
                "mAP의 개념"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 mAP에서 계산하고자하는 쿼리 집합의 평균 정밀도와 같은 의미를 가지는 것은?",
            "choices": [
                "a) 각 쿼리에 대한 평균 정밀도 점수의 총합",
                "b) 각 쿼리에 대한 평균 정밀도 점수의 평균",
                "c) 각 쿼리에 대한 평균 정밀도 점수의 기대값",
                "d) 각 쿼리에 대한 평균 정밀도 점수의 예측값"
            ],
            "answer": "b",
            "topic": [
                "mAP의 계산 방법"
            ]
        },
        "true_false": {
            "question": "mAP는 클래스가 여러개인 경우 각 클래스당 AP를 구한 뒤 그 합을 클래스의 개수로 나누어 계산한다.",
            "answer": "TRUE",
            "topic": [
                "mAP의 계산 방법"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:153:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.7 AUROC (Area Under Receiver Operating Characteristic) 구분 내 용 개념 Ÿ 이진 분류 문제에 대한 평가지표  세부 내용  Ÿ ROC(Receiver Operator Characteristic) 곡선은 이진 분류 문제에 대한 평가 지표로서, 다양한 임계값에서 FPR에 대한 TPR을 플롯하고 본질적으로 ‘신호’를 ‘잡음’에서 분리하는 확률 곡선을 의미함 Ÿ AUROC는 AUC(Area Under the Curve)와 같으며, 분류기가 클래스를 구별하는 능력의 척도이며 ROC 곡선의 요약으로 사용되는데, AUROC의 값이 최대값인 1에 가까울수록 Positive 클래스와 Negative 클래스를 구별하는 모델의 성능이 향상됨",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:153:0001",
                    "page": 153
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "AUROC은 이진 분류 문제에 대한 평가 지표이다.",
        "long_answer": {
            "question": "AUROC와 ROC 간의 관계에 대해 설명하라.",
            "answer": "ROC 곡선은 다양한 임계값에서 FPR에 대한 TPR을 플롯하고 본질적으로 ‘신호’를 ‘잡음’에서 분리하는 확률 곡선을 의미한다. AUROC는 ROC 곡선의 요약으로 값이 최대값인 1에 가까울수록 Positive 클래스와 Negative 클래스를 구별하는 모델의 성능이 향상되었다는 뜻이다.",
            "rubric": [
                "AUROC; ROC; 확률; 요약; 클래스"
            ]
        },
        "short_answer": {
            "question": "AUROC은 어떤 곡선의 요약으로 볼 수 있는가?",
            "answer": "ROC 곡선",
            "topic": [
                "AUROC의 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음 AUROC에 대한 설명 중 부적합한 것은?",
            "choices": [
                "a) AUROC는 AUC와 같다.",
                "b) AUROC는 분류기가 클래스를 구별하는 능력의 척도이다.",
                "c) AUROC값은 최소값인 0에 가까울수록 좋은 성능이라는 뜻이다.",
                "d) AUROC값은 최대값인 1에 가까울수록 좋은 성능이라는 뜻이다."
            ],
            "answer": "c",
            "topic": [
                "AUROC의 설명"
            ]
        },
        "true_false": {
            "question": "AUROC는 ROC 곡선의 요약으로 사용된다.",
            "answer": "TRUE",
            "topic": [
                "AUROC의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:154:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.8 IDF1 (Identification F1-Score) 구분 내 용 개념 Ÿ 참값 정확도의 평균 개수를 계산하여 식별 정밀도를 표현하는 평가지표 세부 내용  Ÿ ID 정밀도(Identification Precision)와 ID 재현율(Identification Recall)은 trade-off 추적에 초점을 맞춘 평가지표인 반면, IDF1은 ID 정밀도와 ID 재현율 간의 조화 평균(harmonic mean)을 계산함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:154:mh: 00001",
                    "page": 154
                }
            },
            {
                "context_id": "2",
                "text": "5.2.1.11 mIoU (mean Intersection Over Union) 구분 내 용 개념 Ÿ 개체 범주 세분화 방법의 성능을 측정하는 데 사용하는 평가지표로서, IoU 값들에  대한 평균값을 의미함  세부 내용 Ÿ IoU(intersection-over-union)는 Jaccard Index라고도 알려져 있으며, Segmentation과 Object Detection에서 많이 활용되는 품질지표임",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:154:mh: 00001",
                    "page": 156
                }
            }
        ],
        "summarization": "IDF1은 참값 정확도의 평균 개수를 계산하여 식별 정밀도를 표현하는 평가지표이다. mIoU는 개체 범주 세분화 방법의 성능을 측정하는 데 사용하는 평가지표로서, IoU 값들에 대한 평균값을 의미한다.",
        "long_answer": {
            "question": "ID 정밀도 및 ID 재현율과 IDF1을 비교하여 서술하라.",
            "answer": "ID 정밀도와 ID 재현율은 trade-off 추적에 초점을 맞춘 평가지표이다. 반면 IDF1은 ID 정밀도와 ID 재현율 간의 조화 평균을 계산한 것으로 참값 정확도의 평균 개수를 계산하여 식별 정밀도를 표현하는 평가지표라 할 수 있다.",
            "rubric": [
                "ID 정밀도; ID 재현율; 조화 평균; 참값 정확도; 평균 개수; 식별 정밀도"
            ]
        },
        "short_answer": {
            "question": "IDF1은 무엇과 무엇 간의 조화 평균을 계산하는가?",
            "answer": "ID 정밀도, ID 재현율",
            "topic": [
                "IDF1의 개념"
            ]
        },
        "multiple_choice": {
            "question": "IDF1과 mIoU에 대한 설명으로 적합하지 않은 것은?",
            "choices": [
                "a) IDF1은 참값 정확도의 평균 개수를 계산하여 식별 정밀도를 표현하는 평가지표이다.",
                "b) IDF1은 ID 정밀도와 ID 재현율간의 조화 평균을 계산한다.",
                "c) mIoU은 개체 범주 세분화 방법의 성능을 측정하는데 사용하는 평가지표이다.",
                "d) mIoU은 IoU값들의 총합을 의미한다."
            ],
            "answer": "d",
            "topic": [
                "IDF1과 mIoU에 대한 설명"
            ]
        },
        "true_false": {
            "question": "IDF1은 trade-off 추적에 초점을 맞춘 평가지표이다.",
            "answer": "FALSE",
            "topic": [
                "IDF1의 개념"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:155:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.10 DICE-Coefficient 구분 내 용 개념 Ÿ 두 개의 데이터셋 간의 유사성을 측정하는 평가지표  세부 내용  Ÿ DICE-Coefficient는 두 데이터셋 간의 유사성을 측정하는 통계 도구이며, 2개의 중첩 영역을 두 이미지의 총 픽셀(pixcel) 수로 나누어 계산함 Ÿ 인공지능으로 생성된 이미지 분할 알고리즘 검증에 특화되어있으며, 이미지 분할에서 가장 일반적으로 사용되는 품질지표임 Ÿ 참고로 DICE-coefficient는 F1-score의 값과 같음 따라서 F1-score를 이미지에 적용한 개념이라고 볼 수 있음",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:155:0001",
                    "page": 155
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "DICE-Coefficient은 두 개의 데이터셋 간의 유사성을 측정하는 평가지표이다.",
        "long_answer": {
            "question": "DICE-Coefficient의 특징에 대해 서술하시오.",
            "answer": "DICE-Coefficient는 2개의 중첩 영역을 두 이미지의 총 픽셀 수로 나누어 계산한다. 이는 인공지능으로 생성된 이미지 분할 알고리즘 검증에 특화되어있으며, 이미지 분할에서 가장 일반적으로 사용되는 품질 지표이다. DICE-Coefficient은 F1-score를 이미지에 적용한 개념이라고 볼 수 있다.",
            "rubric": [
                "DICE-Coefficient; 이미지 분할; 중첩; 총 픽셀 수; 이미지"
            ]
        },
        "short_answer": {
            "question": "DICE-Coefficient는 2개의 중첩 영역을 두 이미지의 무엇으로 나누어 계산하는가?",
            "answer": "총 픽셀 수",
            "topic": [
                "DICE-Coefficient의 계산 방법"
            ]
        },
        "multiple_choice": {
            "question": "DICE-Coefficient에 대한 설명으로 다음 중 옳은 것은?",
            "choices": [
                "a) 두 이미지의 중첩 영역을 전체 픽셀 수로 나누어 계산한다.",
                "b) 인공지능으로 생성된 텍스트 요약 모델의 정확도를 평가하는 데 사용된다.",
                "c) 두 데이터셋 간의 차이를 측정하는 지표로, F1-score와는 관련이 없다.",
                "d) 비디오나 음성 인식 알고리즘에 특화된 지표이다."
            ],
            "answer": "a",
            "topic": [
                "DICE-Coefficient의 특징"
            ]
        },
        "true_false": {
            "question": "DICE-Coefficient를 측정하기 위해서는 두 데이터셋이 필요하다.",
            "answer": "TRUE",
            "topic": [
                "DICE-Coefficient의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:156:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.12 Overall Pixel 정확도 구분 내 용 개념 Ÿ 올바르게 어노테이션이 수행되었는지 지정된 픽셀의 비율을 측정하는 평가지표  세부 내용  Ÿ 전체 픽셀 정확도(Overall Pixel Accuracy)는 올바르게 레이블이 지정된 픽셀의 비율을 측정하여, 검출에 대한 정확도를 판단함 Ÿ 다만, 불균형한 가공 산출물로 인한 결과의 편중(bias)이 발생할 수 있음",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:156:mh: 00001",
                    "page": 156
                }
            },
            {
                "context_id": "2",
                "text": "5.2.1.13 MOTA (Multiple Object Tracking Accuracy) 구분 내 용 개념 Ÿ 다수 객체를 추적하는 데 있어 정확도를 직관적으로 측정하는 평가지표 세부 내용  Ÿ MOTA(Multiple Object Tracking Accuracy)는 다양한 목적 함수 평가 범위에서 각각 여러 성능 측정에 따라 확률 최적화 알고리즘을 조정하는 데 특화되어 있음",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:156:mh: 00001",
                    "page": 157
                }
            }
        ],
        "summarization": "Overall Pixel 정확도는 올바르게 어노테이션이 수행되었는지 지정된 픽셀의 비율을 측정하는 평가지표이다. MOTA는 다수 객체를 추적하는 데 있어 정확도를 직관적으로 측정하는 평가지표이다.",
        "long_answer": {
            "question": "Overall Pixel 정확도의 개념과 사용 시 주의사항에 대해 설명하라.",
            "answer": "Overall Pixel 정확도는 올바르게 어노테이션이 수행되었는지 지정된 픽셀의 비율을 측정하는 평가지표로 올바르게 레이블이 지정된 픽셀의 비율을 측정하여 검출에 대한 정확도를 판단한다. 이 지표를 사용할 때는 불균형한 가공 산출물로 인한 결과의 편중에 주의해야 한다.",
            "rubric": [
                "Overall Pixel 정확도; 어노테이션; 픽셀; 검출; 편중"
            ]
        },
        "short_answer": {
            "question": "Overall Pixel 정확도는 올바르게 레이블이 지정된 무엇의 비율을 측정하여 검출에 대한 정확도를 판단하는가?",
            "answer": "픽셀",
            "topic": [
                "Overall Pixel 정확도의 개념"
            ]
        },
        "multiple_choice": {
            "question": "Overall Pixel 정확도와 MOTA에 대한 설명으로 적합한 것은?",
            "choices": [
                "a) Overall Pixel 정확도는 올바르게 어노테이션이 수행되었는지 지정된 픽셀의 비율을 측정한다.",
                "b) Overall Pixel 정확도는 결과 편중 없는 평가지표로 매우 유용하다.",
                "c) MOTA는 확률 최적화 알고리즘 조정에는 부적합하다.",
                "d) MOTA는 이미지 분할 알고리즘 검증에 특화되어있다."
            ],
            "answer": "a",
            "topic": [
                "Overall Pixel 정확도와 MOTA에 대한 설명"
            ]
        },
        "true_false": {
            "question": "MOTA는 특정 객체를 추적하는데 있어 정밀도를 직관적으로 측정하는 평가지표이다.",
            "answer": "FALSE",
            "topic": [
                "MOTA의 개념"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:157:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.14 OKS (Object Keypoint Similarity) 구분 내 용 개념 Ÿ 관절의 추정 좌표와 참값 좌표의 유사성을 나타내는 평가지표  세부 내용  Ÿ OKS (Object Keypoint Similarity)는 관절의 추정 좌표와 참값 좌표의 유사성의 평균을 나타내는 평가지표이며, 인물의 추정 자세와 정답 자세가 완전히 일치하면 1이 됨 Ÿ Object Detection의 IoU(Intersection over Union)와 유사하며 Keypoint Detection에서 유사성 측정 방법으로 사용됨",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:157:mh: 00001",
                    "page": 157
                }
            },
            {
                "context_id": "2",
                "text": "5.2.1.15 PCK (Percentage of Correct Keypoints) 구분 내 용 개념 Ÿ 키포인트의 추정 좌표와 참값 좌표의 거리가 임계값 기준을 만족하는지 측정하는  평가지표  세부 내용  Ÿ PCK(Percentage of Correct Keypoints)는 키포인트 관절점의 추정 좌표와 참값 좌표의 거리가 임계값 기준을 만족하는지 측정하며, 임계값은 바운딩 박스의 사이즈를 통해 결정됨",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:157:mh: 00001",
                    "page": 158
                }
            }
        ],
        "summarization": "OKS는 관절의 추정 좌표와 참값 좌표의 유사성을 나타내는 평가지표이다. PCK는 키포인트의 추정 좌표와 참값 좌표의 거리가 임계값 기준을 만족하는지 측정하는 평가지표이다.",
        "long_answer": {
            "question": "데이터 품질 평가지표로써의 OKS에 대해 설명하라.",
            "answer": "OKS는 관절의 추정 좌표와 참값 좌표의 유사성의 평균을 나타내는 평가지표이다. 인물의 추정 자세와 정답 자세를 비교했을 때, 완전히 일치하면 1이 된다. OKS는 Keypoint Detection에서 유사성 측정 방법으로 사용되기도 한다.",
            "rubric": [
                "OKS; 추정 좌표; 참값 좌표; 유사성; 평균"
            ]
        },
        "short_answer": {
            "question": "PCK는 키포인트의 추정 좌표와 참값 좌표의 거리가 무엇을 만족하는지를 측정하는 평가지표인가?",
            "answer": "임계값 기준",
            "topic": [
                "PCK의 정의"
            ]
        },
        "multiple_choice": {
            "question": "OKS에 관한 아래의 설명 중 알맞지 않은 것은?",
            "choices": [
                "a) OKS는 관절의 추정 좌표와 참값 좌표의 유사성을 나타내는 평가지표이다.",
                "b) OKS는 인물의 추정 자세와 정답 자세가 완전히 일치하면 0이 된다.",
                "c) OKS는 Object Detection의 IoU와 유사하다.",
                "d) OKS는 Keypoint Detection에서 유사성 측정 방법으로 사용된다."
            ],
            "answer": "b",
            "topic": [
                "OKS에 대한 설명"
            ]
        },
        "true_false": {
            "question": "PCK 측정에서 임계값은 바운딩 박스의 사이즈를 통해 결정된다.",
            "answer": "TRUE",
            "topic": [
                "PCK의 계산 방법"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:159:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.16 MPJPE (Mean Per Joint Position Error) 구분 내 용 개념 Ÿ 관절의 추정 좌표와 참값 좌표의 거리의 평균값을 측정하는 평가지표  세부 내용  Ÿ MPJPE (Mean Per Joint Position Error)는 모든 관절의 추정 좌표와 참값 좌표의 거리(단위: mm)를 평균하여 측정하는 평가지표이며, 값이 작을수록 정확도 우수로 판단 Ÿ Estimated and Ground-truth 3D Pose의 root 관절을 정렬한 후 계산함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:159:mh: 00001",
                    "page": 159
                }
            },
            {
                "context_id": "2",
                "text": "5.2.1.18 NME (Normalized Mean Errors) 구분 내 용 개념 Ÿ 작업자에 따라서 라벨링 결과가 일정하지 않아, 해당 데이터의 불확실성 특성을  판단하기 위한 평가지표  세부 내용  Ÿ NME(Normalized Mean Errors), 즉 정규화 오차는 Facial Landmark Detection 분야에서 많이 사용됨 Ÿ NME를 사용하는 이유는 Facial Landmark의 특성상 데이터 구축 과정에서 작업자에 따라 라벨링 결과의 위치가 일정하지 않으므로, 해당 데이터의 특성을 반영하기 위해서 사용함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:159:mh: 00001",
                    "page": 160
                }
            }
        ],
        "summarization": "MPJPE는 관절의 추정 좌표와 참값 좌표의 거리의 평균값을 측정하는 평가지표이다. NME는 작업자에 따라서 라벨링 결과가 일정하지 않아, 해당 데이터의 불확실성 특성을 판단하기 위한 평가지표이다.",
        "long_answer": {
            "question": "Facial Landmark Detection 분야에서 NME를 사용하는 이유는 무엇인지 서술하시오.",
            "answer": "NME는 Facial Landmark Detection 분야에서 많이 사용된다. NME를 사용하는 이유는 Facial Landmark의 특성상 데이터 구축 과정에서 작업자에 따라 라벨링 결과의 위치가 일정하지 않으므로 해당 데이터의 특성을 반영하기 위함이다.",
            "rubric": [
                "NME; Facial Landmark Detection; 라벨링; 작업자"
            ]
        },
        "short_answer": {
            "question": "NME는 무엇에 따라 라벨링 결과가 일정하지 않았을 때 불확실성 특성을 판단하기 위한 평가지표인가?",
            "answer": "작업자",
            "topic": [
                "NME의 개념"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 MPJPE가 평균하여 측정하고자 하는 평가지표로 적합한 것은?",
            "choices": [
                "a) 관절의 연결 벡터와 참값 벡터의 각도",
                "b) 관절의 검출 확률과 임계값 확률의 차이",
                "c) 관절의 추정 좌표와 참값 좌표의 거리",
                "d) 관절의 예측 깊이와 실제 깊이의 편차"
            ],
            "answer": "c",
            "topic": [
                "MPJPE의 개념"
            ]
        },
        "true_false": {
            "question": "MPJPE 값은 클수록 정확도 우수로 판단한다.",
            "answer": "FALSE",
            "topic": [
                "MPJPE의 개념"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:161:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.19 RMSE (Root Mean Squared Error) 구분 내 용 개념 Ÿ 예측 품질을 평가하기 위해, 실제 값에서 예측이 얼마나 떨어져 있는지 측정하는  평가지표  세부 내용  Ÿ 제곱 평균 제곱근 오차 또는 제곱 평균 제곱근 편차는 예측 품질을 평가하는 데 가장 일반적으로 사용되는 측정 방법 중 하나로서, 유클리드 거리를 사용하여 측정된 실제 값에서 예측이 얼마나 떨어져 있는지 측정함 Ÿ RMSE를 계산하려면 각 데이터 포인트에 대한 잔차(예측과 진실의 차이)를 계산하고, 각 데이터 포인트에 대한 잔차의 노름(norm)을 계산한 뒤, 잔차의 평균을 계산하고 그 평균의 제곱근을 취함 Ÿ RMSE는 각 예측 데이터 포인트에서 실제 측정값을 사용하고 필요로 하기 때문에 지도 학습 애플리케이션에서 일반적으로 사용될 수 있음",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:161:0001",
                    "page": 161
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "RMSE는 예측 품질을 평가하기 위해, 실제 값에서 예측이 얼마나 떨어져 있는지 측정하는 평가지표이다.",
        "long_answer": {
            "question": "RMSE의 개념과 계산 방법을 구체적으로 설명하시오.",
            "answer": "RMSE는 예측값이 실제값에서 얼마나 떨어져 있는지를 측정하는 평가지표이다. 각 데이터 포인트의 잔차(예측과 실제의 차이)를 구한 후, 각 데이터 포인트에 대한 잔차의 노름(norm)을 계산한 뒤, 잔차의 평균을 계산하고 그 평균의 제곱근을 취하여 계산한다.",
            "rubric": [
                "RMSE; 예측값; 실제값; 잔차; 제곱근"
            ]
        },
        "short_answer": {
            "question": "RMSE는 무엇을 측정하기 위한 평가지표인가?",
            "answer": "예측 품질",
            "topic": [
                "RMSE의 개념"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 RMSE에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) RMSE는 실제 값과 예측이 얼마나 떨어져 있는지 측정하는 평가지표이다.",
                "b) RMSE는 유클리드 거리를 사용하여 측정된 실제 값과 예측을 비교하여 측정한다.",
                "c) RMSE의 계산에는 각 데이터 포인트에 대한 잔차를 알아야 한다.",
                "d) RMSE는 각 데이터 포인트에 대한 잔차의 평균을 계산한 값을 취한다."
            ],
            "answer": "d",
            "topic": [
                "RMSE의 개념"
            ]
        },
        "true_false": {
            "question": "RMSE는 각 예측 데이터 포인트에서 실제 측정값을 사용한다.",
            "answer": "TRUE",
            "topic": [
                "RMSE의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:161:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "구분 내 용 개념 Ÿ 주어진 문장에 대해 공백을 포함한 총 문자 수(n)를 필요한 문자의 최소 삽입(i), 대체(s) 및 삭제(d) 수와 비교하여 글자 오류율을 측정하는 평가지표 세부 내용 Ÿ CER(Character Error Rate)는 글자 오류율을 측정하는 지표로 주로 한글과 같이  조사를 사용하는 언어에 사용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:161:mh: 00001",
                    "page": 161
                }
            },
            {
                "context_id": "2",
                "text": "구분 내 용 개념 Ÿ 주어진 문장에 대해 공백을 포함한 총 단어 수(n)를 필요한 단어의 최소 삽입(i), 대체(s) 및 삭제(d) 수와 비교하여 단어 오류율을 측정하는 평가지표 세부 내용 Ÿ WER(Word Error Rate)는 단어 오류율을 측정하는 지표로 영어에 많이 사용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:161:mh: 00001",
                    "page": 162
                }
            }
        ],
        "summarization": "CER은 주어진 문장의 글자 오류율을, WER은 주어진 문장의 단어 오류율을 측정하는 평가지표이다.",
        "long_answer": {
            "question": "CER와 WER을 측정하는 방법에 대하여 설명하시오.",
            "answer": "CER은 공백을 포함한 총 문자 수를 필요한 문자의 최소 삽입, 대체 및 삭제 수와 비교하여 측정한다. WER은 공백을 포함한 총 단어 수를 필요한 단어의 최소 삽입, 대체 및 삭제 수와 비교하여 측정한다.",
            "rubric": [
                "CER; WER; 문자 수; 단어 수"
            ]
        },
        "short_answer": {
            "question": "글자의 오류율을 측정하는 평가지표는 무엇인가?",
            "answer": "CER",
            "topic": [
                "CER의 개념"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 CER과 WER에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) CER은 주로 영어에서 사용한다.",
                "b) WER은 주로 한국어처럼 조사를 사용하는 언어에 사용한다.",
                "c) CER은 글자의 오류율을 측정하는 평가지표이다.",
                "d) WER을 측정할 때는 문장의 공백은 포함하지 않는다."
            ],
            "answer": "c",
            "topic": [
                "CER과 WER의 설명"
            ]
        },
        "true_false": {
            "question": "WER은 주로 영어에서 많이 사용한다.",
            "answer": "TRUE",
            "topic": [
                "WER의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:162:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "구분 내 용  개념 Ÿ 자연어를 기계 번역하여 다른 종류의 자연어로 생성된 문장을 평가하기 위한    평가지표    세부 내용    Ÿ BLEU는 생성된 문장을 참조 문장으로 평가하기 위한 평가지표로서, 완벽한  일치는 1.0의 점수가 나오는 반면 완벽한 불일치는 0.0의 점수가 나옴  Ÿ 측정 기준은 n-gram(n개의 연속적인 단어 나열)에 기반하며, n은 1~4 사이의  범위를 가짐. 여기서 n-gram precision(정밀도)란, n-gram 중 일치하는 개수를  전체 n-gram의 수로 나눈 값을 의미함",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:162:0001",
                    "page": 162
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "BLEU는 자연어를 기계 번역하여 다른 종류의 자연어로 생성된 문장을 평가하기 위한 평가지표이다.",
        "long_answer": {
            "question": "BLEU 평가지표의 개념과 작동 방식을 구체적으로 설명하시오.",
            "answer": "BLEU는 자연어를 기계 번역하여 다른 종류의 자연어로 생성된 문장을 평가하기 위한 평가지표이다. 측정 기준은 n-gram(n개의 연속적인 단어 나열)에 기반하며, n은 1~4 사이의 범위를 가진다. 완벽하게 일치하는 경우 점수는 1.0이 되며, 완전히 불일치할 경우 0.0으로 평가된다.",
            "rubric": [
                "BLEU; n-gram; 자연어; 기계 번역"
            ]
        },
        "short_answer": {
            "question": "기계 번역한 자연어의 문장을 BLEU로 평가할 때 완벽한 일치에서는 몇 점이 나오는가?",
            "answer": "1.0점",
            "topic": [
                "BLEU의 점수"
            ]
        },
        "multiple_choice": {
            "question": "BLEU에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) BLEU는 번역된 자연어 문장을 평가하기 위한 평가지표다.",
                "b) BLEU는 완벽한 일치에서 0.0의 점수가 나온다.",
                "c) BLEU는 완벽한 불일치에서 0.0의 점수가 나온다.",
                "d) BLEU를 측정할 때 연속적으로 나열되는 단어의 수는 1~4개이다."
            ],
            "answer": "b",
            "topic": [
                "BLEU의 특징"
            ]
        },
        "true_false": {
            "question": "BLEU의 측정 기준은 1~4개의 연속적인 단어 나열에 기반한다.",
            "answer": "TRUE",
            "topic": [
                "BLEU의 측정 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:165:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "구분 내 용  개념 Ÿ 챗봇이 사람과 같은 대화를 추구한다고 할 때(human-like), 이를 평가할 수 있는    척도    세부 내용    Ÿ 자연어 처리 분야에서 사용되는 평가 메트릭으로 답변이 합리성(sensible),  구체성(specific)을 사람이 측정한 점수를 계산  Ÿ 챗봇의 대화를 보고 sensiblness값과 specificity값을 평가하여 낸 평균  Ÿ Sensibleness는 common sense, logical coherence, consistency와 같은  요소들을 평가  Ÿ specificity는 response가 sensible한 경우에 specific한지 판단하여 평가함  Ÿ SSA와 PPL(Perplexity)*은 강한 상관관계를 가짐",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:165:0001",
                    "page": 165
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "SSA는 챗봇이 사람과 같은 대화를 추구한다고 할 때 이를 평가할 수 있는 척도이다.",
        "long_answer": {
            "question": "SSA를 측정하는 방식에 대하여 서술하시오.",
            "answer": "SSA는 common sense와 logical coherence, consistency 등을 평가하는 sensibleness, response가 specific한지를 평가하는 specificity의 값을 평가하여 낸 평균으로 사람이 합리성과 구체성을 측정하여 챗봇이 얼마나 사람처럼 대화하는지를 평가한다.",
            "rubric": [
                "SSA; sensibleness; specificity; 사람; 챗봇"
            ]
        },
        "short_answer": {
            "question": "SSA에서 사람은 챗봇의 대화를 보고 무엇과 무엇의 값을 평가하는가?",
            "answer": "sensiblness값, specificity값",
            "topic": [
                "SSA의 측정 방법"
            ]
        },
        "multiple_choice": {
            "question": "아래 요소 중 SSA의 sensibleness값 평가 요소에 해당하지 않는 것은?",
            "choices": [
                "a) common sense",
                "b) Sentiment",
                "c) logical coherence",
                "d) consistency"
            ],
            "answer": "b",
            "topic": [
                "SSA의 sensibleness값 평가 요소"
            ]
        },
        "true_false": {
            "question": "SSA와 PPL 간에는 상관관계가 없다.",
            "answer": "FALSE",
            "topic": [
                "SSA와 PPL의 상관관계"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:163:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.23 ROUGE-L (Recall-Oriented Understudy for Gisting Evaluation-Longest Common Subsequence) 구분 내 용 개념 Ÿ 가장 긴 일치하는 단어 시퀀스를 측정하는 평가지표  세부 내용  Ÿ ROUGE-L (Recall-Oriented Understudy for Gisting Evaluation-LCS)를 사용하여 가장 긴 일치하는 단어 시퀀스를 측정함 Ÿ LCS 개념을 적용한 평가지표 사용 시, 단어의 연속적 일치가 필요 없고 문장 수준의 어순을 반영한 순차적 일치를 측정하므로 유연하다는 장점이 있음",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:163:mh: 00001",
                    "page": 163
                }
            },
            {
                "context_id": "2",
                "text": "5.2.1.24 TQA (Translation Quality Assessment) 구분 내 용 개념 Ÿ 원문의 의미를 포착하고, 적절한 단어가 있으며 오류가 없고 일관성 있게 번역되어  있는지 측정하는 평가지표  세부 내용  Ÿ TQA(Translation Quality Assessment)는 4가지 파라미터로 정의되며, 각각 Meaning(의미), Wording/Expression(단어 및 표현), Errors(오류), Consistency(일관성)임",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:163:mh: 00001",
                    "page": 164
                }
            }
        ],
        "summarization": "ROUGE-L은 가장 긴 일치하는 단어 시퀀스를 측정하는 평가지표이다. TQA는 원문의 의미를 포착하고, 적절한 단어가 있으며 오류가 없고 일관성 있게 번역되어 있는지 측정하는 평가지표이다.",
        "long_answer": {
            "question": "TQA의 개념과 파라미터에 대해 설명하시오.",
            "answer": "TQA는 원문의 의미를 포착하고, 적절한 단어가 있으며 오류가 없고 일관성 있게 번역되어 있는지 측정하는 평가지표이다. 의미, 단어 및 표현, 오류, 일관성이 TQA를 정의하는 네가지 파라미터이다.",
            "rubric": [
                "TQA; 의미; 단어 및 표현; 오류; 일관성"
            ]
        },
        "short_answer": {
            "question": "ROUGE-L은 가장 긴 일치하는 무엇을 측정하는 평가지표인가?",
            "answer": "단어 시퀀스",
            "topic": [
                "ROUGE-L의 개념"
            ]
        },
        "multiple_choice": {
            "question": "TQA의 파라미터로 적합한 것은?",
            "choices": [
                "a) 단어 및 표현",
                "b) 유창성",
                "c) 문법 정확도",
                "d) 완전성"
            ],
            "answer": "a",
            "topic": [
                "TQA의 파라미터"
            ]
        },
        "true_false": {
            "question": "ROUGE-L은 가장 긴 일치하는 단어 시퀀스를 측정하는 평가지표이다.",
            "answer": "TRUE",
            "topic": [
                "ROUGE-L의 개념"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:164:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.25 Perplexity (복잡도) 구분 내 용 개념 Ÿ 확률 분포 또는 확률 모형이 표본을 얼마나 잘 예측하는지 나타내는 평가지표로서, Perplexity(복잡도)가 낮으면 확률 분포가 표본을 잘 예측한다는 것을 나타냄  세부 내용  Ÿ 기본적으로 외부 데이터를 이용하지 않고 언어모델 자체의 성능을 평가하겠다는 아이디어이기 때문에, 언어모델을 기반으로 한 다양한 Task의 간접적인 성능 지표로 사용할 수는 있지만 특정 Task가 정해진 경우에는 그 Task에 보다 적합한 품질지표를 사용하는 것이 일반적인 추세임 Ÿ 즉, 전통적인 n-gram 언어모델에서부터 사용하던 metric이지만 최근에는 그다지 많이 사용되지 않음",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:164:0001",
                    "page": 164
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "복잡도는 확률 분포 또는 확률 모형이 표본을 얼마나 잘 예측하는지 나타내는 평가지표이다.",
        "long_answer": {
            "question": "복잡도의 품질지표로써의 추세에 대해 설명하라.",
            "answer": "복잡도는 외부 데이터를 이용하지 않고 언어모델 자체의 성능을 평가하겠다는 것으로 언어모델을 기반으로 한 다양한 Task의 간접적인 성능 지표로 사용할 수는 있지만 특정 Task가 정해진 경우에는 그 Task에 보다 적합한 품질지표를 사용하는 것이 일반적인 추세이다. 따라서 최근에는 그다지 많이 사용되지 않는다.",
            "rubric": [
                "복잡도; 외부 데이터; 언어모델"
            ]
        },
        "short_answer": {
            "question": "복잡도는 무엇이 표본을 얼마나 잘 예측하는지 나타내는 평가지표인가?",
            "answer": "확률 분포, 확률 모형",
            "topic": [
                "복잡도의 개념"
            ]
        },
        "multiple_choice": {
            "question": "복잡도에 대한 다음의 설명 중 옳은 것을 고르시오.",
            "choices": [
                "a) 복잡도가 낮으면 확률 분포가 표본을 잘 예측한다는 것을 의미한다.",
                "b) 복잡도는 외부 데이터를 이용해 언어모델 자체의 성능을 평가하고자 한다.",
                "c) 복잡도는 최근들어 많이 사용되고있는 평가지표이다.",
                "d) 최근의 언어모델들은 복잡도를 중요한 기본 품질지표로 삼고있다."
            ],
            "answer": "a",
            "topic": [
                "복잡도의 특징"
            ]
        },
        "true_false": {
            "question": "복잡도는 최근에도 많이 사용되고있는 평가지표이다.",
            "answer": "FALSE",
            "topic": [
                "복잡도의 현황"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:165:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.26 EM (Exact Matching) 구분 내 용 개념 Ÿ 실제 참값과 정확하게 일치하는 비율을 측정하는 평가지표 세부 내용 Ÿ 음성인식 분야 중, 특히 Machine Translation에서 정답과 예측값의 정확도를  측정하기 위한 지표 5.2.1.27 MOS (Mean Opinion Score) 구분 내용 개념 Ÿ 음성 통화 성능평가에 주로 사용되는 통계에 의한 주관적 평가 지표  세부 내용  Ÿ MOS(Mean Opinion Score)는 지난 수십 년 동안 전반적인 음성 통화 품질을 측정하기 위해 가장 일반적으로 사용되었음 Ÿ 해당 품질지표는 ITU-T(International Telecommunications Union)에서 표준화되어 공개된 지표임",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:165:0001",
                    "page": 165
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "EM은 실제 참값과 정확하게 일치하는 비율을 측정하는 평가지표이다. MOS는 음성 통화 성능평가에 주로 사용되는 통계에 의한 주관적 평가 지표이다.",
        "long_answer": {
            "question": "EM과 MOS의 개념과 각각이 사용되는 목적을 설명하시오.",
            "answer": "EM은 실제 참값과 정확히 일치하는 비율을 측정하는 평가지표로, 주로 음성인식 및 기계번역 분야에서 모델의 정확도를 평가하는 데 사용된다. MOS는 음성 통화 성능평가에 주로 사용되는 통계에 의한 주관적 평가 지표로, MOS는 ITU-T에서 표준화되어 오랫동안 음성 품질 평가의 대표적인 기준으로 사용되고 있다.",
            "rubric": [
                "EM; 실제 참값; 예측값; 일치; 음성인식; 음성 통화; MOS"
            ]
        },
        "short_answer": {
            "question": "MOS를 표준화 한 곳은 어디인가?",
            "answer": "ITU-T(International Telecommunications Union)",
            "topic": [
                "MOS의 특징"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 EM과 MOS에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) EM은 음성 통화 품질을 평가하기 위한 주관적 지표이다.",
                "b) MOS는 기계번역의 정확도를 수치로 측정하는 지표이다.",
                "c) EM은 정답과 예측값의 일치 정도를 측정하는 평가지표이다.",
                "d) MOS는 ITU-T와는 무관한 비공식 평가 기준이다."
            ],
            "answer": "c",
            "topic": [
                "EM과 MOS의 특징"
            ]
        },
        "true_false": {
            "question": "MOS는 전반적인 음성 통화 품질을 측정하기 위해 그간 일반적으로 사용되었다.",
            "answer": "TRUE",
            "topic": [
                "MOS의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:166:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.29 FID (Fréchet Inception Distance) 구분 내 용 개념 Ÿ FID(Fréchet Inception Distance)는 생성된 이미지의 품질을 평가하는데  사용하는 평가지표  세부 내용  Ÿ 생성된 이미지의 분포를 실제 이미지 집합의 분포와 비교 Ÿ 이미지를 픽셀 단위로 직접 비교하는 대신 Inception-v3에서 가장 깊은 레이어의 평균과 표준 편차를 비교  5.2.1.30 PSNR (Peak Signal-to-noise ratio) 구분 내 용 개념 Ÿ 영상 화질 손실량을 평가하는 지표  세부 내용  Ÿ 이미지 저장, 전송, 압축, 영상 처리 등에서 영상 화질이 바뀌었을 때 사용 Ÿ 손실이 적을수록 (화질이 좋을수록) 높은 값, 무손실 영상의 경우, MSE가 0이 되기 때문에 PSNR을 정의할 수 없음 Ÿ MSE(Mean Square Error)는 원본 이미지와 비교 이미지 간의 각 Pixel 오차를 표시",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:166:0001",
                    "page": 166
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "FID는 생성된 이미지의 품질을 평가하는데 사용하는 평가지표이다. PSNR은 영상 화질 손실량을 평가하는 지표이다.",
        "long_answer": {
            "question": "PSNR의 특징에 대해 서술하라.",
            "answer": "PSNR은 영상 화질 손실량을 평가하는 지표로 이미지 저장, 전송, 압축, 영상 처리 등에서 영상 화질이 바뀌었을 때 사용한다. 손실이 적을수록 높은 값을 나타내고 무손실 영상의 경우 MSE가 0이 되므로 PSNR을 정의할 수 없다.",
            "rubric": [
                "PSNR; 영상 화질; 손실; MSE"
            ]
        },
        "short_answer": {
            "question": "원본 이미지와 비교 이미지 간의 각 픽셀 오차를 표시하는 것을 무엇이라 하는가?",
            "answer": "MSE",
            "topic": [
                "MSE의 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 FID에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 원본 이미지와 생성 이미지의 픽셀 값을 직접 비교한다.",
                "b) Inception-v3에서 가장 깊은 레이어의 평균과 표준 편차를 비교한다.",
                "c) 영상 전송 시 발생하는 손실량을 계산하는 데 사용된다.",
                "d) 무손실 영상에서는 정의할 수 없다."
            ],
            "answer": "b",
            "topic": [
                "FID의 특징"
            ]
        },
        "true_false": {
            "question": "PSNR은 텍스트가 아닌 영상 화질에 대한 지표이다.",
            "answer": "TRUE",
            "topic": [
                "PSNR의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:167:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "5.2.1.31 SSIM (Structural Similarity Index Measure) 구분 내 용 개념 Ÿ SSIM (Structural Similarity Index Measure) 영상 화질 손실량을 평가하는  지표  세부 내용  Ÿ 이미지 저장, 전송, 압축, 영상 처리 등에서 영상 화질이 바뀌었을 때 사용 Ÿ 두 이미지(x, y) 간의 상관계수를 Luminance(휘도), Contrast(대비), Structure(구조) 총 3가지 측면에서 평가합니다. (α=β=γ=1) Ÿ 휘도는 빛의 밝기, 대비는 밝기 차이, 구조는 상관관계를 표시",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:167:0001",
                    "page": 167
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "SSIM은 영상 화질 손실량을 평가하는 지표이다.",
        "long_answer": {
            "question": "SSIM은 영상 화질 손실량을 어떻게 평가하며, 그 구성요소는 무엇인가?",
            "answer": "SSIM은 영상의 화질 손실량을 평가하기 위한 지표로 두 이지미 간의 상관계수를 Luminance(휘도), Contrast(대비), Structure(구조)의 세 가지 측면에서 평가한다. 이때 휘도는 빛의 밝기를, 대비는 밝기 차이를, 구조는 상관관계를 나타낸다.",
            "rubric": [
                "SSIM; 화질 손실량; 휘도; 대비; 구조; 상관계수"
            ]
        },
        "short_answer": {
            "question": "SSIM은 무엇이 바뀌었을 때 사용하는 품질지표인가?",
            "answer": "영상 화질",
            "topic": [
                "SSIM의 정의"
            ]
        },
        "multiple_choice": {
            "question": "SSIM에서 두 이미지 간의 상관계수를 평가하는 측면으로 적합하지 않은 것은?",
            "choices": [
                "a) Similarity",
                "b) Luminance",
                "c) Contrast",
                "d) Structure"
            ],
            "answer": "a",
            "topic": [
                "SSIM의 평가 측면"
            ]
        },
        "true_false": {
            "question": "SSIM은 영상의 색상 변화만을 이용하여 화질을 측정한다.",
            "answer": "FALSE",
            "topic": [
                "SSIM의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:184:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.1 가공 방식 l 데이터 가공은 구축사업 목적 및 특성에 따라 다양한 가공 방식을 사용할 수 있으며, 대표적인 가공 방식은 다음과 같음 가공 유형 설명 세그멘테이션 (Segmentation) Ÿ 이미지, 영상 데이터의 모든 객체를 구분하고 클래스 부여 바운딩 박스 (Bounding Box) Ÿ 객체를 직사각형 박스안에 포함되도록 작업하여 클래스 부여 폴리라인 (Polyline) Ÿ 여러 개의 점을 가진 선을 활용하여 인도, 차선, 경로 등 선형 객체를 구분하고  인식하기 위한 작업  폴리곤 (Polygon) Ÿ 다각형 모양으로 객체의 테두리를 따라 점을 찍어 여백 없이 정확히 객체만을  구분하여 클래스 부여  키포인트 (Keypoint) Ÿ 이미지나 비디오에서 안면, 신체 등 특정 물체의 키포인트(landmark)를  식별하는 작업  큐보이드 (Cuboid) Ÿ 2D로 작업할 수 없는 3D 객체들을 정육면체로 생성 전사 (Transcription) Ÿ 음성을 텍스트로 변환하는 작업 태깅 (Tagging) Ÿ 원본 지문(텍스트)에서 질문에 대한 답 생성 Ÿ 데이터(객체)의 주제나 카테고리를 분류  분류 (Class Labeling) Ÿ 데이터에 대한 레이블을 분류하는 작업 번역 (Machine Translation) Ÿ 컴퓨터를 사용하여 서로 다른 언어를 번역하는 작업 질의/답변 (Sequence Labeling) Ÿ 시퀀스에 따른 요소에 따라 순차적으로 라벨을 할당하는 것 요약 (Text Summary) Ÿ 테스트 문서를 요약하는 작업 이미지 캡셔닝 (Image Captioning) Ÿ 이미지를 입력하여 이미지에 대한 자연어 문장을 생성 및 제공하는 작업 3D 모델링 (3D Modelling) Ÿ 3차원 디지털 모델을 만드는 작업 ",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:184:0001",
                    "page": 184
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 가공은 구축사업 목적 및 특성에 따라 다양한 가공 방식을 사용할 수 있으며, 대표적인 가공 방식에는 세그멘테이션, 바운딩박스, 폴리라인, 폴리곤, 키포인트, 큐보이드, 전사, 태깅, 분류, 번역, 질의/답변, 요약, 이미지 캡셔닝, 3D 모델링 등이 있다.",
        "long_answer": {
            "question": "데이터 가공 유형 중 폴리라인과 폴리곤이 어떤 유형인지 설명하시오.",
            "answer": "폴리라인은 여러 개의 점을 가진 선을 활용하여 인도, 차선, 경로 등 선형 객체를 구분하고 인식하기 위한 작업이며, 폴리곤은 다각형 모양으로 객체의 테두리를 따라 점을 찍어 여백 없이 정확히 객체만을 구분하여 클래스를 부여한다.",
            "rubric": [
                "폴리라인; 폴리곤; 다각형; 선형 객체; 클래스"
            ]
        },
        "short_answer": {
            "question": "데이터 가공의 유형 중 음성을 테스트로 변환하는 작업은 무엇인가?",
            "answer": "전사",
            "topic": [
                "전사의 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 데이터 가공의 유형과 그 설명으로 잘못된 것은?",
            "choices": [
                "a) 바운딩 박스 - 객체를 직사각형 박스 안에 포함되도록 작업하여 클래스 부여",
                "b) 큐보이드 - 2D로 작업할 수 없는 3D 객체들을 정육면체로 생성",
                "c) 요약 - 테스트 문서를 요약하는 작업",
                "d) 세그멘테이션 - 이미지를 입력하여 이미지에 대한 자연어 문장을 생성 및 제공하는 작업"
            ],
            "answer": "d",
            "topic": [
                "바운딩 박스, 큐보이드, 요약, 세그멘테이션 설명"
            ]
        },
        "true_false": {
            "question": "이미지 캡셔닝은 3차원 디지털 모델을 만드는 작업이다.",
            "answer": "FALSE",
            "topic": [
                "이미지 캡셔닝 설명"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:185:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.3.1 텍스트 데이터  l 텍스트 데이터는 정보검색, 대화분석, 질의응답, 명령어 이해, 언어모델 학습 등의 자연어처리 AI  기술개발을 위해 구축되며, 주요 학습 Task 유형으로는 ‘텍스트 분류(Text Classification)’, ‘텍스트  요약(Text Summary)’, ‘기계 번역(Machine Translation)’, ‘순차적 레이블링 (Sequence  Labeling)’, ‘질의응답(Question Answering)’, ‘음성인식(Speech Recognition)’ 등이 있음  ※ 기타 학습 Task 유형으로 광학문자인식(Optical Character Recognition),  정보추출(Information Extraction), 텍스트 생성(Text Generation) 등이 있음  l 텍스트 데이터는 학습 Task 유형별로 적합한 라벨링을 선택하는 것이 필요하며, 선택된 라벨링 유형에  따라 적합한 지표를 적용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:185:0001",
                    "page": 185
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "텍스트 데이터는 자연어 처리 AI 기술개발을 위해 구축된다. 텍스트 데이터의 주요 학습 TASK 유형으로는 텍스트 분류, 텍스트 요약, 기계 번역, 순차적 레이블링, 질의응답, 음성인식 등이 있다.",
        "long_answer": {
            "question": "인공지능 학습데이터 중 텍스트 데이터의 특징과 이와 관련된 주요 학습 TASK 유형에 대해 서술하라.",
            "answer": "텍스트 데이터는 정보검색이나 질의응답 등 자연어처리 인공지능 기술 개발을 위해 구축된다. 이러한 텍스트 데이터의 주요 학습 테스크 유형에는 기계 번역, 텍스트 요약, 텍스트 분류 등이 있다. 텍스트 데이터는 학습 테스크 유형별로 적합한 라벨링 선택이 필요하며, 선택된 라벨링 유형에 맞게 적합한 품질 지표를 적용한다.",
            "rubric": [
                "텍스트 데이터; 자연어처리; 학습 테스크; 라벨링"
            ]
        },
        "short_answer": {
            "question": "정보검색, 대화분석, 명령어 이해, 언어모델 학습 등 자연어 처리 AI 기술개발을 위해 구축되는 데이터를 무엇이라 하는가?",
            "answer": "텍스트 데이터",
            "topic": [
                "텍스트 데이터에 대한 설명"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 텍스트 데이터와 관련된 주요 학습 TASK 유형으로 잘못된 것은?",
            "choices": [
                "a) 기계 번역",
                "b) 순차적 레이블링",
                "c) 음성인식",
                "d) 키포인트 검출"
            ],
            "answer": "d",
            "topic": [
                "텍스트 데이터 학습 TASK의 종류"
            ]
        },
        "true_false": {
            "question": "텍스트 데이터는 학습 Task 유형별로 라벨링을 선택할 필요가 없다.",
            "answer": "FALSE",
            "topic": [
                "텍스트 데이터 학습 Task에서의 라벨링"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:186:0001",
        "lang": "ko-KR",
        "category": [
            "데이터 품질과 표준"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "2.3.2 이미지 데이터 l 이미지 데이터는 시간의 흐름에 따라 지속적인 움직임을 담지 않고 피사체를 고정하여 촬영한 데이터를 의미하며, 주요 학습 Task 유형으로는 ‘객체 인식(Object Detection)’, ‘키포인트 검출(Keypoint Detection)’, ‘얼굴 인식(Face Recognition)’, ‘이미지 분류(Image Classification)’ 등이 있음 l 이미지 데이터는 학습 Task 유형별로 적합한 라벨링을 선택하는 것이 필요하며, 선택된 라벨링 유형에 따라 적합한 지표를 적용",
                "provenance": {
                    "doc_id": "250523_[제1권]_AI_데이터_품질관리_가이드v3.5.pdf:186:0001",
                    "page": 186
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "이미지 데이터는 시간의 흐름에 따라 지속적인 움직임을 담지 않고 피사체를 고정하여 촬영한 데이터를 의미한다. 이미지 데이터의 주요 학습 테스크 유형으로는 객체 인식, 키포인트 검출, 얼굴 인식, 이미지 분류 등이 있다.",
        "long_answer": {
            "question": "이미지 데이터의 정의와 주요 학습 테스크 유형에 대해 설명하라.",
            "answer": "이미지 데이터란 시간의 흐름에 따라 지속적인 움직임을 담는 것이 아니라 피사체를 고정하여 촬영한 데이터를 의미한다. 이미지 데이터의 주요 학습 테스크 유형으로는 키포인트 검출, 얼굴 인식, 객체 인식, 이미지 분류 등이 있다.",
            "rubric": [
                "이미지 데이터; 고정; 학습 테스크"
            ]
        },
        "short_answer": {
            "question": "시간의 흐름에 따라 지속적인 움직임을 담지 않고 피사체를 고정하여 촬영한 데이터를 무엇이라 하는가?",
            "answer": "이미지 데이터",
            "topic": [
                "이미지 데이터의 정의"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 이미지 데이터의 주요학습 Task 유형이 아닌 것은?",
            "choices": [
                "a) 객체 인식",
                "b) 키포인트 검출",
                "c) 자세 추정",
                "d) 이미지 분류"
            ],
            "answer": "c",
            "topic": [
                "이미지 데이터의 주요학습 Task 유형"
            ]
        },
        "true_false": {
            "question": "이미지 데이터는 피사체를 고정하여 촬영한 데이터를 의미한다.",
            "answer": "FALSE",
            "topic": [
                "이미지 데이터의 정의"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:23:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "3. 훈련 및 테스트 Adam 옵티마이저를 사용하여 batch size 128과 총 50 epoch로 훈련. 초기 학습률은 5 ×  10^-4로 설정하고, cosine decay 전략을 적용하여 학습률을 점진적으로 감소시킴. 효율적  인 학습을 위해 훈련 단계에서 스니핏 샘플링 임계값은 200으로 설정. 테스트 단계에서는  이상 점수의 스무딩을 위해 데이터셋별로 다른 윈도우 크기의 pooling 전략을 사용  UCF-Crime과 ShanghaiTech에서는 각각 슬라이딩 풀링 윈도우 크기를 7과 3으로 설정하  고, XD-Violence에서는 Moving Pooling 윈도우 크기를 9로 설정하여 점수를 스무딩. 이를  통해 모델은 각 데이터셋에 맞는 최적의 성능을 발휘하도록 학습 및 테스트 과정을 수행",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:23:0001",
                    "page": 23
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "Adam 옵티마이저와 cosine decay를 적용해 학습률을 조정하고, 데이터셋별 풀링 윈도우 크기로 테스트 성능을 최적화한다.",
        "long_answer": {
            "question": "모델 훈련 및 테스트 단계에서 적용된 주요 설정과 그 목적을 설명하시오.",
            "answer": "모델은 Adam 옵티마이저를 사용하여 batch size 128, 총 50 epoch으로 훈련되었다. 초기 학습률은 5×10^-4로 설정하고 cosine decay 전략을 적용해 학습률을 점진적으로 감소시켰으며, 스니핏 샘플링 임계값은 200으로 설정하여 효율적인 학습을 수행하였다. 테스트 단계에서는 이상 점수의 스무딩을 위해 UCF-Crime에는 윈도우 크기 7, ShanghaiTech에는 3, XD-Violence에는 9의 풀링 윈도우를 적용해 데이터셋별 최적 성능을 확보하였다.",
            "rubric": [
                "Adam 옵티마이저; cosine decay; 스니핏 샘플링 임계값; 이상 점수 스무딩; 풀링 윈도우"
            ]
        },
        "short_answer": {
            "question": "모델 훈련 단계에서 학습률 감소를 위해 적용된 전략은?",
            "answer": "cosine decay",
            "topic": [
                "모델 훈련 단계 적용 전략"
            ]
        },
        "multiple_choice": {
            "question": "모델 훈련 및 테스트 설정에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 모든 데이터셋에 동일한 풀링 윈도우 크기 5를 적용",
                "b) 스니핏 샘플링 임계값은 500으로 설정",
                "c) Adam 옵티마이저를 사용하고 cosine decay로 학습률 조정",
                "d) 테스트 단계에서는 이상 점수 스무딩 미적용"
            ],
            "answer": "c",
            "topic": [
                "모델 훈련 및 테스트 설정"
            ]
        },
        "true_false": {
            "question": "모델 학습에서 초기 학습률은 5×10^-4로 설정하고, cosine decay로 점진적으로 감소시켰다.",
            "answer": "TRUE",
            "topic": [
                "모델 학습률 설정 및 조정 방식"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:6:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "Weakly-Supervised 비디오 이상 탐지에서 효율적인 컨텍스트 모델링과 의미론적 분별력 향상을 달성함. 제안된 Temporal Context Aggregation (TCA) 모듈은 기존의 병렬 구조 기반 방법들과 비교해 더 효율적으로 컨텍스트 정보를 캡처하여 모델의 파라미터 수와 계산 비용을 감소시킴. 이로써 UCF-Crime 데이터셋에서 AUC 기준 85.72%를 달성하고, XD-Violence 데이터셋에서는 AP 기준 83.28%의 성능을 보여 기존의 RTFM이나 HL-Net과 같은 최첨단 방법 대비 우수한 성능을 보임. Prompt-Enhanced Learning (PEL) 모듈의 도입을 통해서는 비디오 내 이상 클래스 간의 세분화된 탐지 성능을 크게 향상시킴. 특히 PEL 모듈을 적용한 후 UCF-Crime 데이터셋에서 AUC가 86.76%로 상승하였으며, XD-Violence에서는 AP 기준 85.59%를 달성함. 이는 특히 다양한 유형의 이상 행동이 혼재된 XD-Violence 데이터셋에서 기존 방법 대비 3% 이상의 AP 향상을 보여줌. 또한, 제안된 프레임워크는 일부 세분화된 이상 클래스에서 약 10%의 탐지 정확도 향상을 보이며, 특히 UCF-Crime 데이터셋 내에서 Abuse나 Assault와 같은 클래스에 대해 다른 모델 대비 뛰어난 분별력을 나타냄.",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:6:0001",
                    "page": 6
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "제안된 TCA와 PEL 모듈은 비디오 이상 탐지에서 컨텍스트 모델링 효율성과 의미론적 분별력을 높여 기존 방법보다 우수한 성능을 달성했다.",
        "long_answer": {
            "question": "TCA 모듈과 PEL 모듈이 비디오 이상 탐지 성능 향상에 기여한 방식에 대해 설명하시오.",
            "answer": "TCA 모듈은 병렬 구조 기반 기존 방법보다 효율적으로 컨텍스트 정보를 캡처하여 모델의 파라미터 수와 계산 비용을 줄였다. 이로 인해 최첨단 방법 대비 우수한 성능을 보일 수 있었다. PEL 모듈은 다양한 유형의 이상 행동이 혼재된 XD-Violence 데이터셋에서 기존 방법 대비 AP 향상을 보여줬으며, 클래스 간의 세분화된 탐지 성능 또한 크게 향상시켰다.",
            "rubric": [
                "TCA 모듈; 파라미터 수와 계산 비용 계산 비용 감소; PEL 모듈; AP 향상"
            ]
        },
        "short_answer": {
            "question": "PEL 모듈이 UCF-Crime 데이터셋 내에서 뛰어난 분별력을 나타낸 클래스는?",
            "answer": "Abuse, Assault",
            "topic": [
                "PEL 모듈의 성능"
            ]
        },
        "multiple_choice": {
            "question": "TCA 모듈의 특징으로 옳은 것은?",
            "choices": [
                "a) 컨텍스트 정보를 효율적으로 캡처하여 계산 비용을 감소시킴",
                "b) 병렬 구조 기반으로 파라미터 수를 증가시킴",
                "c) 컨텍스트 정보를 비효율적으로 처리함",
                "d) 기존 RTFM보다 낮은 성능을 보임"
            ],
            "answer": "a",
            "topic": [
                "TCA 모듈의 특징"
            ]
        },
        "true_false": {
            "question": "PEL 모듈 적용 후 모델의 이상 클래스 분별력이 감소하였다.",
            "answer": "FALSE",
            "topic": [
                "PEL 모듈 적용 결과"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:26:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "3. 서비스 활용 3.1 서비스 활용 예시 및 시나리오 Ÿ 본 과제를 통해 구축될 데이터는 안전사고 4종(침입, 쓰러짐, 싸움, 군집) 및 특화데이터(인파밀집, 침수) 상황을 예방 및 감지할 수 있는 AI 모델 개발을 위한 학습용 동영상 데이터 300건임 Ÿ Ÿ 본 과제가 성공적으로 수행될 경우, 지자체에서 보유하고 있는 초거대 규모의 동영상 데이터를 적은 인적자원으로도 학습데이터 전환이 가능한 유효성을 검증할 수 있으며, 공동연구기관인 쿠도 커뮤니케이션에서 이미 지자체에 구축한 지능형 CCTV 시스템에 즉시 AI 모델을 투입할 수 있음 Ÿ Ÿ 또한 지능형 CCTV를 구축하고자하는 민간 기업 지자체는 지능형 CCTV 시스템의 기초 학습데이터로서 활용할 수 있음",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:26:0001",
                    "page": 26
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "동영상 학습데이터를 구축해 지자체, 민간에서 효율적인 활용이 가능하도록 한다.",
        "long_answer": {
            "question": "본 과제의 활용 시나리오에 대해 설명하시오.",
            "answer": "본 과제는 안전사고 4종 및 특화데이터 상황을 예방 및 감지할 수 있는 AI 모델 개발을 위한 학습용 동영상 데이터 300건 구축을 목적으로 한다. 이것이 성공할 경우, 지자체 보유 초거대 규모 동영상 데이터를 적은 인적자원으로도 학습데이터로 전환하여 유효성을 검증할 수 있다. 또한 지능형 CCTV를 구축하려는 민간 기업 지자체가 본 과제를 시스템 학습데이터로 활용이 가능하다.",
            "rubric": [
                "안전사고 및 특화데이터 예방 및 감지; 학습용 동영상 데이터; 유효성 검증; 학습데이터로 활용"
            ]
        },
        "short_answer": {
            "question": "본 과제가 구축하고자 하는 동영상 데이터 수량은?",
            "answer": "300건",
            "topic": [
                "동영상 데이터 구축 수량"
            ]
        },
        "multiple_choice": {
            "question": "초거대 동영상 데이터의 활용성에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) 지자체 영상 데이터 전환 효율성 검증",
                "b) 쿠도커뮤니케이션 시스템에 AI 모델 투입",
                "c) 민간 지능형 CCTV 기초데이터로 활용",
                "d) 교통신호 제어 시스템 구축"
            ],
            "answer": "d",
            "topic": [
                "초거대 동영상 데이터의 활용성"
            ]
        },
        "true_false": {
            "question": "본 과제의 구축 데이터에는 침입, 쓰러짐, 싸움, 군집 등 4종의 안전상황이 포함된다.",
            "answer": "TRUE",
            "topic": [
                "안전상황 관련 데이터"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:12:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 구축 과정 프로세스 설계 Ÿ 개인정보 보호, 촬영 환경 다양성 등 문제를 분석하고 데이터 익명화 및 표준화로 해결 방안 수립 Ÿ 재난·사고 감지, 교통 혼잡, 공공 안전 등 이벤트에 맞는 CCTV 영상을 선별해 품질과 관련성을 고려하여 데이터 확보 방안을 수립",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:12:0001",
                    "page": 12
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "CCTV 데이터 구축 관련 문제 해결 방안 및 데이터 확보 방안을 수립한다.",
        "long_answer": {
            "question": "데이터 구축 과정에서 CCTV와 관련하여 발생할 수 있는 문제와 해결 방안에 대해 서술하시오.",
            "answer": "데이터 구축 과정에서는 개인정보 보호나 촬영 환경 다양성 등의 문제가 발생할 수 있다. 따라서 데이터 익명화나 표준화로 해결 방안을 수립할 수 있다. 또한 재난이나 사고 감지, 교통 혼잡, 공공 안전 등의 이벤트에 맞는 CCTV 영상을 선별함으로써 품질과 관련성까지 고려한 데이터 확보를 할 수 있다.",
            "rubric": [
                "개인정보 보호; 촬영 환경 다양성; 데이터 익명화 및 표준화; CCTV 영상 선별"
            ]
        },
        "short_answer": {
            "question": "CCTV 영상 선별을 통해 데이터 확보 방안을 수립할 때 고려해야 할 것은?",
            "answer": "품질, 관련성",
            "topic": [
                "CCTV 영상 선별을 통한 데이터 확보"
            ]
        },
        "multiple_choice": {
            "question": "CCTV 데이터 설계 단계에서 적합하지 않은 활동은?",
            "choices": [
                "a) 이벤트별 영상 선별",
                "b) 대량의 영상 확보",
                "c) 익명화 수행",
                "d) 데이터 확보 방안 수립"
            ],
            "answer": "b",
            "topic": [
                "CCTV 데이터의 설계 단계"
            ]
        },
        "true_false": {
            "question": "데이터 설계 단계는 아직 개인정보 보호 문제까지 고려할 단계가 아니다.",
            "answer": "FALSE",
            "topic": [
                "데이터 설계 시 개인정보 보호"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:12:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "Ÿ 지자체로부터 수집한 동영상 데이터에서 데이터 자르기 수행  Ÿ 제시한 시간별 수량에 맞게 데이터가 잘려졌는지 책임연구원  이상 직원의 품질 검수 수행  Ÿ 수집 영상의 품질 검수 및 개인정보 비식별화  Ÿ CCTV 내 안면, 차량 번호판, 간판, 도로명주소 비식별화 작업",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:12:0001",
                    "page": 12
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "수집한 CCTV 동영상 데이터를 자르고 품질과 개인정보 비식별화를 검수하여 안전하게 가공한다.",
        "long_answer": {
            "question": "동영상 데이터 가공 단계에서 수행하는 절차에 대해 서술하시오.",
            "answer": "동영상 데이터 가공 첫 단계에서는 지자체로부터 수집한 데이터를 자른다. 이후 책임연구원 이상 직원이 제시한 시간별로 수량에 맞게 데이터가 잘렸는지에 대한 품질 검수를 수행한다. 이때 CCTV 내 안면, 차량 번호판, 간판, 도로명주소 등 개인정보 관련한 정보는 비식별화한다.",
            "rubric": [
                "데이터 자르기; 품질 검수; 개인정보 비식별화"
            ]
        },
        "short_answer": {
            "question": "동영상 데이터의 품질 검수 수행을 할 수 있는 직책은?",
            "answer": "책임연구원 이상 직원",
            "topic": [
                "동영상 데이터의 품질 검수 수행"
            ]
        },
        "multiple_choice": {
            "question": "동영상 데이터 가공 단계의 특징으로 옳은 것은?",
            "choices": [
                "a) 수집 데이터는 가공 없이 바로 학습에 사용한다.",
                "b) 데이터 자르기가 수행된다.",
                "c) 개인정보 비식별화는 선택 사항이다.",
                "d) 책임연구원 이상은 데이터 검수에 참여하지 않는다."
            ],
            "answer": "b",
            "topic": [
                "동영상 데이터 가공 단계의 특징"
            ]
        },
        "true_false": {
            "question": "동영상 데이터 가공 단계에서는 CCTV 영상 내 안면을 비식별화한다.",
            "answer": "TRUE",
            "topic": [
                "동영상 데이터의 비식별화"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:13:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "사전 계획 수립  Ÿ 수집할 CCTV 영상의 종류와 요구사항을 명확히 정의하고, 수집 일정 과 절차를 체계적으로 계획 Ÿ 각 이벤트(침입, 쓰러짐, 싸움, 군집, 인파밀집, 침수)에 대한 구체적 인 데이터 수집 방안 마련  법적 검토 및 협약  Ÿ 데이터 수집을 위한 법적 검토를 수행하며, 지자체 및 데이터 제공 기관과 협약을 통해 데이터 사용 권한 확보 Ÿ 수집 과정에서 개인정보 보호법을 준수하기 위해 가명정보처리위원 회의 승인 절차를 거쳐 데이터 반출 계획 수립  수집 절차의 체계적 진행 Ÿ 지정된 관제센터 및 보안 환경 내에서 CCTV 영상을 수집하며, 필요 한 경우 지자체 측 담당자와 협력하여 원활한 데이터 확보 보장 Ÿ 수집된 영상은 원시 형태로 안전하게 보관된 후 비식별화 및 전처리 작업 진행  실시간 모니터링 Ÿ 데이터 수집이 계획대로 진행되는지 확인하며, 수집 중 발생하는 품 질 문제나 예외 상황에 대해 즉각적인 조정 및 재수집 절차를 적용  보안 강화  Ÿ 수집된 데이터는 보안이 강화된 서버에 저장하며, 접근 권한은 제한 된 인원에게만 부여 Ÿ 모든 데이터 처리와 관리 활동은 보안 서약서를 작성한 인원에 의해 수행",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:13:0001",
                    "page": 13
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "CCTV 데이터 수집 단계에서 계획 수립, 법적 협약, 체계적 수집, 모니터링, 보안 강화 절차를 수행한다.",
        "long_answer": {
            "question": "사전 계획 수립 단계에 대해 설명하시오.",
            "answer": "사전 계획 수립 단계에서는 수집할 CCTV 영상의 종류와 요구사항을 명확히 정의하고, 수집 일정과 절차를 체계적으로 계획한다. 각 이벤트에 대한 구체적인 데이터 수집 방안 마련 또한 사전 계획 수립 단계에 포함된다. 이때 이벤트 종류로는 침입, 쓰러짐, 싸움, 군집, 인파밀집, 침수 등이 있다.",
            "rubric": [
                "종류 및 요구사항 정의; 수집 일정 및 절차 계획; 이벤트별 데이터 수집 방안 마련"
            ]
        },
        "short_answer": {
            "question": "모든 데이터 처리와 관리 활동은 무엇을 작성해야만 수행이 가능한가?",
            "answer": "보안 서약서",
            "topic": [
                "데이터 처리와 관리 활동"
            ]
        },
        "multiple_choice": {
            "question": "데이터 수집 단계에서 부적절한 활동은?",
            "choices": [
                "a) 이벤트별 데이터 수집 계획 수립",
                "b) 개인정보 보호법 준수를 위한 승인 절차 수행",
                "c) 지정 관제센터를 통한 데이터 수집",
                "d) 데이터 접근 권한을 관련 인원에게 부여"
            ],
            "answer": "d",
            "topic": [
                "데이터 수집 단계에서의 부적절한 활동"
            ]
        },
        "true_false": {
            "question": "수집된 데이터는 정보의 투명성을 위해 공개 서버에 저장한다.",
            "answer": "FALSE",
            "topic": [
                "수집 데이터의 서버 저장"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:13:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 반출 및 처리  Ÿ 지자체에서 수집한 데이터는 법적 승인 절차를 거쳐 안전하게 반출 하며, 이 과정은 보안이 강화된 공간에서 이루어지며, 영상 데이터 는 지정된 서버에 업로드됨  품질 점검  Ÿ 수집된 데이터는 품질 검수를 통해 영상의 해상도, 프레임 속도, 이 벤트 식별 가능성 등을 점검함. 품질 미흡 시 재수집 또는 보완 작 업을 진행함",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:13:0001",
                    "page": 13
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "지자체에서 수집한 데이터는 법적 승인 후 안전하게 반출·업로드되며, 품질 점검을 통해 필요한 경우 추가 작업을 한다.",
        "long_answer": {
            "question": "데이터 반출과 품질 점검 과정에 대해 설명하시오.",
            "answer": "데이터는 지자체에서 법적 승인 절차를 통해 안전하게 반출된다. 이는 보안이 강화된 공간에서 이루어지고 영상 데이터는 지정 서버에 업로드된다. 이후 품질 검수를 통해 영상 해상도, 프레임 속도, 이벤트 식별 가능성 등을 점검하며, 품질이 미흡하다 판단될 경우 재수집이나 보완 작업을 진행한다.",
            "rubric": [
                "지자체; 법적 승인 절차; 지정 서버; 품질 검수; 재수집 및 보완"
            ]
        },
        "short_answer": {
            "question": "수집 데이터 중 영상 데이터가 업로드되는 공간은?",
            "answer": "지정된 서버",
            "topic": [
                "영상 데이터의 업로드 공간"
            ]
        },
        "multiple_choice": {
            "question": "데이터 반출 및 처리 단계에 관한 설명으로 옳은 것은?",
            "choices": [
                "a) 데이터는 보안이 강화된 공간에서 안전하게 반출된다.",
                "b) 법적 승인 없이 데이터를 반출한다.",
                "c) 품질 점검은 생략 가능하다.",
                "d) 반출 후 데이터를 즉시 삭제한다."
            ],
            "answer": "a",
            "topic": [
                "데이터 반출 및 처리 단계의 특징"
            ]
        },
        "true_false": {
            "question": "품질 점검에서는 데이터 해상도, 프레임 속도, 이벤트 식별 가능성을 확인한다.",
            "answer": "TRUE",
            "topic": [
                "데이터 품질 점검 항목"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "가공 데이터 선정  Ÿ 정제된 영상 데이터 중 이벤트 발생 구간이 명확한 데이터를 가공 대상으로 선정 Ÿ 안전사고 데이터 4종(침입, 쓰러짐, 싸움, 군집) 200건과 특화 데이터 2종(인파밀집, 침수) 100건을 포함하여 총 300건의 데이터를 선정  원천데이터 가공도구 확보  Ÿ 원활한 가공을 위해 한국딥러닝(주) 자체 개발한 프로그램 활용 (구간 태깅 및 캡셔닝 : DeepLable_v1)  이벤트 시작 및 종료 프레임 태깅  Ÿ 각 이벤트의 시작과 종료 프레임을 태깅하여 이벤트 구간을 명확히 표시 Ÿ 구간 태깅은 가이드라인에 따라 일관성 있게 수행되며, 각 이벤트 의 흐름을 정확히 반영  이벤트 핵심 프레임 캡셔닝  Ÿ 이벤트 주요 특징이 잘 나타나는 프레임을 선택하여 캡셔닝 작업수행 Ÿ 캡셔닝은 이벤트의 상황과 특징을 설명하는 짧은 텍스트로 작성되 며, AI 모델이 이벤트를 이해할 수 있도록 구체적인 정보를 포함  라벨링 품질검수  Ÿ 구간 태깅 및 캡셔닝 작업이 완료된 데이터에 대해 품질검수팀이 가이드라인에 따라 검수 Ÿ 오류나 불일치가 발견되면 해당 부분을 수정하고 보완 작업을 수행  다양성 및 일관성 검토  Ÿ 가공된 데이터가 다양한 이벤트 상황과 환경을 충분히 포괄하는지 검토 Ÿ 작업이 일관되게 수행되었는지 확인하여 데이터 품질을 보장  최종 검수 및 승인 절차  Ÿ 가공이 완료된 데이터는 최종 검수 단계에서 품질을 점검하고, 필 요한 경우 추가 보완 작업을 거쳐 승인 절차를 밟음 Ÿ 승인된 데이터는 AI 학습 데이터셋에 포함될 준비가 완료됨  데이터 저장 및 관리  Ÿ 최종 가공된 데이터는 보안이 강화된 서버에 저장 Ÿ 데이터 관리 절차에 따라 접근 권한이 제한된 인원만 데이터를 사 용할 수 있도록 관리하며, 데이터 무결성을 보장",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "이벤트 발생 구간이 명확한 데이터를 선정하고, 구간 태깅·캡셔닝·검수를 거쳐 안전하게 관리한다.",
        "long_answer": {
            "question": "데이터 가공 프로세스에서 이벤트 핵심 프레임 캡셔닝은 어떤 방식으로 이루어지는지 설명하시오.",
            "answer": "이벤트 핵심 프레임 캡셔닝은 이벤트의 주요 특징이 잘 두드러지는 프레임을 선택하여 캡셔닝 작업을 수행한다. 이때 캡셔닝은 이벤트의 상황과 특징을 설명하는 짧은 텍스트로 작성되어야 한다. 또한 캡셔닝 작업 시, AI모델이 이벤트를 이해할 수 있도록 구체적인 정보를 포함해야 한다.",
            "rubric": [
                "프레임 선택; 짧은 텍스트; 구체적 정보"
            ]
        },
        "short_answer": {
            "question": "라벨링 품질 검수를 수행하는 주체는?",
            "answer": "품질관리팀",
            "topic": [
                "라벨링 품질 검수 수행"
            ]
        },
        "multiple_choice": {
            "question": "데이터 가공 프로세스에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) 각 이벤트의 시작과 종료 프레임을 태깅한다.",
                "b) 오류나 불일치가 발견되면 해당 부분을 수정한다.",
                "c) 가공 데이터는 안전사고 데이터 2종과 특화 데이터 4종으로 구성된다.",
                "d) 이벤트 발생 구간이 명확한 데이터만이 가공 데이터 대상이 될 수 있다."
            ],
            "answer": "c",
            "topic": [
                "데이터 가공 프로세스의 특징"
            ]
        },
        "true_false": {
            "question": "원활한 데이터 가공을 위해, 전문 회사에 외주로 맡긴 개발 프로그램을 사용한다.",
            "answer": "FALSE",
            "topic": [
                "원천데이터 가공 도구"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "사업수행계획 서 및 데이터 구축 요건 일치 Ÿ 사업수행계획서에 정의한 데이터 구축 기준에 맞추어 데이터 를 획득/수집/수집하도록 모니터링 및 검사  데이터 획득/수집 시 품질고려 Ÿ 쿠도 커뮤니케이션에서 지자체로부터 획득하는 데이터에서 품 질을 검수하며, 품질이 떨어지거나 기획서와 부합하지 못하는 영상은 P/F 검수를 통해 즉각 재수집 요청  사실적 획득/수집 환경 구성  Ÿ 지자체에서 실제로 발생한 안전사고 CCTV 동영상 데이터를 수집 데이터 동기화 Ÿ 다중 속성의 데이터 소스 간 정교한 동기화를 위한 절차 마련 학습모델 구축 목적의 적합성 Ÿ 데이터 설계 담당자, 학습 모델 개발자가 초기 수집한 원시데 이터를 검토하고 모델 개발 목적에 부합하는지와 수집된 데이 터의 제반 품질이 학습에 적합한지를 획득/수집의 초기에 검 토 및 피드백 수행",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 획득/수집 시 사업수행계획 기준 부합, 사실적 획득/수집 환경 부합, 동기화, 목적 적합성을 확인한다.",
        "long_answer": {
            "question": "본 사업에서 학습모델 구축 목적의 적합성을 확인하는 방법에 대해 설명하시오.",
            "answer": "학습모델 구축 목적의 적합성을 확인하기 위해 데이터 설계 담당자, 학습 모델 개발자가 초기 수집한 원시데이터를 검토한다. 수집 데이터가 모델 개발 목적에 부합하는지, 수집 데이터 제반 품질이 학습에 적합한지에 대한 확인 여부가 주 목적이다. 구축 목적 적합성 확인은 획득/수집의 초기에 검토 및 피드백을 수행한다.",
            "rubric": [
                "원시데이터 검토; 개발 목적 부합성; 제반 품질 학습 적합성"
            ]
        },
        "short_answer": {
            "question": "데이터 획득/수집 시 품질이 낮은 데이터를 처리하는 방법은?",
            "answer": "P/F 검수를 통해 즉각 재수집 요청",
            "topic": [
                "저품질 데이터 처리 방법"
            ]
        },
        "multiple_choice": {
            "question": "데이터 획득/수집 기준에 대한 설명으로 적절한 것은?",
            "choices": [
                "a) 기준에 부합하지 않는 데이터는 재수집을 요청한다.",
                "b) 사업수행계획 기준보다 우선적으로 데이터 수집을 진행한다.",
                "c) 소수 속성의 데이터 소스 간 정교한 동기화를 위한 절차를 마련한다.",
                "d) 초기 수집한 원시데이터를 정부 기관에서 검토한다."
            ],
            "answer": "a",
            "topic": [
                "데이터 획득/수집 기준"
            ]
        },
        "true_false": {
            "question": "개발계획서에 정의한 데이터 구축 기준에 맞추어 데이터를 획득/수집하도록 모니터링 및 검사를 진행한다.",
            "answer": "FALSE",
            "topic": [
                "데이터 획득/수집을 위한 모니터링"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:16:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "이벤트 확인 불가 영역에 대한 비식별화 처리 이벤트 행위를 확인할 수 있는 영역은 개인정보 개별 블러 처리함 Ÿ 이벤트 행위와 관계 없으며, CCTV 시각에서 너무 멀리 있는 개인정보의 경우 영역 블러 처리 Ÿ 이벤트 행위와 관계 없고 다수의 인원이 밀집된 상태에서 개별 비식별화 작업 시 블러 처리 안되는 영역은, 개인정보 노출 우려가 있는 경우 해당 영역 전체 블러 처리",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:16:0001",
                    "page": 16
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "이벤트와 무관하거나 확인 불가한 개인정보는 블러 처리하여 비식별화한다.",
        "long_answer": {
            "question": "이벤트 확인 불가 영역별 비식별화 처리 방법에 대해 설명하시오.",
            "answer": "이벤트 영역 확인이 불가한 영역은 개인정보를 개별 블러 처리한다. 이벤트 행위와 관계가 없거나, CCTV 시각에서 멀리 떨어진 개인정보는 영역 블러 처리한다. 특히 다수의 인원이 밀집된 상태에서 개별 비식별화 작업을 할 때 블러처리가 되지 않는 영역은 개인정보 노출 우려가 있을 때 해당 영역을 전체 블러 처리한다.",
            "rubric": [
                "개별 블러 처리; 영역 블러 처리; 전체 블러 처리"
            ]
        },
        "short_answer": {
            "question": "이벤트 행위와 관계 없는 개인정보의 비식별화 처리 방법은?",
            "answer": "영역 블러 처리",
            "topic": [
                "이벤트와 무관한 개인정보 비식별화"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 이벤트 관련 개인정보 비식별화 과정에 대해 부적절하게 짝지어진 것은?",
            "choices": [
                "a) 이벤트 확인 불가능 개인정보: 개별 블러 처리",
                "b) 이벤트와 무관한 개인정보: 영역 블러 처리",
                "c) 다수 인원 밀집 시 개인정보: 전체 블러 처리",
                "d) 다수 인원 밀집 시 개인정보: 전체 블러 생략 가능"
            ],
            "answer": "d",
            "topic": [
                "이벤트 관련 개인정보 비식별화"
            ]
        },
        "true_false": {
            "question": "CCTV 시각에서 너무 멀리 있는 개인정보의 경우, 영역 블러 처리한다.",
            "answer": "TRUE",
            "topic": [
                "CCTV 시각에서 먼 개인정보 비식별화"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:16:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "가공(라벨링) 기준 가. 구간 태깅 기준 Ÿ 침입 이벤트 다수의 사람이 순차적으로 침입하는  경우  Ÿ 여러 사람이 순차적으로 침입하더라도, 동일 구역과 동일 맥락에서 발생하면 하나의 이벤트로 간주 Ÿ 동일 영상 내에서 시간차를 두고 다른 무리가 침입을 시도할 경우, 각각의 무 리를 기준으로 독립적인 구간 태깅 진 행 경계 구역 안쪽에서 바깥쪽으로 침입하는  경우  Ÿ 경계 구역 안쪽에서 바깥쪽으로 침입하 는 사람이 보이기 시작하는 순간을 기 준으로 구간 태깅 시작점을 설정",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:16:0001",
                    "page": 16
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "침입 이벤트는 동일 맥락 여부에 따라 하나로 태깅하거나 구분하며, 경계 안쪽에서 바깥쪽으로 이동 시점을 기준으로 태깅을 시작한다.",
        "long_answer": {
            "question": "침입 이벤트 구간별 태깅 기준에 대해 설명하시오.",
            "answer": "다수의 사람이 순차적으로 침입하는 경우애는 여러 사람이 순차적으로 침입하더라도 동일 구역과 동일 맥락에서 발생하면 하나의 이벤트로 간주한다. 동일 영상 내에서 시간차를 두고 다른 무리가 침입을 시도할 경우, 각각의 무리를 기준으로 독립적인 구간 태깅을 한다. 경계 구역 안쪽에서 바깥쪽으로 침입하는 경우에는 경계 구역 안쪽에서 바깥쪽으로 침입하는 사람이 보이기 시작하는 순간을 기준으로 구간 태깅 시작점을 설정한다.",
            "rubric": [
                "다수 순차적 침입; 시간차 침입; 안쪽에서 바깥쪽으로 침입"
            ]
        },
        "short_answer": {
            "question": "동일 영상 내에서 시간차를 두고 다른 무리가 침입을 시도할 경우, 구간 태깅의 기준이 되는 것은?",
            "answer": "각각의 무리",
            "topic": [
                "시간차 침입 시 태깅 기준"
            ]
        },
        "multiple_choice": {
            "question": "침입 이벤트 구간 태깅 기준에 부합하지 않는 것은?",
            "choices": [
                "a) 동일 맥락의 순차적 침입을 하나로 태깅",
                "b) 동일 영상 내 모든 인원을 통합 태깅",
                "c) 시간차 침입 무리를 각각 태깅",
                "d) 경계 구역 안쪽에서 바깥쪽으로 침입 시 태깅 시작점 설정"
            ],
            "answer": "b",
            "topic": [
                "침입 이벤트의 구간 태깅 기준"
            ]
        },
        "true_false": {
            "question": "동일 구역에서 동일 맥락으로 발생한 다수의 침입은 하나의 이벤트로 간주한다.",
            "answer": "TRUE",
            "topic": [
                "동일 맥락 내 다수 침입 시 이벤트 맥락"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:16:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "Ÿ 쓰러짐 이벤트 기본 머리나 몸 일부가 지면 또는 기구에 닿으며 균형을 잃은 경우  Ÿ 몸이 지면에 닿은 시점을 기준으로 쓰 러짐으로 판단  변수 쓰러진 후 다시 일어나는 경우  Ÿ 머리나 신체가 바닥 면에 닿은 후 다시 일어나는 시점까지를 하나의 이벤트로 처리  동일 인물이 반복적으로 넘어지는 경우 Ÿ 동일 인물이 반복적으로 넘어지더라도  하나의 이벤트로 간주  앉아있다가 쓰러지는 경우 Ÿ 앉아있다가 쓰러지는 경우, 눕는 시점  부터 쓰러짐으로 간주  무리 내에서 각각의 인원들이 시간차를 두고 쓰러지는 경우  Ÿ 무리 내에서 각각의 인원들이 시간차를 두고 쓰러지는 경우 동일한 맥락이라고 판단되면, 하나의 이벤트로 간주 주저앉았다가 곧바로 쓰러지는 경우 Ÿ 주저앉은 시점을 기준으로 쓰러짐으로  판단",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:16:0001",
                    "page": 16
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "지면 접촉 시점을 기준으로 쓰러짐을 판정하며, 동일 맥락의 반복 쓰러짐은 하나의 이벤트로 처리한다.",
        "long_answer": {
            "question": "쓰러짐 이벤트 구간 태깅의 기본적인 기준과 변수 처리 규칙에 대해 설명하시오.",
            "answer": "쓰러짐 이벤트는 기본적으로 머리나 몸 일부가 지면 또는 기구에 닿으며 균형을 잃었을 때, 몸이 지면에 닿은 시점을 기준으로 한다. 다만 쓰러진 후 다시 일어나는 경우, 머리나 신체가 바닥 면에 닿은 후 다시 일어나는 시점까지를 하나의 이벤트로 처리하며, 동일 인물이 반복적으로 넘어지더라도 하나의 이벤트로 간주한다. 앉아있다가 쓰러지는 경우에는 눕는 시점부터 쓰러짐으로 간주한다. 무리 내에서 각각의 인원들이 시간차를 두고 쓰러지는 경우, 동일한 맥락이라고 판단되면 하나의 이벤트로 간주한다. 또한 주저앉았다가 곧바로 쓰러지는 경우에는 주저앉은 시점을 기준으로 쓰러짐으로 판단한다.",
            "rubric": [
                "지면에 닿은 시점; 쓰러진 후 다시 일어남; 반복 쓰러짐; 앉아있다가 쓰러짐; 시간차 쓰러짐; 주저앉았다가 쓰러짐"
            ]
        },
        "short_answer": {
            "question": "한 사람이 3번 연속 쓰러졌을 경우, 이벤트는 몇 개로 간주되는가?",
            "answer": "하나",
            "topic": [
                "동일 인물이 반복적으로 쓰러졌을 경우의 이벤트 개수"
            ]
        },
        "multiple_choice": {
            "question": "쓰러짐 이벤트의 태깅 기준으로 옳은 것은?",
            "choices": [
                "a) 일어나는 시점을 기준으로 한다.",
                "b) 쓰러짐이 반복될 때마다 각각 태깅한다.",
                "c) 머리가 지면에 닿는 시점을 기준으로 한다.",
                "d) 앉아있는 상태에서의 움직임은 제외한다."
            ],
            "answer": "c",
            "topic": [
                "쓰러짐 이벤트의 태깅 기준"
            ]
        },
        "true_false": {
            "question": "쓰러짐 이벤트는 의식을 잃은 시점이 태깅의 기준이 된다.",
            "answer": "FALSE",
            "topic": [
                "쓰러짐 이벤트의 태깅 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:16:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "Ÿ 싸움 이벤트 기본 폭행으로 볼 수 있는 신체적 접촉이 발생하는 경우  Ÿ 신체적 접촉이 시작된 시점부터 종료된 시점까지를 하나의 구간으로 처리 *단, 신체적 접촉이 종료되더라도, 맥락상 싸움 이벤트가 지속된다고 판단되는 시점을 종료 구간으로 간주  변수 싸움이 중단되었다가 재개되는 경우  Ÿ 싸움이 중단되었다가 다시 시작하더라도, 참여자, 장소, 이유 등 싸움의 맥락이 동 일하다면 동일한 이벤트로 간주 Ÿ 단, 같은 맥락이라도 연속성이 끊긴 경 우에는 별개의 이벤트로 간주  다수 인물이 싸움에 새로 참여하거나 나가는 경우  Ÿ 새로운 인물이 참여하거나 나가더라도, 같은 맥락에서 싸움이 이어지면 하나의 이벤트로 처리",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:16:0001",
                    "page": 16
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "신체 접촉이 발생한 시점을 기준으로 싸움 이벤트를 태깅하며, 동일 맥락의 중단 및 재개는 하나로 처리한다.",
        "long_answer": {
            "question": "싸움 이벤트의 태깅 방식에 대해 서술하시오.",
            "answer": "폭행으로 간주되는 신체적 접촉이 발생하는 경우를 싸움 이벤트라고 하며, 신체적 접촉이 시작된 시점부터 종료된 시점까지가 하나의 구간으로 처리된다. 단, 신체적 접촉이 종료되더라도, 맥락상 싸움 이벤트가 지속된다고 판단되는 시점을 종료 구간으로 간주한다. 싸움이 중단되었다가 재개되는 경우에는 싸움이 중단되었다가 다시 시작하더라도 참여자, 장소, 이유 등 싸움의 맥락이 동일하다면 동일한 이벤트가 되지만, 같은 맥락이라도 연속성이 끊긴 경우에는 별개의 이벤트가 된다. 다수가 싸움에 새로 참여하거나 나가는 경우, 같은 맥락에서 싸움이 이어지면 하나의 이벤트로 처리된다.",
            "rubric": [
                "신체적 접촉; 종료 구간; 싸움 중단 후 재개; 다수 참여; 연속성"
            ]
        },
        "short_answer": {
            "question": "싸움 이벤트 구간 태깅이 시작되는 기준은?",
            "answer": "신체적 접촉이 시작된 시점",
            "topic": [
                "싸움 이벤트의 구간 태깅 시작 기준"
            ]
        },
        "multiple_choice": {
            "question": "싸움 이벤트 태깅 기준으로 적절한 설명은?",
            "choices": [
                "a) 고성이 시작되는 시점을 기준으로 한다.",
                "b) 맥락이 같으면 중단 후 재개도 하나의 이벤트로 처리한다.",
                "c) 싸움이 끝난 후 10초를 종료 기준으로 한다.",
                "d) 참여자가 바뀌면 기본적으로 새 이벤트로 간주한다."
            ],
            "answer": "b",
            "topic": [
                "싸움 이벤트의 태깅 기준"
            ]
        },
        "true_false": {
            "question": "참여자, 장소, 이유가 동일해도 싸움이 일시 중단되면 별개의 이벤트로 본다.",
            "answer": "FALSE",
            "topic": [
                "싸움 일시 중단 시 이벤트 맥락"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:17:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "Ÿ 군집 이벤트 기본 2인 이상의 인원이 손이 닿을 거리 내에 밀집된 상태로 모여 있으며, 이동하지 않는 경우  Ÿ 군집이 형성된 시점부터 완전히 해체된 시점까지를 하나의 이벤트로 처리 변수 군집이 분리되거나 다시 합쳐지는  경우  Ÿ 군집 내 일부 인원이 분리되거나 합쳐 지더라도, 전체적으로 같은 장소에서 유 지되고 있다고 판단되면 하나의 이벤트 로 간주 군집 내 일부 인원이 사라지거나 새로운 인원이 추가되는 경우  Ÿ 군집 내 일부 인원이 분리되거나 합쳐 지더라도, 전체적으로 같은 장소에서 유 지되고 있다고 판단되면 하나의 이벤트 로 간주  군집 내 인원이 늘어나거나 줄어드는 경우  Ÿ 군집에서 일부 인원이 사라지더라도, 흐 름이 동일하다면 하나의 이벤트로 처리  한 영상 내에 2개 이상의 군집이 독립적으로 발생할 경우  Ÿ 한 영상 내에 2개 이상의 군집이 독립 적으로 발생할 경우, 각각 별개의 군집 이벤트로 구분  영상 시작 지점부터 2인 이상의 군집을 형성하고 있는 경우  Ÿ 영상 시작 시점에서 2인 이상의 군집이 존재하는 경우, 군집의 형태를 관찰하 며, 기존 군집의 형태가 변경되는 시점 을 기준으로 이벤트 시작점 설정",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:17:0001",
                    "page": 17
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "2인 이상이 밀집된 상태로 모여 있을 때 군집으로 간주하며, 동일 장소나 맥락이 유지되면 인원 변동이 있어도 하나의 이벤트로 처리한다.",
        "long_answer": {
            "question": "군집 이벤트의 구간 태깅 방식과 각각의 변수 처리 방식에 대해 서술하시오.",
            "answer": "2인 이상이 손이 닿을 거리 내에 밀집된 상태로 모여 있으면서 이동하지 않는 경우를 군집이라고 하며, 군집이 형성된 시점부터 완전히 해체된 시점까지를 기본적으로 하나의 이벤트로 처리한다. 만약 군집이 분리되거나 다시 합쳐지는 경우, 군집 내 일부 인원이 분리되거나 합쳐지더라도 전체적으로 같은 장소에서 유지되고 있다고 판단되면 하나의 이벤트로 간주한다. 군집 내 일부 인원이 사라지거나 새로운 인원이 추가되는 경우 또한 마찬가지다. 군집 내 인원이 늘어나거나 줄어드는 경우, 군집에서 일부 인원이 사라지더라도 흐름이 동일하다면 하나의 이벤트로 처리한다. 한 영상 내에 2개 이상의 군집이 독립적으로 발생할 경우에는 각각 별개의 군집 이벤트로 구분한다. 마지막으로 영상 시작 지점부터 2인 이상의 군집을 형성하고 있는 경우, 군집의 형태를 관찰하면서 기존 군집의 형태가 변경되는 시점을 기준으로 이벤트 시작점을 설정한다.",
            "rubric": [
                "군집 분리 후 합체; 군집 일부 사라짐 후 인원 추가; 군집 내 인원 변동; 2개 이상 군집"
            ]
        },
        "short_answer": {
            "question": "군집으로 분류되는 인원의 기준은?",
            "answer": "2인 이상",
            "topic": [
                "군집의 인원 기준"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 군집 이벤트 처리 방식으로 거리가 먼 것은?",
            "choices": [
                "a) 일부 인원이 사라져도 같은 장소면 하나의 이벤트로 처리한다.",
                "b) 2개 이상의 독립 군집은 각각 별개의 이벤트로 처리한다.",
                "c) 군집 내 인원 변경 시, 변경 시작점을 기준으로 새로운 이벤트가 된다.",
                "d) 기존 군집의 형태가 바뀌면 이벤트 시작점을 새로 설정한다."
            ],
            "answer": "c",
            "topic": [
                "군집 이벤트의 처리 방식"
            ]
        },
        "true_false": {
            "question": "군집 이벤트는 군집이 형성된 시점부터 완전히 해체된 시점까지를 하나의 이벤트로 본다.",
            "answer": "TRUE",
            "topic": [
                "군집 이벤트의 구간 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:17:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "Ÿ 인파밀집 이벤트 기본 20명 이상의 인원이 이동 Ÿ 20명 이상의 인원이 밀집된 시점부터 분 산된 시점까지를 하나의 이벤트로 처리  변수 인원이 20명 미만으로 줄어들거나 다시 증가하는 경우  Ÿ 밀집 상태에서 일시적으로 20명 미만으 로 줄어들더라도, 밀집 상태가 유지되 고 있다면 동일 이벤트로 간주",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:17:0001",
                    "page": 17
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "20명 이상의 인원이 밀집된 상태를 인파밀집으로 간주하며, 인원 수가 일시적으로 줄어도 밀집 유지 시 동일 이벤트로 처리한다.",
        "long_answer": {
            "question": "상황별 인파밀집 이벤트 처리 방식을 설명하시오.",
            "answer": "인파밀집 이벤트는 20명 이상의 인원이 밀집된 시점부터 분산된 시점까지를 하나의 이벤트로 처리한다. 인원이 20명 미만으로 감소하는 경우, 일시적으로 감소했더라도 밀집 상태가 유지되고 있다면 동일 이벤트로 간주한다. 인원이 다시 증가하는 경우에도 동일하게 처리한다.",
            "rubric": [
                "20명 이상; 인원 감소; 인원 다시 증가"
            ]
        },
        "short_answer": {
            "question": "인파밀집 이벤트의 기본적인 종료 구간은?",
            "answer": "인원이 분산된 시점",
            "topic": [
                "인파밀집 이벤트의 종료 구간"
            ]
        },
        "multiple_choice": {
            "question": "인파밀집 이벤트 처리 방식으로 적절하지 않은 것은?",
            "choices": [
                "a) 인원이 일시적으로 20명 미만으로 줄어도 밀집이 유지되면 동일 이벤트로 본다.",
                "b) 인원 수가 증가하더라도 동일한 장소에서 유지되면 같은 이벤트로 간주한다.",
                "c) 인파밀집이 분산되기 전까지는 하나의 이벤트로 처리한다.",
                "d) 인원이 20명 미만으로 줄면 반드시 이벤트를 새로 시작한다."
            ],
            "answer": "d",
            "topic": [
                "인파밀집 이벤트의 처리 방식"
            ]
        },
        "true_false": {
            "question": "인파밀집 이벤트는 20명 이상 인원이 밀집된 시점부터 분산된 시점까지를 하나의 이벤트로 본다.",
            "answer": "TRUE",
            "topic": [
                "인파밀집 이벤트의 구간 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:17:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "기본 비가 내려서 도로가 젖어 있는  상태 Ÿ 침수 0단계로 설정 변수 빗물이 도로에 고여서 자동차 운행 시 물이 튀는 상태 Ÿ 침수 1단계로 설정  자동차 바퀴의 50% 이상이 물에 잠긴 상태 Ÿ 침수 2단계로 설정  침수 상태가 일정하지 않고 변화가 반복되는 경우  Ÿ 침수 상태가 자주 바뀌더라도, 영상 내에서 가장 심각한 단계에 맞춰 하나의 이벤트로 간주  영상 내 차량이 없거나, 차량 기준으로 침수 단계 구분이 어려운 경우  Ÿ 영상 내에 차량이 없거나 차량을 기준으로 단계 구분이 어려운 경우, 행인의 무릎 높이, 주변 사물(가로수, 벤치, 도로 경계석 등)을 기준으로 도로의 침수 단계를 예측하여 적용",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:17:0001",
                    "page": 17
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "도로의 침수 정도를 0~2단계로 구분하며, 가장 심각한 상태를 기준으로 하나의 이벤트로 처리한다.",
        "long_answer": {
            "question": "침수 이벤트의 단계별 기준과 이벤트 처리 방식에 대해 서술하시오.",
            "answer": "침수 이벤트는 0단계부터 2단계로 이루어져 있다. 침수 0단계는 비가 내려서 도로가 젖어 있는, 침수 1단계는 빗물이 도로에 고여서 자동차 운행 시 물이 튀는 상태, 침수 2단계는 자동차 바퀴의 50% 이상이 물에 잠긴 상태를 말한다. 침수 상태가 일정하지 않고 변화가 반복되는 경우, 침수 상태가 자주 바뀌더라도 영상 내에서 가장 심각한 단계에 맞춰 하나의 이벤트로 간주한다. 또한 영상 내에 차량이 없거나 차량을 기준으로 단계 구분이 어려운 경우에는 행인의 무릎 높이, 주변 사물(가로수, 벤치, 도로 경계석 등)을 기준으로 도로의 침수 단계를 예측하여 적용한다.",
            "rubric": [
                "0단계; 1단계; 2단계; 가장 심각한 단계; 침수 단계 예측 적용"
            ]
        },
        "short_answer": {
            "question": "운전할 때 도로의 빗물이 튀는 상태는 침수 이벤트 몇 단계인가?",
            "answer": "1단계",
            "topic": [
                "침수 이벤트의 단계"
            ]
        },
        "multiple_choice": {
            "question": "침수 이벤트 단계 구분 기준으로 옳은 것은?",
            "choices": [
                "a) 자동차 바퀴가 절반 이상 잠기면 침수 2단계로 설정한다.",
                "b) 도로가 젖은 상태는 침수 1단계로 설정한다.",
                "c) 차량 주행 시 물이 튀면 침수 0단계로 설정한다.",
                "d) 주변 사물은 이벤트 구분 기준에 사용하지 않는다."
            ],
            "answer": "a",
            "topic": [
                "침수 이벤트 단계 구분 기준"
            ]
        },
        "true_false": {
            "question": "침수 상태가 자주 바뀌면 각 상태에 맞는 이벤트로 변경하여 처리한다.",
            "answer": "FALSE",
            "topic": [
                "침수 이벤트 변동 처리"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:18:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "다. 이벤트 핵심 프레임 캡셔닝 기준 가공 기본 규칙  Ÿ 영상에 대한 캡셔닝은 MS COCO 이미지 캡셔닝 데이터셋의 조건을 따름 1 화면에 보이는 모든 중요한 부분을 묘사할 것 2 단순한 묘사로 ’~가 있다.‘ 식의 문장은 지양할 것 3 중요하지 않은 디테일을 중심으로 묘사하지 말 것 4 미래나 과거에 일어날 것 같은 것을 예측하여 묘사하지 말 것 5 사람이 말할 것 같은 느낌을 묘사하지 말 것 6 사람 등에게 임의의 특정 이름을 붙여 묘사하지 말 것 7 2개 이상의 동일 종류 이벤트 발생 시, / 로 이벤트 캡셔닝 구분",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:18:0001",
                    "page": 18
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "이벤트 캡셔닝은 MS COCO 데이터셋 조건을 따르며, 객관적으로 묘사하되 과도한 세부 묘사나 추측, 인명 지정, 감정 표현을 피한다.",
        "long_answer": {
            "question": "이벤트 핵심 프레임 캡셔닝의 기본 규칙에 대해 설명하시오.",
            "answer": "이벤트 핵심 프레임 캡셔닝은 MS COCO 이미지 캡셔닝 조건을 따른다. 이때 화면 내 모든 중요 부분을 묘사해야 하며, 단순 묘사와 디테일 중심 묘사는 지양한다. 또한 일어나지 않은 일에 대해 예측하여 묘사하는 것은 금지되며, 사람이 말하는 것 같은 느낌 또한 금지된다. 임의의 특정 이름을 붙여 묘사하는 것도 피해야 할 요소이다. 2개 이상의 동일 종류 이벤트가 발생하면 / 로 이벤트 캡셔닝을 구분한다.",
            "rubric": [
                "MS COCO; 단순/디테일/예측/임의 이름 묘사 금지; 캡셔닝 구분"
            ]
        },
        "short_answer": {
            "question": "동일한 종류의 이벤트가 3개 발생했을 때, 캡셔닝 구분 방법은?",
            "answer": "/ (슬래시)",
            "topic": [
                "동일 종류 이벤트 발생 시 캡셔닝 구분 방법"
            ]
        },
        "multiple_choice": {
            "question": "이벤트 핵심 프레임 캡셔닝의 규칙으로 옳은 것은?",
            "choices": [
                "a) 세부 묘사도 모두 포함한다.",
                "b) 감정 표현과 예측을 자유롭게 포함한다.",
                "c) 인명 지정은 허용되지 않는다.",
                "d) 같은 이벤트는 쉼표(,)로 구분한다."
            ],
            "answer": "c",
            "topic": [
                "이벤트 핵심 프레임 캡셔닝의 규칙으로 옳은 것은?"
            ]
        },
        "true_false": {
            "question": "이벤트 핵심 프레임 캡셔닝 시, 묘사는 최대한 단순한 문장을 사용한다.",
            "answer": "FALSE",
            "topic": [
                "이벤트 핵심 프레임 캡셔닝 묘사의 문체"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:18:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "캡션 길이 이벤트에 대한 캡션은 9어절을 맞추어야 한다  개인 정보 개인정보를 나타낼 수 있는 성별, 키, 나이 등의 정보를 추정하여 캡션하면 안된다.  필수 포함 클래스 정보와 장소 정보는 필수적으로 캡션에 포함되어야 함  객관 적 표현 상황을 최대한 객관적으로 묘사하기 위해‘굉장히’,‘매우’ 등 주관적인 느낌을 묘사하는 단어는 사용하면 안된다.",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:18:0001",
                    "page": 18
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "이벤트 캡션은 9어절 내외로 작성하며 개인정보 추정 금지, 클래스 및 장소 정보 필수 포함, 주관적 표현 배제 원칙을 따른다.",
        "long_answer": {
            "question": "이벤트 캡션 작성 시, 유의해야 할 4가지 주요 기준을 모두 서술하시오.",
            "answer": "첫째, 이벤트 캡션은 9어절로 작성해야 한다. 둘째, 성별/나이/키 등 개인정보를 추정하는 표현을 사용하지 않는다. 셋째, 클래스 정보와 장소 정보는 필수적으로 포함해야 한다. 넷째, ‘매우’, ‘굉장히’와 같은 주관적 표현은 사용하지 않고, 상황을 최대한 객관적으로 묘사해야 한다.",
            "rubric": [
                "9어절; 개인정보 추정 금지; 필수 정보 포함; 객관적 묘사"
            ]
        },
        "short_answer": {
            "question": "이벤트 캡션에서 제한하는 문장 길이는?",
            "answer": "9어절",
            "topic": [
                "이벤트 캡션의 길이 기준"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 이벤트 캡션 작성 규칙으로 올바르지 않은 것은?",
            "choices": [
                "a) 캡션 길이는 9어절 이상으로 맞춰야 한다.",
                "b) 묘사 시 객관적인 표현을 사용한다.",
                "c) 장소 정보는 필수로 포함한다.",
                "d) 개인정보를 추정하지 않는다."
            ],
            "answer": "a",
            "topic": [
                "금지된 캡셔닝 방식"
            ]
        },
        "true_false": {
            "question": "이벤트 캡션에는 반드시 클래스 정보가 포함되어야 한다.",
            "answer": "TRUE",
            "topic": [
                "이벤트 캡션의 필수 정보"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:21:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1.2 데이터 구축 유의사항 가. 원시데이터 획득/수집 관련 기준 및 고려사항 Ÿ 지자체&기관에서 운영중인 지능형 CCTV에서 발생되는 이벤트 중 정탐 기준 산정 Ÿ CCTV 영상은 민감 개인정보가 담겨 있어 비식별화 및 가명정보 처리를 관제센터 내 수행 후 기관 가명정보위원회 승인 후 반출 나. 개인정보 보호를 위한 가명정보 위원회 및 개인정보 활용 고시 Ÿ 개인정보 관리자인 지자체나 기관이 개인정보 보호의 대상인 시민에게 개인정보가 어떠한 이유로 활용되는지에 대해 고지해야함. 제 3자 제공은 학습데이터셋 형태로만 제공 가능.(개인정보위원회 개정 매뉴얼 내용중) Ÿ 기관별 가명정보 위원회 구성: 데이터 반출 심의, 보호 조치 관리 감독 등 관련 업무 담당 다. 원시데이터는 CCTV 영상 기반 이벤트 검출 기준으로 구성되며, 구체적으로 자연 및 사회재난 관제를 위한 침입, 쓰러짐, 싸움, 군집 4종 이벤트로 구성",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:21:0001",
                    "page": 21
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "원시데이터는 CCTV 기반 이벤트로 구성되며, 개인정보는 비식별화 및 가명정보 처리 후 반출해야 한다.",
        "long_answer": {
            "question": "원시데이터 획득/수집 관련 기준과 유의사항에 대해 설명하시오.",
            "answer": "원시데이터는 지자체나 기관의 지능형 CCTV에서 발생하는 이벤트 중 정탐 기준으로 산정하며 침입, 쓰러짐, 싸움, 군집 4종 이벤트로 구성된다. 영상에는 민감한 개인정보가 포함되어 있으므로 관제센터 내에서 비식별화 및 가명정보 처리를 수행 및 반출해야 한다. 데이터 반출 전 기관의 가명정보위원회 승인을 받아야 하며, 개인정보 관리자인 지자체 혹은 기관이 개인정보 활용 이유를 정보 보호 대상에게 고지해야 한다. 또한 개인정보는 학습데이터셋 형태라는 조건 하에서만 제3자에게 제공될 수 있다.",
            "rubric": [
                "4종 이벤트; 개인정보 비식별화 및 가명정보 처리; 개인정보 활용 이유 고지"
            ]
        },
        "short_answer": {
            "question": "4종 이벤트에 포함되는 이벤트 종류는?",
            "answer": "침입, 쓰러짐, 싸움, 군집",
            "topic": [
                "4종 이벤트 종류"
            ]
        },
        "multiple_choice": {
            "question": "원시데이터 획득/수집 기준으로 옳은 것은?",
            "choices": [
                "a) 원시데이터는 영상 파일을 원본 그대로 반출한다.",
                "b) 데이터 종류에 따라 비식별화 없이 기관 외부로 반출이 가능하다.",
                "c) 수집된 원시데이터는 필요 시 제3자에게 자유로운 제공이 가능하다.",
                "d) 지자체는 시민에게 개인정보 활용 사유에 대한 고지 의무가 있다."
            ],
            "answer": "d",
            "topic": [
                "원시데이터 획득/수집 기준"
            ]
        },
        "true_false": {
            "question": "CCTV 영상 기반 원시데이터는 침입, 쓰러짐, 싸움, 침수 이벤트로 구성된다.",
            "answer": "FALSE",
            "topic": [
                "원시데이터의 이벤트 구성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:22:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "PEL4VAD 아키텍쳐  Weakly-Supervised 비디오 이상 탐지에서 효율적인 컨텍스트 모델링과 의미론적 분별력 향 상을 달성함 제안된 Temporal Context Aggregation (TCA) 모듈은 기존의 병렬 구조 기반 방법들과 비교해 더 효율적으로 컨텍스트 정보를 캡처하여 모델의 파라미터 수와 계산 비용을 감소시킴. 이로 써 UCF-Crime 데이터셋에서 AUC 기준 85.72%를 달성하고, XD-Violence 데이터셋에서는 AP 기준 83.28%의 성능을 보여 기존의 RTFM이나 HL-Net과 같은 최첨단 방법 대비 우수한 성능 을 보임 Prompt-Enhanced Learning (PEL) 모듈의 도입을 통해서는 비디오 내 이상 클래스 간의 세분 화된 탐지 성능을 크게 향상시킴. 특히 PEL 모듈을 적용한 후 UCF-Crime 데이터셋에서 AUC 가 86.76%로 상승하였으며, XD-Violence에서는 AP 기준 85.59%를 달성함. 이는 특히 다양한 유형의 이상 행동이 혼재된 XD-Violence 데이터셋에서 기존 방법 대비 3% 이상의 AP 향상 을 보여줌 또한, 제안된 프레임워크는 일부 세분화된 이상 클래스에서 약 10%의 탐지 정확도 향상을 보 이며, 특히 UCF-Crime 데이터셋 내에서 Abuse나 Assault와 같은 클래스에 대해 다른 모델 대 비 뛰어난 분별력을 나타냄 테스트 단계에서 사용된 Score Smoothing (SS) 전략을 통해 오탐률(FAR)이 개선되었으며, ShanghaiTech 데이터셋에서 AUC 98.14%, FAR 0%를 달성함으로써 모델이 일반적인 샘플에 대해 충분한 신뢰성과 견고성을 갖추고 있음을 입증함 이러한 정량적인 성과는 제안된 프레임워크가 기존의 약한 지도 학습 기반 비디오 이상 탐지 기법 대비 더욱 효율적이고 정확하다는 것을 증명함",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:22:0001",
                    "page": 22
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "PEL4VAD는 TCA와 PEL 모듈을 통해 Weakly-Supervised 비디오 이상 탐지 성능을 향상시키며, 스무딩 전략으로 오탐률을 개선한다.",
        "long_answer": {
            "question": "PEL4VAD 아키텍처의 각 모듈이 비디오 이상 탐지 성능 향상에 기여하는 방식에 대해 설명하시오.",
            "answer": "PEL4VAD 아키텍처는 Weakly-Supervised 기반 비디오 이상 탐지 프레임워크다. TCA 모듈은 병렬 구조 대비 효율적으로 컨텍스트 정보를 캡처해 모델 파라미터 수와 계산 비용을 감소시키며, PEL 모듈은 이상 클래스 간 세분화된 탐지 성능을 향상시킨다. 또한 테스트 단계에서 Score Smoothing 전략을 적용해 오탐률(FAR)을 개선하며, 다양한 데이터셋에서 기존 방법 대비 높은 신뢰성과 견고성을 입증한다. 이는 PEL4VAD 아키텍처 프레임워크의 효율성과 정확성을 증명한다.",
            "rubric": [
                "TCA 모듈; PEL 모듈; Score Smoothing 전략"
            ]
        },
        "short_answer": {
            "question": "Score Smoothing 전략으로 개선된 것은?",
            "answer": "오탐률(FAR)",
            "topic": [
                "Score Smoothing 전략의 효과"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 PEL4VAD 성능 관련 설명으로 옳지 않은 것은?",
            "choices": [
                "a) PEL 모듈은 RTFM이나 HL-Net보다 우수한 성능을 보였다.",
                "b) 일부 세분화된 이상 클래스에서 정확도가 하락했다.",
                "c) Weakly-Supervised 기반 비디오 이상 탐지를 위한 모델이다.",
                "d) 테스트 단계에서 신뢰성과 견고성을 입증했다."
            ],
            "answer": "b",
            "topic": [
                "PEL4VAD의 성능"
            ]
        },
        "true_false": {
            "question": "PEL4VAD는 효율적인 컨텍스트 모델링과 의미론적 분별력 향상을 달성했다.",
            "answer": "TRUE",
            "topic": [
                "PEL4VAD의 성과"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:22:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "비디오 단위의 이상 탐지에서 스니핏(영상 조각) 단위의 이상 점수로부터 비디오의 이상 여부를 예측하기 위해, Multiple Instance Learning (MIL) 기반의 손실 함수를 사용함. 비디오의 가장 높은 이상 점수 top-k의 평균을 계산하여 비디오 수준의 예측 값을 만들 고, 이것을 이진 교차 엔트로피(Binary Cross Entropy)로 학습 또한프롬프트를 활용하여 시각적 특징과 텍스트 프롬프트 간의 정렬을 유도하는 Cross-Modal Alignment Loss는 시각적 특징과 지식 기반 프롬프트 간의 의미적 일관성을 향상시키기 위한 Kullback-Leibler Divergence 기반 loss를 제시 최종 Loss = MIL-based Loss + λ* Cross-Modal Alignment Loss, 이를 통해 모델은 비디오 내에서 일반 및 이상 행동 간의 구분을 효과적으로 학습하며, 프롬프트를 활용하여 세분화된 이상 탐지 능력을 향상시킴",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:22:0001",
                    "page": 22
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "비디오 단위 이상 탐지에서 MIL 기반 손실과 Cross-Modal Alignment Loss를 결합해 스니핏 단위 점수로 비디오 이상 여부를 학습하고, 세분화된 이상 탐지 성능을 향상시켰다.",
        "long_answer": {
            "question": "비디오 단위의 이상 탐지의 목적과 학습 방식에 대해 설명하시오.",
            "answer": "비디오 단위의 이상 탐지는 스니핏 단위의 이상 점수를 통해 비디오의 이상 여부를 예측하기 위함이다. 이를 위해 비디오 내 top-k 이상 점수 평균으로 예측값을 계산하고, 그것을 Binary Cross Entropy로 학습하는 MIL 기반 손실을 사용한다. 또한 프롬프트를 활용한 Cross-Modal Alignment Loss를 적용하여 시각적 특징과 텍스트 프롬프트 간 의미적 일관성을 높이고, 세분화된 이상 탐지 성능을 향상시킨다. 최종 손실함수는 MIL 기반 손실과 λ*Cross-Modal Alignment Loss의 합으로 구성된다.",
            "rubric": [
                "스니핏; 이상 여부 예측; MIL 기반 손실; Cross-Modal Alignment Loss; 의미적 일관성"
            ]
        },
        "short_answer": {
            "question": "비디오 이상 탐지에서 사용하는 단위의 명칭은?",
            "answer": "스니핏",
            "topic": [
                "비디오 이상 탐지의 단위"
            ]
        },
        "multiple_choice": {
            "question": "비디오 단위 이상 탐지 학습의 특징으로 잘못된 설명은?",
            "choices": [
                "a) 프롬프트 활용으로 의미적 일관성 강화",
                "b) top-k 대신 전체 스니핏 평균 사용",
                "c) Cross-Modal Alignment Loss는 Kullback-Leibler Divergence 기반",
                "d) Binary Cross Entropy로 비디오 수준 예측 학습"
            ],
            "answer": "b",
            "topic": [
                "비디오 단위 이상 탐지 학습의 특징"
            ]
        },
        "true_false": {
            "question": "비디오 단위 이상 탐지의 프롬프트는 텍스트 프롬프트 간 정렬을 유도하기 위함이다.",
            "answer": "TRUE",
            "topic": [
                "비디오 단위 이상 탐지의 프롬프트"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:22:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "- 구현 세부 사항 1. 데이터 전처리 각 데이터셋에서 비디오 스니핏을 추출하기 위해 I3D 네트워크를 활용. 이 I3D 네트워크 는 Kinetics-400 데이터셋으로 사전 학습되어 있으며, UCF-Crime, XD-Violence, ShanghaiTech 데이터셋의 비디오에서 스니핏 특징을 추출. 데이터 증강의 경우, UCF-Crime과 ShanghaiTech에서는 각 비디오의 중심, 네 모서리, 그리고 이들의 반전된 버전을 포함한 10-crop 증강 전략을 사용하고, XD-Violence에서는 중심과 네 모서리만 포 함한 5-crop 증강을 사용",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:22:0001",
                    "page": 22
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "I3D 네트워크로 비디오 스니핏 특징을 추출하고, 데이터셋별로 10-crop 또는 5-crop 증강 전략을 적용한다.",
        "long_answer": {
            "question": "비디오 스니핏 추출 데이터셋의 종류와 각 데이터셋의 증강 전략에 대해 설명하시오.",
            "answer": "각 데이터셋에서 비디오 스니핏을 추출하기 위해 활용하는 I3D 네트워크는 Kinetics-400 데이터셋으로 사전 학습되어 있으며 UCF-Crime, XD-Violence, ShanghaiTech 데이터셋의 비디오에서 스니핏 특징을 추출한다. 데이터 증강 시, UCF-Crime과 ShanghaiTech는 각 비디오의 중심, 네 모서리, 그리고 이들의 반전 버전이 포함된 10-crop 증강 전략을 사용한다. 반면, XD-Violence는 중심과 네 모서리만 포함한 5-crop 증강 전략을 사용한다.",
            "rubric": [
                "I3D 네트워크; UCF-Crime; XD-Violence; ShanghaiTech; 10-crop; 5-crop"
            ]
        },
        "short_answer": {
            "question": "XD-Violence에서 사용되는 증강 전략은?",
            "answer": "5-crop",
            "topic": [
                "XD-Violence의 증강 전략"
            ]
        },
        "multiple_choice": {
            "question": "비디오 스니핏 추출 데이터셋의 증강 전략에 관한 설명으로 옳은 것은?",
            "choices": [
                "a) UCF-Crime은 각 비디오의 중심과 네 모서리, 반전 버전이 포함된 전략을 사용한다.",
                "b) XD-Violence는 중심과 두 모서리를 포함한 전략을 사용한다.",
                "c) ShanghaiTech는 5-crop 증강 전략을 사용한다.",
                "d) UCF-Crime은 5-crop 증강 전략을 사용한다."
            ],
            "answer": "a",
            "topic": [
                "비디오 스니핏 추출 데이터셋의 증강 전략"
            ]
        },
        "true_false": {
            "question": "I3D 네트워크는 Kinetics-400 데이터셋으로 미리 학습이 되어있다.",
            "answer": "TRUE",
            "topic": [
                "I3D 네트워크의 사전 학습"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:22:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "2. 하이퍼파라미터 세팅  TCA 모듈의 숨겨진 차원 크기는 128로 설정하고, 로컬과 글로벌 컨텍스트 융합을 위한",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:22:mh: 00001",
                    "page": 22
                }
            },
            {
                "context_id": "2",
                "text": "가중치α는 0.5로 초기화. 다층 퍼셉트론(MLP)은 두 개의 Conv1D 레이어로 구성되며 각 레이어는 512와 300개의 노드를 가지고, 드롭아웃 비율은 0.1로 설정. 로컬 윈도우 크기는 각 데이터셋마다 다르게 설정되어 UCF-Crime과 XD-Violence에서는 9, ShanghaiTech에서 는 5의 크기를 가짐. Causal Convolution의 커널 크기는 UCF-Crime, XD-Violence, ShanghaiTech에 대해 각각 9, 3, 3으로 설정. 텍스트와 비주얼 간의 정렬을 위한 온도 계 수 τ는 각 데이터셋별로 다르게 설정되는데, UCF-Crime은 0.09, XD-Violence는 0.05, ShanghaiTech는 0.2를 사용. 컨텍스트 분리를 위한 스케일링 팩터 μ는 10으로 설정하며, 손실 가중치 λ는 UCF-Crime과 XD-Violence에서 1, ShanghaiTech에서는 9로 설정.",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:22:mh: 00001",
                    "page": 23
                }
            }
        ],
        "summarization": "TCA 모듈의 차원, 융합 가중치, 윈도우 크기, 커널 크기, 온도 계수, 스케일링 팩터 및 손실 가중치 등 하이퍼파라미터를 데이터셋별로 상이하게 설정한다.",
        "long_answer": {
            "question": "TCA 모듈과 각 데이터셋에 적용된 하이퍼파라미터 설정 방식을 설명하시오.",
            "answer": "TCA 모듈의 숨겨진 차원은 128이며, 로컬과 글로벌 컨텍스트 융합 가중치 α는 0.5로 초기화한다. 다층 퍼셉트론은 두 개의 Conv1D 레이어(512, 300 노드)로 구성하고 드롭아웃 비율은 0.1로 설정한다. UCF-Crime과 XD-Violence의 로컬 윈도우 크기는 9, ShanghaiTech은 5로 설정하며 커널 크기는 각각 9, 3, 3으로 다르다. 온도 계수 τ는 데이터셋별로 0.09, 0.05, 0.2이고, 손실 가중치 λ는 UCF-Crime과 XD-Violence는 1, ShanghaiTech은 9로 설정한다.",
            "rubric": [
                "다층 퍼셉트론; 로컬 윈도우 크기; 커널 크기; 온도 계수; 손실 가중치"
            ]
        },
        "short_answer": {
            "question": "다층 퍼셉트론을 구성하는 요소는?",
            "answer": "두 개의 Conv1D 레이어",
            "topic": [
                "다층 퍼셉트론의 구성 요소"
            ]
        },
        "multiple_choice": {
            "question": "XD-Violence 데이터셋의 커널 크기에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) UCF-Crime보다 작은 값이다.",
                "b) 3으로 설정한다.",
                "c) 9로 설정한다.",
                "d) ShanghaiTech과 동일하다."
            ],
            "answer": "c",
            "topic": [
                "XD-Violence 데이터셋의 커널 크기"
            ]
        },
        "true_false": {
            "question": "온도 계수 τ는 모든 데이터셋에 일정하게 적용된다.",
            "answer": "FALSE",
            "topic": [
                "데이터셋에 적용되는 온도 계수"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:26:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "스마트시티관리 AI 기반의 실시간 사고 탐지 및 대응 시스템 구축  공공장소에서 발생하는 싸움이나 쓰러짐 상황을 자동으로 탐지해 관리센터에 알림을 전송하고 신속한 대응 유도  보안 및 감시  침입 및 이상 행동 탐지 AI를 활용한 실시간 경고 시스템 구축  보안구역에 침입이 감지될 경우 경보를 울리고, 감시 카메라 영상을 분석해 보안 인력에게 알림을 제공  재난 및 안전 관리  인파 밀집도를 예측해 사고 위험 지역에 대한 사전 경고 및 대피 안내 제공  대규모 행사장에서 인파 밀집 상황을 감지하고, 위험도가 높은 구역에 대피 방송 및 안내를 자동으로 전송  헬스케어 및 응급 서비스 군집 행동 데이터를 분석하여 공공 정책 개발에 활용  노인들이 자주 다니는 장소에서 쓰러짐이 감지될 경우, 가까운 의료기관이나 응급 대응팀에 자동으로 알림을 전송  교육 및 훈련 사고 대응 훈련 및 시뮬레이션 AI 데이터로 활용  경찰, 소방대, 보안 요원의 훈련을 위한 사고 시뮬레이션 및 행동 분석 훈련 데이터로 활용",
                "provenance": {
                    "doc_id": "24년 (04)년지능형 관제 서비스 CCTV 영상 데이터 활용 가이드라인(20250310).pdf:26:0001",
                    "page": 26
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "AI 기반 스마트시티관리 시스템은 공공장소에서의 이상 행동을 탐지하고, 다양한 분야에서 실시간 대응과 정책 개발에 활용된다.",
        "long_answer": {
            "question": "스마트시티관리 시스템의 목적과 활용 분야에 대해 서술하시오.",
            "answer": "스마트시티관리는 공공장소에서 발생하는 사고를 자동으로 탐지해 관리센터에 알림을 전송하고 신속한 대응을 유도하는 시스템이다. 침입 및 이상 행동 탐지 AI를 활용하여 실시간으로 경고하고, 인파 밀집도 예측으로 사고 위험 지역에 대해 사전 경고 및 대피 안내를 제공하고, 군집 행동 데이터를 분석하여 공공 정책 개발에 활용한다. 또한 해당 시스템은 교육 및 훈련 사고 대응 훈련과 시뮬레이션 AI 데이터로도 활용이 가능하다.",
            "rubric": [
                "침입 및 이상 행동 탐지; 사고 위험 지역 경고 및 대피 안내; 공공 정책 개발; 시뮬레이션 AI 데이터"
            ]
        },
        "short_answer": {
            "question": "스마트시티관리 시스템은 무엇을 분석하여 공공 정책 개발에 활용하는가?",
            "answer": "군집 행동 데이터",
            "topic": [
                "스마트시티관리 시스템의 공공 정책 개발 활용도"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 스마트시티관리 시스템의 기능으로 옳은 것은?",
            "choices": [
                "a) 침입 및 이상 행동 탐지 AI를 활용하여 사건 발생 후 대처한다.",
                "b) 사고 위험 지역에 대한 제보를 받는다.",
                "c) 개인 행동 데이터를 분석하여 헬스케어 서비스의 기반으로 사용한다.",
                "d) 싸움이나 쓰러짐 등의 상황을 자동으로 탐지한다."
            ],
            "answer": "d",
            "topic": [
                "스마트시티관리 시스템의 기능"
            ]
        },
        "true_false": {
            "question": "AI 기반 교육 및 훈련 시스템은 실제 사고 발생 데이터를 직접 저장하는 것이 목적이다.",
            "answer": "FALSE",
            "topic": [
                "AI 기반 교육 및 훈련 시스템의 목적"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:9:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "◯ 데이터 구축 규모 Ÿ 총 구축 수량: 원천데이터 260,000개, 라벨링데이터 260,000개, QA 데이터 3개 Ÿ 원천데이터 100,000장 및 라벨링데이터 100,000건 데이터 구축 후 YOLOv8, RT-DETR, MDETR 각 모델별 <학습, 검증, 테스트> 데이터 분류 Ÿ 폐의류 이미지 1장에 대하여 라벨링 데이터 1개로 구성되며, QA의 경우 별도로 구성됨 Ÿ 전체 분류(클래스 구분): 폐의류의 처리 목적에 따라 3종으로 분류 Ÿ 클래스 별 수집량: 의복의 형태에 따라서 11종으로 분류",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:9:0001",
                    "page": 9
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "폐의류 데이터는 원천 26만 개, 라벨링 26만 개, QA 3개로 구성되며, 처리 목적과 클래스별 수집량에 따라 분류된다.",
        "long_answer": {
            "question": "폐의류 데이터 구축 데이터 수량과 구성 방식, 클래스 구분에 대해 설명하시오.",
            "answer": "폐의류 데이터의 총 구축 수량은 원천데이터 260,000개, 라벨링데이터 260,000개, QA 데이터 3개가 포함된다. 이미지 1장에 대한 라벨링 데이터 1개로 구성되며, QA의 경우 별도로 구성된다. 클래스 구분은 폐의류 처리 목적에 따라 3종으로 분류되며, 클래스별 수집량은 의복 형태에 따라 11종으로 분류된다.",
            "rubric": [
                "원천데이터; 라벨링데이터; QA 데이터; 폐의류 처리 목적; 3종; 의복 형태; 11종"
            ]
        },
        "short_answer": {
            "question": "클래스별 수집량을 분류하는 기준은?",
            "answer": "의복 형태",
            "topic": [
                "클래스별 수집량 분류 기준"
            ]
        },
        "multiple_choice": {
            "question": "폐의류 데이터 분류 방식으로 틀린 설명은?",
            "choices": [
                "a) YOLOv8, RT-DETR, MDETR 모델별 학습/검증/테스트로 분류",
                "b) 원천데이터와 라벨링 데이터를 모두 100,000건씩 먼저 분류",
                "c) QA 데이터는 별도 구성",
                "d) 폐의류 이미지 1장당 라벨링 데이터 2개를 연결"
            ],
            "answer": "d",
            "topic": [
                "폐의류 데이터의 분류 방식"
            ]
        },
        "true_false": {
            "question": "폐의류 데이터의 원천데이터와 라벨링데이터의 수량은 동일하다.",
            "answer": "TRUE",
            "topic": [
                "폐의류 데이터의 수량 구성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:15:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 구축 절차 요약  1) 폐의류 분류 사업장에서 대분류 3종, 중분류 11종에 대해 이미지 직접 촬영 2) 촬영된 이미지에 대해 의류, 손상, 오염, 부착물 바운딩박스 라벨링 3) 이미지와 바운딩박스 기반으로 이미지캡션 작성 4) 이미지와 이미지캡션 기반으로 질의응답 데이터 작성",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:15:0001",
                    "page": 15
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "폐의류 데이터 구축은 촬영, 라벨링, 이미지 캡션 작성, 질의응답 생성 순으로 진행된다.",
        "long_answer": {
            "question": "폐의류 데이터 구축 절차에 대해 서술하시오.",
            "answer": "폐의류 데이터 구축을 위해선 분류 사업장에서 대분류 3종, 중분류 11종 이미지를 촬영해야 한다. 촬영한 이미지를 대상으로 의류, 손상, 오염, 부착물 바운딩박스 라벨링을 한다. 이후 이미지와 바운딩박스 기반 이미지캡션을 작성한다. 마지막으로 작성된 이미지캡션과 이미지를 기반으로 질의응답 데이터를 작성한다.",
            "rubric": [
                "이미지 촬영; 라벨링; 이미지캡션; 질의응답 데이터"
            ]
        },
        "short_answer": {
            "question": "폐의류 이미지의 주요 라벨링 항목은?",
            "answer": "의류, 손상, 오염, 부착물 바운딩박스",
            "topic": [
                "폐의류 이미지의 라벨링 항목"
            ]
        },
        "multiple_choice": {
            "question": "폐의류 데이터 구축 절차에 대한 내용으로 옳은 것은?",
            "choices": [
                "a) 대분류 3종, 중분류 11종에 대한 이미지를 직접 촬영한다.",
                "b) 대분류 11종, 중분류 3종에 대한 이미지를 직접 촬영한다.",
                "c) 의류, 손상 기반으로 이미지캡션을 작성한다.",
                "d) 이미지캡션 기반으로 홍보 데이터를 작성한다."
            ],
            "answer": "a",
            "topic": [
                "폐의류 데이터 구축 절차"
            ]
        },
        "true_false": {
            "question": "폐의류 데이터 구축 과정에서 캡션 작성 단계는 라벨링 이전에 수행된다.",
            "answer": "FALSE",
            "topic": [
                "폐의류 데이터 구축 시 캡션 작성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:32:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "준비단계  ▪계획수립 ▪수행 작업자 컨택 ▪작업 실무 교육  데이터수집  ▪클래스 분류가 명시 된 작업문서 전달 ▪지역별, 주차별 작업문서 수집 ▪주차별 품질검사 운영 ▪일정별 수집 목표량 점검 및 유연 운영  데이터 검수 및 저장  ▪폐의류 분류 이미지, 메타데이터 파일 검수 ▪주관기업 서버에 데이터 작업 기록 및 백업 자동화 데이터 유실 방지",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:32:0001",
                    "page": 32
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터는 준비, 수집, 검수 및 저장 단계를 거친다.",
        "long_answer": {
            "question": "데이터 검수 및 저장 단계에 대해 설명하시오.",
            "answer": "데이터 검수와 저장은 데이터 수집 이후에 진행된다. 이때 폐의류 분류 이미지와 메타데이터 파일을 검수한다. 또한 주관기업 서버에 데이터 작업을 기록하고 백업함으로써 자동화 데이터의 유실을 방지한다.",
            "rubric": [
                "파일 검수; 데이터 작업 기록 및 백업; 자동화 데이터 유실 방지"
            ]
        },
        "short_answer": {
            "question": "데이터 수집 단계에서 무엇이 명시된 작업문서를 전달받는가?",
            "answer": "클래스 분류",
            "topic": [
                "데이터 수집 단계"
            ]
        },
        "multiple_choice": {
            "question": "데이터 검수 단계와 관련이 없는 항목은?",
            "choices": [
                "a) 이미지 검수",
                "b) 자동화데이터 유실 방지",
                "c) 수집 목표량 검수",
                "d) 데이터 작업 기록"
            ],
            "answer": "c",
            "topic": [
                "데이터 검수 단계"
            ]
        },
        "true_false": {
            "question": "데이터 준비 단계에서는 데이터 백업을 먼저 수행한다.",
            "answer": "FALSE",
            "topic": [
                "데이터 준비 단계"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:33:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "정제 작업 진행 Ÿ 정제 가이드 및 정제 SW에 따라 작업 진행 - 클래스 점검 - 파일 포맷 점검 - 폐의류 이미지 / 클래스 일치성 점검 - 이미지 적절성 점검 - 중복 파일 점검 - 컬러 센서 데이터 포맷 점검",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:33:0001",
                    "page": 33
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "정제 작업에서는 클래스, 포맷, 적절성, 중복 등을 점검한다.",
        "long_answer": {
            "question": "정제 단계에서 수행되는 주요 작업 항목을 설명하시오.",
            "answer": "정제 작업은 정제 가이드 및 정제 SW에 따라 작업이 진행된다. 이때 클래스, 파일 포맷, 폐의류 이미지와 클래스 일치성을 점검한다. 이미지 적절성과 중복 파일, 컬러 센서 데이터 포맷 점검 또한 정제 작업 내용에 포함된다.",
            "rubric": [
                "클래스; 파일 포맷; 이미지/클래서 일치성; 중복 파일; 컬러 센서 데이터 포맷"
            ]
        },
        "short_answer": {
            "question": "정제 단계에서 작업의 기준이 되는 것은?",
            "answer": "정제 가이드, 정제 SW",
            "topic": [
                "정제 작업의 기준"
            ]
        },
        "multiple_choice": {
            "question": "정제 단계에서 수행되는 항목으로 옳은 것은?",
            "choices": [
                "a) 수집 목표량 점검",
                "b) 중복 파일 점검",
                "c) 작업자 교육 내용 점검",
                "d) 백업 상황 점검"
            ],
            "answer": "b",
            "topic": [
                "정제 단계의 수행 항목"
            ]
        },
        "true_false": {
            "question": "정제 작업 시, 폐의류 이미지와 클래스 일치성에 대해 점검한다.",
            "answer": "TRUE",
            "topic": [
                "정제 작업의 일치성 점검"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:33:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1차 검사  Ÿ 정제 1차 검사는 작업자가 정제한 데이터가 원천데이 터로서 적합한지 검사자가 확인하는 단계로 클래스, 파일 포맷, 이미지/클래스 일치성, 적절성, 중복 파일 삭제 여부 등을 점검 Ÿ 작업완성도에 따라 승인/거정 처리, 거절 시 작업자는 추가 정제 작업을 수행 Ÿ 재작업 검사 후 수정사항 발생 시 2차, 3차 검사/수정 을 반복 실시  2차 검사  Ÿ 검사자에 의해 1차 검사가 완료된 원천데이터에 대해 검사 담당자가 2차 검사 수행 Ÿ 검사/정제 가이드에 따라 정제 작업 내용에 대한 전수 검사 진행. 검사 기준 미달 시, 거절 처리를 하며 거절 시 작업자는 추가 수정 실시 Ÿ 검사 기준 미달 파일들의 담당 검사자에 대해 1:1 추 가 교육을 실시하여 품질 수준 확보 Ÿ 불량률이 높은 작업자 대상 재교육 실시  데이터 저장 Ÿ 2차 검수 통과한 데이터에 대해 검수 주관기관 서버에 데이터 작업 기록 및 백업 자동화 데이터 유실 방지",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:33:0001",
                    "page": 33
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터는 1차와 2차 검사를 거쳐 품질을 확인하고, 통과 데이터는 서버에 백업하여 저장한다.",
        "long_answer": {
            "question": "1차 검사의 점검 대상과 수행 내용에 대해 설명하시오.",
            "answer": "1차 검사는 작업자가 정제한 데이터가 원천데이터로 적합한지 검사자가 확인하는 단계이다. 점검 항목으로는 클래스, 파일 포맷, 이미지/클래스 일치성, 적절성, 중복 파일 삭제 여부 등을 있다. 이때 작업완성도에 따라 승인이나 거절 처리가 되며, 거절 시 작업자는 추가 정제 작업을 수행해야 한다. 재작업 검사 후 수정사항이 발생하면 2차, 3차 검사 및 수정을 반복한다.",
            "rubric": [
                "작업자 정제 데이터; 점검 항목; 작업완성도; 검사 및 수정 반복"
            ]
        },
        "short_answer": {
            "question": "1차와 2차 검사 후 품질을 확보한 데이터가 저장되는 공간은?",
            "answer": "검수 주관기관 서버",
            "topic": [
                "품질 확보된 데이터의 저장 공간"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 2차 검사에 관한 설명으로 옳지 않은 것은?",
            "choices": [
                "a) 거절 처리가 된 작업자는 추가 작업을 실시한다.",
                "b) 정제 작업 내용의 핵심 부분에 대한 심화 검사를 실시한다.",
                "c) 불량률이 높은 작업자는 재교육을 진행한다.",
                "d) 검사 기준 미달 파일 담당 검사자를 1:1로 교육한다."
            ],
            "answer": "b",
            "topic": [
                " 2차 검사의 수행 항목"
            ]
        },
        "true_false": {
            "question": "1차 검사에서는 클래스, 파일 포맷, 이미지/텍스트 일치성 등을 점검한다.",
            "answer": "FALSE",
            "topic": [
                "1차 검사의 점검 항목"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:34:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "원천데이터 확인 Ÿ 수집한 원천데이터(폐의류 이미지) 정보를  데이터 명세서와 비교하여 확인  라벨링  Ÿ 공통 : 이미지 상 의류의 정보, 파일 정보 Ÿ 재사용 : 객체 ID 생성 및 객체 정보, 분류 코드, 의류 외곽 bbox 라벨링 Ÿ 재활용 :객체 ID 생성 및 객체 정보, 비정상 영역 bbox 라벨링, 부착물 bbox 라벨링 Ÿ 폐기 : 객체 ID 생성 및 객체 정보, 비정상 영역 bbox 라벨링 라벨링 검수 Ÿ 검수를 통해 반려 및 라벨링 수정  이미지 캡션  Ÿ 이미지에서 육안 상으로 확인할 수 있는 객관적인 정보를 토대로 한 문장을 완성하는 이미지 캡션 작성 Ÿ 재활용ᆞ폐기 의류 이미지에 대하여 완성된 이미지 캡션을 토대로 질의ᆞ응답 작성  이미지 캡션 검수 Ÿ 검수를 통해 반려 및 이미지 캡션 수정 데이터 저장  완료된 결과물(.json) 데이터 NAS 업로드하여 작업 기록 및 백업 자동화로 데이터 유실 방지",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:34:0001",
                    "page": 34
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "수집한 데이터는 원천 확인과 라벨링, 이미지 캡션 작성 후 검수를 거쳐 NAS 서버에 저장된다.",
        "long_answer": {
            "question": "이미지 캡션 과정에 대해 설명하시오.",
            "answer": "이미지 캡션은 이미지에서 육안으로 확인할 수 있는 객관적인 정보를 토대로 한 문장을 완성하는 작업이다. 폐기 의류 이미지에 대해 완성된 이미지 캡션을 토대로 질의 및 응답을 작성한다. 이후 검수를 통해 반려하거나 이미지 캡션을 수정하는 방식으로 이루어진다.",
            "rubric": [
                "객관적 정보; 질의 및 응답; 검수; 반려 및 수정"
            ]
        },
        "short_answer": {
            "question": "완성된 폐의류 이미지 캡션과 라벨링 결과물이 저장되는 곳은?",
            "answer": "NAS",
            "topic": [
                "이미지 캡션 및 라벨링 결과물 저장"
            ]
        },
        "multiple_choice": {
            "question": "이미지 캡션 작성 시 문장을 완성하는 기준으로 알맞은 것은?",
            "choices": [
                "a) 외부 설명 자료 인용",
                "b) 작업자 판단",
                "c) 이전 데이터의 캡션 복사",
                "d) 육안으로 확인 가능한 객관적 정보"
            ],
            "answer": "d",
            "topic": [
                "이미지 캡션 작성 기준"
            ]
        },
        "true_false": {
            "question": "이미지 상 의류 정보, 파일 정보에는 공통적으로 라벨링이 들어간다.",
            "answer": "TRUE",
            "topic": [
                "이미지에 적용되는 공통 라벨링"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:41:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "클래스 점검 Ÿ 수집 대상 클래스 내역에 포함되어 있는지 여부 확인 Ÿ 수집 대상 클래스 외 수집 데이터에 관해서는 삭제 처리  파일 포맷 점검  Ÿ 폐의류 이미지는 래스터 형태의 이미지 파일(JPG)로 제작 Ÿ 폐의류 이미지 해상도 및 비율 점검 - 해상도 : 3000 × 4000 이상 - 이미지 비율 : 3 : 4 Ÿ 폐의류의 컬러 센서 데이터의 포맷 RGB 형식 점검  클래스 일치성 점검  Ÿ 폐의류 이미지는 동일한 클래스 객체로 표현되어야 함 Ÿ 폐의류 이미지와 재사용 복종 클래스가 일치하지 않거나 유사성이 현저히 떨 어질 경우 반려 대상 Ÿ 폐의류 이미지와 재활용 손상 클래스가 일치하지 않거나 유사성이 현저히 떨 어질 경우 반려 대상 Ÿ 컬러 센서 데이터와 폐의류 이미지의 육안상 컬러가 일치하지 않거나 유사성 이 현저히 떨어질 경우 반려 대상  데이터 적절성 점검  Ÿ RFP 요구사항에 준하는 데이터 카테고리 점검 Ÿ 재사용/재활용/폐기 여부에 따라 데이터의 파일명이 사전 정의된 분류 코드 순으로 정리가 되어 있는지 점검 Ÿ 컬러 센서 데이터의 포맷 형식 점검  이미지 적절성 점검  Ÿ 폐의류 이미지는 이미지 내에 폐의류가 벗어남 없이 모든 부분을 시각적으로 확인할 수 있는 형태로 수집되어야 함 Ÿ 폐의류 이미지는 조명, 이물질 등 상태를 확인할 수 없게 만드는 외부 요인 이 없는 상태로 수집되어야 함  중복파일 점검 Ÿ 동일한 클래스에 대한 폐의류 데이터를 반복 수집한 경우 데이터 품질이 가  장 우수한 항목을 최종 데이터로 선정  저작권 Ÿ 2차 저작권, 기업 상표권에 대한 이슈 사항 점검 확인",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:41:0001",
                    "page": 41
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "폐의류 데이터는 클래스, 포맷, 일치성, 적절성, 중복, 저작권을 중심으로 품질 점검을 수행한다.",
        "long_answer": {
            "question": "데이터 적절성 점검 대상과 방식에 대해 서술하시오.",
            "answer": "데이터 적절성 점검 과정에서는 RFP 요구사항에 준하는 데이터 카테고리를 점검한다. 재사용/재활용/폐기 여부에 따라 데이터의 파일명이 사전에 정의된 분류 코드 순으로 정리가 되어있는지 점검한다. 컬러 센서 데이터의 포맷 형식 점검 또한 데이터 적절성의 점검 항목이다.",
            "rubric": [
                "RFP; 분류 코드; 컬러 센서 데이터 포맷 형식"
            ]
        },
        "short_answer": {
            "question": "폐의류 이미지의 비율은?",
            "answer": "3:4",
            "topic": [
                "폐의류 이미지의 비율"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 폐의류 데이터 중복파일 점검 시 수행하는 조치로 적절한 것은?",
            "choices": [
                "a) 무작위로 하나 선택",
                "b) 가장 해상도가 낮은 파일 선정",
                "c) 품질이 가장 우수한 항목을 최종 데이터로 선정",
                "d) 모든 중복 파일 삭제"
            ],
            "answer": "c",
            "topic": [
                "폐의류 데이터의 중복파일 점검"
            ]
        },
        "true_false": {
            "question": "폐의류 데이터는 클래스 외 수집 항목도 품질 확보를 위해 유지된다.",
            "answer": "FALSE",
            "topic": [
                "폐의류 데이터의 클래스"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:41:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "재사용 의류  라벨링    Ÿ 이미지의 의류 객체에 바운딩박스 라벨링  Ÿ 의류 상하좌우 영역의 외곽을 기준으로 하여 처리  Ÿ 태깅 범위 오차범위 : ±20px 까지 허용",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:41:0001",
                    "page": 41
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "재사용 의류는 의류 객체를 기준으로 하며, 오차 범위를 허용한다.",
        "long_answer": {
            "question": "재사용 의류 라벨링 시, 적용되는 기준에 대해 설명하시오.",
            "answer": "재사용 의류의 라벨링은 이미지의 의류 객체에 바운딩박스 라벨링을 한다. 이때 의류 상하좌우 영역 외관을 기준으로 하여 처리한다. 태깅 범위의 오차범위는 ±20px까지 허용된다.",
            "rubric": [
                "의류 객체; 바운딩박스 라벨링; 영역 외관; 오차범위"
            ]
        },
        "short_answer": {
            "question": "재사용 의류 라벨링의 태깅 오차범위는 얼마까지 허용되는가?",
            "answer": "20px",
            "topic": [
                "재사용 의류 라벨링의 태깅 오차범위"
            ]
        },
        "multiple_choice": {
            "question": "재사용 의류 라벨링 기준에 해당하지 않는 것은?",
            "choices": [
                "a) 50px 이상 오차 허용",
                "b) 바운딩박스 라벨링 수행",
                "c) 객체 외곽 기준 처리",
                "d) 20px 오차 허용"
            ],
            "answer": "a",
            "topic": [
                "재사용 의류 라벨링의 기준"
            ]
        },
        "true_false": {
            "question": "재사용 의류 라벨링은 의류 내부 패턴을 기준으로 한다.",
            "answer": "FALSE",
            "topic": [
                "재사용 의류 라벨링의 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:42:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "Ÿ 재활용 의류의 손상 영역인 찢어짐, 헤짐 부분에 대하여 바운딩박스 라벨링 Ÿ 육안상 식별할 수 있는 손상 영역을 대상으로 하여 라벨링 처리 Ÿ 손상 영역이 여러 부분일 경우 복수개의 라벨링 진행 Ÿ 손상 영역이 이어져 있어 특정하기 어려울 경우 해당 부분 전체를 라벨링 Ÿ 재활용 의류의 부착물(단추, 지퍼)을 대상으로 바운딩박스 라벨링 - 의류에 붙어 있는 섬유 소재 외의 부착물을 대상으로 함 - 섬유 소재의 주머니, 벨트고리, 자수, 드로스트링 등은 부착물에서 제외 - 섬유 소재가 아닌 단추, 지퍼, 프린팅 등을 부착물 대상으로 처리 Ÿ 육안상 부착물이 보일 경우에만 라벨링 진행 Ÿ 부착물의 외곽 영역을 기준으로 하여 처리 Ÿ 태깅 범위 오차범위 : ±50px 까지 허용",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:42:0001",
                    "page": 42
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "재활용 의류의 손상 영역과 부착물은 육안으로 확인 가능한 부분을 바운딩박스로 라벨링하며, 오차범위를 허용한다.",
        "long_answer": {
            "question": "재활용 의류의 손상 영역과 부착물 라벨링 기준을 서술하시오.",
            "answer": "재활용 의류의 손상 영역인 찢어짐과 헤짐은 육안으로 식별 가능한 부분을 기준으로 바운딩박스로 라벨링한다. 손상 영역이 여러 곳이면 복수 라벨링을, 영역이 이어져 있어 구분이 어려운 경우에는 해당 부분 전체를 라벨링한다. 또한 단추나 지퍼, 프린팅 등 섬유 소재가 아닌 부착물에 대해서만 외곽 영역을 기준으로 라벨링하며, 태깅 오차범위는 ±50px까지 허용한다.",
            "rubric": [
                "육안 식별; 바운딩박스; 손상 영역; 부착물; 오차범위"
            ]
        },
        "short_answer": {
            "question": "손상 영역 특정이 어려운 재활용 의류의 라벨링 방식은?",
            "answer": "해당 부분 전체를 라벨링",
            "topic": [
                "손상 영역 특정이 어려운 재활용 의류의 라벨링"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 재활용 의류 부착물 라벨링 기준이라고 볼 수 없는 것은?",
            "choices": [
                "a) 섬유 소재의 주머니나 자수는 부착물로 포함된다.",
                "b) 지퍼와 단추는 부착물로 처리한다.",
                "c) 부착물의 외곽을 기준으로 라벨링한다.",
                "d) 육안으로 확인 가능한 부착물만 라벨링한다."
            ],
            "answer": "a",
            "topic": [
                "재활용 의류 부착물의 라벨링 기준"
            ]
        },
        "true_false": {
            "question": "재활용 의류에서 눈으로 부착물이 보이지 않을 경우, 라벨링을 하지 않아도 된다.",
            "answer": "TRUE",
            "topic": [
                "재활용 의류 부착물의 라벨링 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:43:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "Ÿ 폐기 의류의 오염 부분에 대하여 바운딩박스 라벨링  Ÿ 육안상 식별할 수 있는 오염 영역을 대상으로 하여 라벨링 처리  Ÿ 오염 영역이 여러 부분일 경우 복수개의 라벨링 진행  Ÿ 오염 영역이 이어져 있어 특정하기 어려울 경우 해당 부분 전체를 라벨링  Ÿ 태깅 범위 오차범위 : ±50px 까지 허용",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:43:0001",
                    "page": 43
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "폐기 의류는 오염 영역에 따라 바운딩박스로 라벨링하며, 오차범위를 허용한다.",
        "long_answer": {
            "question": "폐기 의류의 경우에는 라벨링을 어떤 방식으로 진행하는지 설명하시오.",
            "answer": "폐기 의류의 오염 부위는 육안으로 식별 가능한 영역을 기준으로 바운딩박스로 라벨링한다. 오염 부위가 여러 곳이면 복수 라벨링을 진행하며, 오염 영역이 이어져 있어 특정이 어려운 경우에는 해당 부분 전체를 라벨링한다. 이때 태깅 오차범위는 ±50px까지 허용된다.",
            "rubric": [
                "육안 식별; 바운딩박스; 오염 영역; 오차범위"
            ]
        },
        "short_answer": {
            "question": "육안상 폐기 의류 오염 부분이 3곳이면 라벨링은 몇 개를 하는가?",
            "answer": "3개",
            "topic": [
                "폐기 의류 오염 부분에 따른 라벨링 개수"
            ]
        },
        "multiple_choice": {
            "question": "폐기 의류의 오염 영역 라벨링에 대한 설명으로 적합한 것은?",
            "choices": [
                "a) 태깅 오차범위는 ±20px까지 허용된다.",
                "b) 오염 부위가 이어져 있을 경우 라벨링하지 않는다.",
                "c) 육안으로 식별 가능한 오염 영역을 기준으로 라벨링한다.",
                "d) 오염이 여러 곳이면 하나의 라벨링만 적용한다."
            ],
            "answer": "c",
            "topic": [
                "폐기 의류의 오염 영역 라벨링"
            ]
        },
        "true_false": {
            "question": "폐기 의류의 오염 영역은 육안으로 식별 가능한 부분만 라벨링한다.",
            "answer": "TRUE",
            "topic": [
                "폐기 의류의 오염 영역 라벨링"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:46:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터  수집/획득    1) 이미지 촬영  2) 메타데이터 획득    Ÿ 폐의류 분류 현장 폐의류 촬영으  로 이미지 획득  Ÿ 현장에서 이미지에 따른 메타데  이터 입력  Ÿ 컬러 센서 데이터 입력    Ÿ 원시데이터 110,000장  획득  Ÿ 목표대비 10% 초과  촬영을 통해 정제 시 탈락  데이터 대비",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:46:0001",
                    "page": 46
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "폐의류 데이터 수집/획득은 이미지를 촬영 및 데이터를 입력하는 과정이다.",
        "long_answer": {
            "question": "폐의류 데이터 수집/획득 단계의 주요 절차에 대해 설명하시오.",
            "answer": "폐의류 데이터의 수집/획득 과정은 일단 분류 현장에서 이미지를 촬영해 메타데이터를 확보한다. 이후 각 이미지에 대한 메타데이터와 컬러 센서 데이터를 현장에서 입력한다. 총 110,000장의 원시데이터를 확보하며, 목표 대비 10%를 초과적으로 촬영하여 정제 과정 중 탈락 데이터를 대비한다.",
            "rubric": [
                "메타데이터; 컬러 센서 데이터; 원시데이터; 탈락 데이터"
            ]
        },
        "short_answer": {
            "question": "폐의류 데이터 수집/획득 단계에서 목표 대비 초과 촬영하는 이유는?",
            "answer": "정제 시 탈락 데이터 대비",
            "topic": [
                "목표 대비 초과 촬영의 목적"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 데이터 수집 단계의 특징으로 볼 수 없는 것은?",
            "choices": [
                "a) 폐의류 현장에서 직접 촬영한다.",
                "b) 확보된 데이터는 목표 대비 10% 부족한 수준이다.",
                "c) 이미지별 메타데이터와 컬러 센서 데이터가 필요하다.",
                "d) 정제 시 탈락 데이터를 고려해 일부러 초과치를 넘겨 촬영한다."
            ],
            "answer": "b",
            "topic": [
                "데이터 수집 단계의 특징"
            ]
        },
        "true_false": {
            "question": "폐의류 데이터는 분류 현장에서 촬영과 동시에 메타데이터 및 컬러 센서 데이터가 입력된다.",
            "answer": "TRUE",
            "topic": [
                "폐의류 데이터의 촬영 및 데이터 입력"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:46:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 정제 1) 기계적 정제  2) 휴먼 정제    Ÿ 자체 제작 프로그램을 이용한  데이터 중복 검사 및 포맷 점검  Ÿ 정제 가이드에 따라 작업 진행    Ÿ 원천데이터 100,000장  구축",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:46:0001",
                    "page": 46
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 정제는 두 종류로, 중복 검사와 포맷 점검을 수행하고 가이드에 따라 작업이 진행된다.",
        "long_answer": {
            "question": "데이터 정제의 종류와 진행 방식을 서술하시오.",
            "answer": "데이터 정제는 기계적 정제와 휴먼 정제로 나뉜다. 정제 시 자체 제작 프로그램으로 데이터 중복 검사와 포맷 점검이 이루어지며, 모든 작업은 정제 가이드에 따른다. 그 결과, 원천데이터 10만 장이 구축되었다.",
            "rubric": [
                "기계적 정제; 휴먼 정제; 데이터 중복 검사; 포맷 점검; 정제 가이드"
            ]
        },
        "short_answer": {
            "question": "데이터 정제의 종류는?",
            "answer": "기계적 정제, 휴먼 정제",
            "topic": [
                "데이터 정제의 종류"
            ]
        },
        "multiple_choice": {
            "question": "데이터 정제 단계에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 정제 시, 구축 가이드를 따른다.",
                "b) 기계적 정제의 비율이 대부분을 차지한다.",
                "c) 외부 상용 프로그램으로 데이터 중복을 제거한다.",
                "d) 자체 제작 프로그램을 사용한다."
            ],
            "answer": "d",
            "topic": [
                "데이터 정제 단계"
            ]
        },
        "true_false": {
            "question": "데이터 정제 시, 정확도를 고려하여 사람의 공수는 배제한다.",
            "answer": "FALSE",
            "topic": [
                "데이터 정제 수행 대상"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:46:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 가공 (라벨링)  1) 이미지 바운딩박스 라벨링 2) 이미지캡션 가공 3) 질의응답 캡션 가공  Ÿ 재사용 의류, 재활용 의류, 폐기 의류의 의류 전체 영역 바운딩박스 라벨링 Ÿ 재활용 의류의 손상, 부착물 부분 바운딩박스 라벨링 Ÿ 폐기 의류의 오염 부분 바운딩 박스 라벨링 Ÿ 이미지캡션 진행 Ÿ 질의응답캡션 진행  Ÿ 라벨링데이터 100,000건 구축 Ÿ 이미지캡션 100만 토큰 이상 구축 Ÿ 질의응답 캡션 VQA.JSON 생성 Ÿ 데이터 학습을 위하여 각 모델별 <학습, 검증, 테스트> 데이터로 분리하여 원천데이터 총 260,000장 / 라벨링데이터 총 260,000건 구축",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:46:0001",
                    "page": 46
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 가공은 바운딩박스 라벨링, 이미지캡션, 질의응답 캡션으로 구성되며, 총 260,000장 원천데이터와 260,000건 라벨링데이터를 구축했다.",
        "long_answer": {
            "question": "데이터 가공의 종류와 결과에 대해 서술하시오.",
            "answer": "데이터 가공은 이미지 바운딩박스 라벨링, 이미지캡션 가공, 질의응답 캡션 가공으로 구성된다. 가공의 결과는 라벨링데이터 100,000건, 이미지캡션의 경우 100만 토큰 이상 구축되었다. 질의응답 캡션 VQA와 JSON이 생성되었고, 각 모델별 학습, 검증, 테스트 데이터로 분리하여 원천데이터 총 260,000장, 라벨링데이터 총 260,000건이 구축되었다.",
            "rubric": [
                "이미지 바운딩박스 라벨링; 이미지캡션 가공; 질의응답 캡션 가공; VQA; JSON"
            ]
        },
        "short_answer": {
            "question": "데이터 가공을 통해 생성된 질의응답 캡션 양식은?",
            "answer": "VQA, JSON",
            "topic": [
                "질의응답 캡션의 양식"
            ]
        },
        "multiple_choice": {
            "question": "가공 데이터를 학습, 검증, 테스트 세트로 분리하는 이유로 옳은 것은?",
            "choices": [
                "a) 파일 용량 축소",
                "b) 모델 학습",
                "c) 데이터 중복 방지",
                "d) 수작업 편의성 개선"
            ],
            "answer": "b",
            "topic": [
                "가공 데이터의 세트 분리 목적"
            ]
        },
        "true_false": {
            "question": "질의응답 캡션은 이미지와 무관한 외부 데이터 기반으로 작성된다.",
            "answer": "FALSE",
            "topic": [
                "질의응답 캡션의 작성 기반"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:46:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "AI 모델 학습 1) 알고리즘 개발 2) 학습 모델을 활용하여 구축 데이터 셋 유효성 검증  Ÿ 의류 종류 분류 성능:Accuracy/F1-score  Ÿ 학습 80,000장 Ÿ 테스트 10,000장 Ÿ 검증 10,000장 Ÿ 유효성 지표/결과 - Accuracy/ 95.95% - F1-score / 95.84%  Ÿ 손상ᆞ오염ᆞ부착물 탐지 성능:mAP@IoU50  Ÿ 학습 48,000장 Ÿ 테스트 6,000장 Ÿ 검증 6,000장 Ÿ 유효성 지표/결과 - mAP@IoU50 / 66.46  Ÿ 시각적 질의응답 성능:Accuracy  Ÿ 학습 80,000장 Ÿ 테스트 10,000장",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:46:mh: 00001",
                    "page": 46
                }
            },
            {
                "context_id": "2",
                "text": "Ÿ 검증 10,000장  Ÿ 유효성 지표/결과 - Accuracy/ 84.84%",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:46:mh: 00001",
                    "page": 47
                }
            }
        ],
        "summarization": "AI 모델 학습 단계에서는 의류 종류 분류, 손상/오염/부착물 탐지, 시각적 질의응답 성능을 검증한다.",
        "long_answer": {
            "question": "AI 모델 학습 단계에서 데이터셋 유효성을 검증하는 방식과 사용된 지표에 대해 설명하시오.",
            "answer": "AI 모델 학습 단계에서는 알고리즘 개발과 학습 모델을 활용하여 구축 데이터셋 유효성을 검증한다. 검증 대상은 의류 종류 분류, 손상/오염/부착물 탐지, 시각적 질의응답 성능이다. 이때 각 영역별로 학습, 테스트, 검증 데이터를 활용한다. 의류 종류 분류에는 Accurac와 F1-score, 손상/오염/부착물 탐지에는 mAP@IoU50, 시각적 질의응답 성능에는 Accuracy 지표가 각각 사용되었다.",
            "rubric": [
                "의류 종류 분류; 손상/오염/부착물 탐지; 시각적 질의응답 성능; Accuracy; F1-score; mAP@IoU50"
            ]
        },
        "short_answer": {
            "question": "시각적 질의응답 성능 검증 시 사용된 지표는?",
            "answer": "Accuracy",
            "topic": [
                "시각적 질의응답 성능 검증 지표"
            ]
        },
        "multiple_choice": {
            "question": "구축 데이터셋 유효성 검증에 관한 설명으로 부적절한 것은?",
            "choices": [
                "a) 의류 종류 분류 검증 시, Accuracy에서 더 좋은 평가를 받았다.",
                "b) 시각적 질의응답 성능 검증에는 10,000장의 데이터가 사용되었다.",
                "c) 부착물 탐지 검증에 사용되는 지표는 mAP@IoU50이다.",
                "d) 부착물 탐지 검증에 사용되는 지표는 F1-score다."
            ],
            "answer": "d",
            "topic": [
                "구축 데이터셋 유효성 검증"
            ]
        },
        "true_false": {
            "question": "AI 모델 학습 단계에서는 오염 탐지 관련 유효성도 검증된다.",
            "answer": "TRUE",
            "topic": [
                "AI 모델 학습 단계의 유효성 검증"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:48:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "- (YOLOv8) YOLO는 2015년 출시된 모델로, 객체의 좌표와 클래스를 한번에 예측함으로써 처리과정을 간소화하여 속도를 높임. Anchor Box, Feature Pyramid Pooling, Mosaic Augmentation 등의 기술이 추가되면서 현재 YOLOv9까지 출시 - YOLOv8은 2023년 1월 Ultralytics사에서 공개한 모델이며 정확도와 속도 간의 최적의 균형을 유지하는 데 중점을 둬 실시간 물체 감지 작업에 적합 - (YOLOv8 특징) 앵커를 사용하지 않아 오프셋 대신 객체의 중심을 직접 예측하며 이로 인해 상자 예측 수를 줄여 NMS을 가속화 - Head의 구조를 regression과 classification으로 분리한 decoupled head를 사용하므로써 one head 에 비해 속도와 AP를 향상시킴",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:48:mh: 00001",
                    "page": 48
                }
            },
            {
                "context_id": "2",
                "text": "- YOLOv5에서 사용된 Convolution Block을 일부 변경(C3를 C2F로 교체, 일부 레이어의 크기 변경 및 삭제)을 통해 파라미터 수를 줄임 - YOLOv4에서 제안되었던 Mosaic Augmentation Mosaic Augmentation: 4개의 이미지를 하나로 연결하여 모델이 부분 폐색, 및 다른 주변 픽셀에 대해 객체를 학습할 수 있도록 데이터를 증강하는 방법 에 대해 성능 저하를 확인하여 마지막 10 epoch에서는 사용하지 않도록 변경하여 성능을 개선",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:48:mh: 00001",
                    "page": 49
                }
            }
        ],
        "summarization": "YOLOv8은 앵커를 사용하지 않고 decoupled head를 적용해 속도와 정확도를 개선한 실시간 객체 감지 모델이다.",
        "long_answer": {
            "question": "YOLOv8의 구조적 특징과 성능 개선 방법에 대해 서술하시오.",
            "answer": "YOLOv8은 앵커를 사용하지 않아 객체 중심을 직접 예측하여 상자 예측 수를 줄여 NMS를 가속화한다. Head 구조를 regression과 classification으로 분리된 decoupled head를 사용하여 속도와 AP를 향상시킨다. 또한, 기존 모델에서 사용되었던 일부 Convolution Block의 일부 변경을 통해 파라미터 수를 감소시킨다.",
            "rubric": [
                "객체 중심 직접 예측; decoupled head; Convolution Blok"
            ]
        },
        "short_answer": {
            "question": "YOLOv8에서는 Convolution Block의 레이어 크기 변경이나 삭제 외 또 어떤 것을 변경하였는가?",
            "answer": "CF를 C2F로 교체",
            "topic": [
                "YOLOv8의 Convolution Block 변경"
            ]
        },
        "multiple_choice": {
            "question": "YOLOv8의 설계 특징으로 올바른 것은?",
            "choices": [
                "a) 앵커 기반 예측 구조",
                "b) Mosaic Augmentation 고정 적용",
                "c) decoupled head 적용",
                "d) C3 적용 유지"
            ],
            "answer": "c",
            "topic": [
                "YOLOv8의 설계 특징"
            ]
        },
        "true_false": {
            "question": "YOLOv8은 객체 중심을 직접 예측하기 때문에 앵커가 필요하지 않다.",
            "answer": "TRUE",
            "topic": [
                "YOLOv8의 앵커 필요성"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:49:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "- (RT-DETR) CVPR 2024에 발표된 DETRs Beat YOLOs on Real-time Object Detection에서 제안된 모델이며 자연어처리에서 많이 사용되는 Transformer 구조를 사용 - RT-DETR은 backbone, efficient hybrid encoder, 클래스와 bounding box를 생성하는 head가 있는 Transformer decoder로 구성 - (RT-DETR 특징) NMS와 같은 수작업 구성 요소를 제거하면서 파이프라인을 단순화한 end-to-end object detection을 실현 - Transformer의 encoder 대신 사용되는 efficient hybrid encoder의 입력으로 backbone의 마지막 세 단계의 출력 feature를 활용함으로써 특징 상호작용 및 스케일 간 특징 융합을 통해 일련의 이미 지 feature로 변환 - 보조 예측 헤드가 있는 디코더는 Transformer의 decoder와 달리 순차적으로 예측하지 않고 N개의 bounding box를 동시에 출력하며, ground truth의 어떤 object를 검출하고 있는지 1:1로 매칭하는 bipartite matching을 진행. 이로써 NMS로 인한 지연을 방지 - 또한 인코더 출력 시퀀스에서 고정된 개수의 이미지 feature를 선택하는 데 사용되는 IoU-aware query selection을 통해 디코더의 object query 초기화를 개선함으로써 가장 관련성이 높은 객체에 집중하여 정확도를 높임",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:49:0001",
                    "page": 49
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "RT-DETR은 Transformer 구조를 활용해 NMS를 제거하고 end-to-end object detection을 구현한 모델이다.",
        "long_answer": {
            "question": "RT-DETR이 파이프라인 단순화 및 탐지 효율을 높인 핵심 원리를 설명하시오.",
            "answer": "RT-DETR은 NMS와 같은 수작업 구성 요소를 제거하여 end-to-end object detection를 실현했다. 디코더가 순차적 예측 대신 N개의 bounding box를 동시에 출력하며 bipartite matching을 통해 ground truth의 object와 1:1 매칭한다. 또한 IoU-aware query selection을 적용해 디코더가 관련성이 높은 객체에 집중하도록 하여 탐지 정확도를 높였다.",
            "rubric": [
                "NMS; end-to-end object detection; bipartite matching; IoU-aware query selection"
            ]
        },
        "short_answer": {
            "question": "RT-DETR에서 NMS를 대체하여 객체를 1:1로 매칭하는 방식은?",
            "answer": "bipartite matching",
            "topic": [
                "RT-DETR의 탐지 방식"
            ]
        },
        "multiple_choice": {
            "question": "RT-DETR의 구조적 구성 요소로 옳지 않은 것은?",
            "choices": [
                "a) decoupled head",
                "b) backbone",
                "c) efficient hybrid encoder",
                "d) Transformer decoder"
            ],
            "answer": "a",
            "topic": [
                "RT-DETR의 구성 요소"
            ]
        },
        "true_false": {
            "question": "RT-DETR의 디코더는 YOLO처럼 순차적으로 bounding box를 하나씩 생성한다.",
            "answer": "FALSE",
            "topic": [
                "RT-DETR의 구조"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:50:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "- (MDETR 성능) 사전 훈련된 RoBERTa 기반 모델이 텍스트 인코더로 사용하였으며, 정확도를 확인하 기 위해 두 가지 서로 다른 감지 backbone 모델인 ResNet-101과 EfficientNetB3가 MDETR에 적용 - (MDETR 다운스트림, VQA 성능) VQA 다운스트림 모델은 질문 단어를 개체 상자와 정렬하기 위해 GQA 데이터 세트의 장면 그래프를 활용하였으며, MEDTR은 객체 탐지 및 특수 질문 처리를 위해 디코더에 학습된 임베딩으로 객체 쿼리를 통합하여 성능 평가 수행",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:50:0001",
                    "page": 50
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "MDETR은 텍스트 인코더로 RoBERTa를 활용하고, ResNet-101과 EfficientNetB3를 적용해 객체 탐지와 질의응답 성능을 평가한 모델이다.",
        "long_answer": {
            "question": "MDETR 모델의 구성 요소와 질의응답 성능 평가 방식에 대해 설명하시오.",
            "answer": "MDETR은 사전에 훈련된 RoBERTa를 텍스트 인코더로 사용한다. 정확도 확인을 위해 ResNet-101과 EfficientNetB3 두 가지 backbone 모델을 적용하였다. GQA 데이터 세트의 장면 그래프를 활용하여 질문 단어와 객체 상자를 정렬하고, 디코더에 학습된 임베딩 기반 객체 쿼리를 통합하여 수행하였다.",
            "rubric": [
                "텍스트 인코더; backbone 모델; GQA 데이터 세트; 객체 쿼리"
            ]
        },
        "short_answer": {
            "question": "MDETR에서 사용된 텍스트 인코더는?",
            "answer": "RoBERTa",
            "topic": [
                "MDETR의 구성 요소"
            ]
        },
        "multiple_choice": {
            "question": "MDETR의 성능 평가를 위해 활용된 데이터 세트는?",
            "choices": [
                "a) MS-COCO",
                "b) GQA",
                "c) EfficientNetB3",
                "d) ResNet-101"
            ],
            "answer": "b",
            "topic": [
                "MDETR의 성능 평가"
            ]
        },
        "true_false": {
            "question": "MDETR은 EfficientNetB3 backbone 모델만을 사용하여 평가되었다.",
            "answer": "FALSE",
            "topic": [
                "MDETR의 성능 평가"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:59:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "폐의류 분류 자동화 서비스  활용  폐의류의 손상, 오염, 부착물 탐지로 폐의류 분류 자동화 서비스 및 연구개발에 활용  시각적질의응답 활용 영세 폐의류 업장 및 개인을 위한 중고 의류 분류 서비스에 활용 데이터 셋을 통한 표준화 및 적용성 확대  데이터 셋의 프로세스 및 분석, 가공 도구는 오픈소스 기반으로 제작되어 데이터 이용자가 다양한 분석에 활용 폐의류 분류 데이터셋의 표준체계 정립 가능",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인(서식)_241228_v.1.3.pdf:59:0001",
                    "page": 59
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "폐의류 데이터는 손상, 오염, 부착물 탐지와 시각적 질의응답을 통해 폐의류 분류 자동화 및 서비스 표준화에 활용된다.",
        "long_answer": {
            "question": "폐의류 분류 자동화 서비스의 주요 활용 방안에 대해 설명하시오.",
            "answer": "폐의류의 손상, 오염, 부착물 탐지로 폐의류 분류 자동화 서비스 및 연구개발에 활용된다. 또한 시각적질의응답 기능을 활용하여 영세 폐의류 업장이나 개인의 중고 의류 분류 서비스에도 적용된다. 이 데이터 셋의 프로세스와 분석, 가공 도구는 오픈소스 기반으로 제작되어 데이터 이용자가 분석에 활용할 수 있게 하였으며, 폐의류 분류 데이터셋의 표준체계 정립이 가능하다.",
            "rubric": [
                "자동화 서비스; 연구개발; 시각적질의응답; 데이터셋 표준체계 정립"
            ]
        },
        "short_answer": {
            "question": "폐의류 분류 자동화 서비스에서 영세 업장과 개인을 위해 활용되는 기술은?",
            "answer": "시각적질의응답",
            "topic": [
                "폐의류 분류 자동화 서비스의 활용"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 폐의류 데이터셋의 특징으로 옳지 않은 것은?",
            "choices": [
                "a) 오픈소스 기반",
                "b) 다양한 분석에 활용",
                "c) 표준체계 정립이 가능",
                "d) 외부 비공개 시스템을 통한 접근"
            ],
            "answer": "d",
            "topic": [
                "폐의류 데이터셋의 특징"
            ]
        },
        "true_false": {
            "question": "폐의류 분류 자동화 서비스는 손상, 오염, 부착물 탐지 기능과 관련이 있다.",
            "answer": "TRUE",
            "topic": [
                "폐의류 분류 자동화 서비스의 특징"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:6:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 형식 - 3D CAD 스캔데이터(*.obj, *.mtl, *.png) - 실제/가상 환경 촬영 데이터(*.png, *.npy) 데이터 출처 - 제조, 물류 등 산업 현장에서 사용되는 물체 200종에 대한 3D CAD 스캔 데이터 - 실제 환경과 3D CAD 데이터를 이용한 가상 환경에서 다양한 각도로 촬영한 물체 이미지  라벨링 유형 세그멘테이션(이미지) / 캡션(텍스트)  라벨링 형식 *.json 데이터 활용서비스 로봇이 제조/물류 환경에서 사람과 함께 협력 작업 수행 데이터 구축년도 2024년 데이터 구축량 - 3D CAD 스캔데이터 200세트  - 실제/가상 환경 촬영 데이터 100,000세트  배포버전 v1.0",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:6:0001",
                    "page": 6
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "제조, 물류 산업 물체 200종의 3D CAD 스캔데이터와 실제/가상 환경 촬영 이미지를 기반으로 세그멘테이션과 캡션 라벨링이 적용된 협업 로봇용 데이터셋이다.",
        "long_answer": {
            "question": "메타데이터의 구성 요소를 상세히 서술하시오.",
            "answer": "메타데이터는 3D CAD 스캔데이터와 실제/가상 환경에서 촬영된 이미지로 구성된다. 라벨링은 세그멘테이션과 캡션 형태로 *.json 파일로 제공된다. 제조와 물류 환경의 물체 200종을 기반으로 구축되었으며, 데이터 활용서비스 로봇이 산업 현장에서 사람과 협력 작업을 수행한다. 데이터 구축은 3D CAD와 실제/가상 촬영 데이터로 총 100,000세트가 포함된다.",
            "rubric": [
                "스캔데이터; 실제/가상 환경; 세그멘테이션; 캡션; 데이터 활용서비스 로봇"
            ]
        },
        "short_answer": {
            "question": "3D CAD 스캔데이터의 파일 형식은?",
            "answer": "*.obj, *.mtl, *.png",
            "topic": [
                "3D CAD 스캔데이터의 파일 형식"
            ]
        },
        "multiple_choice": {
            "question": "3D CAD 스캔데이터의 라벨링 유형에 해당하는 것은?",
            "choices": [
                "a) 감정 분류",
                "b) 음성 인식",
                "c) 세그멘테이션",
                "d) 기계 번역"
            ],
            "answer": "c",
            "topic": [
                "3D CAD 스캔데이터의 라벨링 유형"
            ]
        },
        "true_false": {
            "question": "3D CAD 스캔데이터는 제조와 물류 산업에서 활용되는 물체를 대상으로 구축되었다.",
            "answer": "TRUE",
            "topic": [
                "3D CAD 스캔데이터의 출처"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:13:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "- 'Polyformer: Referring image segmentation as sequential polygon generation.' CVPR 2023 - 선정 사유: - 기존 픽셀 레벨로 해결한 다른 모델과 다른 접근이 polygon을 예측하는 방식을 픽셀 레벨로 문제를 해결한 다른 모델의 모듈과 함께 사용해 성능을 향상하고 자 선정 - 특징: 기존 픽셀레벨로 해결했던 segmentatio 및 detection 문제를 polygon을 예측하 는 문제로 바꾸어 문제를 해결함. 이를 위해 regression-based transformer decoder를 제안 - AI 모델 적용 인공지능 활용 예시: 물체의 정확한 형상까지 원하는 경우가 아닌 경우 더 높은 정확도로 물체가 놓여 있는 위치를 검출할 수 있기 때문에 목표 물체까지의 로봇 내비게이션과 같은 작업에 사용될 수 있음",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:13:0001",
                    "page": 13
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "Polyformer는 기존 픽셀 기반 접근을 polygon 예측 방식으로 바꿔 정확도를 높인 모델이다. 이를 통해 로봇 내비게이션 등 위치 검출 작업에 활용될 수 있다.",
        "long_answer": {
            "question": "Polyformer 모델이 기존 픽셀 레벨 segmentation 방법과 다른 점과 로봇 분야에서 활용되는 방식을 설명하시오.",
            "answer": "Polyformer는 기존에 픽셀 단위로 해결하던 segmentation과 detection 문제를 polygon 예측 문제로 바꾸어 처리한다. 이를 위해 regression-based transformer decoder를 사용하여 성능을 향상시킨다. 이를 통해 정확도가 향상된 위치 정보는 물체 위치 검출이 가능하므로 목표 물체까지의 로봇 내비게이션 작업에 활용될 수 있다.",
            "rubric": [
                "polygon; regression-based transformer decoder; 로봇 내비게이션"
            ]
        },
        "short_answer": {
            "question": "Polyformer가 segmentation 문제를 해결할 때 사용한 구조는?",
            "answer": "regression-based transformer decoder",
            "topic": [
                "Polyformer 모델의 특징"
            ]
        },
        "multiple_choice": {
            "question": "Polyformer 모델의 특징으로 알맞지 않은 것은?",
            "choices": [
                "a) 픽셀 단위 예측만 수행한다.",
                "b) polygon 예측 문제로 변환하였다.",
                "c) transformer decoder를 적용하였다.",
                "d) 로봇 내비게이션에 활용된다."
            ],
            "answer": "a",
            "topic": [
                "Polyformer 모델의 특징"
            ]
        },
        "true_false": {
            "question": "Polyformer 모델은 자동차 내비게이션에 활용이 가능하다.",
            "answer": "FALSE",
            "topic": [
                "Polyformer 모델의 활용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:13:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "- LAVT: Language-Aware Vision Transformer for Referring Image Segmentation, CVPR,  2022  - RIS 태스크를 수행할 수 있는 모델  - 선정 사유: 2024년 기준 RIS 최고 성능 모델  - 특징: 이미지 transformer에 언어 인코더에서 나온 특징을 직접적으로 사용  - AI 모델 적용 인공지능 활용 예시: 로봇이 제조/물류 환경에서 사람과 함께 작업할 때, 물체의 공식적 명칭뿐 아니라 물체의 특징(크기, 색상, 위치 등)을 통한 표현을 통해서  도 물체를 인식하고 협력 작업에 활용",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:13:0001",
                    "page": 13
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "LAVT는 이미지 transformer와 언어 인코더 특징을 결합하여 RIS 태스크 수행이 가능하며, 로봇의 제조/물류 협력 작업에 활용할 수 있다.",
        "long_answer": {
            "question": "LAVT 모델의 RIS 태스크 수행 방식과 실제 산업 환경에서의 활용에 대해 설명하시오.",
            "answer": "LAVT는 이미지 transformer와 언어 인코더의 특징을 결합해 RIS 태스크를 수행한다. 이를 통해 물체의 공식 명칭뿐 아니라 크기, 색상, 위치 등 특징을 기반으로 인식할 수 있다. 따라서 로봇이 제조나 물류 환경에서 사람과 함께 작업할 때 협력 작업에 활용 가능하다.",
            "rubric": [
                "이미지 transformer; 언어 인코더; RIS; 특징 기반 인식"
            ]
        },
        "short_answer": {
            "question": "LAVT 모델이 수행 가능한 태스크는?",
            "answer": "RIS",
            "topic": [
                "LAVT 모델의 태스크"
            ]
        },
        "multiple_choice": {
            "question": "LAVT 모델의 특징에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 이미지와 언어 정보를 결합하여 활용",
                "b) 텍스트 정보만 사용",
                "c) 로봇 협력과 무관",
                "d) 물체의 공식 명칭만 기반으로 인식"
            ],
            "answer": "a",
            "topic": [
                "LAVT 모델의 특징"
            ]
        },
        "true_false": {
            "question": "LAVT 모델은 로봇과 사람의 협력 작업에 활용이 가능하다.",
            "answer": "TRUE",
            "topic": [
                "LAVT 모델의 활용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:25:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "전 공정 설계 및 데이터 명세 확보 - 수집 장소, 목록, 장비 선정 - 각 공정별 임무 정의 및 가이드라인 작성 - 각 공정별 일정 및 계획 수립 - 품질목표 및 점검기준 수립   원시데이터 수집 - 수집 장비 세팅 - 수집 가이드라인 작성 - 데이터의 다양성, 편향성, 사실성 등을 고려한 원시 데이터 수집 - 해상도 및 파일 포맷 준수 - 품질실무협의회의 기준에 따라 원시데이터 검사  데이터 정제 - 작업장 및 장비, 정제 도구 확보 등 정제 공정 준비 - 정제 공정 가이드라인 기 준 수립 - 정제 도구 활용 가이드라인 및 정제 공정 가이드라인 작성 - 정의된 기준에 따라 영상 에서 이미지 추출을 통한 원천데이터 확보 - 정제도구 활용하여 중복성 검사 - 품질실무협의회의 기준에 따라 원천데이터 검사",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:25:0001",
                    "page": 25
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 수집과 정제를 위해 수집 전 장비 세팅, 가이드라인 작성, 품질 검사, 중복성 검사 등을 수행한다.",
        "long_answer": {
            "question": "원시데이터 수집 단계에서 이루어지는 주요 활동에 대해 설명하시오.",
            "answer": "원시데이터 수집 단계에서는 수집 장비를 세팅하고, 수집 가이드라인을 작성한다. 원시데이터 수집 시 데이터의 다양성, 편향성, 사실성 등을 고려해야 한다. 또한 해상도 및 파일 포맷을 준수해야 하며, 품질실무협의회의 기준에 따라 원시데이터를 검사한다.",
            "rubric": [
                "장비 세팅; 가이드라인; 고려사항; 해상도 및 파일 포맷 준수; 품질실무협의회"
            ]
        },
        "short_answer": {
            "question": "무엇의 기준을 중점으로 원천데이터 검사가 진행되는가?",
            "answer": "품질실무협의회",
            "topic": [
                "원천데이터의 검사 기준"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 데이터 정제 단계에 관해 틀린 설명은?",
            "choices": [
                "a) 원천데이터 확보를 위해 영상에서 이미지 추출",
                "b) 정제 단계에서 중복성 검사를 수행",
                "c) 원시데이터 수집",
                "d) 정제 공정 준비"
            ],
            "answer": "c",
            "topic": [
                "데이터 정제 단계"
            ]
        },
        "true_false": {
            "question": "수집 장비 세팅은 공정 설계 및 데이터 명세 확보 과정에서 이루어진다.",
            "answer": "FALSE",
            "topic": [
                "데이터 수집 장비 세팅"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:25:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 라벨링 - 라벨링 방법 선정 - 가공 도구 사전확보 및 가공 작업자 선발 - 가공 도구 : 자체 저작도구 - 가공 도구 및 가이드라인 교육 - 데이터 가공 결과에 대해 서는 지속적인 피드백 및 교육을 진행 - 품질실무협의회의 기준 및 정확성(의미 정확성, 구문 정확성 중점)에 따라 라벨 링 데이터 검사  데이터 학습 - AI 학습모델 선정 - 정량적 목표 달성 여부 확인 - 유효성 수치값 확인 - 수시 샘플링 검사, 정기적 품질검사를 통한 우수한 데이터 확보  데이터 공개 및 배포 - 학습용 데이터 공개 - 서비스 활용 시나리오 작성",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:25:0001",
                    "page": 25
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "라벨링은 자체 도구와 가이드라인에 따라 작업하며, AI 학습모델 검증과 품질검사 후 학습용 데이터를 공개하고 활용 시나리오를 작성한다.",
        "long_answer": {
            "question": "데이터 라벨링 과정에서 수행되는 주요 작업과 기준에 대해 설명하시오.",
            "answer": "라벨링 방법을 선정하고 가공 도구 사전확보 및 가공작업자를 선발한다. 이때 가공 도구는 자체 저작도구를 말하며, 가공 도구와 가이드라인을 교육한다. 데이터 가공 결과에 대해 지속적 피드백과 교육이 진행된다. 의미 정확성, 구문 정확성을 중점으로 라벨링 데이터를 검사하며, 품질실무협의회의 기준을 따른다.",
            "rubric": [
                "가공 도구; 의미 정확성; 구문 정확성"
            ]
        },
        "short_answer": {
            "question": "데이터 학습 단계에서 확인해야 하는 두 가지는?",
            "answer": "정량적 목표 달성 여부, 유효성 수치값",
            "topic": [
                "데이터 학습 단계"
            ]
        },
        "multiple_choice": {
            "question": "데이터 학습 단계에서 틀린 설명은?",
            "choices": [
                "a) 학습모델 선정",
                "b) 데이터 공개 전 품질검사 생략",
                "c) 정량적 목표 달성 여부 확인",
                "d) 샘플링 및 정기 검사 수행"
            ],
            "answer": "b",
            "topic": [
                "데이터 학습 단계"
            ]
        },
        "true_false": {
            "question": "데이터 라벨링은 실용성 중심으로 검사가 진행된다.",
            "answer": "FALSE",
            "topic": [
                "데이터 라벨링의 검사 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:26:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "(1) 원시데이터 직접 제작 - 3D 스캐닝: 고정밀 3D 스캐너를 사용하여 물체의 3D 모델을 생성. 스캐닝은 다각도에서 수행 되어야 함. - 사진 촬영: 물체의 다양한 각도에서 고해상도 사진을 촬영하여, 사진으로부터 3D 모델을 재구 성할 수 있음. - 개인정보보호법 등에 따라 적절한 법적, 기술적 절차를 거친 데이터를 활용하며, 그렇지 않은 데이터는 정제 과정에서 처리될 수 있도록 함. (2) 원시데이터 획득/수집 항목 - 3D 메시 및 CAD 데이터: 제조/물류 환경에서 빈번히 사용되는 200종 물체 (3) 데이터 획득/수집 및 저장 절차 구성 - 장소 선정: 제조 및 물류 공간 내에서 섭외 및 선정 - 수집 일정 계획 수립 - 기간: 1달 (2024년 5월 1일부터 5월 31일까지) - 시간: 매주 2회, 오전 10시부터 12시까지 (획득 시간 총 2시간) - 데이터 획득: 3D 스캐너 조작자가 3D 스캐너를 사용하여 다양한 각도에서 물체를 촬영하여 - 3D 모델을 생성 - 데이터 저장 · 3D CAD 데이터: obj, mtl, png 형식으로 저장 - 데이터 전송: Scan-to-Cloud 기능과 WiFi 연결을 통해 무선으로 데이터 전송 - 데이터 중복성 검사 및 파일명 규칙: 촬영된 데이터는 중복성 검사 후, 정의된 파일명 규칙에 따라 이름 변경. (ex. 모델명_MM-SS-HG-001)",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:26:0001",
                    "page": 26
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "3D 스캐닝과 사진 촬영을 통해 200종 물체의 원시데이터를 제작하고, 중복 검사와 파일명 규칙을 적용하여 저장한다.",
        "long_answer": {
            "question": "원시데이터 직접 제작 과정에 대해 설명하시오.",
            "answer": "원시데이터 직접 제작에는 고정밀 3D 스캐너를 사용하여 물체의 3D 모델을 생성하며, 이때 스캐닝은 다각도에서 수행되어야 한다. 또한 물체의 다양한 각도에서 고해상도 사진을 촬영하여, 사진으로부터 3D 모델을 재구성할 수 있다. 개인정보보호법 등에 따라 적절한 법적, 기술적 절차를 거친 데이터를 활용하며, 그렇지 않은 데이터는 정제 과정에서 처리될 수 있도록 한다.",
            "rubric": [
                "고정밀 3D 스캐너; 고해상도 사진; 개인정보보호법"
            ]
        },
        "short_answer": {
            "question": "데이터 획득 총 시간은?",
            "answer": "2시간",
            "topic": [
                "데이터 획득 시간"
            ]
        },
        "multiple_choice": {
            "question": "원시데이터 제작 과정에서 수행되는 작업으로 올바른 것은?",
            "choices": [
                "a) 사진 촬영 없이 3D 모델 생성",
                "b) 무작위 데이터 사용",
                "c) 3D 모델로부터 사진을 재구성",
                "d) 고정밀 3D 스캐너를 이용한 다양한 각도 스캐닝"
            ],
            "answer": "d",
            "topic": [
                "원시데이터 제작 과정"
            ]
        },
        "true_false": {
            "question": "데이터는 Scan-to-Cloud 기능과 WiFi 연결을 통해 무선으로 전송한다.",
            "answer": "TRUE",
            "topic": [
                "데이터 전송"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:27:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "- Artec Leo 장비를 활용하여 물체 3D 스캔 원시데이터와 카메라 파라미터를 Mesh 데이터로 병합 - 3D 객체 세트 원시데이터와 scene 정보(scene 장소 종류, scene ID 등), 물체 종류 정보(semantic class, instance class, object id 등)를 매칭 - Artec Leo 스캐너를 이용해 물체 스캐닝 한 후, Artec Studio SW를 활용하면 후 처리 가공 툴을 통해 손쉽게 메시 및 포인트 클라우드 획득 가능 - 물체 3D 스캔 데이터 취득이 간편하고 초당 3천 5백만 포인트를 처리가능하여 작업시간 시간 단축에도 효과적임 - 원시데이터에서 전달받은 물체 종류 정보를 바탕으로, 모든 물체가 안정적으로 배치된 데이터를 선별함 - 데이터는 라벨링 과정에서 불확실성을 유발할 수 있는 번짐 등의 노이즈가 없도 록 선별함",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:27:0001",
                    "page": 27
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "Artec Leo 스캐너와 Artec Studio SW를 활용하여 3D 메시 및 포인트 클라우드를 획득하고, 안정적 배치 및 노이즈 없는 데이터를 선별한다.",
        "long_answer": {
            "question": "Artec Leo 장비와 소프트웨어를 활용한 정제 데이터 구축 절차를 설명하시오.",
            "answer": "Artec Leo 장비를 활용하여 물체 3D 스캔 원시데이터와 카메라 파라미터를 Mesh 데이터로 병합한다. 일단 Artec Leo 장비를 이용해 물체를 스캔한 후, Artec Studio SW를 활용하여 메시와 포인트 클라우드를 획득한다. 3D 객체 세트 원시데이터와 물체 종류 정보인 semantic class, instance class, object id와 scene 정보를 매칭하여 구성한다. 이후 원시데이터에서 번짐 등의 노이즈가 없고, 모든 물체가 안정적으로 배치된 데이터를 선별한다.",
            "rubric": [
                "Artec Studio SW; 메시 및 포인트 클라우드 획득; 물체 종류 정보; scene 정보"
            ]
        },
        "short_answer": {
            "question": "scene 정보로는 무엇이 포함되는가?",
            "answer": "scene 장소 종류, scene ID",
            "topic": [
                "scene 정보"
            ]
        },
        "multiple_choice": {
            "question": "Artec Leo 스캐너 활용 과정에 대한 설명으로 올바른 것은?",
            "choices": [
                "a) 물체 종류 정보에는 immediate class, roundabout class가 포함",
                "b) 스캔 데이터는 후처리 없이 바로 라벨링",
                "c) 약간의 번짐이 있어도 사용 가능 데이터로 간주",
                "d) Artec Studio SW로 메시와 포인트 클라우드 획득"
            ],
            "answer": "d",
            "topic": [
                "Artec Leo 스캐너 활용 과정"
            ]
        },
        "true_false": {
            "question": "Artec Leo 장비를 활용하면, 분당 3천 5백만 포인트를 처리 가능하다.",
            "answer": "FALSE",
            "topic": [
                "Artec Leo 장비의 포인트 처리 성능"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:28:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "이미지 쌍 선별  - 원시데이터에서 전달받은 물체 종류 정보를 바탕으로, 모든 물체가 안정적으로 배치된 원시데이터를 SW 선별 (떨어진 물체 및 이동 등의 의도하지 않은 이미지 제거, 이때 이동에 의한 모션 블러 등의 노이즈가 예상될 시 데이터 제거)  깊이 정보 보정 - 원시데이터 중, 깊이 정보에 대한 오류(깊이 값이 들어가 있지 않거나 비정  상적인 None/Nan) 제거 알고리즘을 통해 깊이 정보를 SW 보정  유사 환경 이미지 선별  - 원시데이터를 재구성한 Meta데이터를 통해, 배경, Scene 내 등장 물체, 카 메라 View 데이터, 조명 설정 등을 참조하여 중복되는 데이터를 최소화하기 위한 SW 선별을 진행",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:28:0001",
                    "page": 28
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "이미지 데이터의 품질을 높이기 위해 물체 안정성, 깊이 정보, 유사 환경 여부 등을 기준으로 SW가 자동 선별 및 보정을 수행한다.",
        "long_answer": {
            "question": "이미지 쌍 선별의 개념과 상황별 데이터 제거 방법을 기술하시오.",
            "answer": "이미지 쌍 선별은 원시데이터에서 전달받은 물체 종류 정보를 바탕으로 모든 물체가 안정적으로 배치된 원시데이터를 SW 선별하는 것을 말한다. 떨어진 물체나 이동 등의 의도하지 않은 이미지를 제거한다. 이때 이동에 의한 모션 블러 등의 노이즈가 예상될 시에는 데이터를 제거한다.",
            "rubric": [
                "SW 선별; 의도하지 않은 이미지; 모션 블러"
            ]
        },
        "short_answer": {
            "question": "깊이 정보 보정 과정에서 비정상적인 깊이 값으로 간주되어 제거되는 항목은?",
            "answer": "None/Nan",
            "topic": [
                "깊이 정보 보정 과정의 제거 항목"
            ]
        },
        "multiple_choice": {
            "question": "이미지 쌍 선별 단계의 설명으로 틀린 것은?",
            "choices": [
                "a) 물체의 안정적인 배치를 확인한다.",
                "b) 모션 블러로 인한 노이즈가 예상될 경우 데이터를 삭제한다.",
                "c) 의도치 않은 이동이 발생한 이미지를 제거한다.",
                "d) 물체의 색상 대비를 조정하여 데이터 품질을 향상시킨다."
            ],
            "answer": "d",
            "topic": [
                "이미지 쌍 선별 단계의 특징"
            ]
        },
        "true_false": {
            "question": "원시데이터에서 떨어진 물체는 제거한다.",
            "answer": "TRUE",
            "topic": [
                "원시데이터 내 물체 제거 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:31:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1. 제조 및 물류 환경에서의 물체를 지칭하는 다양한 표현을 담을 수 있도록 다양한 성별, 연령, 직업을 가진 20명 이상의 작업자를 활용해 물체를 설명하는 텍스트 라 벨을 작성 - 수집된 각 물체 이미지 1장당 50토큰(5문장) 이상의 텍스트 라벨링(총 500만 토큰 이상) - 하나의 물체에 대해 수집된 이미지들은 20명 이상의 사람이 서로 다른 표현으 로 물체와 관련된 문장을 작성 2. 라벨링 시 표현의 다양성을 고려하여 라벨링을 진행하도록 사전 교육 진행 - 작업자들의 수월한 라벨링을 위해 라벨링 가이드를 제공하는 자체 라벨링 툴 제작 - 무결성 및 중복성 검토를 위한 SW 알고리즘 수행으로 데이터를 검수 - 중복성 검사 알고리즘을 통해 유사도를 측정, 유사도 값을 0~1사이의 값으로 하여 동일한 문장에 대해 유사도 1을 기준으로 0.68 미만의 데이터를 저장 (정 규 분포 중, 1 표준편차 범위 68%, μ ± 1σ ) - 수집된 전체 문장에 대해 유사도를 측정 한 뒤 수집 갯수를 충족할 수 있도록 재수집 수행 - 동일한 물체가 중복하여 출연하는 것을 고려하여 라벨링 시 n명의 작업자가 텍 스트 라벨링 작업을 수행, 중복 표현을 방지하고 텍스트 라벨링에 도움을 주기 위해 텍스트 라벨링 가이드를 구축하여 각 라벨링 작업자가 다른 라벨링을 하 도록 가이드*를 제공 - 텍스트의 생성 및 합성에는 생성형 AI를 활용하지 않음",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:31:0001",
                    "page": 31
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "제조 및 물류 환경의 물체 이미지를 다수의 작업자가 다양한 표현으로 라벨링하고, 유사도 검사를 통해 중복을 최소화하며 데이터 품질을 검증한다.",
        "long_answer": {
            "question": "제조 및 물류 환경의 물체 이미지에 대한 텍스트 라벨링 과정에서 다양성과 무결성을 확보하기 위한 절차를 구체적으로 설명하시오.",
            "answer": "데이터 구축 과정에서는 성별, 연령, 직업이 다양한 20명 이상의 작업자가 동일한 물체에 대해 서로 다른 표현으로 라벨을 작성한다. 각 이미지당 최소 50토큰 이상의 문장이 작성되며, 이를 통해 다양한 시각의 묘사 데이터를 확보한다. 이후 중복성 검사 알고리즘을 적용해 문장 유사도를 0~1 범위로 산출하고, 유사도 0.68 미만의 문장만 저장하여 중복을 제거한다. 또한, 라벨링 가이드를 제공하고 각 라벨링 작업자가 다른 라벨링을 하며, 이때 생성형 AI는 사용하지 않는다.",
            "rubric": [
                "20명 이상의 작업자; 중복성 검사 알고리즘; 라벨링 가이드"
            ]
        },
        "short_answer": {
            "question": "중복성 검사 알고리즘을 통한 유사도 값의 범위는?",
            "answer": "0~1",
            "topic": [
                "중복성 검사 알고리즘의 유사도 값 범위"
            ]
        },
        "multiple_choice": {
            "question": "텍스트 라벨링 과정의 설명으로 적절한 것은?",
            "choices": [
                "a) 생성형 AI를 활용하여 문장 다양성을 향상",
                "b) 각 물체에 대해 다수의 작업자가 서로 다른 표현으로 문장을 작성",
                "c) 20명 미만의 작업자가 동일한 물체를 라벨링",
                "d) 동일한 문장에 대해 유사도 0.68 이상인 데이터를 저장"
            ],
            "answer": "b",
            "topic": [
                "텍스트 라벨링 과정"
            ]
        },
        "true_false": {
            "question": "수집된 각 물체 이미지 1장당 최소 80토큰 이상의 텍스트 라벨링을 한다.",
            "answer": "FALSE",
            "topic": [
                "물체 이미지의 텍스트 라벨링 토큰"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:32:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 구축요건 일치  ∙ 선정된 물체 200종은 산업 환경에서 대표적으로 사용되는 물체여야 함 ∙ 실제 환경에서 물체 촬영 시 3개 이상의 뷰 포인트에서 촬영되어야 함 ∙ 실제 환경에서 물체 촬영 시 다양한 조도 환경 내에서 촬영되어야 함 ∙ 가상 환경에서 물체 촬영시 각도가 다른 카메라 10대로 촬영되어야 함  데이터 다양성 확보  ∙ 200종의 물체들은 동등한 빈도로 촬영되어야 하며, 촬영된 이미지 중 특정 물체 들의 비율이 과하게 높거나 과하게 낮아서는 안 됨 ∙ 데이터 수집 시, 다양한 각도와 조도 및 배경 환경에서 촬영되어야 하며, 장면을 구성하는 물체들의 배치 또한 다양해야 함  사실적 획득/수집 환경 구성  ∙ 데이터 취득 시 사람-로봇 공유 작업이 가능하도록 사람 및 로봇의 일상적인 눈 높이에 맞는 범위에서 취득되어야 함 ∙ 데이터를 취득하는 환경은 실제 산업 환경과 유사해야 함 ∙ 시뮬레이터에서 가상 데이터 수집 시, 실제 환경에서 스캐닝한 물체 3D 및 실제 와 유사한 배경 등 촬영 조건을 통일하여 실제 데이터와 유사한 데이터를 획득 해야 함 데이터 획득/수집 시 품질 고려  ∙ 데이터 취득 시 반드시 사전에 지정한 촬영 기기를 활용하여야 하며, 사용하는 기기의 성능이 보장받는 범위 내의 조건에서 데이터가 수집되어야 함 ∙ 데이터 취득 시 이미지가 흔들리거나 초점이 맞지 않아서는 안되며, 이미지 내 흔들림 없이 모든 물체가 선명하게 찍혀야 함",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:32:0001",
                    "page": 32
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "산업 환경에서 활용되는 물체 데이터를 구축하기 위해 실제 및 가상 환경에서 다양한 각도와 조도 조건을 확보하고, 촬영 품질과 장비 요건을 철저히 관리한다.",
        "long_answer": {
            "question": "산업 환경에서 물체 데이터 구축 시, 데이터의 다양성과 사실성을 확보하기 위한 요건을 서술하시오.",
            "answer": "200종의 물체들은 동등한 빈도로 촬영되어야 하며, 촬영된 이미지 중 특정 물체 비율이 과하게 높거나 과하게 낮아서는 안 된다. 또한 데이터 수집 시, 다양한 각도와 조도 및 배경 환경에서 촬영되어야 하며, 장면을 구성하는 물체들의 배치 또한 다양해야 한다. 데이터 취득 시에는 사람-로봇 공유 작업이 가능하도록 사람 및 로봇의 일상적인 눈높이에 맞는 범위에서 취득되어야 한다. 이때 데이터 취득 환경은 실제 산업 환경과 유사해야 하며, 시뮬레이터에서 가상 데이터 수집 시, 실제 환경에서 스캐닝한 물체 3D 및 실제와 유사한 배경 등 촬영 조건을 통일하여 실제 데이터와 유사한 데이터를 획득해야 한다.",
            "rubric": [
                "물체 비율; 다양한 각도 및 조도; 실제 산업 환경과 유사; 촬영 조건 통일"
            ]
        },
        "short_answer": {
            "question": "가상 환경에서 물체 촬영 시, 사용해야 하는 카메라의 최소 개수는?",
            "answer": "10대",
            "topic": [
                "가상 환경 촬영 시 필요 조건"
            ]
        },
        "multiple_choice": {
            "question": "데이터 획득/수집 시 품질 관리 기준에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) 촬영 중 이미지가 흔들려도 일부 데이터는 허용된다.",
                "b) 성능이 검증된 촬영 장비를 사용해야 한다.",
                "c) 초점이 흐릿한 이미지는 수집 대상에서 제외된다.",
                "d) 지정된 촬영 기기를 활용하여야 한다."
            ],
            "answer": "a",
            "topic": [
                "데이터 획득/수집 시 품질 관리 기준"
            ]
        },
        "true_false": {
            "question": "시뮬레이터를 활용한 가상 데이터 수집 시에는 실제 스캔한 물체와 유사한 3D 모델 및 배경을 사용해야 한다.",
            "answer": "TRUE",
            "topic": [
                "시뮬레이터를 활용한 가상 데이터 수집 환경"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:38:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 정제 1) 기계적 정제 2) 휴먼 정제  - 작업장 및 장비, 정제 도구 확보 등 정제 공정 준비 - 정제 공정 가이드라인 기준 수립 - 정의된 기준에 따라 원천데이터 확보 - 정제도구 활용하여 중복성 검사 - 품질실무협의회의 기준에 따라 원천데이터 검사  Ÿ 원천데이터 100,000장 구축  데이터 가공 (라벨링)  1) 이미지 텍스트 추출 2) 텍스트 오류 확인 3) 휴먼 검수 4) 최종 검수  - 라벨링 방법 선정 - 가공 도구 사전확보 및 가공 작업 자 선발 - GIST 자체 제작한 저작도구 S/W 인 2024-aihub-labeltool.exe 활용 - 가공 도구 및 가이드라인 교육 - 데이터 가공 결과에 대해서는 지 속적인 피드백 및 교육을 진행 - 품질실무협의회의 기준 및 정확 성(의미 정확성, 구문 정확성 중 점)에 따라 라벨링 데이터 검사  Ÿ 라벨링데이터 100,000장 구축",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:38:0001",
                    "page": 38
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "데이터 구축 과정은 기계적·휴먼 정제를 거쳐 중복성과 품질을 검증하고, 이후 라벨링 단계에서 자체 제작 도구를 활용해 의미·구문 정확성을 확보한다.",
        "long_answer": {
            "question": "데이터 정제와 가공의 각 구성요소와 그 결과에 대해 서술하시오.",
            "answer": "데이터 정제는 기계적 정제와 휴먼 정제로 이루어져 있다. 작업장과 정제 도구를 확보하고 품질실무협의회의 기준에 따른 원천데이터 검사 및 정제도구를 이용한 중복성을 점검한다. 그 결과 원천데이터 100,000장이 구축되었다. 데이터 가공은 이미지 텍스트 추출, 텍스트 오류 확인, 휴먼 검수, 최종 검수의 단계가 포함되며 GIST가 자체 제작한 툴을 활용하여 가공 작업을 수행하여 의미적/구문적 정확성을 중점으로 라벨링 데이터를 검증한다. 그 결과 라벨링데이터 100,000장이 구축되었다.",
            "rubric": [
                "기계적 정제; 휴먼 정제; 원천데이터; 이미지 텍스트 추출; 텍스트 오류 확인; 휴먼 검수; 최종 검수; 라벨링데이터"
            ]
        },
        "short_answer": {
            "question": "데이터 가공 과정에서 사용된 GIST 자체 제작 저작도구의 명칭은?",
            "answer": "2024-aihub-labeltool.exe",
            "topic": [
                "데이터 가공 과정의 저작도구"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 데이터 라벨링 과정에 포함되지 않는 것은?",
            "choices": [
                "a) 이미지 텍스트 추출",
                "b) 텍스트 오류 확인",
                "c) 로봇 검수",
                "d) 휴먼 검수"
            ],
            "answer": "c",
            "topic": [
                "데이터 라벨링 과정"
            ]
        },
        "true_false": {
            "question": "데이터 가공 과정에서는 품질실무협의회의 검수 기준을 적용하지 않는다.",
            "answer": "FALSE",
            "topic": [
                "데이터 가공 과정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:40:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "[PolyFormer] - 참고 논문: Liu, Jiang, et al. 'Polyformer: Referring image segmentation as sequential polygon generation.' CVPR 2023 - 특징: 기존 픽셀레벨로 해결했던 segmentatio 및 detection 문제를 polygon을 예측하는 문제로 바꾸 어 문제를 해결함. 이를 위해 regression-based transformer decoder를 제안함. - 선정 사유: 기존 픽셀 레벨로 해결한 다른 모델과 다른 접근이 polygon을 예측하는 방식을 픽셀 레벨 로 문제를 해결한 다른 모델의 모듈과 함께 사용해 성능을 향상하고자 선정함. - 평가 방법: RefCOCO, RefCOCO+, RefCOCOg, ReferIt 데이터셋의 val, test split에서 평가를 진행. 입 력 텍스트의 output으로 나온 bouding box와 정답 bounding box의 영역이 50프로 이상 겹치는 경 우 정답으로 평가",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:40:0001",
                    "page": 40
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "PolyFormer는 기존의 픽셀 기반 문제를 polygon 예측 문제로 전환하고, regression 기반 transformer decoder를 활용해 문제를 해결한다.",
        "long_answer": {
            "question": "PolyFormer 모델이 기존 세그멘테이션 접근법과 구별되는 구조적 특징과 평가 방식을 설명하시오.",
            "answer": "PolyFormer는 기존의 픽셀 단위로 해결하던 segmentatio 및 detection 문제를 poly­gon 예측 문제로 변환한 모델이다. 이를 위해 regression-based transformer decoder를 제안하여 문제를 해결하며, 픽셀 레벨 접근을 보완한다. 성능 평가는 RefCOCO, RefCOCO+, RefCOCOg, ReferIt 데이터셋의 val, test split에서 수행되고, 모델이 출력한 bounding box가 정답 영역과 50% 이상 겹칠 때 정답으로 판단한다.",
            "rubric": [
                "polygon; regression-based transformer decoder;  RefCOCO; RefCOCO+; RefCOCOg; ReferIt"
            ]
        },
        "short_answer": {
            "question": "PolyFormer 모델은 어느 데이터셋을 기반으로 평가가 진행되는가?",
            "answer": "RefCOCO, RefCOCO+, RefCOCOg, ReferIt",
            "topic": [
                "PolyFormer 모델의 평가 데이터셋"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 PolyFormer의 핵심 접근 방식으로 옳은 것은?",
            "choices": [
                "a) 픽셀 단위 마스크를 직접 예측한다.",
                "b) 세그멘테이션 문제를 다각형 예측 문제로 전환한다.",
                "c) 텍스트 정보 없이 bounding box만 생성한다.",
                "d) CNN 기반 분류기를 활용해 객체를 검출한다."
            ],
            "answer": "b",
            "topic": [
                "PolyFormer의 접근 방식"
            ]
        },
        "true_false": {
            "question": "PolyFormer는 모델이 출력한 bounding box가 정답 영역과 절반 이상 겹칠 때 정답으로 판단한다.",
            "answer": "TRUE",
            "topic": [
                "PolyFormer의 정답 영역"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:41:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "[LAVT] - 참고 논문: LAVT: Yang, Zhao, et al. 'Lavt: Language-aware vision transformer for referring image segmentation.' CVPR 2022 - 특징: LAVT는 자연어 표현으로 지시된 객체를 이미지에서 분할하는 작업에서 기존의 비전-언어 융합 방식의 한계를 해결하고자, 시각 트랜스포머 인코더의 중간 레이어에서 언어와 시각 특징을 조기에 융합하는 접근을 제안하여 트랜스포머 인코더의 상관관계 모델링 능력을 활용하여 더 나은 다중 모달 정렬을 달성하고, 가벼운 마스크 예측기를 통해 정확한 분할 결과를 얻음 - 선정 사유: LAVT는 RefCOCO, RefCOCO+, G-Ref 데이터셋에서 기존 최신 성능을 큰 폭으로 능가했기 때문에 본 데이터셋으로 학습하였을 때 로봇 도메인에 적용 가능하도록 미세조정이 효과적으로 가능 할 것이라 보여 선정함 - 평가 방법: 모델이 출력한 분할 마스크와 실제 정답에 해당하는 분할 마스크의 IoU를 계산하여 평가",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:41:0001",
                    "page": 41
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "LAVT는 시각 트랜스포머 인코더의 중간 레이어에서 언어와 시각 특징을 조기에 융합해 상관관계 모델링을 강화하고, 가벼운 마스크 예측기를 통해 정확한 분할 결과를 얻는 모델이다.",
        "long_answer": {
            "question": "LAVT 모델이 기존 비전-언어 융합 한계를 해결하기 위해 제안한 접근 방법과 평가 방식을 서술하시오.",
            "answer": "LAVT는 자연어로 지시된 객체를 이미지에서 분할하는 작업에서 기존의 비전-언어 융합 방식이 가진 한계를 해결하기 위해, 시각 트랜스포머 인코더의 중간 레이어에서 언어와 시각 특징을 조기에 융합하는 방식을 제안한다. 이를 통해 트랜스포머 인코더의 상관관계 모델링 능력을 활용하여 다중 모달 정렬을 강화하고, 가벼운 마스크 예측기를 사용해 정확한 분할 결과를 얻는다. 성능 평가는 모델이 생성한 분할 마스크와 실제 정답 마스크 간의 IoU 값을 계산하여 수행한다.",
            "rubric": [
                "조기 융합; 다중 모달 정렬 강화; 마스크 예측기; IoU 값"
            ]
        },
        "short_answer": {
            "question": "LAVT는 무엇을 활용하여 언어와 시각 특징을 조기에 융합하는가?",
            "answer": "언어와 시각 융합 방식",
            "topic": [
                "LAVT의 융합 방식"
            ]
        },
        "multiple_choice": {
            "question": "LAVT의 주요 특징으로 옳은 것은?",
            "choices": [
                "a) 텍스트 정보를 분할 단계에서 제거한다.",
                "b) 언어와 시각 정보를 최종 출력 단계에서 결합한다.",
                "c) 시각 트랜스포머 인코더의 중간 레이어에서 언어와 시각 특징을 조기에 융합한다.",
                "d) 트랜스포머 인코더의 상관관계 모델링 능력을 활용하여 더 나은 단수 모달 정렬을 달성한다."
            ],
            "answer": "c",
            "topic": [
                "LAVT의 주요 특징"
            ]
        },
        "true_false": {
            "question": "LAVT 로봇 도메인에 적용이 가능하지만, 미세조정에는 한계가 있다.",
            "answer": "FALSE",
            "topic": [
                "LAVT의 로봇 도메인 적용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:46:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "m 참조 물체 위치 검출 (Referring Expression Comprehension) - 물체의 정확한 형상까지 원하는 경우가 아닌 경우 더 높은 정확도로 물체가 놓여 있는 위치를 검출할 수 있기 때문에 목표 물체까지의 로봇 내비게이션과 같은 작업에 사용될 수 있음  m 참조 이미지 분할 (Referring Image Segmentation) - 로봇이 제조/물류 환경에서 사람과 함께 작업할 때, 물체의 공식적 명칭뿐 아니라 물체의 특징(크기, 색상, 위치 등)을 통한 표현을 통해서도 물체를 인식하고 협력 작업에 활용될 수 있음",
                "provenance": {
                    "doc_id": "24년 활용 가이드라인_제조환경 사람-로봇 공유 작업 데이터_v1.1.pdf:46:0001",
                    "page": 46
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "물체 위치 검출과 이미지 분할을 통해 로봇이 협력 작업에 활용될 수 있다.",
        "long_answer": {
            "question": "참조 물체 위치 검출과 참조 이미지 분할이 로봇의 제조 및 물류 환경에서 어떤 방식으로 활용될 수 있는지 설명하시오.",
            "answer": "물체의 정확한 형상까지 원하는 경우가 아닌 경우, 더 높은 정확도로 물체가 놓여 있는 위치를 검출할 수 있기 때문에 목표 물체까지의 로봇 내비게이션과 같은 작업에 사용될 수 있다. 또한 로봇이 제조나 물류 환경에서 사람과 함께 작업할 때, 물체의 공식적 명칭 외에도 물체의 특징을 통해 인식하고 협력 작업에 활용될 수 있다. 이때 물체의 특징에는 크기, 색상, 위치 등이 포함된다.",
            "rubric": [
                "로봇 내비게이션; 물체의 특징 인식; 협력 작업"
            ]
        },
        "short_answer": {
            "question": "물체의 특징에 해당되는 요소는?",
            "answer": "크기, 색상, 위치",
            "topic": [
                "물체의 특징 요소"
            ]
        },
        "multiple_choice": {
            "question": "Referring Image Segmentation의 활용 목적에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) 물체의 형상을 단일 시점에서만 단순히 추정한다.",
                "b) 로봇이 사람과 함께 작업할 때 물체의 특징을 활용해 인식한다.",
                "c) 물체의 명칭이 아닌 색상 등의 표현을 통해 인식한다.",
                "d) 제조/물류 환경에서 협력 작업에 적용할 수 있다."
            ],
            "answer": "a",
            "topic": [
                "Referring Image Segmentation의 활용 목적"
            ]
        },
        "true_false": {
            "question": "참조 물체 위치 검출에서는 물체의 형상을 복원하기보다 위치를 검출하는 데 초점을 둔다.",
            "answer": "TRUE",
            "topic": [
                "참조 물체 위치 검출"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:2:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "라벨링 유형 바운딩박스(굴뚝탐지), 라인(굴뚝높이), 세그멘테이션(산업단지, 시가지) 라벨링 형식 JSON(굴뚝탐지, 굴뚝높이), TIF(산업단지, 시가지) 데이터 활용서비스 국내외 대기환경 오염물질의 주요 배출원 및 이동 경로를 파악하기 위한 중요한 기초자료로  활용 데이터 구축년도 2024년  데이터 구축량  원천데이터 25,065장, 60,000건 (Kompsat 10,065장, Sentinel-2 10,000장, Landsat 8/9 5,000장) (GEMS 위성이미지 NO2 월평균(1년) 15,000건, 대기오염측정망 오염물질데이터 NO2, SO2, CO 월평균(1년) 45,000건) 라벨링데이터 35,130장 (굴뚝탐지 10,065장, 굴뚝높이 10,065장, 산업단지 10,000장, 시가지 5,000장)",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:2:0001",
                    "page": 2
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "이 데이터는 굴뚝 탐지, 굴뚝 높이, 산업단지 및 시가지 구분을 위해 JSON과 TIF 형식으로 라벨링되었으며, 국내외 대기오염 물질의 배출원과 이동 경로를 파악하기 위한 기초자료로 활용된다.",
        "long_answer": {
            "question": "위성 영상 데이터 구축의 주요 라벨링 유형과 활용서비스에 대해 설명하시오.",
            "answer": "데이터는 굴뚝 탐지를 위한 바운딩박스, 굴뚝 높이 측정을 위한 라인, 산업단지와 시가지를 위한 세그멘테이션 유형으로 라벨링되었다. 굴뚝 탐지와 굴뚝 높이 데이터는 JSON 형식으로, 산업단지와 시가지 데이터는 TIF 형식으로 저장된다. 구축된 데이터는 국내외 대기환경 오염물질의 주요 배출원과 이동 경로를 파악하기 위한 기초자료로 활용되며, 총 25,065장의 원천데이터와 35,130장의 라벨링데이터로 구성되어 있다.",
            "rubric": [
                "바운딩박스; 라인; 라벨링; 국내외 대기환경의 주요 배출원 및 이동 경로"
            ]
        },
        "short_answer": {
            "question": "굴뚝 높이를 측정하기 위해 사용된 라벨링 유형은?",
            "answer": "라인",
            "topic": [
                "데이터의 라벨링 유형"
            ]
        },
        "multiple_choice": {
            "question": "데이터 구축의 주요 활용 서비스에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 위성영상의 시각화 성능 향상을 위한 이미지 압축 연구에 사용된다.",
                "b) 산업단지 조성계획 수립을 위한 토지이용 제작에 사용된다.",
                "c) 위성 간 통신 오류를 검출하기 위한 신호처리 데이터로 사용된다.",
                "d) 국내외 대기환경 오염물질의 주요 배출원과 이동 경로를 파악하기 위한 기초자료로 활용된다."
            ],
            "answer": "d",
            "topic": [
                "데이터 구축의 주요 활용 서비스"
            ]
        },
        "true_false": {
            "question": "산업단지와 시가지 데이터는 굴뚝 높이 측정과 동일하게 JSON 형식으로 라벨링된다.",
            "answer": "FALSE",
            "topic": [
                "데이터의 라벨링 형식"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:6:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1. 데이터 구축 규모  - 1m 이하 해상도 Kompsat 3/3A 위성영상 원천데이터를 활용하여 굴뚝탐지(바운딩  박스, JSON) 10,065장, 굴뚝높이(라인, JSON) 10,065장을 구축  - 10m 해상도 Sentinel-2 위성영상 원천데이터를 활용하여 산업단지(세그멘테이션, TIF) 10,000장을 구축  - 30m 해상도 Landsat 8/9 위성영상",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:6:0001",
                    "page": 6
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "위성영상을 활용하여 굴뚝 탐지, 굴뚝 높이, 산업단지 라벨링 데이터를 구축한다.",
        "long_answer": {
            "question": "해상도별 위성영상을 활용한 데이터 구축 규모에 대해 설명하시오.",
            "answer": "1m 이하 해상도의 Kompsat 3/3A 위성영상을 사용하여 굴뚝 탐지(바운딩박스, JSON) 10,065장과 굴뚝 높이(라인, JSON) 10,065장을 구축했다. 10m 해상도의 Sentinel-2 위성영상을 활용하여 산업단지(세그멘테이션, TIF) 10,000장을 구축했다. 또한 30m 해상도 Landsat 8/9 위성영상도 데이터 구축에 활용하였다.",
            "rubric": [
                "1m 이하 해상도; Kompsat 3/3A; 10m 해상도; Sentinel-2; 30m 해상도; Landsat 8/9"
            ]
        },
        "short_answer": {
            "question": "산업단지 데이터 구축에 활용된 위성영상의 해상도는?",
            "answer": "10m",
            "topic": [
                "산업단지 데이터 위성영상의 해상도"
            ]
        },
        "multiple_choice": {
            "question": "Sentinel-2 위성영상을 활용한 데이터 구축 설명으로 틀리게 짝지어진 것은?",
            "choices": [
                "a) 굴뚝 높이 라벨링 데이터: 10,065장",
                "b) 산업단지 구축: 10,000장",
                "c) 라벨링 형식: TIF",
                "d) 해상도: 10m"
            ],
            "answer": "a",
            "topic": [
                "Sentinel-2 위성영상을 활용한 데이터 구축"
            ]
        },
        "true_false": {
            "question": "Landsat 8/9 위성영상의 해상도는 30m이다.",
            "answer": "TRUE",
            "topic": [
                "Landsat 8/9 위성영상의 해상도"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:7:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1. 모델 학습 본 사업에서는 LMM 연계방안을 고려하여 다양한 해상도의 위성영상자료를 활용하는 멀티모달 AI 알고리즘을 개발함; 1) 굴뚝의 객체를 탐지하고 탐지된 굴뚝의 높이를 추정하는 인공지능 모델 2) 대규모 산업단지를 분류하는 인공지능 모델 3) 시가지를 분류하는 인공지능 모델. 1.1 굴뚝 탐지 및 높이 추론 모델 (YOLOv8 + Regression) - 입력데이터: KOMPSAT-3/3A 위성 이미지(512×512픽셀) - 라벨데이터 : 굴뚝 객체의 위치를 정의한 바운딩박스 데이터 - 학습데이터셋 비율 : train:val:test = 8:1:1로 분할",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:7:0001",
                    "page": 7
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "다양한 해상도 위성영상을 활용해 여러 작업을 수행하는 멀티모달 AI 모델을 개발하며, 굴뚝 탐지 및 추론 YOLOv8과 Regression이 사용됐다.",
        "long_answer": {
            "question": "위성영상 기반 멀티모달 AI 모델 학습에서 개발하는 모델 종류와 굴뚝 탐지 및 높이 추론 모델의 구성 및 내용에 대해 설명하시오.",
            "answer": "본 사업에서는 다양한 해상도의 위성영상자료를 활용하는 멀티모달 AI 알고리즘을 개발한다. 그 종류로는 굴뚝 객체를 탐지하여 탐지된 굴뚝 높이를 추정하는 모델, 대규모 산업단지 분류 모델, 시가지 분류 모델이 포함된다. 굴뚝 탐지 및 높이 추정 모델은 YOLOv8과 Regression 방식을 결합하여 학습된다. 입력데이터로는 KOMPSAT-3/3A 위성 이미지를 사용하며, 라벨데이터는 굴뚝 객체의 위치를 정의한 바운딩박스로 제공된다. 학습 데이터셋은 train:val:test 비율을 8:1:1로 분할하여 모델을 학습하고 검증한다.",
            "rubric": [
                "굴뚝 높이 추정 모델; 대규모 산업단지 분류 모델; 시가지 분류 모델; 입력 데이터; 라벨 데이터; 학습 데이터셋"
            ]
        },
        "short_answer": {
            "question": "학습데이터셋의 train:val:test 비율은?",
            "answer": "8:1:1",
            "topic": [
                "학습데이터셋의 비율"
            ]
        },
        "multiple_choice": {
            "question": "굴뚝 탐지 및 높이 추론 모델 학습에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) YOLOv8과 Regression을 결합하여 학습한다.",
                "b) 입력데이터는 KOMPSAT-3/3A 위성이미지를 사용한다.",
                "c) 입력데이터는 Sentinel-2 위성영상을 사용한다.",
                "d) 학습데이터셋 비율은 train:val:test = 8:1:1이다."
            ],
            "answer": "c",
            "topic": [
                "굴뚝 탐지 및 높이 추론 모델의 학습"
            ]
        },
        "true_false": {
            "question": "본 사업에서 시가지를 분류하는 인공지능 모델은 다루지 않는다.",
            "answer": "FALSE",
            "topic": [
                "시가지 분류 모델"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:7:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1.2 산업단지 분류 모델 (Modified Trans-UNet) - 입력데이터: Sentinel-2(512×512픽셀) 이미지, GEMS(64×64픽셀) 이미지, 대기오염 측정망 데이터(64×64픽셀) - 라벨데이터 : 산업단지 영역 분류(Semantic Segmentation)를 위해 tif 이미지로 구축 - 학습데이터셋 비율 : train:val:test = 8:1:1로 분할",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:7:0001",
                    "page": 7
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "Sentinel-2, GEMS, 대기오염 측정망 데이터 입력으로 산업단지 영역 분류를 위해 구축한다.",
        "long_answer": {
            "question": "산업단지 분류 모델 학습에서 사용된 입력데이터와 라벨데이터, 학습데이터셋 분할 방식에 대해 구체적으로 설명하시오.",
            "answer": "산업단지 분류 모델의 입력데이터는 Sentinel-2 이미지와 GEMS 이미지, 대기오염 측정망 데이터로 구성된다. 라벨데이터는 산업단지 영역 분류를 위해 tif 이미지로 구축한다. 이때 학습데이터셋의 비율은 train:val:test를 8:1:1로 분할한다.",
            "rubric": [
                "Sentinel-2; GEMS; 대기오염 측정망 데이터; tif 이미지"
            ]
        },
        "short_answer": {
            "question": "산업단지 분류 모델 라벨데이터의 이미지 형식은?",
            "answer": "tif",
            "topic": [
                "산업단지 분류 모델 라벨데이터의 이미지 형식"
            ]
        },
        "multiple_choice": {
            "question": "산업단지 분류 모델 학습에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 모델 구조는 YOLOv8 기반 회귀 모델이다.",
                "b) 입력데이터에는 GEMS, 대기오염 측정망 데이터가 포함된다.",
                "c) 산업단지 영역 분류를 위해 jpg 이미지로 구축한다",
                "d) 라벨데이터는 바운딩박스로 구축된다."
            ],
            "answer": "b",
            "topic": [
                "산업단지 분류 모델 학습"
            ]
        },
        "true_false": {
            "question": "Sentinel-2 이미지의 픽셀은 512×512픽셀이다.",
            "answer": "TRUE",
            "topic": [
                "Sentinel-2 이미지의 픽셀"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:7:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "1.3 시가지 분류 모델 (Modified Trans-UNet) - 입력데이터: Landsat 8/9(256×256픽셀) 이미지, GEMS(64×64픽셀) 이미지, 대기오염 측정망 데이터(64×64픽셀) - 라벨데이터 : 시가지 영역 분류(Semantic Segmentation)를 위해 tif 이미지로 구축 - 학습데이터셋 비율 : train:val:test = 8:1:1로 분할",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:7:0001",
                    "page": 7
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "Landsat 8/9, GEMS, 대기오염 측정망 데이터를 기반으로 시가지 분류 모델을 구축한다.",
        "long_answer": {
            "question": "시가지 분류 모델의 입력데이터와 라벨데이터의 종류 및 픽셀 조건을 서술하시오.",
            "answer": "시가지 분류 모델의 입력데이터는 Landsat 8/9 이미지와 GEMS 이미지, 대기오염 측정망 데이터가 있다. Landsat 8/9 이미지의 픽셀은 256x256이며, GEMS 이미지는 64x64 픽셀, 대기오염 측정망 데이터 또한 동일하다. 라벨데이터는 시가지 영역 분류를 위해 tif 이미지로 구축된다.",
            "rubric": [
                "Landsat 8/9; GEMS; 대기오염 측정망 데이터; 픽셀; tif 이미지"
            ]
        },
        "short_answer": {
            "question": "시가지 분류 모델의 구조는?",
            "answer": "Modified Trans-UNet",
            "topic": [
                "시가지 분류 모델의 구조"
            ]
        },
        "multiple_choice": {
            "question": "시가지 분류 모델 학습에 대한 올바른 설명은?",
            "choices": [
                "a) 입력데이터는 Landsat 8/9, GEMS, 대기오염 측정망 데이터이다.",
                "b) 학습데이터셋 비율은 train:val:test = 7:2:1이다.",
                "c) 모델 구조는 YOLOv8이 사용되었다.",
                "d) 시가지 영역 분류를 위해 tif 이미지로 구축된다."
            ],
            "answer": "a",
            "topic": [
                "시가지 분류 모델의 학습"
            ]
        },
        "true_false": {
            "question": "시가지 분류 모델의 GEMS 이미지 픽셀은 대기오염 측정망 데이터보다 크다.",
            "answer": "FALSE",
            "topic": [
                "시가지 분류 모델의 데이터 픽셀"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:7:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "2. 서비스 활용 시나리오 - 본 사업에서 구축한 AI 학습용 데이터셋은 대기오염 현황분석 및 대기오염 관리를 위한 기반 자료로 활용 가능 - 본 사업에서 구축한 멀티모달 AI 알고리즘은 해상도가 다른 다양한 위성영상 자료를",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:7:mh: 00001",
                    "page": 7
                }
            },
            {
                "context_id": "2",
                "text": "입력데이터로 활용하여 효과적인 국내외 대기오염 배출원 정보를 구축 가능 - 우리나라 대기질에 영향을 주는 대규모 대기오염 배출원인 산업단지와 시가지, 굴뚝을 탐지하는 기술 연구에 적용 및 활용 가능",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:7:mh: 00001",
                    "page": 8
                }
            }
        ],
        "summarization": "구축된 AI 학습용 데이터셋과 멀티모달 AI 알고리즘은 다양한 해상도의 위성영상을 활용하여 국내외 대기오염 배출원 정보를 분석하고, 다양한 기술 연구에 활용될 수 있다.",
        "long_answer": {
            "question": "구축한 AI 학습용 데이터셋과 멀티모달 AI 알고리즘이 대기오염 관리 및 분석에 어떻게 활용될 수 있는지 설명하시오.",
            "answer": "AI 학습용 데이터셋은 대기오염 현황분석 및 관리의 기반 자료로 활용된다. 멀티모달 AI 알고리즘은 서로 다른 해상도의 위성영상을 입력데이터로 사용하여 국내외 대기오염 배출원 정보를 효과적으로 구축할 수 있다. 이를 통해 우리나라 대기질에 영향을 주는 산업단지, 시가지, 굴뚝 등 대규모 대기오염 배출원을 탐지하는 기술 연구에 적용할 수 있다.",
            "rubric": [
                "대기오염 현황분석 및 관리; 국내외 대기오염 배출원 정보; 기술 연구"
            ]
        },
        "short_answer": {
            "question": "대규모 대기오염 배출원에 포함되는 항목은?",
            "answer": "산업단지, 시가지, 굴뚝",
            "topic": [
                "대규모 대기오염 배출원원"
            ]
        },
        "multiple_choice": {
            "question": "AI 학습용 데이터셋과 멀티모달 AI 알고리즘 활용과 관련하여 거리가 먼 것은?",
            "choices": [
                "a) 데이터셋은 대기오염 현황분석의 기반 자료로 활용된다.",
                "b) 멀티모달 AI는 해상도가 다른 위성영상을 입력데이터로 활용한다.",
                "c) 데이터셋은 자연어 처리 기반 문장 생성을 위해 구축된다.",
                "d) 탐지 대상에는 산업단지, 시가지, 굴뚝이 포함된다."
            ],
            "answer": "c",
            "topic": [
                "AI 학습용 데이터셋과 멀티모달 AI 알고리즘 활용"
            ]
        },
        "true_false": {
            "question": "해상도가 다른 위성영상은 국내외 대기오염 배출원 정보를 구축하는 데 효과적이다.",
            "answer": "TRUE",
            "topic": [
                "해상도가 다른 위성영상의 활용"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:8:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터셋  명  국문 대기오염 배출원 공간 분포 데이터  영문 Air pollution source space distribution data  구축 목적 국내 대기환경에 영향을 주는 오염원 탐지를 AI로 분석하기 위한 대기오염 배출원 데이터로    굴뚝탐지 및 높이, 대규모 산업단지 및 시가지 예측 기술 개발    소개 초거대 AI 기술을 적용하여 한국, 중국 일부 지역을 대상으로 대기오염 배출원(굴뚝탐지와    높이, 산업단지, 시가지)을 추정하는 데이터의 구축    활용 분야 국내외 대기환경 오염물질의 주요 배출원 및 이동 경로를 파악하기 위한 중요한 기초자료로    활용    데이터 구축  절차 요약    - 데이터 수집 : 한국항공우주연구원 Kompsat 3/3A, ESA Sentinel-2, USGS Landsat  8/9 위성영상, 국립환경과학원 환경위성센터 GEMS 위성영상, 에어코리아/UNEP Air Quality Monitoring Platform 대기오염측정망  오염물질데이터 수집  - 데이터 정제 : Kompsat 3/3A, Sentinel-2, Landsat 8/9, GEMS 위성이미지, 대기오염측정망 오염물질데이터 정제  - 데이터 가공 : 굴뚝탐지, 굴뚝높이, 산업단지, 시가지 라벨링데이터 가공",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:8:0001",
                    "page": 8
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "국내외 대기오염 배출원을 탐지하기 위해 대기오염측정망 데이터를 수집, 정제, 가공하여 굴뚝, 산업단지, 시가지를 예측할 수 있는 AI 학습용 데이터셋을 구축하였다.",
        "long_answer": {
            "question": "대기오염 배출원 공간 분포 데이터의 구축 개요와 절차를 구체적으로 설명하시오.",
            "answer": "대기오염 배출원 공간 분포 데이터는 국내 대기환경에 영향을 미치는 주요 오염원을 AI로 분석하기 위한 기초 데이터로 구축되었다. 한국항공우주연구원, ESA, USGS 등에서 제공하는 Kompsat 3/3A, Sentinel-2, Landsat 8/9 위성영상과 GEMS 위성영상, 대기오염측정망 오염물질데이터를 수집하였다. 수집된 데이터는 굴뚝탐지, 굴뚝높이, 산업단지, 시가지에 대한 정제 데이터를 가공하여 AI 학습용 형태로 변환하였다.",
            "rubric": [
                "국내 대기환경; 위성영상; 대기오염측정망 오염물질데이터; 정제; 가공"
            ]
        },
        "short_answer": {
            "question": "대기오염 배출원 공간 분포 데이터 구축의 주요 단계 세 가지는?",
            "answer": "수집, 정제 가공",
            "topic": [
                "대기오염 배출원 공간 분포 데이터 구축의 주요 단계"
            ]
        },
        "multiple_choice": {
            "question": "대기오염 배출원 공간 분포 데이터 구축 절차에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) Kompsat, Sentinel-2, Landsat, GEMS, 대기오염측정망 데이터를 수집하였다.",
                "b) 데이터는 텍스트 문장 합성을 중심으로 수집되었다.",
                "c) 국외 대기오염 분석을 위한 기반 데이터로 구축되었다.",
                "d) 텍스트 생성형 데이터셋으로 구축되었다."
            ],
            "answer": "a",
            "topic": [
                "대기오염 배출원 공간 분포 데이터 구축 절차"
            ]
        },
        "true_false": {
            "question": "대기오염 배출원 공간 분포 데이터 구축에는 대기오염측정망 데이터만 활용되었다.",
            "answer": "FALSE",
            "topic": [
                "대기오염 배출원 공간 분포 데이터 구축의 데이터"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:8:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "데이터 분야 재난안전환경 데이터 유형 이미지 데이터 형식 JSON, TIF 데이터 출처 자체수집 라벨링 유형 바운딩박스, 라인, 세그멘테이션 라벨링 형식 JSON, TIF 데이터 활용 서비스 국내외 대기환경 오염물질 주요 배출원 분석  데이터 구축년도/ 데이터 구축량 2024년 / 35,130장",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:8:0001",
                    "page": 8
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "재난안전환경 분야의 이미지 데이터로, 자체수집한 위성영상 기반 JSON 및 TIF 형식으로 구축되었으며, 라벨링이 적용되었다.",
        "long_answer": {
            "question": "본 데이터의 형식과 라벨링 유형 그리고 활용 방안에 대해 설명하시오.",
            "answer": "해당 데이터는 재난안전환경 데이터 유형 이미지로, 2024년 총 35,130장이 구축되었다. 형식은 자체수집한 JSON, TIF 데이터이며, 바운딩박스와 라인, 세그멘테이션을 JSON과 TIF 형식으로 라벨링했다. 이는 국내외 대기환경 오염물질의 주요 배출원 분석에 활용되었다.",
            "rubric": [
                "JSON; TIF; 배출원 분석"
            ]
        },
        "short_answer": {
            "question": "데이터의 라벨링 형식은?",
            "answer": "JSON, TIF",
            "topic": [
                "데이터의 라벨링 형식"
            ]
        },
        "multiple_choice": {
            "question": "데이터의 구축 정보로 틀린 것은?",
            "choices": [
                "a) 데이터는 자체 수집을 통해 구축되었다.",
                "b) 2024년에 총 35,130장이 구축되었다.",
                "c) 라벨링은 세그멘테이션 방식만 포함된다.",
                "d) JSON과 TIF 형식으로 구성되어 있다."
            ],
            "answer": "c",
            "topic": [
                "데이터의 구축 정보"
            ]
        },
        "true_false": {
            "question": "재난안전환경 이미지 데이터의 출처는 자체수집이다.",
            "answer": "TRUE",
            "topic": [
                "재난안전환경 이미지 데이터의 출처"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:13:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "○ Kompsat 3/3A - Arirang Satellite Image Search & Order System에 회원가입 및 로그인하여 지도상에 원하는 범위를 표기하고, 촬영기간, 운량조건, 위성종류 등을 선택한 후 위성영상을 검색 - 신청하고자 하는 위성영상 목록을 선택하고, 한국항공우주연구원과 위성정보활용 협의체인 국립환경과학원 환경위성센터를 통해 오프라인 수집 및 오프라인 저장·관리 * 중국은 베이징, 텐진시, 허베이성, 산둥성, 상하이, 저장성, 장쑤성 일대를 위주로 검색 및 다운로드",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:13:0001",
                    "page": 13
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "Kompsat 3/3A 위성영상은 Arirang Satellite Image Search & Order System을 통해 검색 후, 국립환경과학원 환경위성센터를 통해 오프라인으로 수집·저장된다.",
        "long_answer": {
            "question": "Kompsat 3/3A 위성영상의 수집 과정을 설명하시오.",
            "answer": "Kompsat 3/3A 위성영상은 Arirang Satellite Image Search & Order System에 회원가입 및 로그인한 후 지도상에서 원하는 범위를 지정하고 촬영기간, 운량조건, 위성종류 등을 선택하여 검색한다. 원하는 위성영상 목록을 선택한 뒤, 한국항공우주연구원과 위성정보활용 협의체인 국립환경과학원 환경위성센터를 통해 영상을 오프라인으로 수집하고 저장·관리한다. 또한 중국 지역은 베이징, 텐진시, 허베이성, 산둥성, 상하이, 저장성, 장쑤성 일대를 중심으로 위성영상을 검색 및 다운로드한다.",
            "rubric": [
                "Arirang Satellite Image Search & Order System; 촬영기간; 운량조건; 위성종류; 오프라인 수집"
            ]
        },
        "short_answer": {
            "question": "Kompsat 3/3A 위성영상을 검색하기 위해 사용되는 시스템은?",
            "answer": "Arirang Satellite Image Search & Order System",
            "topic": [
                "Kompsat 3/3A 위성영상 검색"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 Kompsat 3/3A 위성영상 수집 절차에 대한 설명으로 옳은 것은?",
            "choices": [
                "a) 위성영상은 자동으로 온라인 저장소에만 저장된다.",
                "b) Arirang 시스템에서 촬영기간과 운량조건을 설정해 검색할 수 있다.",
                "c) 중국 전역의 모든 도시를 대상으로 수집된다.",
                "d) 위성정보는 외부 민간기관을 통해 관리된다."
            ],
            "answer": "b",
            "topic": [
                "Kompsat 3/3A 위성영상 수집 절차"
            ]
        },
        "true_false": {
            "question": "국립환경과학원 환경위성센터를 통해 영상을 오프라인으로 수집한다.",
            "answer": "TRUE",
            "topic": [
                "Kompsat 3/3A 위성영상의 오프라인 수집"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:13:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "○ Sentinel-2 - ESA Copernicus Data Space Ecosystem에 회원가입 및 로그인하여 지도상에 원하는 범위를 표기하고, 위성종류, 촬영기간을 선택한 후 위성영상을 검색 - 신청하고자 하는 한·중 일대 위성영상 목록을 선택하고, 웹 다운로드 실시 * 중국은 베이징, 텐진시, 허베이성, 산둥성, 상하이, 저장성, 장쑤성 일대를 위주로 검색 및",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:13:mh: 00001",
                    "page": 13
                }
            },
            {
                "context_id": "2",
                "text": "다운로드",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:13:mh: 00001",
                    "page": 14
                }
            }
        ],
        "summarization": "Sentinel-2 위성영상은 ESA Copernicus Data Space Ecosystem을 통해 회원가입 후 검색하고, 한·중 지역 영상을 선택하여 웹으로 다운로드한다.",
        "long_answer": {
            "question": "Sentinel-2 위성영상의 획득 경로 및 절차를 서술하시오.",
            "answer": "Sentinel-2 위성영상은 ESA Copernicus Data Space Ecosystem에 회원가입 및 로그인한 후, 지도상에서 원하는 범위를 표기하고 위성종류와 촬영기간을 선택하여 검색한다. 신청하고자 하는 한·중 일대의 위성영상 목록을 선택한 뒤, 웹 다운로드를 실시한다. 또한 중국 지역은 베이징, 텐진시, 허베이성, 산둥성, 상하이, 저장성, 장쑤성 일대를 중심으로 위성영상을 검색 및 다운로드한다.",
            "rubric": [
                "ESA Copernicus Data Space Ecosystem; 위성종류; 촬영기간; 웹 다운로드"
            ]
        },
        "short_answer": {
            "question": "ESA Copernicus Data Space Ecosystem에서 선택 가능한 옵션은?",
            "answer": "위성종류, 촬영기간",
            "topic": [
                "ESA Copernicus Data Space Ecosystem의 선택 가능 옵션"
            ]
        },
        "multiple_choice": {
            "question": "Sentinel-2 위성영상 수집 절차에 대한 설명으로 틀린 것은?",
            "choices": [
                "a) ESA Copernicus Data Space Ecosystem을 이용한다.",
                "b) 중국의 베이징, 상하이, 저장성 일대를 중심으로 검색한다.",
                "c) 웹 다운로드 방식으로 영상을 수집한다.",
                "d) 오프라인 다운로드 방식으로 영상을 수집한다."
            ],
            "answer": "d",
            "topic": [
                "Sentinel-2 위성영상 수집 절차"
            ]
        },
        "true_false": {
            "question": "Sentinel-2 위성영상 수집 시, 신청 가능한 위성영상의 지역은 한국과 일본이다.",
            "answer": "FALSE",
            "topic": [
                "Sentinel-2 위성영상 신청 가능 지역"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "○ Landsat 8/9 - USGS EarthExplorer에 회원가입 및 로그인하여 지도상에 원하는 범위를 표기하고, 촬영기간, 위성종류 등을 선택한 후 위성영상을 검색 - 신청하고자 하는 위성영상 목록을 선택하고, 웹 다운로드 실시 * 중국은 베이징, 텐진시, 허베이성, 산둥성, 상하이, 저장성, 장쑤성 일대를 위주로 검색 및 다운로드",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "Landsat 8/9 위성영상은 USGS EarthExplorer 플랫폼을 통해 회원가입 후 검색하고, 선택한 영상 목록을 웹으로 다운로드한다.",
        "long_answer": {
            "question": "Landsat 8/9 위성영상 수집 및 다운로드 방법에 대해 설명하시오.",
            "answer": "Landsat 8/9 위성영상은 USGS EarthExplorer에 회원가입 및 로그인한 후, 지도상에서 원하는 범위를 표기하고 촬영기간과 위성종류를 선택하여 검색한다. 신청하고자 하는 위성영상 목록을 선택한 뒤, 웹 다운로드를 실시한다. 중국 지역은 베이징, 텐진시, 허베이성, 산둥성, 상하이, 저장성, 장쑤성 일대를 중심으로 검색 및 다운로드한다.",
            "rubric": [
                "USGS EarthExplorer; 촬영기간; 위성종류; 웹 다운로드"
            ]
        },
        "short_answer": {
            "question": "Landsat 8/9 위성영상 다운로드가 가능한 중국 지역은?",
            "answer": "베이징, 텐진시, 허베이성, 산둥성, 상하이, 저장성, 장쑤성",
            "topic": [
                "Landsat 8/9 위성영상 다운로드 지역"
            ]
        },
        "multiple_choice": {
            "question": "Landsat 8/9 위성영상 수집 절차에 대한 설명으로 적절한 것은?",
            "choices": [
                "a) 국립환경과학원 환경위성센터를 통해 오프라인으로 수집된다.",
                "b) 한국 지역만 대상으로 검색이 허용된다.",
                "c) ESA Copernicus Data Space Ecosystem에 회원가입 후 검색한다.",
                "d) USGS EarthExplorer를 통해 회원가입 후 검색한다."
            ],
            "answer": "d",
            "topic": [
                "Landsat 8/9 위성영상 수집 절차"
            ]
        },
        "true_false": {
            "question": "Landsat 8/9 위성영상은 촬영기간, 위성종류 등을 선택하여 검색할 수 있다.",
            "answer": "TRUE",
            "topic": [
                "Landsat 8/9 위성영상의 검색 범위"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "○ GEMS 위성이미지 - 국립환경과학원 환경위성센터 홈페이지에 회원가입 및 로그인하여 자료서비스에서 GEMS Open-API를 통해 키를 발급받고(승인필요) 원하는 데이터 웹 다운로드 실시 - 또는 국립환경과학원 환경위성센터에 직접 요청하는 방식으로 데이터 획득",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GEMS 위성이미지는 국립환경과학원 환경위성센터에서 회원가입 후 웹 다운로드하거나, 요청하여 획득할 수 있다.",
        "long_answer": {
            "question": "GEMS 위성이미지 데이터 수집 및 다운로드 절차에 대해 서술하시오.",
            "answer": "GEMS 위성이미지는 국립환경과학원 환경위성센터 홈페이지에 회원가입 및 로그인한 후, 자료서비스에서 GEMS Open-API를 통해 키를 발급받아야 한다. 이때 승인이 필요하며, 이후 데이터 웹 다운로드가 가능하다. 또한 필요할 경우 환경위성센터에 직접 요청하여 데이터를 획득할 수도 있다.",
            "rubric": [
                "국립환경과학원 환경위성센터; GEMS Open-API; 직접 요청"
            ]
        },
        "short_answer": {
            "question": "GEMS 위성이미지 다운로드 시 필요한 키의 획득 경로는?",
            "answer": "GEMS Open-API",
            "topic": [
                "GEMS 위성이미지의 다운로드 경로"
            ]
        },
        "multiple_choice": {
            "question": "GEMS 위성이미지 데이터 수집 절차에 대한 설명으로 부적합한 것은?",
            "choices": [
                "a) 회원가입 후 Open-API 키 발급이 필요하다.",
                "b) 데이터는 ESA Copernicus Data Space Ecosystem을 통해 다운로드한다.",
                "c) 승인 절차를 거쳐 웹 다운로드가 가능하다.",
                "d) 데이터는 국립환경과학원 환경위성센터에 직접 요청해 획득할 수도 있다."
            ],
            "answer": "b",
            "topic": [
                "GEMS 위성이미지의 데이터 수집 절차"
            ]
        },
        "true_false": {
            "question": "GEMS 위성이미지는 별도의 승인 절차 없이 다운로드가 가능하다.",
            "answer": "FALSE",
            "topic": [
                "GEMS 위성이미지의 데이터 수집 절차"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "○ 대기오염측정망 오염물질데이터 - (한국) 에어코리아 통계정보에서 최종확정 측정자료 조회에서 조회기간 및 측정망, 지역, 측정소(전체 선택 가능)을 선택하여 웹 다운로드 실시 - (중국) UNEP Air Quality Monitoring Platform에서 측정소 위치를 확인하고, 해당 측정소별 측정값을 Air Pollution in World에서 다운로드 실시",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "한국과 중국의 대기오염측정망 자료는 플랫폼을 통해 조회·선택 후 웹 다운로드하며, 중국 측정소 데이터는 Air Pollution in World에서 획득한다.",
        "long_answer": {
            "question": "대기오염측정망 오염물질데이터의 국가별 수집 절차를 각각 서술하시오.",
            "answer": "대기오염측정망 오염물질데이터는 한국의 경우, 에어코리아 통계정보에서 최종확정 측정자료 조회를 한다. 이후 조회기간, 측정망, 지역 측정소를 선택한 후 웹 다운로드가 가능하다. 중국의 경우, UNEP Air Quality Monitoring Platform에서 측정소 위치를 확인하고, 해당 측정소별 측정값을 Air Pollution in World에서 다운로드한다.",
            "rubric": [
                "에어코리아 통계정보; UNEP Air Quality Monitoring Platform; Air Pollution in World"
            ]
        },
        "short_answer": {
            "question": "대기오염측정망 오염물질데이터의 측정소별 측정값 다운로드가 가능한 플랫폼은?",
            "answer": "Air Pollution in World",
            "topic": [
                "대기오염측정망 오염물질데이터의 측정소별 측정값 다운로드"
            ]
        },
        "multiple_choice": {
            "question": "대기오염측정망 오염물질데이터 수집 절차에 대한 옳은 설명은?",
            "choices": [
                "a) 한국에서는 Air Pollution in World에서 다운로드한다.",
                "b) 중국에서는 Air Pollution in World에서 다운로드한다.",
                "c) Open-API 키를 발급받아 다운로드한다.",
                "d) 오프라인 데이터로만 수집 가능하다."
            ],
            "answer": "b",
            "topic": [
                "대기오염측정망 오염물질데이터의 수집 절차"
            ]
        },
        "true_false": {
            "question": "중국 대기오염 측정망 자료는 ESA Copernicus Data Space Ecosystem을 통해 다운로드된다.",
            "answer": "FALSE",
            "topic": [
                "중국 대기오염 측정망 자료 다운로드"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "○ 굴뚝탐지 및 높이 - Kompsat 3/3A 3개의 밴드로 구성된 0.7m/0.55m 위성이미지로 정제 - QGIS 가상 래스터 생성 툴을 이용하여, Red, Green, Blue 3밴드의 Tiff 포맷 이미지로 정제 * 굴뚝탐지 및 높이 확인을 위해 촬영각도는 10도 이상의 위성영상을 선정 - 중국 베이징, 텐진시, 허베이성, 산둥성, 상하이, 저장성, 장쑤성 일대를 대상지에 포함 - 굴뚝 탐지 데이터는 GEMS 위성이미지를 활용하여 대기질이 안좋은 지역을 선정하고, 중국 굴뚝 현황을 확인하여 대상지로 선정 - 학습데이터용 원시데이터 정제 (= 위성이미지 원천데이터) : 위성이미지 원시데이터를 굴뚝의 위치가 이미지에 고루 분포할 수 있도록, 픽셀크기 512×512 및 중복률 50%로 이미지 분할",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "굴뚝탐지 및 높이 데이터는 Kompsat 3/3A 위성이미지를 정제하고 촬영각도, 픽셀 크기, 중복률 기준으로 분할하여 굴뚝 위치가 이미지에 고르게 분포하도록 구성한다.",
        "long_answer": {
            "question": "굴뚝탐지 및 높이 데이터의 정제 과정과 대상지 선정 기준을 상세히 설명하시오.",
            "answer": "Kompsat 3/3A 3밴드로 구성된 0.7m/0.55m 위성이미지로 정제하며, QGIS 가상 래스터 생성 툴을 이용하여 Red, Green, Blue 3밴드 Tiff 포맷으로 정제한다. 촬영각도가 10도 이상인 위성영상 선정하고, 중국의 베이징, 텐진시, 허베이성, 산둥성, 상하이, 저장성, 장쑤성 일대를 대상지에 포함한다. 굴뚝탐지 데이터는 GEMS 위성이미지를 활용하여 대기질이 안 좋은 지역을 선정하고, 중국 굴뚝 현황을 확인하여 대상지를 결정하며, 학습용 원시데이터는 픽셀 크기 512×512, 중복률 50% 기준으로 이미지 분할한다.",
            "rubric": [
                "Kompsat 3/3A; 3밴드; QGIS 가상 래스터 생성 툴; 촬영각도; 굴뚝탐지 데이터; 픽셀 크기; 중복률"
            ]
        },
        "short_answer": {
            "question": "Tiff 포맷으로 정제된 3밴드의 종류는?",
            "answer": "Red, Green, Blue",
            "topic": [
                "Tiff 포맷으로 정제된 3밴드의 종류"
            ]
        },
        "multiple_choice": {
            "question": "굴뚝탐지 데이터 정제 기준으로 올바르지 않은 것은?",
            "choices": [
                "a) 촬영각도가 8도 이상인 위성영상을 선정한다.",
                "b) Kompsat 3/3A 위성이미지를 사용한다.",
                "c) 중국 주요 도시 및 성 지역을 대상지로 포함한다.",
                "d) 중복률 50%로 이미지를 분할한다."
            ],
            "answer": "a",
            "topic": [
                "굴뚝탐지 데이터 정제 기준으로 올바르지 않은 것은?"
            ]
        },
        "true_false": {
            "question": "굴뚝탐지 데이터는 GEMS 위성이미지를 활용하여 대기질이 나쁜 지역을 대상지로 선정한다.",
            "answer": "TRUE",
            "topic": [
                "굴뚝탐지 데이터의 대상지 선정"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "○ 산업단지 - Sentinel-2 각 밴드를 조합하여 4개 밴드로 구성된 10m 위성이미지로 정제 - QGIS 가상 래스터 생성 툴을 이용하여, Red, Green, Blue, Nir 4밴드의 Tiff 포맷이미지로 정제 - QGIS 래스터 재투영 툴을 이용하여 EPSG 5186 (Korea2000/Central Blet 2010) 으로 변환 * 중국은 UTM zone 50(32650), UTM zone 51(32651)으로 변환 - 학습데이터용 원시데이터 정제 (= 위성이미지 원천데이터) : 위성이미지 원시데이터를 픽셀크기 512×512 및 중복률 25%로 이미지 분할",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "산업단지 데이터는 Sentinel-2 4밴드 이미지로 정제하고 한국 및 중국으로 재투영하며, 픽셀 크기와 중복률을 기준으로 이미지를 분할한다.",
        "long_answer": {
            "question": "산업단지 데이터의 정제 및 재투영 과정에 대해 설명하시오.",
            "answer": "Sentinel-2 각 밴드를 조합하여 4개 밴드의 10m 위성이미지로 정제하고 Red, Green, Blue, Nir 4밴드로 구성된 10m 위성이미지를 QGIS 가상 래스터 생성 툴을 이용하여 Tiff 포맷으로 정제한다. QGIS 래스터 재투영 툴로 한국은 EPSG 5186, 중국은 UTM zone 50과 UTM zone 51으로 재투영한다. 학습용 원시데이터는 픽셀 크기 512×512, 중복률 25% 기준으로 이미지를 분할한다.",
            "rubric": [
                "Sentinel-2; 4밴드; QGIS 가상 래스터 생성 툴; QGIS 래스터 재투영 툴"
            ]
        },
        "short_answer": {
            "question": "산업단지 데이터의 학습용 원시데이터 이미지 분할 시, 픽셀 크기는?",
            "answer": "512x512",
            "topic": [
                "산업단지 데이터의 학습용 원시데이터 분할 픽셀 크기"
            ]
        },
        "multiple_choice": {
            "question": "산업단지 데이터 정제 기준에 대한 특징으로 올바르게 짝지어진 것은?",
            "choices": [
                "a) 정제 위성이미지 - 15m",
                "b) 재투영 - 한국 UTM zone 50, 중국 UTM zone 51",
                "c) 4밴드 - Red, Green, Blue, Yellow",
                "d) 중복률 - 25%"
            ],
            "answer": "d",
            "topic": [
                "산업단지 데이터의 정제 기준"
            ]
        },
        "true_false": {
            "question": "산업단지 데이터는 Sentinel-2 3밴드 Tiff 이미지로 정제 후, EPSG 5186 및 UTM zone 50/51으로 재투영된다.",
            "answer": "FALSE",
            "topic": [
                "산업단지 데이터의 정제 및 재투영 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "○ 시가지 - Landsat 8/9 각 밴드를 조합하여 4개 밴드로 구성된 30m 위성이미지로 정제 - QGIS 가상 래스터 생성 툴을 이용하여 Red, Green, Blue, NIR 4밴드의 Tiff 포맷 이미지로 정제 - QGIS 래스터 재투영 툴을 이용하여 EPSG 5186 (Korea2000/Central Blet 2010) 으로 변환 * 중국은 UTM zone 50(32650), UTM zone 51(32651)으로 변환 - 30m 위성이미지 데이터 정제 (= 위성이미지 원천데이터) : 위성이미지 원시데이터를 픽셀크기 256×256 및 중복률 25%로 이미지 분할",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "시가지 데이터는 Landsat 8/9 4밴드 Tiff 이미지로 정제하고, 한국 및 중국으로 재투영하며, 픽셀 크기와 중복률 기준으로 이미지를 분할한다.",
        "long_answer": {
            "question": "시가지 데이터의 정제 내용에 대해 서술하시오.",
            "answer": "Landsat 8/9 각 밴드를 조합하여 Red, Green, Blue, NIR 4밴드로 구성된 30m 위성이미지를 QGIS 가상 래스터 생성 툴을 이용하여 Tiff 포맷으로 정제한다. 한국은 EPSG 5186으로, 중국은 UTM zone 50(32650)과 UTM zone 51으로 재투영한다. 학습용 원시데이터는 픽셀 크기 256×256, 중복률 25% 기준으로 이미지를 분할하여 시가지 영역이 고르게 분포하도록 한다.",
            "rubric": [
                "Landsat 8/9; 4밴드; QGIS 가상 래스터 생성 툴"
            ]
        },
        "short_answer": {
            "question": "시가지 데이터에서 Tiff 포맷으로 정제하는 위성이미지의 크기는?",
            "answer": "30m",
            "topic": [
                "시가지 데이터 위성이미지의 크기"
            ]
        },
        "multiple_choice": {
            "question": "시가지 데이터 정제 기준으로 적합한 것은?",
            "choices": [
                "a) Sentinel-2 4밴드 Tiff, UTM 50/51, 픽셀 512×512, 중복률 25%",
                "b) Landsat 8/9 3밴드 Tiff, EPSG 4326, 픽셀 512×512, 중복률 50%",
                "c) Landsat 8/9 4밴드 Tiff, EPSG 5186(한국), 픽셀 256×256, 중복률 25%",
                "d) Kompsat 3/3A 3밴드, EPSG 5186, 픽셀 512×512, 중복률 50%"
            ],
            "answer": "c",
            "topic": [
                "시가지 데이터 정제 기준"
            ]
        },
        "true_false": {
            "question": "QGIS 가상 래스터 생성 툴을 이용하여 Red, Green, Blue, NIR 4밴드의 Tiff 포맷 이미지로 정제한다.",
            "answer": "TRUE",
            "topic": [
                "시가지 데이터 4밴드의 정제"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "○ GEMS 위성이미지 - 원자료인 L2, L4 자료는 불규칙한 간격으로 관측된 점 패턴(point-pattern) 데이터임 - Linear Interpolation 방식(국립환경과학원, 2024)을 활용하여 재격자화(re-grid) 하여 정제함 - 이때 재격자화를 위한 분석 도구는 본 연구팀이 수행한 기존 연구(국립환경과학원, 2024)에서 개발한 도구 활용 가능 - GEMS L2, L4 원시자료를 대상으로 공간범위 필터링, 재격자화 과정을 거친 데이터는 표준화된 격자형 자료 구조로 구성되게 됨 - 재격자화 된 위성이미지에 대해 동북아시아 및 한반도 범위로 구역 정제 작업 수행 ○ 대기오염측정망 - 측정망 포인트 SHP 파일로 정제 - 측정망 SHP 파일과 최종확정 측정자료 파일 조인",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:0001",
                    "page": 14
                }
            },
            {
                "context_id": "",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "GEMS 위성이미지는 Linear Interpolation으로 재격자화하고, 동북아시아 및 한반도 범위로 구역을 정제하며, 대기오염측정망은 SHP 파일과 최종 측정자료를 조인하여 정제한다.",
        "long_answer": {
            "question": "GEMS 위성이미지의 재격자화와 정제에 관해 서술하시오.",
            "answer": "원자료인 L2, L4 자료는 불규칙한 간격으로 관측된 점 패턴 데이터로, Linear Interpolation 방식을 활용하여 재격자화하여 정제한다. 이때 재격자화를 위한 분석 도구는 본 연구팀이 수행한 기존 연구에서 개발한 도구 활용이 가능하다. GEMS L2, L4 원시자료를 대상으로 공간범위 필터링, 재격자화 과정을 거친 데이터는 표준화된 격자형 자료 구조로 구성된다. 이후 재격자화 된 위성이미지에 대해 동북아시아 및 한반도 범위로 구역 정제 작업을 수행한다.",
            "rubric": [
                "L2; L4; Linear Interpolation; 격자형 자료 구조"
            ]
        },
        "short_answer": {
            "question": "GEMS 위성이미지 재격자화에 사용되는 방식은?",
            "answer": "Linear Interpolation",
            "topic": [
                "GEMS 위성이미지의 재격자화 방식"
            ]
        },
        "multiple_choice": {
            "question": "GEMS 위성이미지 정제 기준으로 잘못 설명된 것은?",
            "choices": [
                "a) 원자료로는 L2, L4가 있다.",
                "b) 재격자화된 위성이미지의 정제 범위에는 동북아시아와 한반도가 포함된다.",
                "c) 최종확정 측정자료를 조인한다.",
                "d) 공간범위 필터링, 재격자화 과정을 거친다."
            ],
            "answer": "c",
            "topic": [
                "GEMS 위성이미지 정제 기준"
            ]
        },
        "true_false": {
            "question": "대기오염측정망 데이터는 측정망 SHP 파일과 최종확정 측정자료 파일을 조인한다.",
            "answer": "TRUE",
            "topic": [
                "대기오염측정망 데이터의 정제 기준"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:mh: 00001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": true,
        "hops": 2,
        "context": [
            {
                "context_id": "1",
                "text": "○ 굴뚝탐지 - 굴뚝 하단부에 건물로 인하여 가려져 있는 경우, 보이는 부분만 구획 * 허용 오차는 픽셀 9개 (가로세로 3픽셀×3픽셀) 이내",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:mh: 00001",
                    "page": 14
                }
            },
            {
                "context_id": "2",
                "text": "○ 굴뚝높이 - 굴뚝 옆면을 기준으로 선(Line)으로 구획 후, 선의 길이 값을 구하여 입력 - 굴뚝 하단부에 건물로 인하여 가려져 있는 경우, 보이는 부분만 구획 * 허용 오차는 픽셀 9개 (가로세로 3픽셀×3픽셀) 이내 * 굴뚝높이 데이터는 굴뚝 옆면을 기준으로 선(Line)으로 구획 후, 위성에서의 촬영 각도와 영상에서의 굴뚝 길이를 계산하여 굴뚝의 높이 입력(JSON 파일)",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:14:mh: 00001",
                    "page": 15
                }
            }
        ],
        "summarization": "굴뚝탐지와 높이 데이터는 건물로 가려진 부분은 보이는 영역만 구획하며, 굴뚝높이는 옆면 기준 선으로 측정하고 허용 오차 범위 내에서 JSON 파일로 기록한다.",
        "long_answer": {
            "question": "굴뚝높이 구획 과정에 대해 서술하시오.",
            "answer": "굴뚝높이는 굴뚝 옆면을 기준으로 선 구획 후, 그 길이 값을 구하여 입력한다. 굴뚝 하단부가 건물로 가려질 경우에는 보이는 부분만 구획한다. 허용 오차는 픽셀 9개, 가로세로 3픽셀x3픽셀 이내이다. 굴뚝 옆면을 기준으로 위성 촬영 각도와 영상 굴뚝 길이를 계산한 후, 굴뚝 높이를 JSON으로 입력한다.",
            "rubric": [
                "굴뚝 옆면; 허용 오차; 위성 촬영 각도; 영상 굴뚝 길이; 굴뚝 높이; JSON"
            ]
        },
        "short_answer": {
            "question": "굴뚝높이의 허용 오차 범위는 가로와 세로가 각각 몇 픽셀인가?",
            "answer": "3픽셀, 3픽셀",
            "topic": [
                "굴뚝높이의 허용 오차 범위"
            ]
        },
        "multiple_choice": {
            "question": "굴뚝탐지 구획 수칙으로 틀린 것은?",
            "choices": [
                "a) 모든 굴뚝은 항상 전체 길이를 입력해야 한다.",
                "b) 하단부가 건물로 가려진 경우, 보이는 부분만 구획한다.",
                "c) 허용 오차는 가로세로 픽셀 3×3 이내이다.",
                "d) 허용 오차는 가로세로 픽셀 9개이다."
            ],
            "answer": "a",
            "topic": [
                "굴뚝탐지 구획 수칙"
            ]
        },
        "true_false": {
            "question": "굴뚝높이 구획 시, 하단부가 건물로 인하여 가려져 있으면 구획 대상에서 제외한다.",
            "answer": "FALSE",
            "topic": [
                "굴뚝높이 구획 수칙"
            ]
        }
    },
    {
        "schema_version": "1.0.0",
        "dataset_version": "2025-11-04",
        "qid": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:15:0001",
        "lang": "ko-KR",
        "category": [
            "도메인 응용"
        ],
        "subcategory": [],
        "created_at": "2025-11-04",
        "updated_at": "",
        "multi_hop": false,
        "hops": 1,
        "context": [
            {
                "context_id": "1",
                "text": "○ 산업단지 - 산업단지의 객체 내부를 구획 - 초지는 포함하지 않고 구획 * 최소분류 기준 : 픽셀 100개 (가로세로 10픽셀×10픽셀) 이상의 객체를 분류 (Sentinel-2) * 원천데이터를 기준으로 명확히 구분되는 객체를 대상으로 분류 학습데이터 단위(512×512)의 경계 부분은 최소분류 기준 적용 제외",
                "provenance": {
                    "doc_id": "(33-53) 24년 활용 가이드라인_대기오염 배출원 공간 분포 데이터_20250221.pdf:15:0001",
                    "page": 15
                }
            },
            {
                "context_id": "2",
                "text": "",
                "provenance": {
                    "doc_id": "",
                    "page": ""
                }
            }
        ],
        "summarization": "업단지 객체는 초지를 제외하고 구획하며, 최소 100픽셀 이상의 객체를 분류하고, 학습데이터 경계 부분은 최소분류 기준을 미적용한다.",
        "long_answer": {
            "question": "산업단지 내부 구획 방법에 대해 기술하시오.",
            "answer": "산업단지 구획 시, 객체 내부를 구획한다. 이때 초지는 포함하지 않는다. 최소분류 기준은 가로세로 10픽셀 즉, 픽셀 100개 이상의 객체이며, 원천데이터 기준 명확히 구분대는 객체만 대상으로 한다. 학습데이터 단위는 512x512로, 경계 부분은 최소분류 기준을 적용하지 않는다.",
            "rubric": [
                "객체 내부; 초지; 최소분류 기준; 학습데이터 단위"
            ]
        },
        "short_answer": {
            "question": "학습데이터 단위에서 최소분류 기준이 적용되지 않는 부분은?",
            "answer": "경계 부분",
            "topic": [
                "학습데이터 단위의 최소분류 기준"
            ]
        },
        "multiple_choice": {
            "question": "다음 중 산업단지 구획 기준으로 옳은 것은?",
            "choices": [
                "a) 최소 50픽셀 이상 구획",
                "b) 초지 제외",
                "c) 초지 포함",
                "d) 200픽셀 미만 객체 구획, 경계 부분 포함"
            ],
            "answer": "b",
            "topic": [
                "산업단지 구획 기준"
            ]
        },
        "true_false": {
            "question": "산업단지 구획은 Sentinel-2와 관련이 있다.",
            "answer": "TRUE",
            "topic": [
                "산업단지 구획 기준"
            ]
        }
    }
]